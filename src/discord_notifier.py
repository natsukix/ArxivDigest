"""
Discord Webhooké€šçŸ¥æ©Ÿèƒ½
"""
import requests
import json
from datetime import date


def split_message(text, max_length=2000):
    """
    Discordã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é•·åˆ¶é™(2000æ–‡å­—)ã«åˆã‚ã›ã¦ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ†å‰²
    """
    if len(text) <= max_length:
        return [text]
    
    chunks = []
    current_chunk = ""
    
    for line in text.split('\n'):
        if len(current_chunk) + len(line) + 1 > max_length:
            if current_chunk:
                chunks.append(current_chunk)
            current_chunk = line
        else:
            if current_chunk:
                current_chunk += '\n' + line
            else:
                current_chunk = line
    
    if current_chunk:
        chunks.append(current_chunk)
    
    return chunks


def html_to_discord_markdown(html_text):
    """
    HTMLã‚’Discordã®Markdownå½¢å¼ã«å¤‰æ›
    """
    # ç°¡æ˜“çš„ãªå¤‰æ›
    text = html_text.replace('<br>', '\n')
    text = text.replace('<br/>', '\n')
    text = text.replace('<br />', '\n')
    
    # ãƒªãƒ³ã‚¯ã®å¤‰æ›: <a href="url">text</a> -> [text](url)
    import re
    text = re.sub(r'<a href="([^"]+)">([^<]+)</a>', r'[\2](\1)', text)
    
    # ãã®ä»–ã®HTMLã‚¿ã‚°ã‚’å‰Šé™¤
    text = re.sub(r'<[^>]+>', '', text)
    
    return text


def format_papers_for_discord(papers_html, topic, categories, threshold, paper_count=None):
    """
    è«–æ–‡æƒ…å ±ã‚’Discordç”¨ã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
    """
    papers_text = html_to_discord_markdown(papers_html)
    papers_list = papers_text.split('\n\n')
    
    # ãƒ˜ãƒƒãƒ€ãƒ¼
    today = date.today().strftime('%Yå¹´%mæœˆ%dæ—¥')
    header = f"ğŸ“š **arXivè«–æ–‡ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆ - {today}**\n"
    header += f"ãƒˆãƒ”ãƒƒã‚¯: {topic}\n"
    if categories:
        header += f"ã‚«ãƒ†ã‚´ãƒª: {', '.join(categories)}\n"
    header += f"é–¢é€£æ€§ã‚¹ã‚³ã‚¢é–¾å€¤: {threshold}ä»¥ä¸Š\n"
    # paper_countãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚Œã°ãã‚Œã‚’ä½¿ç”¨ã€ãªã‘ã‚Œã°papers_listã®é•·ã•
    count = paper_count if paper_count is not None else len(papers_list)
    header += f"è©²å½“è«–æ–‡æ•°: {count}ä»¶\n"
    header += "â”€" * 40 + "\n\n"
    
    return header, papers_list


def send_to_discord(webhook_url, papers_html, topic, categories, threshold, papers_with_summary=None):
    """
    Discord Webhookã«è«–æ–‡æƒ…å ±ã‚’æŠ•ç¨¿
    
    Args:
        webhook_url: Discord Webhook URL
        papers_html: HTMLå½¢å¼ã®è«–æ–‡ãƒªã‚¹ãƒˆ
        topic: ãƒˆãƒ”ãƒƒã‚¯å
        categories: ã‚«ãƒ†ã‚´ãƒªãƒªã‚¹ãƒˆ
        threshold: é–¢é€£æ€§ã‚¹ã‚³ã‚¢é–¾å€¤
        papers_with_summary: è¦ç´„ä»˜ãè«–æ–‡ãƒªã‚¹ãƒˆï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    
    Returns:
        bool: æˆåŠŸã—ãŸå ´åˆTrue
    """
    if not webhook_url:
        print("Discord Webhook URLãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
        return False
    
    try:
        # å®Ÿéš›ã®è«–æ–‡æ•°ã‚’è¨ˆç®—ï¼ˆpapers_with_summaryãŒã‚ã‚‹å ´åˆã¯ãã‚Œã‚’ä½¿ç”¨ï¼‰
        actual_paper_count = len(papers_with_summary) if papers_with_summary else None
        header, papers_list = format_papers_for_discord(papers_html, topic, categories, threshold, paper_count=actual_paper_count)
        
        # ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’é€ä¿¡
        payload = {
            "content": header,
            "username": "ArxivDigest Bot"
        }
        response = requests.post(webhook_url, json=payload)
        
        if response.status_code not in [200, 204]:
            print(f"Discordã¸ã®æŠ•ç¨¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {response.status_code}")
            return False
        
        print(f"âœ“ Discordã«ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’æŠ•ç¨¿ã—ã¾ã—ãŸ")
        
        # è¦ç´„ä»˜ãè«–æ–‡ãŒã‚ã‚‹å ´åˆã¯å€‹åˆ¥æŠ•ç¨¿ï¼ˆã‚«ãƒ†ã‚´ãƒªæ¯ã«ä¸Šä½2ä»¶ï¼‰
        if papers_with_summary:
            import time
            from relevancy import process_subject_fields
            
            # ã‚«ãƒ†ã‚´ãƒªæ¯ã«è«–æ–‡ã‚’åˆ†é¡
            papers_by_category = {}
            for paper in papers_with_summary:
                processed_subjects = process_subject_fields(paper.get('subjects', ''))
                # æŒ‡å®šã‚«ãƒ†ã‚´ãƒªã«è©²å½“ã™ã‚‹ã‚‚ã®ã‚’åˆ†é¡
                matched_category = None
                for cat in categories:
                    if cat in processed_subjects:
                        matched_category = cat
                        break
                
                if matched_category:
                    if matched_category not in papers_by_category:
                        papers_by_category[matched_category] = []
                    papers_by_category[matched_category].append(paper)
            
            print(f"\n=== DiscordæŠ•ç¨¿: ã‚«ãƒ†ã‚´ãƒªæ¯ã«ä¸Šä½2ä»¶ ===")
            total_posted = 0
            max_per_category = 2
            
            for category, cat_papers in papers_by_category.items():
                # ä¸Šä½2ä»¶ã‚’æŠ•ç¨¿
                display_papers = cat_papers[:max_per_category]
                for idx, paper in enumerate(display_papers, 1):
                    title = paper.get('title', 'ã‚¿ã‚¤ãƒˆãƒ«ä¸æ˜')
                    authors = paper.get('authors', 'è‘—è€…ä¸æ˜')
                    
                    # ãƒªãƒ³ã‚¯ã‚’å–å¾—ï¼ˆè¤‡æ•°ã®å¯èƒ½æ€§ã‚’ãƒã‚§ãƒƒã‚¯ï¼‰
                    main_page = paper.get('main_page') or paper.get('link') or paper.get('url') or ''
                    
                    # PDFãƒªãƒ³ã‚¯ã«å¤‰æ›
                    if main_page and '/abs/' in main_page:
                        link = main_page.replace('/abs/', '/pdf/') + '.pdf'
                    elif main_page:
                        link = main_page
                    else:
                        link = 'ï¼ˆãƒªãƒ³ã‚¯æƒ…å ±ãªã—ï¼‰'
                    score = paper.get('Relevancy score', 'N/A')
                    reason_en = paper.get('Reasons for match', '')
                    reason_ja = paper.get('Reasons for match (ja)', '')
                    summary = paper.get('summary', {})
                    summary_en = summary.get('summary_en', '') if isinstance(summary, dict) else ''
                    summary_ja = summary.get('summary_ja', '') if isinstance(summary, dict) else ''
                    
                    # 1è«–æ–‡ã‚’1ã¤ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«ã¾ã¨ã‚ã‚‹ï¼ˆã‚«ãƒ†ã‚´ãƒªãƒ˜ãƒƒãƒ€ãƒ¼å«ã‚€ï¼‰
                    paper_content = f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
                    paper_content += f"**ğŸ“‚ ã‚«ãƒ†ã‚´ãƒª: {category}** ({len(cat_papers)}ä»¶ä¸­ {idx}/{min(len(cat_papers), max_per_category)}ä»¶ç›®)\n"
                    paper_content += f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\n"
                    paper_content += f"**ğŸ“š {title}**\n\n"
                    paper_content += f"**ğŸ‘¥ è‘—è€…:** {authors}\n"
                    paper_content += f"**â­ é–¢é€£æ€§ã‚¹ã‚³ã‚¢:** {score}/10\n\n"
                    
                    # æ—¥æœ¬èªã®ç†ç”±ãŒã‚ã‚Œã°ãã‚Œã‚’ä½¿ç”¨ã€ãªã‘ã‚Œã°è‹±èªç‰ˆ
                    if reason_ja:
                        paper_content += f"**ğŸ’¡ ãªãœé‡è¦ã‹:**\n{reason_ja}\n\n"
                    elif reason_en:
                        paper_content += f"**ğŸ’¡ Why Important:**\n{reason_en}\n\n"
                    
                    if summary_ja:
                        paper_content += f"**ğŸ“„ è¦ç´„ï¼ˆæ—¥æœ¬èªï¼‰:**\n{summary_ja}\n\n"
                    
                    if summary_en:
                        paper_content += f"**ğŸ“„ Summary (English):**\n{summary_en}\n\n"
                    
                    paper_content += f"**ğŸ”— ãƒªãƒ³ã‚¯:** {link}\n"
                    paper_content += "â”€" * 40
                    
                    # 2000æ–‡å­—åˆ¶é™ãƒã‚§ãƒƒã‚¯
                    if len(paper_content) > 1950:
                        paper_content = paper_content[:1950] + "\n\n... (è¦ç´„ãŒé•·ã™ãã‚‹ãŸã‚çœç•¥)"
                    
                    payload = {
                        "content": paper_content,
                        "username": "ArxivDigest Bot"
                    }
                    response = requests.post(webhook_url, json=payload)
                    
                    if response.status_code not in [200, 204]:
                        print(f"è«–æ–‡æŠ•ç¨¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {response.status_code}")
                        continue
                    
                    total_posted += 1
                    print(f"âœ“ {category}: è«–æ–‡ {idx}/{min(len(cat_papers), max_per_category)} ã‚’æŠ•ç¨¿")
                    
                    # Rate limitå¯¾ç­–
                    time.sleep(1.5)
            
            # ç·è¨ˆãƒ•ãƒƒã‚¿ãƒ¼
            total_papers = sum(len(papers) for papers in papers_by_category.values())
            footer_content = f"\nğŸ“Š **æŠ•ç¨¿å®Œäº†:** å…¨{total_posted}ä»¶ã®è«–æ–‡ã‚’æŠ•ç¨¿ã—ã¾ã—ãŸï¼ˆå…¨{total_papers}ä»¶ä¸­ï¼‰"
            footer_payload = {
                "content": footer_content,
                "username": "ArxivDigest Bot"
            }
            requests.post(webhook_url, json=footer_payload)
        else:
            # è¦ç´„ãªã—ã®å ´åˆã¯å¾“æ¥ã®ç°¡æ˜“å½¢å¼
            max_papers = 10
            display_papers = papers_list[:max_papers]
            
            if len(papers_list) > max_papers:
                footer = f"\n\n... ä»– {len(papers_list) - max_papers} ä»¶ã®è«–æ–‡ãŒã‚ã‚Šã¾ã™ï¼ˆdigest.htmlã‚’å‚ç…§ï¼‰"
            else:
                footer = ""
            
            papers_content = ""
            for idx, paper in enumerate(display_papers, 1):
                if paper.strip():
                    papers_content += f"\n**ã€{idx}ã€‘**\n{paper.strip()}\n"
            
            papers_content += footer
            
            if len(papers_content) > 1900:
                papers_content = papers_content[:1900] + "\n\n... (ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒé•·ã™ãã‚‹ãŸã‚çœç•¥)"
            
            payload = {
                "content": papers_content,
                "username": "ArxivDigest Bot"
            }
            response = requests.post(webhook_url, json=payload)
            
            if response.status_code not in [200, 204]:
                print(f"è«–æ–‡ãƒªã‚¹ãƒˆã®æŠ•ç¨¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {response.status_code}")
                return False
            
            print(f"âœ“ è«–æ–‡ãƒªã‚¹ãƒˆã‚’æŠ•ç¨¿ã—ã¾ã—ãŸ")
        
        total_count = len(papers_with_summary) if papers_with_summary else len(papers_list)
        display_count = min(total_count, 5 if papers_with_summary else 10)
        print(f"\nğŸ‰ DiscordæŠ•ç¨¿å®Œäº†ï¼ {display_count}ä»¶ã®è«–æ–‡ã‚’æŠ•ç¨¿ã—ã¾ã—ãŸï¼ˆå…¨{total_count}ä»¶ä¸­ï¼‰")
        return True
        
    except Exception as e:
        print(f"Discordã¸ã®æŠ•ç¨¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return False


def send_error_to_discord(webhook_url, error_message):
    """
    ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’Discordã«æŠ•ç¨¿
    """
    if not webhook_url:
        return False
    
    try:
        today = date.today().strftime('%Yå¹´%mæœˆ%dæ—¥')
        payload = {
            "content": f"âš ï¸ **ArxivDigest ã‚¨ãƒ©ãƒ¼ - {today}**\n```\n{error_message}\n```",
            "username": "ArxivDigest Bot"
        }
        response = requests.post(webhook_url, json=payload)
        return response.status_code in [200, 204]
    except Exception as e:
        print(f"ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®DiscordæŠ•ç¨¿ã«å¤±æ•—: {e}")
        return False
