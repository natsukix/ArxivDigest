{"main_page": "https://arxiv.org/abs/2510.17808", "pdf": "https://arxiv.org/pdf/2510.17808", "title": "Title:\n          Machine Learning-Based Performance Evaluation of a Solar-Powered Hydrogen Fuel Cell Hybrid in a Radio-Controlled Electric Vehicle", "authors": "Amirhesam Aghanouri, Mohamed Sabry, Joshua Cherian Varughese, Cristina Olaverri-Monreal", "subjects": "Signal Processing (eess.SP); Systems and Control (eess.SY)", "abstract": "This paper presents an experimental investigation and performance evaluation of a hybrid electric radio-controlled car powered by a Nickel-Metal Hydride battery combined with a renewable Proton Exchange Membrane Fuel Cell system. The study evaluates the performance of the system under various load-carrying scenarios and varying environmental conditions, simulating real-world operating conditions including throttle operation. In order to build a predictive model, gather operational insights, and detect anomalies, data-driven analyses using signal processing and modern machine learning techniques were employed. Specifically, machine learning techniques were used to distinguish throttle levels with high precision based on the operational data. Anomaly and change point detection methods enhanced voltage stability, resulting in fewer critical faults in the hybrid system compared to battery-only operation. Temporal Convolutional Networks were effectively employed to predict voltage behavior, demonstrating potential for use in planning the locations of fueling or charging stations. Moreover, integration with a solar-powered electrolyzer confirmed the system's potential for off-grid, renewable hydrogen use. The results indicate that integrating a Proton Exchange Membrane Fuel Cell with Nickel-Metal Hydride batteries significantly improves electrical performance and reliability for small electric vehicles, and these findings can be a potential baseline for scaling up to larger vehicles."}
{"main_page": "https://arxiv.org/abs/2510.17809", "pdf": "https://arxiv.org/pdf/2510.17809", "title": "Title:\n          In-Process Monitoring of Gear Power Honing Using Vibration Signal Analysis and Machine Learning", "authors": "Massimo Capurso, Luciano Afferrante", "subjects": "Signal Processing (eess.SP); Machine Learning (cs.LG)", "abstract": "In modern gear manufacturing, stringent Noise, Vibration, and Harshness (NVH) requirements demand high-precision finishing operations such as power honing. Conventional quality control strategies rely on post-process inspections and Statistical Process Control (SPC), which fail to capture transient machining anomalies and cannot ensure real-time defect detection. This study proposes a novel, data-driven framework for in-process monitoring of gear power honing using vibration signal analysis and machine learning. Our proposed methodology involves continuous data acquisition via accelerometers, followed by time-frequency signal analysis. We investigate and compare the efficacy of three subspace learning methods for features extraction: (1) Principal Component Analysis (PCA) for dimensionality reduction; (2) a two-stage framework combining PCA with Linear Discriminant Analysis (LDA) for enhanced class separation; and (3) Uncorrelated Multilinear Discriminant Analysis with Regularization (R-UMLDA), adapted for tensor data, which enforces feature decorrelation and includes regularization for small sample sizes. These extracted features are then fed into a Support Vector Machine (SVM) classifier to predict four distinct gear quality categories, established through rigorous geometrical inspections and test bench results of assembled gearboxes. The models are trained and validated on an experimental dataset collected in an industrial context during gear power-honing operations, with gears classified into four different quality categories. The proposed framework achieves high classification accuracy (up to 100%) in an industrial setting. The approach offers interpretable spectral features that correlate with process dynamics, enabling practical integration into real-time monitoring and predictive maintenance systems."}
{"main_page": "https://arxiv.org/abs/2510.17810", "pdf": "https://arxiv.org/pdf/2510.17810", "title": "Title:\n          Exploring Complexity Changes in Diseased ECG Signals for Enhanced Classification", "authors": "Camilo Quiceno Quintero, Sandip Varkey George", "subjects": "Signal Processing (eess.SP); Machine Learning (cs.LG); Chaotic Dynamics (nlin.CD); Data Analysis, Statistics and Probability (physics.data-an)", "abstract": "The complex dynamics of the heart are reflected in its electrical activity, captured through electrocardiograms (ECGs). In this study we use nonlinear time series analysis to understand how ECG complexity varies with cardiac pathology. Using the large PTB-XL dataset, we extracted nonlinear measures from lead II ECGs, and cross-channel metrics (leads II, V2, AVL) using Spearman correlations and mutual information. Significant differences between diseased and healthy individuals were found in almost all measures between healthy and diseased classes, and between 5 diagnostic superclasses ($p<.001$). Moreover, incorporating these complexity quantifiers into machine learning models substantially improved classification accuracy measured using area under the ROC curve (AUC) from 0.86 (baseline) to 0.87 (nonlinear measures) and 0.90 (including cross-time series metrics)."}
{"main_page": "https://arxiv.org/abs/2510.17811", "pdf": "https://arxiv.org/pdf/2510.17811", "title": "Title:\n          Channel Modeling of Satellite-to-Underwater Laser Communication Links: An Analytical-Monte Carlo Hybrid Approach", "authors": "Zhixing Wang, Renzhi Yuan, Haifeng Yao, Chuang Yang, Mugen Peng", "subjects": "Signal Processing (eess.SP); Atmospheric and Oceanic Physics (physics.ao-ph)", "abstract": "Channel modeling for satellite-to-underwater laser communication (StULC) links remains challenging due to long distances and the diversity of the channel constituents. The StULC channel is typically segmented into three isolated channels: the atmospheric channel, the air-water interface channel, and the underwater channel. Previous studies involving StULC channel modeling either focused on separated channels or neglected the combined effects of particles and turbulence on laser propagation. In this paper, we established a comprehensive StULC channel model by an analytical-Monte Carlo hybrid approach, taking into account the effects of both particles and turbulence. We first obtained the intensity distribution of the transmitted laser beam after passing through the turbulent atmosphere based on the extended Huygens-Fresnel principle. Then we derived a closed-form probability density function of the photon propagating direction after passing through the air-water interface, which greatly simplified the modeling of StULC links. At last, we employed a Monte Carlo method to model the underwater links and obtained the power distribution at the receiving plane. Based on the proposed StULC channel model, we analyzed the bit error rate and the outage probability under different environmental conditions. Numerical results demonstrated that, the influence of underwater particle concentration on the communication performance is much pronounced than those of both the atmospheric turbulence and the underwater turbulence. Notably, increasing the wind speed at the air-water interface does not significantly worsen the communication performance of the StULC links."}
{"main_page": "https://arxiv.org/abs/2510.17814", "pdf": "https://arxiv.org/pdf/2510.17814", "title": "Title:\n          LLM Assisted Alpha Fairness for 6 GHz WiFi and NR_U Coexistence: An Agentic Orchestrator for Throughput, Energy, and SLA", "authors": "Qun Wang, Yingzhou Lu, Guiran Liu, Binrong Zhu, Yang Liu", "subjects": "Systems and Control (eess.SY); Artificial Intelligence (cs.AI)", "abstract": "Unlicensed 6GHz is becoming a primary workhorse for high-capacity access, with Wi-Fi and 5G NR-U competing for the same channels under listen-before-talk (LBT) rules. Operating in this regime requires decisions that jointly trade throughput, energy, and service-level objectives while remaining safe and auditable. We present an agentic controller that separates {policy} from {execution}. At the start of each scheduling epoch the agent summarizes telemetry (per-channel busy and baseline LBT failure; per-user CQI, backlog, latency, battery, priority, and power mode) and invokes a large language model (LLM) to propose a small set of interpretable knobs: a fairness index \\alpha, per-channel duty-cycle caps for Wi-Fi/NR-U, and class weights. A deterministic optimizer then enforces feasibility and computes an \\alpha-fair allocation that internalizes LBT losses and energy cost; malformed or unsafe policies are clamped and fall back to a rule baseline. In a 6GHz simulator with two 160MHz channels and mixed Wi-Fi/NR-U users, LLM-assisted policies consistently improve energy efficiency while keeping throughput competitive with a strong rule baseline. One LLM lowers total energy by 35.3% at modest throughput loss, and another attains the best overall trade-off, finishing with higher total bits (+3.5%) and higher bits/J (+12.2%) than the baseline. We release code, per-epoch logs, and plotting utilities to reproduce all figures and numbers, illustrating how transparent, policy-level LLM guidance can safely improve wireless coexistence."}
{"main_page": "https://arxiv.org/abs/2510.17815", "pdf": "https://arxiv.org/pdf/2510.17815", "title": "Title:\n          Towards the True Switching-ON of Transistors", "authors": "Wucheng Ying, Jinwei Qi, Hui Zhao, Ameer Janabi, Hui Li, Biao Zhao, Teng Long", "subjects": "Systems and Control (eess.SY)", "abstract": "Transistors are core component across all domains of electrical and electronic engineering (EEE), such as data centers, electrified transportation, robotics, renewables and grid applications, etc. Transistors' switching behavior governs energy loss, carbon emissions, cooling demand, water use, lifetime, material use and cost etc. throughout EEE. Despite near a century since the transistor's invention, the understanding of transistor switching remains fragmented: switching is treated as a black box relying on observed waveforms, cannot be explained using physical laws alone, and is not integrated into circuit theory. This forms one of the most critical barriers to recognizing the true physical boundaries, prohibiting more sustainable solutions. For example, the conventional Eon prediction model, derived from the conventional switching analysis, exhibits significant prediction errors (ranging from 34.41% to 80.05%). Here we present a unified first-principles paradigm to explain the switching phenomena. Using this paradigm, we revealed the physical origins and mechanisms of switching-ON phenomena across scenarios, and derived the proposed Eon prediction model, with error ranging from 0.88% to 11.60%, achieving a 17-fold average improvement. These results demonstrate the unprecedented power of the proposed paradigm: textbook-level foundations are established, transforming the fundamental understanding of transistor switching from empirical to first-principles analysis, and simultaneously stimulating follow-up research and applications for sustainable development across disciplines."}
{"main_page": "https://arxiv.org/abs/2510.17816", "pdf": "https://arxiv.org/pdf/2510.17816", "title": "Title:\n          Cross-Domain Multi-Person Human Activity Recognition via Near-Field Wi-Fi Sensing", "authors": "Xin Li, Jingzhi Hu, Yinghui He, Hongbo Wang, Jin Gan, Jun Luo", "subjects": "Signal Processing (eess.SP); Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Wi-Fi-based human activity recognition (HAR) provides substantial convenience and has emerged as a thriving research field, yet the coarse spatial resolution inherent to Wi-Fi significantly hinders its ability to distinguish multiple subjects. By exploiting the near-field domination effect, establishing a dedicated sensing link for each subject through their personal Wi-Fi device offers a promising solution for multi-person HAR under native traffic. However, due to the subject-specific characteristics and irregular patterns of near-field signals, HAR neural network models require fine-tuning (FT) for cross-domain adaptation, which becomes particularly challenging with certain categories unavailable. In this paper, we propose WiAnchor, a novel training framework for efficient cross-domain adaptation in the presence of incomplete activity categories. This framework processes Wi-Fi signals embedded with irregular time information in three steps: during pre-training, we enlarge inter-class feature margins to enhance the separability of activities; in the FT stage, we innovate an anchor matching mechanism for cross-domain adaptation, filtering subject-specific interference informed by incomplete activity categories, rather than attempting to extract complete features from them; finally, the recognition of input samples is further improved based on their feature-level similarity with anchors. We construct a comprehensive dataset to thoroughly evaluate WiAnchor, achieving over 90% cross-domain accuracy with absent activity categories."}
{"main_page": "https://arxiv.org/abs/2510.17818", "pdf": "https://arxiv.org/pdf/2510.17818", "title": "Title:\n          Single-Snapshot Gridless 2D-DoA Estimation for UCAs: A Joint Optimization Approach", "authors": "Salar Nouri", "subjects": "Signal Processing (eess.SP); Information Theory (cs.IT); Machine Learning (cs.LG)", "abstract": "This paper tackles the challenging problem of gridless two-dimensional (2D) direction-of-arrival (DOA) estimation for a uniform circular array (UCA) from a single snapshot of data. Conventional gridless methods often fail in this scenario due to prohibitive computational costs or a lack of robustness. We propose a novel framework that overcomes these limitations by jointly estimating a manifold transformation matrix and the source azimuth-elevation pairs within a single, unified optimization problem. This problem is solved efficiently using an inexact Augmented Lagrangian Method (iALM), which completely circumvents the need for semidefinite programming. By unifying the objectives of data fidelity and transformation robustness, our approach is uniquely suited for the demanding single-snapshot case. Simulation results confirm that the proposed iALM framework provides robust and high-resolution, gridless 2D-DOA estimates, establishing its efficacy for challenging array signal processing applications."}
{"main_page": "https://arxiv.org/abs/2510.17821", "pdf": "https://arxiv.org/pdf/2510.17821", "title": "Title:\n          CLARAE: Clarity Preserving Reconstruction AutoEncoder for Denoising and Rhythm Classification of Intracardiac Electrograms", "authors": "Long Lin, Pablo Peiro-Corbacho, Pablo \u00c1vila, Alejandro Carta-Bergaz, \u00c1ngel Arenal, Gonzalo R. R\u00edos-Mu\u00f1oz, Carlos Sevilla-Salcedo", "subjects": "Signal Processing (eess.SP); Machine Learning (cs.LG)", "abstract": "Intracavitary atrial electrograms (EGMs) provide high-resolution insights into cardiac electrophysiology but are often contaminated by noise and remain high-dimensional, limiting real-time analysis. We introduce CLARAE (CLArity-preserving Reconstruction AutoEncoder), a one-dimensional encoder--decoder designed for atrial EGMs, which achieves both high-fidelity reconstruction and a compact 64-dimensional latent representation. CLARAE is designed to preserve waveform morphology, mitigate reconstruction artifacts, and produce interpretable embeddings through three principles: downsampling with pooling, a hybrid interpolation--convolution upsampling path, and a bounded latent space. We evaluated CLARAE on 495,731 EGM segments (unipolar and bipolar) from 29 patients across three rhythm types (AF, SR300, SR600). Performance was benchmarked against six state-of-the-art autoencoders using reconstruction metrics, rhythm classification, and robustness across signal-to-noise ratios from -5 to 15 dB. In downstream rhythm classification, CLARAE achieved F1-scores above 0.97 for all rhythm types, and its latent space showed clear clustering by rhythm. In denoising tasks, it consistently ranked among the top performers for both unipolar and bipolar signals. In order to promote reproducibility and enhance accessibility, we offer an interactive web-based application. This platform enables users to explore pre-trained CLARAE models, visualize the reconstructions, and compute metrics in real time. Overall, CLARAE combines robust denoising with compact, discriminative representations, offering a practical foundation for clinical workflows such as rhythm discrimination, signal quality assessment, and real-time mapping."}
{"main_page": "https://arxiv.org/abs/2510.17823", "pdf": "https://arxiv.org/pdf/2510.17823", "title": "Title:\n          Covariance Matrix Construction with Preprocessing-Based Spatial Sampling for Robust Adaptive Beamforming", "authors": "Saeed Mohammadzadeh, Rodrigo C.de Lamare, Yuriy Zakharov", "subjects": "Signal Processing (eess.SP); Information Theory (cs.IT); Machine Learning (cs.LG)", "abstract": "This work proposes an efficient, robust adaptive beamforming technique to deal with steering vector (SV) estimation mismatches and data covariance matrix reconstruction problems. In particular, the direction-of-arrival(DoA) of interfering sources is estimated with available snapshots in which the angular sectors of the interfering signals are computed adaptively. Then, we utilize the well-known general linear combination algorithm to reconstruct the interference-plus-noise covariance (IPNC) matrix using preprocessing-based spatial sampling (PPBSS). We demonstrate that the preprocessing matrix can be replaced by the sample covariance matrix (SCM) in the shrinkage method. A power spectrum sampling strategy is then devised based on a preprocessing matrix computed with the estimated angular sectors' information. Moreover, the covariance matrix for the signal is formed for the angular sector of the signal-of-interest (SOI), which allows for calculating an SV for the SOI using the power method. An analysis of the array beampattern in the proposed PPBSS technique is carried out, and a study of the computational cost of competing approaches is conducted. Simulation results show the proposed method's effectiveness compared to existing approaches."}
{"main_page": "https://arxiv.org/abs/2510.17825", "pdf": "https://arxiv.org/pdf/2510.17825", "title": "Title:\n          Carbon-Aware Orchestration of Integrated Satellite Aerial Terrestrial Networks via Digital Twin", "authors": "Shumaila Javaid, Nasir Saeed", "subjects": "Signal Processing (eess.SP); Artificial Intelligence (cs.AI); Systems and Control (eess.SY)", "abstract": "Integrated Satellite Aerial Terrestrial Networks (ISATNs) are envisioned as key enablers of 6G, providing global connectivity for applications such as autonomous transportation, Industrial IoT, and disaster response. Their large-scale deployment, however, risks unsustainable energy use and carbon emissions. This work advances prior energy-aware studies by proposing a carbon-aware orchestration framework for ISATNs that leverages Digital Twin (DT) technology. The framework adopts grams of CO$_2$-equivalent per bit (gCO$_2$/bit) as a primary sustainability metric and implements a multi timescale Plan Do Check Act (PDCA) loop that combines day-ahead forecasting with real-time adaptive optimization. ISATN-specific control knobs, including carbon-aware handovers, UAV duty cycling, and renewable-aware edge placement, are exploited to reduce emissions. Simulation results with real carbon intensity data show up to 29\\% lower gCO$_2$/bit than QoS-only orchestration, while improving renewable utilization and resilience under adverse events."}
{"main_page": "https://arxiv.org/abs/2510.17832", "pdf": "https://arxiv.org/pdf/2510.17832", "title": "Title:\n          Synthetic EEG Generation using Diffusion Models for Motor Imagery Tasks", "authors": "Henrique de Lima Alexandre, Clodoaldo Aparecido de Moraes Lima", "subjects": "Signal Processing (eess.SP); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "abstract": "Electroencephalography (EEG) is a widely used, non-invasive method for capturing brain activity, and is particularly relevant for applications in Brain-Computer Interfaces (BCI). However, collecting high-quality EEG data remains a major challenge due to sensor costs, acquisition time, and inter-subject variability. To address these limitations, this study proposes a methodology for generating synthetic EEG signals associated with motor imagery brain tasks using Diffusion Probabilistic Models (DDPM). The approach involves preprocessing real EEG data, training a diffusion model to reconstruct EEG channels from noise, and evaluating the quality of the generated signals through both signal-level and task-level metrics. For validation, we employed classifiers such as K-Nearest Neighbors (KNN), Convolutional Neural Networks (CNN), and U-Net to compare the performance of synthetic data against real data in classification tasks. The generated data achieved classification accuracies above 95%, with low mean squared error and high correlation with real signals. Our results demonstrate that synthetic EEG signals produced by diffusion models can effectively complement datasets, improving classification performance in EEG-based BCIs and addressing data scarcity."}
{"main_page": "https://arxiv.org/abs/2510.17836", "pdf": "https://arxiv.org/pdf/2510.17836", "title": "Title:\n          Two Phases Leakage Detection Strategy Supported by DMAs", "authors": "G. Messa, G. Acconciaioco, S. Ripani, L. Bozzelli, A. Simone, O. Giustolisi", "subjects": "Signal Processing (eess.SP); Systems and Control (eess.SY)", "abstract": "The present work proposes a novel two phases model-based strategy for leakage detection. The two phases are: the identification of the district metering area (DMA) and the pipe pre-localization into the identified DMA. The strategy is based on detecting and pre-localizing the punctual leakage as anomaly with respect to the normal working conditions. A further novelty is the fact that the pre-localization phase returns the sequence of pipes to inspect, which makes the strategy attractive for water utilities, whose aim is to identify the anomaly at DMA level and, successively, to localize it with the minimum inspection cost. Furthermore, a random database is useful to test the performance of the strategy with respect to the configuration of DMAs and the pressure metering system. Consequently, a novel strategy to design the location of pressure meters is also proposed. It is demonstrated that the entire strategy limits false positives during the DMA identification phase by using the recently proposed index named Asset Management Support Indicator (AMSI). AMSI is invariant with respect to the deterioration, i.e., it is sensitive to its increase causing punctual leakage. The strategy is studied and discussed using two real Apulian WDNs managed by Acquedotto Pugliese."}
{"main_page": "https://arxiv.org/abs/2510.17857", "pdf": "https://arxiv.org/pdf/2510.17857", "title": "Title:\n          Introducing Coherent-Control Koopman to Reservoir Scale Porous Media Flow Studies", "authors": "Dimitrios Voulanas, Eduardo Gildin", "subjects": "Systems and Control (eess.SY)", "abstract": "Accurate and robust surrogate modeling is essential for the real time control and optimization of large-scale subsurface systems, such as geological CO2 storage and waterflood management. This study investigates the limits of classical Dynamic Mode Decomposition with control (DMDc) in replicating pressure and water saturation dynamics under challenging prediction scenarios. We benchmark CCKM against DMDc and a Hybrid B-only surrogate that reuses DMDcs bottom B (same step feed through), showing that only CCKM remains stable and accurate under regime shifts. Two representative cases are considered: (i) an out of distribution shut in and restart case, and (ii) an in distribution bottom hole pressure (BHP) drawdown. Results show that only CCKM consistently maintains stability and accuracy across both scenarios, achieving sub bar mean absolute error and sub percent Frobenius norm percent change error even under regime shifts, while DMDc exhibit large unphysical errors during control transients. The findings demonstrate that strict control coherence is critical for reliable surrogate modeling, particularly in settings with abrupt changes in control strategy. The proposed framework is broadly applicable to real time reservoir optimization and can be integrated seamlessly into existing optimization and monitoring workflows, enabling fast and trustworthy decision support in the presence of both expected and unexpected actuation regimes."}
{"main_page": "https://arxiv.org/abs/2510.17859", "pdf": "https://arxiv.org/pdf/2510.17859", "title": "Title:\n          Mixed Monotonicity Reachability Analysis of Neural ODE: A Trade-Off Between Tightness and Efficiency", "authors": "Abdelrahman Sayed Sayed, Pierre-Jean Meyer, Mohamed Ghazel", "subjects": "Systems and Control (eess.SY); Machine Learning (cs.LG)", "abstract": "Neural ordinary differential equations (neural ODE) are powerful continuous-time machine learning models for depicting the behavior of complex dynamical systems, but their verification remains challenging due to limited reachability analysis tools adapted to them. We propose a novel interval-based reachability method that leverages continuous-time mixed monotonicity techniques for dynamical systems to compute an over-approximation for the neural ODE reachable sets. By exploiting the geometric structure of full initial sets and their boundaries via the homeomorphism property, our approach ensures efficient bound propagation. By embedding neural ODE dynamics into a mixed monotone system, our interval-based reachability approach, implemented in TIRA with single-step, incremental, and boundary-based approaches, provides sound and computationally efficient over-approximations compared with CORA's zonotopes and NNV2.0 star set representations, while trading tightness for efficiency. This trade-off makes our method particularly suited for high-dimensional, real-time, and safety-critical applications. Applying mixed monotonicity to neural ODE reachability analysis paves the way for lightweight formal analysis by leveraging the symmetric structure of monotone embeddings and the geometric simplicity of interval boxes, opening new avenues for scalable verification aligned with the symmetry and geometry of neural representations. This novel approach is illustrated on two numerical examples of a spiral system and a fixed-point attractor system modeled as a neural ODE."}
{"main_page": "https://arxiv.org/abs/2510.17860", "pdf": "https://arxiv.org/pdf/2510.17860", "title": "Title:\n          DMTrack: Deformable State-Space Modeling for UAV Multi-Object Tracking with Kalman Fusion and Uncertainty-Aware Association", "authors": "Zenghuang Fu, Xiaofeng Han, Mingda Jia, Jin ming Yang, Qi Zeng, Muyang Zahng, Changwei Wang, Weiliang Meng, Xiaopeng Zhang", "subjects": "Systems and Control (eess.SY); Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Multi-object tracking (MOT) from unmanned aerial vehicles (UAVs) presents unique challenges due to unpredictable object motion, frequent occlusions, and limited appearance cues inherent to aerial viewpoints. These issues are further exacerbated by abrupt UAV movements, leading to unreliable trajectory estimation and identity switches. Conventional motion models, such as Kalman filters or static sequence encoders, often fall short in capturing both linear and non-linear dynamics under such conditions. To tackle these limitations, we propose DMTrack, a deformable motion tracking framework tailored for UAV-based MOT. Our DMTrack introduces three key components: DeformMamba, a deformable state-space predictor that dynamically aggregates historical motion states for adaptive trajectory modeling; MotionGate, a lightweight gating module that fuses Kalman and Mamba predictions based on motion context and uncertainty; and an uncertainty-aware association strategy that enhances identity preservation by aligning motion trends with prediction confidence. Extensive experiments on the VisDrone-MOT and UAVDT benchmarks demonstrate that our DMTrack achieves state-of-the-art performance in identity consistency and tracking accuracy, particularly under high-speed and non-linear motion. Importantly, our method operates without appearance models and maintains competitive efficiency, highlighting its practicality for robust UAV-based tracking."}
{"main_page": "https://arxiv.org/abs/2510.17861", "pdf": "https://arxiv.org/pdf/2510.17861", "title": "Title:\n          Quantum-Driven State-Reduction for Reliable UAV Trajectory Optimization in Low-Altitude Networks", "authors": "Zeeshan Kaleem, Muhammad Afaq, Chau Yuen, Octavia A. Dobre, John M. Cioffi", "subjects": "Systems and Control (eess.SY)", "abstract": "This letter introduces a Graph-Condensed Quantum-Inspired Placement (GC-QAP) framework for reliability-driven trajectory optimization in Uncrewed Aerial Vehicle (UAV) assisted low-altitude wireless networks. The dense waypoint graph is condensed using probabilistic quantum-annealing to preserve interference-aware centroids while reducing the control state space and maintaining link-quality. The resulting problem is formulated as a priority-aware Markov decision process and solved using epsilon-greedy off-policy Q-learning, considering UAV kinematic and flight corridor constraints. Unlike complex continuous-action reinforcement learning approaches, GC-QAP achieves stable convergence and low outage with substantially and lower computational cost compared to baseline schemes."}
{"main_page": "https://arxiv.org/abs/2510.17870", "pdf": "https://arxiv.org/pdf/2510.17870", "title": "Title:\n          Epistemology-Inspired Bayesian Games for Distributed IoT Uplink Power Control", "authors": "Nirmal D. Wickramasinghe, John Dooley, Dirk Pesch, Indrakshi Dey", "subjects": "Systems and Control (eess.SY)", "abstract": "Massive number of simultaneous Internet of Things (IoT) uplinks strain gateways with interference and energy limits, yet devices often lack neighbors' Channel State Information (CSI) and cannot sustain centralized Mobile Edge Computing (MEC) or heavy Machine Learning (ML) coordination. Classical Bayesian solvers help with uncertainty but become intractable as users and strategies grow, making lightweight, distributed control essential. In this paper, we introduce the first-ever, novel epistemic Bayesian game for uplink power control under incomplete CSI that operates while suppressing interference among multiple uplink channels from distributed IoT devices firing at the same time. Nodes run inter-/intra-epistemic belief updates over opponents' strategies, replacing exhaustive expected-utility tables with conditional belief hierarchies. Using an exponential-Gamma SINR model and higher-order utility moments (variance, skewness, kurtosis), the scheme remains computationally lean with a single-round upper bound of $O\\!\\left(N^{2} S^{2N}\\right)$. Precise power control and stronger coverage amid realistic interference: with channel magnitude equal to $1$ and a signal-to-interference-plus-noise ratio (SINR) threshold of $-18$ dB, coverage reaches approximately $60\\%$ at approximately $55\\%$ of the maximum transmit power; mid-rate devices with a threshold of $-27$ dB achieve full coverage with less than $0.1\\%$ of the maximum transmit this http URL $80\\%$ interference, a fourth-moment policy cuts average power from approximately $52\\%$ to approximately $20\\%$ of the maximum transmit power with comparable outage, outperforming expectation-only baselines. These results highlight a principled, computationally lean path to optimal power allocation and higher network coverage under real-world uncertainty within dense, distributed IoT networks."}
{"main_page": "https://arxiv.org/abs/2510.17877", "pdf": "https://arxiv.org/pdf/2510.17877", "title": "Title:\n          DRL-Based Resource Allocation for Energy-Efficient IRS-Assisted UAV Spectrum Sharing Systems", "authors": "Yiheng Wang", "subjects": "Systems and Control (eess.SY); Artificial Intelligence (cs.AI); Information Theory (cs.IT)", "abstract": "Intelligent reflecting surface (IRS) assisted unmanned aerial vehicle (UAV) systems provide a new paradigm for reconfigurable and flexible wireless communications. To enable more energy efficient and spectrum efficient IRS assisted UAV wireless communications, this paper introduces a novel IRS-assisted UAV enabled spectrum sharing system with orthogonal frequency division multiplexing (OFDM). The goal is to maximize the energy efficiency (EE) of the secondary network by jointly optimizing the beamforming, subcarrier allocation, IRS phase shifts, and the UAV trajectory subject to practical transmit power and passive reflection constraints as well as UAV physical limitations. A physically grounded propulsion-energy model is adopted, with its tight upper bound used to form a tractable EE lower bound for the spectrum sharing system. To handle highly non convex, time coupled optimization problems with a mixed continuous and discrete policy space, we develop a deep reinforcement learning (DRL) approach based on the actor critic framework. Extended experiments show the significant EE improvement of the proposed DRL-based approach compared to several benchmark schemes, thus demonstrating the effectiveness and robustness of the proposed approach with mobility."}
{"main_page": "https://arxiv.org/abs/2510.17897", "pdf": "https://arxiv.org/pdf/2510.17897", "title": "Title:\n          Conformal Lesion Segmentation for 3D Medical Images", "authors": "Binyu Tan, Zhiyuan Wang, Jinhao Duan, Kaidi Xu, Heng Tao Shen, Xiaoshuang Shi, Fumin Shen", "subjects": "Image and Video Processing (eess.IV); Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Medical image segmentation serves as a critical component of precision medicine, enabling accurate localization and delineation of pathological regions, such as lesions. However, existing models empirically apply fixed thresholds (e.g., 0.5) to differentiate lesions from the background, offering no statistical guarantees on key metrics such as the false negative rate (FNR). This lack of principled risk control undermines their reliable deployment in high-stakes clinical applications, especially in challenging scenarios like 3D lesion segmentation (3D-LS). To address this issue, we propose a risk-constrained framework, termed Conformal Lesion Segmentation (CLS), that calibrates data-driven thresholds via conformalization to ensure the test-time FNR remains below a target tolerance $\\varepsilon$ under desired risk levels. CLS begins by holding out a calibration set to analyze the threshold setting for each sample under the FNR tolerance, drawing on the idea of conformal prediction. We define an FNR-specific loss function and identify the critical threshold at which each calibration data point just satisfies the target tolerance. Given a user-specified risk level $\\alpha$, we then determine the approximate $1-\\alpha$ quantile of all the critical thresholds in the calibration set as the test-time confidence threshold. By conformalizing such critical thresholds, CLS generalizes the statistical regularities observed in the calibration set to new test data, providing rigorous FNR constraint while yielding more precise and reliable segmentations. We validate the statistical soundness and predictive performance of CLS on six 3D-LS datasets across five backbone models, and conclude with actionable insights for deploying risk-aware segmentation in clinical practice."}
{"main_page": "https://arxiv.org/abs/2510.17945", "pdf": "https://arxiv.org/pdf/2510.17945", "title": "Title:\n          An Exact Quantile-Energy Equality for Terminal Halfspaces in Linear-Gaussian Control with a Discrete-Time Companion, KL/Schrodinger Links, and High-Precision Validation", "authors": "Sandro Andric", "subjects": "Systems and Control (eess.SY); Optimization and Control (math.OC)", "abstract": "We prove an exact equality between the minimal quadratic control energy and the squared normal-quantile gap for terminal halfspaces in linear-Gaussian systems with additive control and quadratic effort $E(u)=\\tfrac12\\!\\int u^\\top M u\\,dt$ where $M=B^\\top\\Sigma^{-1}B$. For terminal halfspace events, the minimal energy equals the squared normal-quantile gap divided by twice a controllability-to-noise ratio $R_T^2(w)=(w^\\topW_c^M w)/(w^\\top V_T w)$ and is attained by a matched-filter control. We provide an exact zero-order-hold discrete-time companion via block exponentials, relate the result to minimum-energy control, Gaussian isoperimetry, risk-sensitive/KL control, and Schrodinger bridges, and validate to high precision with Monte Carlo. We state assumptions, singular-$M$ handling, and edge cases. The statement is a compact synthesis and design-ready translator, not a universal principle. Novelty: while the ingredients (Gramians, Cauchy-Schwarz, Gaussian isoperimetry) are classical, to our knowledge the explicit quantile-energy equality with a constructive matched-filter achiever for terminal halfspaces, and its discrete-time companion, are not recorded together in the cited literature."}
{"main_page": "https://arxiv.org/abs/2510.18008", "pdf": "https://arxiv.org/pdf/2510.18008", "title": "Title:\n          Majority Vote Compressed Sensing", "authors": "Henrik Hellstr\u00f6m, Jiwon Jeong, Ayfer \u00d6zg\u00fcr, Viktoria Fodor, Carlo Fischione", "subjects": "Signal Processing (eess.SP)", "abstract": "We consider the problem of non-coherent over-the-air computation (AirComp), where $n$ devices carry high-dimensional data vectors $\\mathbf{x}_i\\in\\mathbb{R}^d$ of sparsity $\\lVert\\mathbf{x}_i\\rVert_0\\leq k$ whose sum has to be computed at a receiver. Previous results on non-coherent AirComp require more than $d$ channel uses to compute functions of $\\mathbf{x}_i$, where the extra redundancy is used to combat non-coherent signal aggregation. However, if the data vectors are sparse, sparsity can be exploited to offer significantly cheaper communication. In this paper, we propose to use random transforms to transmit lower-dimensional projections $\\mathbf{s}_i\\in\\mathbb{R}^T$ of the data vectors. These projected vectors are communicated to the receiver using a majority vote (MV)-AirComp scheme, which estimates the bit-vector corresponding to the signs of the aggregated projections, i.e., $\\mathbf{y} = \\text{sign}(\\sum_i\\mathbf{s}_i)$. By leveraging 1-bit compressed sensing (1bCS) at the receiver, the real-valued and high-dimensional aggregate $\\sum_i\\mathbf{x}_i$ can be recovered from $\\mathbf{y}$. We prove analytically that the proposed MVCS scheme estimates the aggregated data vector $\\sum_i \\mathbf{x}_i$ with $\\ell_2$-norm error $\\epsilon$ in $T=\\mathcal{O}(kn\\log(d)/\\epsilon^2)$ channel uses. Moreover, we specify algorithms that leverage MVCS for histogram estimation and distributed machine learning. Finally, we provide numerical evaluations that reveal the advantage of MVCS compared to the state-of-the-art."}
{"main_page": "https://arxiv.org/abs/2510.18169", "pdf": "https://arxiv.org/pdf/2510.18169", "title": "Title:\n          Hearing Health in Home Healthcare: Leveraging LLMs for Illness Scoring and ALMs for Vocal Biomarker Extraction", "authors": "Yu-Wen Chen, William Ho, Sasha M. Vergez, Grace Flaherty, Pallavi Gupta, Zhihong Zhang, Maryam Zolnoori, Margaret V. McDonald, Maxim Topaz, Zoran Kostic, Julia Hirschberg", "subjects": "Audio and Speech Processing (eess.AS); Sound (cs.SD)", "abstract": "The growing demand for home healthcare calls for tools that can support care delivery. In this study, we explore automatic health assessment from voice using real-world home care visit data, leveraging the diverse patient information it contains. First, we utilize Large Language Models (LLMs) to integrate Subjective, Objective, Assessment, and Plan (SOAP) notes derived from unstructured audio transcripts and structured vital signs into a holistic illness score that reflects a patient's overall health. This compact representation facilitates cross-visit health status comparisons and downstream analysis. Next, we design a multi-stage preprocessing pipeline to extract short speech segments from target speakers in home care recordings for acoustic analysis. We then employ an Audio Language Model (ALM) to produce plain-language descriptions of vocal biomarkers and examine their association with individuals' health status. Our experimental results benchmark both commercial and open-source LLMs in estimating illness scores, demonstrating their alignment with actual clinical outcomes, and revealing that SOAP notes are substantially more informative than vital signs. Building on the illness scores, we provide the first evidence that ALMs can identify health-related acoustic patterns from home care recordings and present them in a human-readable form. Together, these findings highlight the potential of LLMs and ALMs to harness heterogeneous in-home visit data for better patient monitoring and care."}
{"main_page": "https://arxiv.org/abs/2510.18190", "pdf": "https://arxiv.org/pdf/2510.18190", "title": "Title:\n          Joint Estimation of Piano Dynamics and Metrical Structure with a Multi-task Multi-Scale Network", "authors": "Zhanhong He, Hanyu Meng, David Huang, Roberto Togneri", "subjects": "Audio and Speech Processing (eess.AS); Machine Learning (cs.LG); Sound (cs.SD)", "abstract": "Estimating piano dynamic from audio recordings is a fundamental challenge in computational music analysis. In this paper, we propose an efficient multi-task network that jointly predicts dynamic levels, change points, beats, and downbeats from a shared latent representation. These four targets form the metrical structure of dynamics in the music score. Inspired by recent vocal dynamic research, we use a multi-scale network as the backbone, which takes Bark-scale specific loudness as the input feature. Compared to log-Mel as input, this reduces model size from 14.7 M to 0.5 M, enabling long sequential input. We use a 60-second audio length in audio segmentation, which doubled the length of beat tracking commonly used. Evaluated on the public MazurkaBL dataset, our model achieves state-of-the-art results across all tasks. This work sets a new benchmark for piano dynamic estimation and delivers a powerful and compact tool, paving the way for large-scale, resource-efficient analysis of musical expression."}
{"main_page": "https://arxiv.org/abs/2510.18206", "pdf": "https://arxiv.org/pdf/2510.18206", "title": "Title:\n          Adaptive Per-Channel Energy Normalization Front-end for Robust Audio Signal Processing", "authors": "Hanyu Meng, Vidhyasaharan Sethu, Eliathamby Ambikairajah, Qiquan Zhang, Haizhou Li", "subjects": "Audio and Speech Processing (eess.AS); Sound (cs.SD); Signal Processing (eess.SP)", "abstract": "In audio signal processing, learnable front-ends have shown strong performance across diverse tasks by optimizing task-specific representation. However, their parameters remain fixed once trained, lacking flexibility during inference and limiting robustness under dynamic complex acoustic environments. In this paper, we introduce a novel adaptive paradigm for audio front-ends that replaces static parameterization with a closed-loop neural controller. Specifically, we simplify the learnable front-end LEAF architecture and integrate a neural controller for adaptive representation via dynamically tuning Per-Channel Energy Normalization. The neural controller leverages both the current and the buffered past subband energies to enable input-dependent adaptation during inference. Experimental results on multiple audio classification tasks demonstrate that the proposed adaptive front-end consistently outperforms prior fixed and learnable front-ends under both clean and complex acoustic conditions. These results highlight neural adaptability as a promising direction for the next generation of audio front-ends."}
{"main_page": "https://arxiv.org/abs/2510.18235", "pdf": "https://arxiv.org/pdf/2510.18235", "title": "Title:\n          Urban Air Mobility: A Review of Recent Advances in Communication, Management, and Sustainability", "authors": "Zhitong He, Zijing Wang, Lingxi Li", "subjects": "Systems and Control (eess.SY)", "abstract": "Urban Air Mobility (UAM) offers a transformative approach to addressing urban congestion, improving accessibility, and advancing environmental sustainability. Rapid progress has emerged in three tightly linked domains since 2020: (1) Communication, where dynamic spectrum allocation and low-altitude channel characterization support reliable air-ground data exchange; (2) UAM management, with novel air-traffic control concepts for dense, largely autonomous urban airspace; and (3) Sustainability, driven by energy-efficient propulsion, integrated charging infrastructure, and holistic environmental assessment. This paper reviews and synthesizes the latest research across these areas, compares the state-of-the-art solutions, and outlines the technological and infrastructural milestones that are critical to realizing a scalable, sustainable UAM ecosystem."}
{"main_page": "https://arxiv.org/abs/2510.18273", "pdf": "https://arxiv.org/pdf/2510.18273", "title": "Title:\n          Distributed Allocation and Resource Scheduling Algorithms Resilient to Link Failure", "authors": "Mohammadreza Doostmohammadian, Sergio Pequito", "subjects": "Systems and Control (eess.SY); Distributed, Parallel, and Cluster Computing (cs.DC); Multiagent Systems (cs.MA); Signal Processing (eess.SP); Optimization and Control (math.OC)", "abstract": "Distributed resource allocation (DRA) is fundamental to modern networked systems, spanning applications from economic dispatch in smart grids to CPU scheduling in data centers. Conventional DRA approaches require reliable communication, yet real-world networks frequently suffer from link failures, packet drops, and communication delays due to environmental conditions, network congestion, and security threats. We introduce a novel resilient DRA algorithm that addresses these critical challenges, and our main contributions are as follows: (1) guaranteed constraint feasibility at all times, ensuring resource-demand balance even during algorithm termination or network disruption; (2) robust convergence despite sector-bound nonlinearities at nodes/links, accommodating practical constraints like quantization and saturation; and (3) optimal performance under merely uniformly-connected networks, eliminating the need for continuous connectivity. Unlike existing approaches that require persistent network connectivity and provide only asymptotic feasibility, our graph-theoretic solution leverages network percolation theory to maintain performance during intermittent disconnections. This makes it particularly valuable for mobile multi-agent systems where nodes frequently move out of communication range. Theoretical analysis and simulations demonstrate that our algorithm converges to optimal solutions despite heterogeneous time delays and substantial link failures, significantly advancing the reliability of distributed resource allocation in practical network environments."}
{"main_page": "https://arxiv.org/abs/2510.18336", "pdf": "https://arxiv.org/pdf/2510.18336", "title": "Title:\n          MCANet: A Coherent Multimodal Collaborative Attention Network for Advanced Modulation Recognition in Adverse Noisy Environments", "authors": "Wangye Jiang (1), Haoming Yang (2), Xinyu Lu (1), Mingyuan Wang (1), Huimei Sun (1), Jingya Zhang (1) ((1) Suzhou University of Technology, (2) Jinling Institute of Technology)", "subjects": "Signal Processing (eess.SP)", "abstract": "As wireless communication systems evolve, automatic modulation recognition (AMR) plays a key role in improving spectrum efficiency, especially in cognitive radio systems. Traditional AMR methods face challenges in complex, noisy environments, particularly in low signal-to-noise ratio (SNR) conditions. This paper introduces MCANet (Multimodal Collaborative Attention Network), a multimodal deep learning framework designed to address these challenges. MCANet employs refined feature extraction and global modeling to support its fusion this http URL results across multiple benchmark datasets show that MCANet outperforms mainstream AMR models, offering better robustness in low-SNR conditions."}
{"main_page": "https://arxiv.org/abs/2510.18391", "pdf": "https://arxiv.org/pdf/2510.18391", "title": "Title:\n          MVDR Beamforming for Cyclostationary Processes", "authors": "Giovanni Bologni, Martin Bo M\u00f8ller, Richard Heusdens, Richard C. Hendriks", "subjects": "Audio and Speech Processing (eess.AS); Sound (cs.SD)", "abstract": "Conventional acoustic beamformers assume that noise is stationary within short time frames. This assumption prevents them from exploiting correlations between frequencies in almost-periodic noise sources such as musical instruments, fans, and engines. These signals exhibit periodically varying statistics and are better modeled as cyclostationary processes. This paper introduces the cyclic MVDR (cMVDR) beamformer, an extension of the conventional MVDR that leverages both spatial and spectral correlations to improve noise reduction, particularly in low-SNR scenarios. The method builds on frequency-shifted (FRESH) filtering, where shifted versions of the input are combined to attenuate or amplify components that are coherent across frequency. To address inharmonicity, where harmonic partials deviate from exact integer multiples of the fundamental frequency, we propose a data-driven strategy that estimates resonant frequencies via periodogram analysis and computes the frequency shifts from their spacing. Analytical and experimental results demonstrate that performance improves with increasing spectral correlation. On real recordings, the cMVDR achieves up to 5 dB gain in scale-invariant signal-to-distortion ratio (SI-SDR) over the MVDR and remains effective even with a single microphone. Code is available at this https URL."}
{"main_page": "https://arxiv.org/abs/2510.18420", "pdf": "https://arxiv.org/pdf/2510.18420", "title": "Title:\n          Sliding-Mode Control Strategies for PMSM speed control: A Comprehensive Review, Taxonomy and Research Gaps", "authors": "Abdullah Ajasa, Mubarak Badamasi Aremu, Ali Nasir", "subjects": "Systems and Control (eess.SY)", "abstract": "Permanent Magnet Synchronous Motors (PMSMs) are widely employed in high-performance drive systems due to their high efficiency, power density, and precise dynamic behavior. However, nonlinearities, load disturbances, and parameter uncertainties present persistent challenges to control. Sliding-Mode Control (SMC) remains one of the most reliable strategies for high-performance PMSM drives. Yet, the rapid proliferation of adaptive, fractional-order, and intelligent variants has fragmented recent literature. This paper presents a comprehensive review and taxonomy of SMC-based PMSM speed-control methods published between 2020 and 2025. More than 200 studies are systematically analyzed and classified according to control order, surface design, disturbance-observer integration, optimization approach, and intelligent augmentation. Trends in publication activity, dominant hybrid structures, and application domains are quantitatively summarized. The review reveals a clear evolution from conventional discontinuous SMC toward adaptive, higher-order, and data-driven frameworks that mitigate chattering while preserving robustness. Persistent research gaps are identified in hardware validation, energy-efficiency assessment, and real-time tuning strategies. The taxonomy and critical synthesis provided herein establish a coherent reference for researchers and form the conceptual foundation for the companion paper (Part II), which delivers a unified benchmark and comparative simulation study of representative SMC designs."}
{"main_page": "https://arxiv.org/abs/2510.18422", "pdf": "https://arxiv.org/pdf/2510.18422", "title": "Title:\n          AWSPNet: Attention-based Dual-Tree Wavelet Scattering Prototypical Network for MIMO Radar Target Recognition and Jamming Suppression", "authors": "Yizhen Jia, Siyao Xiao, Wenkai Jia, Hui Chen, Wen-Qin Wang", "subjects": "Signal Processing (eess.SP)", "abstract": "The increasing of digital radio frequency memory based electronic countermeasures poses a significant threat to the survivability and effectiveness of radar systems. These jammers can generate a multitude of deceptive false targets, overwhelming the radar's processing capabilities and masking targets. Consequently, the ability to robustly discriminate between true targets and complex jamming signals, especially in low signal-to-noise ratio (SNR) environments, is of importance. This paper introduces the attention-based dual-tree wavelet scattering prototypical network (AWSPNet), a deep learning framework designed for simultaneous radar target recognition and jamming suppression. The core of AWSPNet is the encoder that leverages the dual-tree complex wavelet transform to extract features that are inherently robust to noise and signal translations. These features are further refined by an attention mechanism and a pre-trained backbone network. To address the challenge of limited labeled data and enhance generalization, we employ a supervised contrastive learning strategy during the training phase. The classification is performed by a prototypical network, which is particularly effective in few-shot learning scenarios, enabling rapid adaptation to new signal types. We demonstrate the efficacy of our approach through extensive experiments. The results show that AWSPNet achieves 90.45\\% accuracy at -6 dB SNR. Furthermore, we provide a physical interpretation of the network's inner workings through t-SNE visualizations, which analyze the feature separability at different stages of the model. Finally, by integrating AWSPNet with a time-domain sliding window approach, we present a complete algorithm capable of not only identifying but also effectively suppressing various types of jamming, thereby validating its potential for practical application in complex electromagnetic environments."}
{"main_page": "https://arxiv.org/abs/2510.18423", "pdf": "https://arxiv.org/pdf/2510.18423", "title": "Title:\n          ProLAP: Probabilistic Language-Audio Pre-Training", "authors": "Toranosuke Manabe, Yuchi Ishikawa, Hokuto Munakata, Tatsuya Komatsu", "subjects": "Audio and Speech Processing (eess.AS); Sound (cs.SD)", "abstract": "Language-audio joint representation learning frameworks typically depend on deterministic embeddings, assuming a one-to-one correspondence between audio and text. In real-world settings, however, the language-audio relationship is inherently many-to-many: one audio segment can be described by multiple captions and vice versa. To address this, we propose Probabilistic Language-Audio Pre-training (ProLAP), which models multiplicity as the spread of probability distributions in a joint language-audio embedding space. To train the intra-modal hierarchical relationship effectively, we also introduce two objectives: (i) hierarchical inclusion loss to promote semantic hierarchical understanding of inputs and (ii) mask repulsive loss to improve the efficiency of learning when optimizing the hierarchical inclusion loss. With this training strategy, our model can learn the hierarchical structure inherent in the data even from small datasets, in contrast to prior probabilistic approaches that rely on large-scale datasets. In our experiments, ProLAP outperforms existing deterministic approaches on audio-text retrieval tasks. Moreover, through experiments on the audio traversal task introduced in this paper, we demonstrate that ProLAP captures the plausible semantic hierarchy."}
{"main_page": "https://arxiv.org/abs/2510.18501", "pdf": "https://arxiv.org/pdf/2510.18501", "title": "Title:\n          Microsecond Federated SVD on Grassmann Manifold for Real-time IoT Intrusion Detection", "authors": "Tung-Anh Nguyen, Van-Phuc Bui, Shashi Raj Pandey, Kim Hue Ta, Nguyen H. Tran, Petar Popovski", "subjects": "Signal Processing (eess.SP)", "abstract": "This paper introduces FedSVD, a novel unsupervised federated learning framework for real-time anomaly detection in IoT networks. By leveraging Singular Value Decomposition (SVD) and optimization on the Grassmann manifolds, FedSVD enables accurate detection of both known and unknown intrusions without relying on labeled data or centralized data sharing. Tailored for deployment on low-power devices like the NVIDIA Jetson AGX Orin, the proposed method significantly reduces communication overhead and computational cost. Experimental results show that FedSVD achieves performance comparable to deep learning baselines while reducing inference latency by over 10x, making it suitable for latency-sensitive IoT applications."}
{"main_page": "https://arxiv.org/abs/2510.18604", "pdf": "https://arxiv.org/pdf/2510.18604", "title": "Title:\n          Channel-Aware Vector Quantization for Robust Semantic Communication on Discrete Channels", "authors": "Zian Meng, Qiang Li, Wenqian Tang, Mingdie Yan, Xiaohu Ge", "subjects": "Signal Processing (eess.SP); Machine Learning (cs.LG); Image and Video Processing (eess.IV)", "abstract": "Deep learning-based semantic communication has largely relied on analog or semi-digital transmission, which limits compatibility with modern digital communication infrastructures. Recent studies have employed vector quantization (VQ) to enable discrete semantic transmission, yet existing methods neglect channel state information during codebook optimization, leading to suboptimal robustness. To bridge this gap, we propose a channel-aware vector quantization (CAVQ) algorithm within a joint source-channel coding (JSCC) framework, termed VQJSCC, established on a discrete memoryless channel. In this framework, semantic features are discretized and directly mapped to modulation constellation symbols, while CAVQ integrates channel transition probabilities into the quantization process, aligning easily confused symbols with semantically similar codewords. A multi-codebook alignment mechanism is further introduced to handle mismatches between codebook order and modulation order by decomposing the transmission stream into multiple independently optimized subchannels. Experimental results demonstrate that VQJSCC effectively mitigates the digital cliff effect, achieves superior reconstruction quality across various modulation schemes, and outperforms state-of-the-art digital semantic communication baselines in both robustness and efficiency."}
{"main_page": "https://arxiv.org/abs/2510.18645", "pdf": "https://arxiv.org/pdf/2510.18645", "title": "Title:\n          Quantifying Security for Networked Control Systems: A Review", "authors": "Sribalaji C. Anand, Anh Tung Nguyen, Andr\u00e9 M.H. Teixeira, Henrik Sandberg, Karl H. Johansson", "subjects": "Systems and Control (eess.SY); Cryptography and Security (cs.CR)", "abstract": "Networked Control Systems (NCSs) are integral in critical infrastructures such as power grids, transportation networks, and production systems. Ensuring the resilient operation of these large-scale NCSs against cyber-attacks is crucial for societal well-being. Over the past two decades, extensive research has been focused on developing metrics to quantify the vulnerabilities of NCSs against attacks. Once the vulnerabilities are quantified, mitigation strategies can be employed to enhance system resilience. This article provides a comprehensive overview of methods developed for assessing NCS vulnerabilities and the corresponding mitigation strategies. Furthermore, we emphasize the importance of probabilistic risk metrics to model vulnerabilities under adversaries with imperfect process knowledge. The article concludes by outlining promising directions for future research."}
{"main_page": "https://arxiv.org/abs/2510.18646", "pdf": "https://arxiv.org/pdf/2510.18646", "title": "Title:\n          Delay Management Using Packet Fragmentation in Wireless Industrial Automation Systems", "authors": "Anwar Ahmed Khan, Shama Siddiqui, Indrakshi Dey", "subjects": "Signal Processing (eess.SP)", "abstract": "Managing delay is one of the core requirements of industrial automation applications due to the high risk associated for equipment and human lives. Using efficient Media Access Control (MAC) schemes guarantees the timely transmission of critical data, particularly in the industrial environments where heterogeneous data is inherently expected. This paper compares the performance of Fragmentation based MAC (FROG-MAC) against Fuzzy Priority Scheduling based MAC (FPS-MAC), both of which have been designed to optimize the performance of heterogenous wireless networks. Contiki has been used as a simulation platform and a single hop star topology has been assumed to resemble the industrial environment. It has been shown that FROG-MAC has the potential to outperform FPS-MAC in terms of energy efficiency and delay both, due to its inherent feature of interrupting ongoing lower priority transmission on the channel."}
{"main_page": "https://arxiv.org/abs/2510.18662", "pdf": "https://arxiv.org/pdf/2510.18662", "title": "Title:\n          A Comparative Analysis of High-Level vs. Low-Level Simulations for Dynamic MAC Protocols in Wireless Sensor Networks", "authors": "Shama Siddiqui, Anwar Ahmed Khan, Indrakshi Dey", "subjects": "Signal Processing (eess.SP)", "abstract": "Simulation studies are conducted at different levels of details for assessing the performance of Media Access Control (MAC) protocols in Wireless Sensor Networks (WSN). In the present-day scenario where hundreds of MAC protocols have been proposed, it is important to assess the quality of performance evaluation being conducted for each of the proposed protocols. It therefore becomes crucial to compare the results of high-level theoretical simulations with the detailed implementation results before any network protocol could be deployed for a real-world scenario. In this work, we present a comparison of high-level theoretical and detailed implementation results for Adaptive and Dynamic Polling-MAC (ADP-MAC). MATLAB has been used for conducting initial theoretical simulations and TinyOS has been used to develop the detailed implementation of protocol for Mica2 platform. Performance evaluation of ADP-MAC using the two levels of simulation has been conducted based on energy and delay. In the high-level implementation, energy consumption was found to be decreasing whereas delay was found to be increasing for increasing channel polling intervals. On the other hand, when detailed implementation was developed, it was observed that both energy consumption and delay revealed an increasing trend with the increasing polling intervals. Therefore, it has been shown that the trends for high- and low-level simulations for ADP-MAC are significantly different, due to the lack of realistic assumptions in the higher-level study."}
{"main_page": "https://arxiv.org/abs/2510.18729", "pdf": "https://arxiv.org/pdf/2510.18729", "title": "Title:\n          mSQUID: Model-Based Leanred Modulo Recovery at Low Sampling Rates", "authors": "Yhonatan Kvich, Rotem Arie, Hana Hasan, Shaik Basheeruddin Shah, Yonina C. Eldar", "subjects": "Signal Processing (eess.SP)", "abstract": "Modulo sampling enables acquisition of signals with unlimited dynamic range by folding the input into a bounded interval prior to sampling, thus eliminating the risk of signal clipping and preserving information without requiring highresolution ADCs. While this enables low-cost hardware, the nonlinear distortion introduced by folding presents recovery challenges, particularly under noise and quantization. We propose a model-based deep unfolding network tailored to this setting, combining the interpretability of classical compress sensing (CS) solvers with the flexibility of learning. A key innovation is a soft-quantization module that encodes the modulo prior by guiding the solution toward discrete multiples of the folding range in a differentiable and learnable way. Our method, modulo soft-quantized unfolded iterative decoder (mSQUID), achieves superior reconstruction performance at low sampling rates under additive Gaussian noise. We further demonstrate its utility in a challenging case where signals with vastly different amplitudes and disjoint frequency bands are acquired simultaneously and quantized. In this scenario, classical sampling often struggles due to weak signal distortion or strong signal clipping, while our approach is able to recover the input signals. Our method also offers significantly reduced runtimes, making it suitable for real-time, resource-limited systems."}
{"main_page": "https://arxiv.org/abs/2510.18738", "pdf": "https://arxiv.org/pdf/2510.18738", "title": "Title:\n          $\\ell_1$-Based Adaptive Identification under Quantized Observations with Applications", "authors": "Xin Zheng, Yifei Jin, Yujing Liu, Lei Guo", "subjects": "Systems and Control (eess.SY)", "abstract": "Quantized observations are ubiquitous in a wide range of applications across engineering and the social sciences, and algorithms based on the $\\ell_1$-norm are well recognized for their robustness to outliers compared with their $\\ell_2$-based counterparts. Nevertheless, adaptive identification methods that integrate quantized observations with $\\ell_1$-optimization remain largely underexplored. Motivated by this gap, we develop a novel $\\ell_1$-based adaptive identification algorithm specifically designed for quantized observations. Without relying on the traditional persistent excitation condition, we establish global convergence of the parameter estimates to their true values and show that the average regret asymptotically vanishes as the data size increases. Finally, we apply our new identification algorithm to a judicial sentencing problem using real-world data, which demonstrates its superior performance and practical significance."}
{"main_page": "https://arxiv.org/abs/2510.18743", "pdf": "https://arxiv.org/pdf/2510.18743", "title": "Title:\n          Wireless-Fed Pinching-Antenna Systems (Wi-PASS) for NextG Wireless Networks", "authors": "Kasun R. Wijewardhana, Animesh Yadav, Ming Zeng, Mohamed Elsayed, Octavia A. Dobre, Zhiguo Ding", "subjects": "Signal Processing (eess.SP)", "abstract": "Waveguide-based pinching-antenna systems (PASS) have recently emerged as a promising solution to mitigate severe propagation losses in millimeter-wave and terahertz bands by intelligently and flexibly establishing line-of-sight links. However, their reliance on wire-based feeding confines deployment to areas near the base station (BS), limiting installation flexibility and making them cost-ineffective for serving distant users or regions. To overcome this challenge, this article proposes wireless-fed pinchingantenna systems (Wi-PASS), which employ wireless feeding to energize waveguides. Wi-PASS offer a practical and cost-efficient means to extend coverage beyond the BS vicinity. Several indoor and outdoor use cases demonstrate Wi-PASS advantages over PASS. Numerical results further show that Wi-PASS deliver higher data rates than conventional fixed-antenna systems, confirming the superior feasibility and performance of Wi-PASS. Key future research directions are also discussed to advance Wi-PASS deployment."}
{"main_page": "https://arxiv.org/abs/2510.18744", "pdf": "https://arxiv.org/pdf/2510.18744", "title": "Title:\n          Diffusion Buffer for Online Generative Speech Enhancement", "authors": "Bunlong Lay, Rostislav Makarov, Simon Welker, Maris Hillemann, Timo Gerkmann", "subjects": "Audio and Speech Processing (eess.AS); Machine Learning (cs.LG); Sound (cs.SD)", "abstract": "Online Speech Enhancement was mainly reserved for predictive models. A key advantage of these models is that for an incoming signal frame from a stream of data, the model is called only once for enhancement. In contrast, generative Speech Enhancement models often require multiple calls, resulting in a computational complexity that is too high for many online speech enhancement applications. This work presents the Diffusion Buffer, a generative diffusion-based Speech Enhancement model which only requires one neural network call per incoming signal frame from a stream of data and performs enhancement in an online fashion on a consumer-grade GPU. The key idea of the Diffusion Buffer is to align physical time with Diffusion time-steps. The approach progressively denoises frames through physical time, where past frames have more noise removed. Consequently, an enhanced frame is output to the listener with a delay defined by the Diffusion Buffer, and the output frame has a corresponding look-ahead. In this work, we extend upon our previous work by carefully designing a 2D convolutional UNet architecture that specifically aligns with the Diffusion Buffer's look-ahead. We observe that the proposed UNet improves performance, particularly when the algorithmic latency is low. Moreover, we show that using a Data Prediction loss instead of Denoising Score Matching loss enables flexible control over the trade-off between algorithmic latency and quality during inference. The extended Diffusion Buffer equipped with a novel NN and loss function drastically reduces the algorithmic latency from 320 - 960 ms to 32 - 176 ms with an even increased performance. While it has been shown before that offline generative diffusion models outperform predictive approaches in unseen noisy speech data, we confirm that the online Diffusion Buffer also outperforms its predictive counterpart on unseen noisy speech data."}
{"main_page": "https://arxiv.org/abs/2510.18760", "pdf": "https://arxiv.org/pdf/2510.18760", "title": "Title:\n          Analyse comparative d'algorithmes de restauration en architecture d\u00e9pli\u00e9e pour des signaux chromatographiques parcimonieux", "authors": "Mouna Gharbi, Silvia Villa, Emilie Chouzenoux, Jean-Christophe Pesquet, Laurent Duval", "subjects": "Signal Processing (eess.SP); Machine Learning (cs.LG); Chemical Physics (physics.chem-ph)", "abstract": "Data restoration from degraded observations, of sparsity hypotheses, is an active field of study. Traditional iterative optimization methods are now complemented by deep learning techniques. The development of unfolded methods benefits from both families. We carry out a comparative study of three architectures on parameterized chromatographic signal databases, highlighting the performance of these approaches, especially when employing metrics adapted to physico-chemical peak signal characterization."}
{"main_page": "https://arxiv.org/abs/2510.18827", "pdf": "https://arxiv.org/pdf/2510.18827", "title": "Title:\n          SO(3)-invariant PCA with application to molecular data", "authors": "Michael Fraiman, Paulina Hoyos, Tamir Bendory, Joe Kileel, Oscar Mickelin, Nir Sharon, Amit Singer", "subjects": "Signal Processing (eess.SP); Machine Learning (cs.LG)", "abstract": "Principal component analysis (PCA) is a fundamental technique for dimensionality reduction and denoising; however, its application to three-dimensional data with arbitrary orientations -- common in structural biology -- presents significant challenges. A naive approach requires augmenting the dataset with many rotated copies of each sample, incurring prohibitive computational costs. In this paper, we extend PCA to 3D volumetric datasets with unknown orientations by developing an efficient and principled framework for SO(3)-invariant PCA that implicitly accounts for all rotations without explicit data augmentation. By exploiting underlying algebraic structure, we demonstrate that the computation involves only the square root of the total number of covariance entries, resulting in a substantial reduction in complexity. We validate the method on real-world molecular datasets, demonstrating its effectiveness and opening up new possibilities for large-scale, high-dimensional reconstruction problems."}
