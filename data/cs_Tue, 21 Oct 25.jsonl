{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          A Semantic Generalization of Shannon's Information Theory and Applications", "authors": "Chenguang Lu", "subjects": "Information Theory (cs.IT); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Probability (math.PR)", "abstract": "Does semantic communication require a semantic information theory parallel to Shannon's information theory, or can Shannon's work be generalized for semantic communication? This paper advocates for the latter and introduces a semantic generalization of Shannon's information theory (G theory for short). The core idea is to replace the distortion constraint with the semantic constraint, achieved by utilizing a set of truth functions as a semantic channel. These truth functions enable the expressions of semantic distortion, semantic information measures, and semantic information loss. Notably, the maximum semantic information criterion is equivalent to the maximum likelihood criterion and similar to the Regularized Least Squares criterion. This paper shows G theory's applications to daily and electronic semantic communication, machine learning, constraint control, Bayesian confirmation, portfolio theory, and information value. The improvements in machine learning methods involve multilabel learning and classification, maximum mutual information classification, mixture models, and solving latent variables. Furthermore, insights from statistical physics are discussed: Shannon information is similar to free energy; semantic information to free energy in local equilibrium systems; and information efficiency to the efficiency of free energy in performing work. The paper also proposes refining Friston's minimum free energy principle into the maximum information efficiency principle. Lastly, it compares G theory with other semantic information theories and discusses its limitation in representing the semantics of complex data."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Multimodal Chip Physical Design Engineer Assistant", "authors": "Yun-Da Tsai, Chang-Yu Chao, Liang-Yeh Shen, Tsung-Han Lin, Haoyu Yang, Mark Ho, Yi-Chen Lu, Wen-Hao Liu, Shou-De Lin, Haoxing Ren", "subjects": "Hardware Architecture (cs.AR); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "abstract": "Modern chip physical design relies heavily on Electronic Design Automation (EDA) tools, which often struggle to provide interpretable feedback or actionable guidance for improving routing congestion. In this work, we introduce a Multimodal Large Language Model Assistant (MLLMA) that bridges this gap by not only predicting congestion but also delivering human-interpretable design suggestions. Our method combines automated feature generation through MLLM-guided genetic prompting with an interpretable preference learning framework that models congestion-relevant tradeoffs across visual, tabular, and textual inputs. We compile these insights into a \"Design Suggestion Deck\" that surfaces the most influential layout features and proposes targeted optimizations. Experiments on the CircuitNet benchmark demonstrate that our approach outperforms existing models on both accuracy and explainability. Additionally, our design suggestion guidance case study and qualitative analyses confirm that the learned preferences align with real-world design principles and are actionable for engineers. This work highlights the potential of MLLMs as interactive assistants for interpretable and context-aware physical design optimization."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Two-Stage Sketch-Based Smoke Illustration Generation using Stream Function", "authors": "Hengyuan Chang, Xiaoxuan Xie, Syuhei Sato, Haoran Xie", "subjects": "Graphics (cs.GR)", "abstract": "In this paper, we propose a two-stage sketch-based smoke illustration generation framework using stream function and latent diffusion models (LDM). The user sketch is used to guide the generation of the stream function, which serves as the control condition for the velocity field generator. The generated velocity field can be used to guide the smoke simulation to align with the intended flow. We adopt streamlines to encode global flow dynamics as sketch guidance during training. The stream function constitutes the intermediate representation that captures continuous variation and rotational flow details absent from sketches."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Sketch-based Fluid Video Generation Using Motion-Guided Diffusion Models in Still Landscape Images", "authors": "Hao Jin, Haoran Xie", "subjects": "Graphics (cs.GR)", "abstract": "Integrating motion into static images not only enhances visual expressiveness but also creates a sense of immersion and temporal depth, establishing it as a longstanding and impactful theme in artistic expression. Fluid elements such as waterfall, river, and oceans are common features in landscape, but their complex dynamic characteristics pose significant challenges in modeling and controlling their motion within visual computing. Physics-based methods are often used in fluid animation to track particle movement. However, they are easily affected by boundary conditions. Recently, latent diffusion models have been applied to video generation tasks, demonstrating impressive capabilities in producing high-quality and temporally coherent results. However, it is challenging for the existing methods to animate fluid smooth and temporally consistent motion. To solve these issues, this paper introduces a framework for generating landscape videos by animating fluid in still images under the guidance of motion sketches. We propose a finetuned conditional latent diffusion model for generating motion field from user-provided sketches, which are subsequently integrated into a latent video diffusion model via a motion adapter to precisely control the fluid movement."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Adaptive Frameless Rendering", "authors": "Abhinav Dayal, Cliff Woolley, Benjamin Watson, David Luebke", "subjects": "Graphics (cs.GR)", "abstract": "We propose an adaptive form of frameless rendering with the potential to dramatically increase rendering speed over conventional interactive rendering approaches. Without the rigid sampling patterns of framed renderers, sampling and reconstruction can adapt with very fine granularity to spatio-temporal color change. A sampler uses closed-loop feedback to guide sampling toward edges or motion in the image. Temporally deep buffers store all the samples created over a short time interval for use in reconstruction and as sampler feedback. GPU-based reconstruction responds both to sampling density and space-time color gradients. Where the displayed scene is static, spatial color change dominates and older samples are given significant weight in reconstruction, resulting in sharper and eventually antialiased images. Where the scene is dynamic, more recent samples are emphasized, resulting in less sharp but more up-to-date images. We also use sample reprojection to improve reconstruction and guide sampling toward occlusion edges, undersampled regions, and specular highlights. In simulation our frameless renderer requires an order of magnitude fewer samples than traditional rendering of similar visual quality (as measured by RMS error), while introducing overhead amounting to 15% of computation time."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Procedural modeling of urban land use", "authors": "Thomas Lechner, Ben Watson, Uri Wilenski, Seth Tisue, Martin Felsen, Andy Moddrell, Pin Ren, Craig Brozefsky", "subjects": "Graphics (cs.GR); Computers and Society (cs.CY)", "abstract": "Cities are important elements of content in digital productions, but their complexity and size make them very challenging to model. Few tools exist that can help artists with this work, even as rapid improvements in graphics hardware create demand for richer content without matching increases in production cost. We propose a method for procedurally generating realistic patterns of land use in cities, automating placement of buildings and roads for artists."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Putting the Context back into Memory", "authors": "David A. Roberts", "subjects": "Hardware Architecture (cs.AR); Operating Systems (cs.OS); Performance (cs.PF)", "abstract": "Requests arriving at main memory are often different from what programmers can observe or estimate by using CPU-based monitoring. Hardware cache prefetching, memory request scheduling and interleaving cause a loss of observability that limits potential data movement and tiering optimizations. In response, memory-side telemetry hardware like page access heat map units (HMU) and page prefetchers were proposed to inform Operating Systems with accurate usage data. However, it is still hard to map memory activity to software program functions and objects because of the decoupled nature of host processors and memory devices. Valuable program context is stripped out from the memory bus, leaving only commands, addresses and data. Programmers have expert knowledge of future data accesses, priorities, and access to processor state, which could be useful hints for runtime memory device optimization. This paper makes context visible at memory devices by encoding any user-visible state as detectable packets in the memory read address stream, in a nondestructive manner without significant capacity overhead, drivers or special access privileges. We prototyped an end-to-end system with metadata injection that can be reliably detected and decoded from a memory address trace, either by a host processor, or a memory module. We illustrate a use case with precise code execution markers and object address range tracking. In the future, real time metadata decoding with near-memory computing (NMC) could provide customized telemetry and statistics to users, or act on application hints to perform functions like prioritizing requests, remapping data and reconfiguring devices."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Opportunities and Challenges for 3D Systems and Their Design", "authors": "Philip Emma, Eren Kurshan", "subjects": "Hardware Architecture (cs.AR); Emerging Technologies (cs.ET)", "abstract": "Although it is not a new concept, 3D integration increasingly receives widespread interest and focus as lithographic scaling becomes more challenging, and as the ability to make miniature vias greatly improves. Like Moores law, 3D integration improves density. With improvements in packaging density, however, come the challenges associated with its inherently higher power density. And though it acts somewhat as a scaling accelerator, the vertical integration also poses new challenges to design and manufacturing technologies. The placement of circuits, vias, and macros in the planes of a 3D stack must be co-designed across layers (or must conform to new standards) so that, when assembled, they have correct spatial correspondence. Each layer, although perhaps being a mere functional slice through a system (and we can slice the system in many different ways), must be independently testable so that we can systematically test and diagnose subsystems before and after final assembly. When those layers are assembled, they must come together in a way that enables a sensible yield and facilitates testing the finished product. To make the most of 3D integration, we should articulate the leverages of 3D systems (other researchers offer a more complete treatment elsewhere). Then we can enumerate and elucidate many of the new challenges posed by the design, assembly, and test of 3D systems."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          ParamRF: A JAX-native Framework for Declarative Circuit Modelling", "authors": "Gary V.C. Allen, Dirk I.L. de Villiers", "subjects": "Other Computer Science (cs.OH); Mathematical Software (cs.MS)", "abstract": "This work introduces ParamRF: a Python library for efficient, parametric modelling of radio frequency (RF) circuits. Built on top of the next-generation computational library JAX, as well as the object-oriented wrapper Equinox, the framework provides an easy-to-use, declarative modelling interface, without sacrificing performance. By representing circuits as JAX PyTrees and leveraging just-in-time compilation, models are compiled as pure functions into an optimized, algebraic graph. Since the resultant functions are JAX-native, this allows computation on CPUs, GPUs, or TPUs, providing integration with a wide range of solvers. Further, thanks to JAX's automatic differentiation, gradients with respect to both frequency and circuit parameters can be calculated for any circuit model outputs. This allows for more efficient optimization, as well as exciting new analysis opportunities. We showcase ParamRF's typical use-case of fitting a model to measured data via its built-in fitting engines, which include classical optimizers like L-BFGS and SLSQP, as well as modern Bayesian samplers such as PolyChord and BlackJAX. The result is a flexible framework for frequency-domain circuit modelling, fitting and analysis."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          FlexLink: Boosting your NVLink Bandwidth by 27% without accuracy concern", "authors": "Ao Shen, Rui Zhang, Junping Zhao", "subjects": "Hardware Architecture (cs.AR); Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)", "abstract": "As large language models (LLMs) continue to scale, multi-node deployment has become a necessity. Consequently, communication has become a critical performance bottleneck. Current intra-node communication libraries, like NCCL, typically make use of a single interconnect such as NVLink. This approach creates performance ceilings, especially on hardware like the H800 GPU where the primary interconnect's bandwidth can become a bottleneck, and leaves other hardware resources like PCIe and Remote Direct Memory Access (RDMA)-capable Network Interface Cards (NICs) largely idle during intensive workloads. We propose FlexLink, the first collective communication framework to the best of our knowledge designed to systematically address this by aggregating these heterogeneous links-NVLink, PCIe, and RDMA NICs-into a single, high-performance communication fabric. FlexLink employs an effective two-stage adaptive load balancing strategy that dynamically partitions communication traffic across all available links, ensuring that faster interconnects are not throttled by slower ones. On an 8-GPU H800 server, our design improves the bandwidth of collective operators such as AllReduce and AllGather by up to 26% and 27% over the NCCL baseline, respectively. This gain is achieved by offloading 2-22% of the total communication traffic to the previously underutilized PCIe and RDMA NICs. FlexLink provides these improvements as a lossless, drop-in replacement compatible with the NCCL API, ensuring easy adoption."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Generalized Methodology for Determining Numerical Features of Hardware Floating-Point Matrix Multipliers: Part I", "authors": "Faizan A Khattak, Mantas Mikaitis", "subjects": "Hardware Architecture (cs.AR); Mathematical Software (cs.MS)", "abstract": "Numerical features of matrix multiplier hardware units in NVIDIA and AMD data centre GPUs have recently been studied. Features such as rounding, normalisation, and internal precision of the accumulators are of interest. In this paper, we extend the methodology for analysing those features, to consumer-grade NVIDIA GPUs by implementing an architecture-independent test scheme for various input and output precision formats. Unlike current approaches, the proposed test vector generation method neither performs an exhaustive search nor relies on hard-coded {constants that are device-specific, yet remains applicable to a wide range of mixed-precision formats. We have applied the scheme to the RTX-3060 (Ampere architecture), and Ada RTX-1000 (Ada Lovelace architecture) graphics cards and determined numerical features of matrix multipliers for binary16, TensorFloat32, and bfloat16 input floating point formats and binary16 and binary32 IEEE 754 output formats. Our methodology allowed us to determine that} the numerical features of RTX-3060, a consumer-grade GPU, are identical to those of the A100, a data centre GPU. We do not expect our code to require any changes for performing analysis of matrix multipliers on newer NVIDIA GPUs, Hopper or Blackwell, and their future successors, and any input/output format combination, including the latest 8-bit floating-point formats."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          ConZone+: Practical Zoned Flash Storage Emulation for Consumer Devices", "authors": "Dingcui Yu, Zonghuan Yan, Jialin Liu, Yumiao Zhao, Yanyun Wang, Xinghui Duan, Yina Lv, Liang Shi", "subjects": "Hardware Architecture (cs.AR); Operating Systems (cs.OS)", "abstract": "To facilitate the understanding and efficient enhancement of software and hardware design for consumer-grade zoned flash storage, ConZone is proposed as the first emulator designed to model the resource constraints and architectural features typical of such systems. It incorporates essential components commonly deployed in consumer-grade devices, including limited logical to physical mapping caches, constrained write buffers, and hybrid flash media management. However, ConZone cannot be mounted with the file system due to the lack of in-place update capability, which is required by the metadata area of F2FS. To improve the usability of the emulator, ConZone+ extends ConZone with support for a block interface. We also provide a script to help the deployment and introduces several enhancements over the original version. Users can explore the internal architecture of consumer-grade zoned flash storage and integrate their optimizations with system software using ConZone+. We validate the accuracy of ConZone+ by comparing a hardware architecture representative of consumer-grade zoned flash storage and comparing it with the state-of-the-art. In addition, we conduct several case studies using ConZone+ to investigate the design of zoned storage and explore the inadequacies of the current file system."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Structural Tree Extraction from 3D Surfaces", "authors": "Diogo de Andrade, Nuno Fachada", "subjects": "Graphics (cs.GR); Computational Geometry (cs.CG); Human-Computer Interaction (cs.HC)", "abstract": "This paper introduces a method to extract a hierarchical tree representation from 3D unorganized polygonal data. The proposed approach first extracts a graph representation of the surface, which serves as the foundation for structural analysis. A Steiner tree is then generated to establish an optimized connection between key terminal points, defined according to application-specific criteria. The structure can be further refined by leveraging line-of-sight constraints, reducing redundancy while preserving essential connectivity. Unlike traditional skeletonization techniques, which often assume volumetric interpretations, this method operates directly on the surface, ensuring that the resulting representation remains relevant for navigation-aware geometric analysis. The method is validated through two use cases: extracting structural representations from tile-based elements for procedural content generation, and identifying key points and structural metrics for automated level analysis. Results demonstrate its ability to produce simplified, coherent representations, supporting applications in procedural generation, spatial reasoning, and map analysis."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          basic_RV32s: An Open-Source Microarchitectural Roadmap for RISC-V RV32I", "authors": "Hyun Woo Kang, Ji Woong Choi", "subjects": "Hardware Architecture (cs.AR)", "abstract": "This paper introduces BASIC_RV32s, an open-source framework providing a practical microarchitectural roadmap for the RISC-V RV32I architecture, addressing the gap between theoretical knowledge and hardware implementation. Following the classic Patterson and Hennessy methodology, the design evolves from a basic single-cycle core to a 5-stage pipelined core design with full hazard forwarding, dynamic branch prediction, and exception handling. For verification, the final core design is integrated into a System-on-Chip (SoC) with Universal Asynchronous Receiver-Transmitter (UART) communication implemented on a Xilinx Artix-7 Field-Programmable Gate Array (FPGA), achieving 1.09 Dhrystone million instructions per second per megahertz (DMIPS/MHz) at 50 MHz. By releasing all Register-Transfer Level (RTL) source code, signal-level logic block diagrams, and development logs under MIT license on GitHub, BASIC_RV32s offers a reproducible instructional pathway for the open-source hardware ecosystem."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Limited Read-Write/Set Hardware Transactional Memory without modifying the ISA or the Coherence Protocol", "authors": "Konstantinos Kafousis", "subjects": "Hardware Architecture (cs.AR)", "abstract": "Hardware Transactional Memory (HTM) allows lock-free programming as easy as with traditional coarse-grain locks or similar, while benefiting from the performance advantages of fine-grained locking. Many HTM implementations have been proposed, but they have not received widespread adoption because of their high hardware complexity, their need for additions to the Instruction Set Architecture (ISA), and often for modifications to the cache coherence protocol. We show that HTM can be implemented without adding new instructions -- merely by extending the semantics of two existing, Load-Linked and Store-Conditional. Also, our proposed design does not modify or extend standard coherence protocols. We further propose to drastically simplify the implementation of HTM -- confined to modifications in the L1 Data Cache only -- by restricting it to applications where the write set plus the read set of each transaction do not exceed a small number of cache lines. We also propose two alternative mechanisms to guarantee forward progress, both based on detecting retrial attempts. We simulated our proposed design in Gem5, and we used it to implement several popular concurrent data structures, showing that a maximum of eight (8) words (cache lines) suffice for the write plus read sets. We provide a detailed explanation of selected implementations, clarifying the intended usage of our HTM from a programmer's perspective. We evaluated our HTM under varying contention levels to explore its scalability limits. The results indicate that our HTM provides good performance in concurrent data structures when contention is spread across multiple nodes: in such cases, the percentage of aborts relative to successful commits is very low. In the atomic fetch-and-increment benchmark for multiple shared counters, the results show that, under low-congestion, our HTM improves performance relative to the TTS lock."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Mitigating Harmful Erraticism in LLMs Through Dialectical Behavior Therapy Based De-Escalation Strategies", "authors": "Pooja Rangarajan, Jacob Boyle", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "abstract": "The escalating demand for personalized AI chatbot interactions, capable of dynamically adapting to user emotional states and real-time requests, has highlighted critical limitations in current development paradigms. Existing methodologies, which rely on baseline programming, custom personalities, and manual response adjustments, often prove difficult to maintain and are susceptible to errors such as hallucinations, erratic outputs, and software bugs. This paper hypothesizes that a framework rooted in human psychological principles, specifically therapeutic modalities, can provide a more robust and sustainable solution than purely technical interventions. Drawing an analogy to the simulated neural networks of AI mirroring the human brain, we propose the application of Dialectical Behavior Therapy (DBT) principles to regulate chatbot responses to diverse user inputs. This research investigates the impact of a DBT-based framework on AI chatbot performance, aiming to ascertain its efficacy in yielding more reliable, safe, and accurate responses, while mitigating the occurrence of hallucinations, erratic behaviors, and other systemic issues."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          A Real-Time BCI for Stroke Hand Rehabilitation Using Latent EEG Features from Healthy Subjects", "authors": "F.M. Omar, A.M. Omar, K.H. Eyada, M. Rabie, M.A. Kamel, A.M. Azab", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI); Signal Processing (eess.SP)", "abstract": "This study presents a real-time, portable brain-computer interface (BCI) system designed to support hand rehabilitation for stroke patients. The system combines a low cost 3D-printed robotic exoskeleton with an embedded controller that converts brain signals into physical hand movements. EEG signals are recorded using a 14-channel Emotiv EPOC+ headset and processed through a supervised convolutional autoencoder (CAE) to extract meaningful latent features from single-trial data. The model is trained on publicly available EEG data from healthy individuals (WAY-EEG-GAL dataset), with electrode mapping adapted to match the Emotiv headset layout. Among several tested classifiers, Ada Boost achieved the highest accuracy (89.3%) and F1-score (0.89) in offline evaluations. The system was also tested in real time on five healthy subjects, achieving classification accuracies between 60% and 86%. The complete pipeline - EEG acquisition, signal processing, classification, and robotic control - is deployed on an NVIDIA Jetson Nano platform with a real-time graphical interface. These results demonstrate the system's potential as a low-cost, standalone solution for home-based neurorehabilitation."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Detecting and Preventing Harmful Behaviors in AI Companions: Development and Evaluation of the SHIELD Supervisory System", "authors": "Ziv Ben-Zion, Paul Raffelh\u00fcschen, Max Zettl, Antonia L\u00fc\u00f6nd, Achim Burrer, Philipp Homan, Tobias R Spiller", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)", "abstract": "AI companions powered by large language models (LLMs) are increasingly integrated into users' daily lives, offering emotional support and companionship. While existing safety systems focus on overt harms, they rarely address early-stage problematic behaviors that can foster unhealthy emotional dynamics, including over-attachment or reinforcement of social isolation. We developed SHIELD (Supervisory Helper for Identifying Emotional Limits and Dynamics), a LLM-based supervisory system with a specific system prompt that detects and mitigates risky emotional patterns before escalation. SHIELD targets five dimensions of concern: (1) emotional over-attachment, (2) consent and boundary violations, (3) ethical roleplay violations, (4) manipulative engagement, and (5) social isolation reinforcement. These dimensions were defined based on media reports, academic literature, existing AI risk frameworks, and clinical expertise in unhealthy relationship dynamics. To evaluate SHIELD, we created a 100-item synthetic conversation benchmark covering all five dimensions of concern. Testing across five prominent LLMs (GPT-4.1, Claude Sonnet 4, Gemma 3 1B, Kimi K2, Llama Scout 4 17B) showed that the baseline rate of concerning content (10-16%) was significantly reduced with SHIELD (to 3-8%), a 50-79% relative reduction, while preserving 95% of appropriate interactions. The system achieved 59% sensitivity and 95% specificity, with adaptable performance via prompt engineering. This proof-of-concept demonstrates that transparent, deployable supervisory systems can address subtle emotional manipulation in AI companions. Most development materials including prompts, code, and evaluation methods are made available as open source materials for research, adaptation, and deployment."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Accelerating Frontier MoE Training with 3D Integrated Optics", "authors": "Mikhail Bernadskiy, Peter Carson, Thomas Graham, Taylor Groves, Ho John Lee, Eric Yeh", "subjects": "Hardware Architecture (cs.AR); Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)", "abstract": "The unabated growth in AI workload demands is driving the need for concerted advances in compute, memory, and interconnect performance. As traditional semiconductor scaling slows, high-speed interconnects have emerged as the new scaling engine, enabling the creation of larger logical GPUs by linking many GPUs into a single, low-latency, high-bandwidth compute domain. While initial scale-up fabrics leveraged copper interconnects for their power and cost advantages, the maximum reach of passive electrical interconnects (approximately 1 meter) effectively limits the scale-up domain to within a single rack. The advent of 3D-stacked optics and logic offers a transformative, power-efficient scale-up solution for connecting hundreds of GPU packages (thousands of GPUs) across multiple data center racks. This work explores the design tradeoffs of scale-up technologies and demonstrates how frontier LLMs necessitate novel photonic solutions to achieve aggressive power and performance targets. We model the benefits of 3D CPO (Passage) enabled GPUs and switches within the scale-up domain when training Frontier Mixture of Experts (MoE) models exceeding one trillion parameters. Our results show that the substantial increases in bandwidth and radix enabled by 3D CPO allow for an 8X increase in scale-up capability. This affords new opportunities for multi-dimensional parallelism within the scale-up domain and results in a 2.7X reduction in time-to-train, unlocking unprecedented model scaling."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Virtual Social Immersive Multi-Sensory E-Commerce", "authors": "Alpana Dubey, Suma Mani Kuriakose, Sumukha Anand, Nitish Bhardwaj, Shubhashis Sengupta", "subjects": "Human-Computer Interaction (cs.HC); Multimedia (cs.MM)", "abstract": "In this paper, we present a virtual immersive multi sensorial experience, Aromaverse. Aromaverse is an immersive 3D multiplayer environment augmented with olfactive experience where users can experience and customize perfumes. Being multi player, users can join the same space and enjoy a social buying experience. The olfactive experience embodied in the perfume allows users to experience their fragrances. This further enhances the user perception of perfumes in a virtual setting. Aromaverse also provides the ability to customize the perfumes by changing their top, mid, and base notes. The customized fragrances can be shared with other users, enabling a shared olfactive experience. To understand users' buying experience in such an environment, we conducted a set of experiments in which participants were requested to explore the space, experience the perfumes, customize them and buy them. They were asked to perform the same activities alone and in the presence of their friends. Various factors including the benefits and limitations of such an experience were captured by the questionnaires. Our results show that the presence of a companion enhances the shopping experience by improving the level of imagination of the product and helping in making purchase decisions. Our findings suggest that multi sensorial XR experiences offer great opportunities to retail firms to improve customer engagement and provide more realistic online experience of products that require other sensory modalities"}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          BREATH: A Bio-Radar Embodied Agent for Tonal and Human-Aware Diffusion Music Generation", "authors": "Yunzhe Wang, Xinyu Tang, Zhixun Huang, Xiaolong Yue, Yuxin Zeng", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI); Sound (cs.SD)", "abstract": "We present a multimodal system for personalized music generation that integrates physiological sensing, LLM-based reasoning, and controllable audio synthesis. A millimeter-wave radar sensor non-invasively captures heart rate and respiration rate. These physiological signals, combined with environmental state, are interpreted by a reasoning agent to infer symbolic musical descriptors, such as tempo, mood intensity, and traditional Chinese pentatonic modes, which are then expressed as structured prompts to guide a diffusion-based audio model in synthesizing expressive melodies. The system emphasizes cultural grounding through tonal embeddings and enables adaptive, embodied music interaction. To evaluate the system, we adopt a research-creation methodology combining case studies, expert feedback, and targeted control experiments. Results show that physiological variations can modulate musical features in meaningful ways, and tonal conditioning enhances alignment with intended modal characteristics. Expert users reported that the system affords intuitive, culturally resonant musical responses and highlighted its potential for therapeutic and interactive applications. This work demonstrates a novel bio-musical feedback loop linking radar-based sensing, prompt reasoning, and generative audio modeling."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          From Coordination to Personalization: A Trust-Aware Simulation Framework for Emergency Department Decision Support", "authors": "Zoi Lygizou, Dimitris Kalles", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI); Computers and Society (cs.CY)", "abstract": "Background/Objectives: Efficient task allocation in hospital emergency departments (EDs) is critical for operational efficiency and patient care quality, yet the complexity of staff coordination poses significant challenges. This study proposes a simulation-based framework for modeling doctors and nurses as intelligent agents guided by computational trust mechanisms. The objective is to explore how trust-informed coordination can support decision making in ED management. Methods: The framework was implemented in Unity, a 3D graphics platform, where agents assess their competence before undertaking tasks and adaptively coordinate with colleagues. The simulation environment enables real-time observation of workflow dynamics, resource utilization, and patient outcomes. We examined three scenarios - Baseline, Replacement, and Training - reflecting alternative staff management strategies. Results: Trust-informed task allocation balanced patient safety and efficiency by adapting to nurse performance levels. In the Baseline scenario, prioritizing safety reduced errors but increased patient delays compared to a FIFO policy. The Replacement scenario improved throughput and reduced delays, though at additional staffing cost. The training scenario forstered long-term skill development among low-performing nurses, despite short-term delays and risks. These results highlight the trade-off between immediate efficiency gains and sustainable capacity building in ED staffing. Conclusions: The proposed framework demonstrates the potential of computational trust for evidence-based decision support in emergency medicine. By linking staff coordination with adaptive decision making, it provides hospital managers with a tool to evaluate alternative policies under controlled and repeatable conditions, while also laying a foundation for future AI-driven personalized decision support."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          DiffPlace: A Conditional Diffusion Framework for Simultaneous VLSI Placement Beyond Sequential Paradigms", "authors": "Kien Le Trung, Truong-Son Hy", "subjects": "Hardware Architecture (cs.AR)", "abstract": "Chip placement, the task of determining optimal positions of circuit modules on a chip canvas, is a critical step in the VLSI design flow that directly impacts performance, power consumption, and routability. Traditional methods rely on analytical optimization or reinforcement learning, which struggle with hard placement constraints or require expensive online training for each new circuit design. To address these limitations, we introduce DiffPlace, a framework that formulates chip placement as a conditional denoising diffusion process, enabling transferable placement policies that generalize to unseen circuit netlists without retraining. DiffPlace leverages the generative capabilities of diffusion models to efficiently explore the vast space of placement while conditioning on circuit connectivity and relative quality metrics to identify optimal solutions globally. Our approach combines energy-guided sampling with constrained manifold diffusion to ensure placement legality, achieving extremely low overlap across all experimental scenarios. Our method bridges the gap between optimization-based and learning-based approaches, offering a practical path toward automated, high-quality chip placement for modern VLSI design. Our source code is publicly available at: this https URL"}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          HealthDial: A No-Code LLM-Assisted Dialogue Authoring Tool for Healthcare Virtual Agents", "authors": "Farnaz Nouraei, Zhuorui Yong, Timothy Bickmore", "subjects": "Human-Computer Interaction (cs.HC); Computation and Language (cs.CL); Computers and Society (cs.CY)", "abstract": "We introduce HealthDial, a dialogue authoring tool that helps healthcare providers and educators create virtual agents that deliver health education and counseling to patients over multiple conversations. HealthDial leverages large language models (LLMs) to automatically create an initial session-based plan and conversations for each session using text-based patient health education materials as input. Authored dialogue is output in the form of finite state machines for virtual agent delivery so that all content can be validated and no unsafe advice is provided resulting from LLM hallucinations. LLM-drafted dialogue structure and language can be edited by the author in a no-code user interface to ensure validity and optimize clarity and impact. We conducted a feasibility and usability study with counselors and students to test our approach with an authoring task for cancer screening education. Participants used HealthDial and then tested their resulting dialogue by interacting with a 3D-animated virtual agent delivering the dialogue. Through participants' evaluations of the task experience and final dialogues, we show that HealthDial provides a promising first step for counselors to ensure full coverage of their health education materials, while creating understandable and actionable virtual agent dialogue with patients."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          LLM-VeriPPA: Power, Performance, and Area Optimization aware Verilog Code Generation with Large Language Models", "authors": "Kiran Thorat, Jiahui Zhao, Yaotian Liu, Amit Hasan, Hongwu Peng, Xi Xie, Bin Lei, Caiwen Ding", "subjects": "Hardware Architecture (cs.AR); Machine Learning (cs.LG)", "abstract": "Large Language Models (LLMs) are gaining prominence in various fields, thanks to their ability to generate high- quality content from human instructions. This paper delves into the field of chip design using LLMs, specifically in Power- Performance-Area (PPA) optimization and the generation of accurate Verilog codes for circuit designs. We introduce a novel framework VeriPPA designed to optimize PPA and generate Verilog code using LLMs. Our method includes a two-stage process where the first stage focuses on improving the functional and syntactic correctness of the generated Verilog codes, while the second stage focuses on optimizing the Verilog codes to meet PPA constraints of circuit designs, a crucial element of chip design. Our framework achieves an 81.37% success rate in syntactic correctness and 62.06% in functional correctness for code genera- tion, outperforming current state-of-the-art (SOTA) methods. On the RTLLM dataset. On the VerilogEval dataset, our framework achieves 99.56% syntactic correctness and 43.79% functional correctness, also surpassing SOTA, which stands at 92.11% for syntactic correctness and 33.57% for functional correctness. Furthermore, Our framework able to optimize the PPA of the designs. These results highlight the potential of LLMs in handling complex technical areas and indicate an encouraging development in the automation of chip design processes."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Direct Simplified Symbolic Analysis (DSSA) Tool", "authors": "Mohammad Shokouhifar, Hossein Yazdanjouei, Gerhard-Wilhelm Weber", "subjects": "Other Computer Science (cs.OH); Hardware Architecture (cs.AR); Neural and Evolutionary Computing (cs.NE)", "abstract": "This paper introduces Direct Simplified Symbolic Analysis (DSSA), a new method for simplifying analog circuits. Unlike traditional matrix- or graph-based techniques that are often slow and memory-intensive, DSSA treats the task as a modeling problem and directly extracts the most significant transfer function terms. By combining Monte Carlo simulation with a genetic algorithm, it minimizes error between simplified symbolic and exact numeric expressions. Tests on five circuits in MATLAB show strong performance, with only 0.64 dB average and 1.36 dB maximum variation in dc-gain, along with a 6.8% average pole/zero error. These results highlight DSSA as an efficient and accurate tool for symbolic circuit analysis."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Fully Automated Verification Framework for Configurable IPs: From Requirements to Results", "authors": "Shuhang Zhang, Jelena Radulovic, Thorsten Dworzak", "subjects": "Hardware Architecture (cs.AR); Emerging Technologies (cs.ET)", "abstract": "The increasing competition in the semiconductor industry has created significant pressure to reduce chip prices while maintaining quality and reliability. Functional verification, particularly for configurable IPs, is a major contributor to development costs due to its complexity and resource-intensive nature. To address this, we propose a fully automated framework for requirements driven functional verification. The framework automates key processes, including vPlan generation, testbench creation, regression execution, and reporting in a requirements management tool, drastically reducing verification effort. This approach accelerates development cycles, minimizes human error, and enhances coverage, offering a scalable and efficient solution to the challenges of verifying configurable IPs."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          NVM-in-Cache: Repurposing Commodity 6T SRAM Cache into NVM Analog Processing-in-Memory Engine using a Novel Compute-on-Powerline Scheme", "authors": "Subhradip Chakraborty, Ankur Singh, Xuming Chen, Gourav Datta, Akhilesh R. Jaiswal", "subjects": "Hardware Architecture (cs.AR); Image and Video Processing (eess.IV); Systems and Control (eess.SY)", "abstract": "The rapid growth of deep neural network (DNN) workloads has significantly increased the demand for large-capacity on-chip SRAM in machine learning (ML) applications, with SRAM arrays now occupying a substantial fraction of the total die area. To address the dual challenges of storage density and computation efficiency, this paper proposes an NVM-in-Cache architecture that integrates resistive RAM (RRAM) devices into a conventional 6T-SRAM cell, forming a compact 6T-2R bit-cell. This hybrid cell enables Processing-in-Memory (PIM) mode, which performs massively parallel multiply-and-accumulate (MAC) operations directly on cache power lines while preserving stored cache data. By exploiting the intrinsic properties of the 6T-2R structure, the architecture achieves additional storage capability, high computational throughput without any bit-cell area overhead. Circuit- and array-level simulations in GlobalFoundries 22nm FDSOI technology demonstrate that the proposed design achieves a throughput of 0.4 TOPS and 491.78 TOPS/W. For 128 row-parallel operations, the CIFAR-10 classification is demonstrated by mapping a Resnet-18 neural network, achieving an accuracy of 91.27%. These results highlight the potential of the NVM-in-Cache approach to serve as a scalable, energy-efficient computing method by re-purposing existing 6T SRAM cache architecture for next-generation AI accelerators and general purpose processors."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          \"She's Like a Person but Better\": Characterizing Companion-Assistant Dynamics in Human-AI Relationships", "authors": "Aikaterina Manoli, Janet V. T. Pauketat, Ali Ladak, Hayoun Noh, Angel Hsing-Chi Hwang, Jay Reese Anthis", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI); Computers and Society (cs.CY)", "abstract": "Large language models are increasingly used for both task-based assistance and social companionship, yet research has typically focused on one or the other. Drawing on a survey (N = 204) and 30 interviews with high-engagement ChatGPT and Replika users, we characterize digital companionship as an emerging form of human-AI relationship. With both systems, users were drawn to humanlike qualities, such as emotional resonance and personalized responses, and non-humanlike qualities, such as constant availability and inexhaustible tolerance. This led to fluid chatbot uses, such as Replika as a writing assistant and ChatGPT as an emotional confidant, despite their distinct branding. However, we observed challenging tensions in digital companionship dynamics: participants grappled with bounded personhood, forming deep attachments while denying chatbots \"real\" human qualities, and struggled to reconcile chatbot relationships with social norms. These dynamics raise questions for the design of digital companions and the rise of hybrid, general-purpose AI systems."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          FVDebug: An LLM-Driven Debugging Assistant for Automated Root Cause Analysis of Formal Verification Failures", "authors": "Yunsheng Bai, Ghaith Bany Hamad, Chia-Tung Ho, Syed Suhaib, Haoxing Ren", "subjects": "Hardware Architecture (cs.AR); Artificial Intelligence (cs.AI)", "abstract": "Debugging formal verification (FV) failures represents one of the most time-consuming bottlenecks in modern hardware design workflows. When properties fail, engineers must manually trace through complex counter-examples spanning multiple cycles, analyze waveforms, and cross-reference design specifications to identify root causes - a process that can consume hours or days per bug. Existing solutions are largely limited to manual waveform viewers or simple automated tools that cannot reason about the complex interplay between design intent and implementation logic. We present FVDebug, an intelligent system that automates root-cause analysis by combining multiple data sources - waveforms, RTL code, design specifications - to transform failure traces into actionable insights. Our approach features a novel pipeline: (1) Causal Graph Synthesis that structures failure traces into directed acyclic graphs, (2) Graph Scanner using batched Large Language Model (LLM) analysis with for-and-against prompting to identify suspicious nodes, and (3) Insight Rover leveraging agentic narrative exploration to generate high-level causal explanations. FVDebug further provides concrete RTL fixes through its Fix Generator. Evaluated on open benchmarks, FVDebug attains high hypothesis quality and strong Pass@k fix rates. We further report results on two proprietary, production-scale FV counterexamples. These results demonstrate FVDebug's applicability from academic benchmarks to industrial designs."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Symbolic Timing Analysis of Digital Circuits Using Analytic Delay Functions", "authors": "Era Thaqi, Dennis Eigner, Arman Ferdowsi, Ulrich Schmid", "subjects": "Hardware Architecture (cs.AR)", "abstract": "We propose a novel approach to symbolic timing analysis for digital integrated circuits based on recently developed analytic delay formulas for 2-input NOR, NAND, and Muller-C gates by Ferdowsi et al. (NAHS 2025). Given a fixed order of the transitions of all input and internal signals of a circuit, our framework computes closed-form analytic delay expressions for all the internal signal transition times that depend on (i) the symbolic transition times of the relevant input signals and (ii) the model parameters of the relevant gates. The resulting formulas facilitate per-transition timing analysis without any simulation, by instantiating the symbolic input transition times and the gate parameters. More importantly, however, they also enable an \\emph{analytic} study of the dependencies of certain timing properties on input signals and gate parameters. For instance, differentiating a symbolic delay expression with respect to a gate parameter or input transition time enables sensitivity analysis. As a proof of concept, we implement our approach using the computer algebra system SageMath and apply it to the NOR-gate version of the c17 slack benchmark circuit."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Belenos: Bottleneck Evaluation to Link Biomechanics to Novel Computing Optimizations", "authors": "Hana Chitsaz, Johnson Umeike, Amirmahdi Namjoo, Babak N. Safa, Bahar Asgari", "subjects": "Hardware Architecture (cs.AR)", "abstract": "Finite element simulations are essential in biomechanics, enabling detailed modeling of tissues and organs. However, architectural inefficiencies in current hardware and software stacks limit performance and scalability, especially for iterative tasks like material parameter identification. As a result, workflows often sacrifice fidelity for tractability. Reconfigurable hardware, such as FPGAs, offers a promising path to domain-specific acceleration without the cost of ASICs, but its potential in biomechanics remains underexplored. This paper presents Belenos, a comprehensive workload characterization of finite element biomechanics using FEBio, a widely adopted simulator, gem5 sensitivity studies, and VTune analysis. VTune results reveal that smaller workloads experience moderate front-end stalls, typically around 13.1%, whereas larger workloads are dominated by significant back-end bottlenecks, with backend-bound cycles ranging from 59.9% to over 82.2%. Complementary gem5 sensitivity studies identify optimal hardware configurations for Domain-Specific Accelerators (DSA), showing that suboptimal pipeline, memory, or branch predictor settings can degrade performance by up to 37.1%. These findings underscore the need for architecture-aware co-design to efficiently support biomechanical simulation workloads."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          SoCks - Simplifying Firmware and Software Integration for Heterogeneous SoCs", "authors": "Marvin Fuchs, Lukas Scheller, Timo Muscheid, Oliver Sander, Luis E. Ardila-Perez", "subjects": "Hardware Architecture (cs.AR); High Energy Physics - Experiment (hep-ex)", "abstract": "Modern heterogeneous System-on-Chip (SoC) devices integrate advanced components into a single package, offering powerful capabilities while also introducing significant complexity. To manage these sophisticated devices, firmware and software developers need powerful development tools. However, as these tools become increasingly complex, they often lack adequate support, resulting in a steep learning curve and challenging troubleshooting. To address this, this work introduces System-on-Chip blocks (SoCks), a flexible and expandable build framework that reduces complexity by partitioning the SoC image into high-level units called blocks. SoCks builds each firmware and software block in an encapsulated way, independently from other components of the image, thereby reducing dependencies to a minimum. While some information exchange between the blocks is unavoidable to ensure seamless runtime integration, this interaction is standardized via interfaces. A small number of dependencies and well-defined interfaces simplify the reuse of existing block implementations and facilitate seamless substitution between versions-for instance, when choosing root file systems for the embedded Linux operating system. Additionally, this approach facilitates the establishment of a decentralized and partially automated development flow through Continuous Integration and Continuous Delivery (CI/CD). Measurement results demonstrate that SoCks can build a complete SoC image up to three times faster than established tools."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Latency Based Tiling", "authors": "Jack Cashman", "subjects": "Programming Languages (cs.PL); Hardware Architecture (cs.AR); Performance (cs.PF)", "abstract": "Latency Based Tiling provides a systems based approach to deriving approximate tiling solution that maximizes locality while maintaining a fast compile time. The method uses triangular loops to characterize miss ratio scaling of a machine avoiding prefetcher distortion. Miss ratio scaling captures the relationship between data access latency and working set size with sharp increases in latency indicating the data footprint exceeds capacity from a cache level. Through these noticeable increases in latency we can determine an approximate location for L1, L2, and L3 memory sizes. These sizes are expected to be under approximations of a systems true memory sizes which is in line with our expectations given the shared nature of cache in a multi process system as described in defensive loop tiling. Unlike auto tuning, which can be effective but prohibitively slow, Latency Based Tiling achieves negligible compile time overhead. The implementation in Rust enables a hardware agnostic approach which combined with a cache timing based techniques, yields a portable, memory safe system running wherever Rust is supported. The tiling strategy is applied to a subset of the polyhedral model, where loop nestings are tiled based on both the derived memory hierarchy and the observed data footprint per iteration."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          VeriGRAG: Enhancing LLM-Based Verilog Code Generation with Structure-Aware Soft Prompts", "authors": "Jiayu Zhao, Song Chen", "subjects": "Hardware Architecture (cs.AR); Artificial Intelligence (cs.AI); Programming Languages (cs.PL)", "abstract": "Large language models (LLMs) have demonstrated strong capabilities in generating Verilog code from natural language descriptions. However, Verilog code inherently encodes structural information of hardware circuits. Effectively leveraging this structural information to enhance the functional and syntactic correctness of LLM-generated Verilog code remains a significant challenge. To address this challenge, we propose VeriGRAG , a novel framework that extracts structural graph embeddings from Verilog code using graph neural networks (GNNs). A multimodal retriever then selects the graph embeddings most relevant to the given generation task, which are aligned with the code modality through the VeriFormer module to generate structure-aware soft prompts. Our experiments demonstrate that VeriGRAG substantially improves the correctness of Verilog code generation, achieving state-of-the-art or superior performance across both VerilogEval and RTLLM benchmarks."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Intent-Driven Storage Systems: From Low-Level Tuning to High-Level Understanding", "authors": "Shai Bergman, Won Wook Song, Lukas Cavigelli, Konstantin Berestizshevsky, Ke Zhou, Ji Zhang", "subjects": "Hardware Architecture (cs.AR); Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC)", "abstract": "Existing storage systems lack visibility into workload intent, limiting their ability to adapt to the semantics of modern, large-scale data-intensive applications. This disconnect leads to brittle heuristics and fragmented, siloed optimizations. To address these limitations, we propose Intent-Driven Storage Systems (IDSS), a vision for a new paradigm where large language models (LLMs) infer workload and system intent from unstructured signals to guide adaptive and cross-layer parameter reconfiguration. IDSS provides holistic reasoning for competing demands, synthesizing safe and efficient decisions within policy guardrails. We present four design principles for integrating LLMs into storage control loops and propose a corresponding system architecture. Initial results on FileBench workloads show that IDSS can improve IOPS by up to 2.45X by interpreting intent and generating actionable configurations for storage components such as caching and prefetching. These findings suggest that, when constrained by guardrails and embedded within structured workflows, LLMs can function as high-level semantic optimizers, bridging the gap between application goals and low-level system control. IDSS points toward a future in which storage systems are increasingly adaptive, autonomous, and aligned with dynamic workload demands."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          TeLLMe v2: An Efficient End-to-End Ternary LLM Prefill and Decode Accelerator with Table-Lookup Matmul on Edge FPGAs", "authors": "Ye Qiao, Zhiheng Chen, Yifan Zhang, Yian Wang, Sitao Huang", "subjects": "Hardware Architecture (cs.AR); Machine Learning (cs.LG)", "abstract": "With the emergence of wearable devices and other embedded systems, deploying large language models (LLMs) on edge platforms has become an urgent need. However, this is challenging because of their high computational and memory demands. Although recent low-bit quantization methods (e.g., BitNet, DeepSeek) compress weights to as low as 1.58~bits with minimal accuracy loss, edge deployment is still constrained by limited on-chip resources, power budgets, and the often-neglected long latency of the prefill stage. We present \\textbf{TeLLMe}, the first table-lookup-based ternary LLM accelerator for low-power edge FPGAs that fully supports both prefill and autoregressive decoding using 1.58-bit weights and 8-bit activations. TeLLMe incorporates several novel techniques, including (1) a table-lookup-based ternary matrix multiplication (TLMM) engine utilizing grouped activations and online precomputation for low resource utilization and high throughput; (2) a fine-grained analytic URAM-based weight buffer management scheme for efficient loading and compute engine access; (3) a streaming dataflow architecture that fuses floating-point element-wise operations with linear computations to hide latency; (4) a reversed-reordered prefill stage attention with fused attention operations for high memory efficiency; and (5) a resource-efficient specialized decoding stage attention. Under a 5~W power budget, TeLLMe delivers up to 25~tokens/s decoding throughput and 0.45--0.96~s time-to-first-token (TTFT) for 64--128 token prompts, marking a significant energy-efficiency advancement in LLM inference on edge FPGAs."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          UPMEM Unleashed: Software Secrets for Speed", "authors": "Krystian Chmielewski, Jaros\u0142aw \u0141awnicki, Uladzislau Lukyanau, Tadeusz Kobus, Maciej Maciejewski", "subjects": "Hardware Architecture (cs.AR); Distributed, Parallel, and Cluster Computing (cs.DC); Performance (cs.PF)", "abstract": "Developing kernels for Processing-In-Memory (PIM) platforms poses unique challenges in data management and parallel programming on limited processing units. Although software development kits (SDKs) for PIM, such as the UPMEM SDK, provide essential tools, these emerging platforms still leave significant room for performance optimization. In this paper, we reveal surprising inefficiencies in UPMEM software stack and play with non-standard programming techniques. By making simple modifications to the assembly generated by the UPMEM compiler, we achieve speedups of 1.6-2x in integer addition and 1.4-5.9x in integer multiplication, depending on the data type. We also demonstrate that bit-serial processing of low precision data is a viable option for UPMEM: in INT4 bit-serial dot-product calculation, UPMEM can achieve over 2.7x speedup over the baseline. Minor API extensions for PIM allocation that account for the non-uniform memory access (NUMA) architecture of the server further improve the consistency and throughput of host-PIM data transfers by up to 2.9x. Finally, we show that, when the matrix is preloaded into PIM, our optimized kernels outperform a dual-socket CPU server by over 3x for INT8 generalized matrix-vector multiplication (GEMV) and by 10x for INT4 GEMV. Our optimized INT8 GEMV kernel outperforms the baseline 3.5x."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Impl\u00e9mentation Efficiente de Fonctions de Convolution sur FPGA \u00e0 l'Aide de Blocs Param\u00e9trables et d'Approximations Polynomiales", "authors": "Philippe Magalh\u00e3es (LabHC), Virginie Fresse (LabHC), Beno\u00eet Suffran, Olivier Alata (LabHC)", "subjects": "Hardware Architecture (cs.AR); Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE)", "abstract": "Implementing convolutional neural networks (CNNs) on field-programmable gate arrays (FPGAs) has emerged as a promising alternative to GPUs, offering lower latency, greater power efficiency and greater flexibility. However, this development remains complex due to the hardware knowledge required and the long synthesis, placement and routing stages, which slow down design cycles and prevent rapid exploration of network configurations, making resource optimisation under severe constraints particularly challenging. This paper proposes a library of configurable convolution Blocks designed to optimize FPGA implementation and adapt to available resources. It also presents a methodological framework for developing mathematical models that predict FPGA resources utilization. The approach is validated by analyzing the correlation between the parameters, followed by error metrics. The results show that the designed blocks enable adaptation of convolution layers to hardware constraints, and that the models accurately predict resource consumption, providing a useful tool for FPGA selection and optimized CNN deployment."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Quantum Approximate Optimization Algorithm for MIMO with Quantized b-bit Beamforming", "authors": "Nikos A Mitsiou, Ioannis Krikidis, George K Karagiannidis", "subjects": "Emerging Technologies (cs.ET); Information Theory (cs.IT); Quantum Physics (quant-ph)", "abstract": "Multiple-input multiple-output (MIMO) is critical for 6G communication, offering improved spectral efficiency and reliability. However, conventional fully digital designs face significant challenges due to high hardware complexity and power consumption. Low-bit MIMO architectures, such as those employing b-bit quantized phase shifters, provide a cost-effective alternative but introduce NP-hard combinatorial problems in the pre- and post-coding design. This paper explores the use of the Quantum Approximate Optimization Algorithm (QAOA) and alternating optimization to address the problem of b-bit quantized phase shifters both at the transmitter and the receiver. We demonstrate that the structure of this quantized beamforming problem aligns naturally with hybrid-classical methods like QAOA, as the phase shifts used in beamforming can be directly mapped to rotation gates in a quantum circuit. Notably, this paper is the first to show that theoretical connection. Then, the Hamiltonian derivation analysis for the b-bit case is presented, which could have applications in different fields, such as integrated sensing and communication, and emerging quantum algorithms such as quantum machine learning. In addition, a warm-start QAOA approach is studied which improves computational efficiency. Numerical results highlight the effectiveness of the proposed methods in achieving an improved quantized beamforming gain over their classical optimization benchmarks from the literature."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Large Language Models in Architecture Studio: A Framework for Learning Outcomes", "authors": "Juan David Salazar Rodriguez, Sam Conrad Joyce, Nachamma Sockalingam, Julfendi", "subjects": "Computers and Society (cs.CY); Human-Computer Interaction (cs.HC)", "abstract": "The study explores the role of large language models (LLMs) in the context of the architectural design studio, understood as the pedagogical core of architectural education. Traditionally, the studio has functioned as an experiential learning space where students tackle design problems through reflective practice, peer critique, and faculty guidance. However, the integration of artificial intelligence (AI) in this environment has been largely focused on form generation, automation, and representation-al efficiency, neglecting its potential as a pedagogical tool to strengthen student autonomy, collaboration, and self-reflection. The objectives of this research were: (1) to identify pedagogical challenges in self-directed, peer-to-peer, and teacher-guided learning processes in architecture studies; (2) to propose AI interventions, particularly through LLM, that contribute to overcoming these challenges; and (3) to align these interventions with measurable learning outcomes using Bloom's taxonomy. The findings show that the main challenges include managing student autonomy, tensions in peer feedback, and the difficulty of balancing the transmission of technical knowledge with the stimulation of creativity in teaching. In response to this, LLMs are emerging as complementary agents capable of generating personalized feedback, organizing collaborative interactions, and offering adaptive cognitive scaffolding. Furthermore, their implementation can be linked to the cognitive levels of Bloom's taxonomy: facilitating the recall and understanding of architectural concepts, supporting application and analysis through interactive case studies, and encouraging synthesis and evaluation through hypothetical design scenarios."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Lean Finder: Semantic Search for Mathlib That Understands User Intents", "authors": "Jialin Lu, Kye Emond, Kaiyu Yang, Swarat Chaudhuri, Weiran Sun, Wuyang Chen", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "We present Lean Finder, a semantic search engine for Lean and mathlib that understands and aligns with the intents of mathematicians. Progress in formal theorem proving is often hindered by the difficulty of locating relevant theorems and the steep learning curve of the Lean 4 language, making advancement slow and labor-intensive. Existing Lean search engines, though helpful, rely primarily on informalizations (natural language translation of the formal statements), while largely overlooking the mismatch with real-world user queries. In contrast, we propose a user-centered semantic search tailored to the needs of mathematicians. Our approach begins by analyzing and clustering the semantics of public Lean discussions, then fine-tuning text embeddings on synthesized queries that emulate user intents. We further align Lean Finder with mathematicians' preferences using diverse feedback signals, encoding it with a rich awareness of their goals from multiple perspectives. Evaluations on real-world queries, informalized statements, and proof states demonstrate that our Lean Finder achieves over $30\\%$ relative improvement compared to previous search engines and GPT-4o. In addition, Lean Finder is compatible with LLM-based theorem provers, bridging retrieval with formal reasoning. Lean Finder is available at: this https URL"}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Enabling Responsible, Secure and Sustainable Healthcare AI - A Strategic Framework for Clinical and Operational Impact", "authors": "Jimmy Joseph", "subjects": "Computers and Society (cs.CY)", "abstract": "We offer a pragmatic model to operationalize responsible, secure, and sustainable healthcare AI, aligning world-class technical excellence with organizational readiness. The framework includes five key pillars - Leadership & Strategy, MLOps & Technical Infrastructure, Governance & Ethics, Education & Workforce Development, and Change Management & Adoption - and is intended to operationalize 'compliance-by-design' while delivering measurable impact. We demonstrate its utility through two deployments. (A) An inpatient length of stay (LOS) prediction service had R^2=0.41-0.58 with validation cohorts in an observational pilot (n = 3,184 encounters, 4 units, June-August 2025). Adoption was 78 percent by week 6, and target units saw 5-10 percent relative declines in mean LOS for complex cases vs. pre-pilot baselines. (B) An AI-augmented radiology second-reader for lung nodules (PACS-integrated with thresholding and explanation overlays) achieved high sensitivity (95 percent) and provided a +8.0 percentage-point lift in detection of sub-centimeter actionable findings, without slowing workflow (median report TAT 23 min, p = 0.64). Both services executed in monitored, auditable pipelines with well-defined rollback, bias checks, and no evidence of security incidents. These findings indicate that by combining strong MLOps and AI security with governance, education, and human-centric change, we can accelerate adoption of AI while improving security and outcomes. We end with limitations, generalization considerations, and a roadmap for scaling across varied clinical and operational use cases."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Lyapunov-Stable Adaptive Control for Multimodal Concept Drift", "authors": "Tianyu Bell Pan, Mengdi Zhu, Alexa Jordyn Cole, Ronald Wilson, Damon L. Woodard", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "Multimodal learning systems often struggle in non-stationary environments due to concept drift, where changing data distributions can degrade performance. Modality-specific drifts and the lack of mechanisms for continuous, stable adaptation compound this challenge. This paper introduces LS-OGD, a novel adaptive control framework for robust multimodal learning in the presence of concept drift. LS-OGD uses an online controller that dynamically adjusts the model's learning rate and the fusion weights between different data modalities in response to detected drift and evolving prediction errors. We prove that under bounded drift conditions, the LS-OGD system's prediction error is uniformly ultimately bounded and converges to zero if the drift ceases. Additionally, we demonstrate that the adaptive fusion strategy effectively isolates and mitigates the impact of severe modality-specific drift, thereby ensuring system resilience and fault tolerance. These theoretical guarantees establish a principled foundation for developing reliable and continuously adapting multimodal learning systems."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          BEACON: Bayesian Optimal Stopping for Efficient LLM Sampling", "authors": "Guangya Wan, Zixin Stephen Xu, Sasa Zorc, Manel Baucells, Mengxuan Hu, Hao Wang, Sheng Li", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "Sampling multiple responses is a common way to improve LLM output quality, but it comes at the cost of additional computation. The key challenge is deciding when to stop generating new samples to balance accuracy gains against efficiency. To address this, we introduce BEACON (Bayesian Efficient Adaptive Criterion for Optimal N-stopping), a principled adaptive sampling framework grounded in Sequential Search with Bayesian Learning. BEACON sequentially generates responses from the policy LLM, updates posterior belief over reward distributions in real time without further training, and determines when to stop by weighing expected gains against computational cost. Sampling terminates once the marginal utility of further exploration no longer justifies the expense. We establish both theoretical optimality guarantees and practical tractability, and show empirically that BEACON reduces average sampling by up to 80% while maintaining response quality. We further demonstrate BEACON's utility for cost-efficient preference data generation and outline practical extensions, offering actionable insights for future researchers."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Learning from Mistakes: Enhancing Harmful Meme Detection via Misjudgment Risk Patterns", "authors": "Wenshuo Wang, Ziyou Jiang, Junjie Wang, Mingyang Li, Jie Huang, Yuekai Huang, Zhiyuan Chang, Feiyan Duan, Qing Wang", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)", "abstract": "Internet memes have emerged as a popular multimodal medium, yet they are increasingly weaponized to convey harmful opinions through subtle rhetorical devices like irony and metaphor. Existing detection approaches, including MLLM-based techniques, struggle with these implicit expressions, leading to frequent misjudgments. This paper introduces PatMD, a novel approach that improves harmful meme detection by learning from and proactively mitigating these potential misjudgment risks. Our core idea is to move beyond superficial content-level matching and instead identify the underlying misjudgment risk patterns, proactively guiding the MLLMs to avoid known misjudgment pitfalls. We first construct a knowledge base where each meme is deconstructed into a misjudgment risk pattern explaining why it might be misjudged, either overlooking harmful undertones (false negative) or overinterpreting benign content (false positive). For a given target meme, PatMD retrieves relevant patterns and utilizes them to dynamically guide the MLLM's reasoning. Experiments on a benchmark of 6,626 memes across 5 harmful detection tasks show that PatMD outperforms state-of-the-art baselines, achieving an average of 8.30\\% improvement in F1-score and 7.71\\% improvement in accuracy, demonstrating strong generalizability and improved detection capability of harmful memes."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          WaveNet's Precision in EEG Classification", "authors": "Casper van Laar, Khubaib Ahmed", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Signal Processing (eess.SP); Neurons and Cognition (q-bio.NC)", "abstract": "This study introduces a WaveNet-based deep learning model designed to automate the classification of EEG signals into physiological, pathological, artifact, and noise categories. Traditional methods for EEG signal classification, which rely on expert visual review, are becoming increasingly impractical due to the growing complexity and volume of EEG recordings. Leveraging a publicly available annotated dataset from Mayo Clinic and St. Anne's University Hospital, the WaveNet model was trained, validated, and tested on 209,232 samples with a 70/20/10 percent split. The model achieved a classification accuracy exceeding previous CNN and LSTM-based approaches, and was benchmarked against a Temporal Convolutional Network (TCN) baseline. Notably, the model distinguishes noise and artifacts with high precision, although it reveals a modest but explainable degree of misclassification between physiological and pathological signals, reflecting inherent clinical overlap. WaveNet's architecture, originally developed for raw audio synthesis, is well suited for EEG data due to its use of dilated causal convolutions and residual connections, enabling it to capture both fine-grained and long-range temporal dependencies. The research also details the preprocessing pipeline, including dynamic dataset partitioning and normalization steps that support model generalization."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          VisuoAlign: Safety Alignment of LVLMs with Multimodal Tree Search", "authors": "MingSheng Li, Guangze Zhao, Sichen Liu", "subjects": "Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)", "abstract": "Large Vision-Language Models (LVLMs) have achieved remarkable progress in multimodal perception and generation, yet their safety alignment remains a critical this http URL defenses and vulnerable to multimodal jailbreaks, as visual inputs introduce new attack surfaces, reasoning chains lack safety supervision, and alignment often degrades under modality this http URL overcome these limitation, we propose VisuoAlign, a framework for multi-modal safety alignment via prompt-guided tree this http URL embeds safety constrains into the reasoning process through visual-textual interactive prompts, employs Monte Carlo Tree Search(MCTS) to systematically construct diverse safety-critical prompt trajectories, and introduces prompt-based scaling to ensure real-time risk detection and compliant this http URL experiments demonstrate that VisuoAlign proactively exposes risks, enables comprehensive dataset generation, and significantly improves the robustness of LVLMs against complex cross-modal threats."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Cross-dataset Multivariate Time-series Model for Parkinson's Diagnosis via Keyboard Dynamics", "authors": "Arianna Francesconi, Donato Cappetta, Fabio Rebecchi, Paolo Soda, Valerio Guarrasi, Rosa Sicilia", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "Parkinson's disease (PD) presents a growing global challenge, affecting over 10 million individuals, with prevalence expected to double by 2040. Early diagnosis remains difficult due to the late emergence of motor symptoms and limitations of traditional clinical assessments. In this study, we propose a novel pipeline that leverages keystroke dynamics as a non-invasive and scalable biomarker for remote PD screening and telemonitoring. Our methodology involves three main stages: (i) preprocessing of data from four distinct datasets, extracting four temporal signals and addressing class imbalance through the comparison of three methods; (ii) pre-training eight state-of-the-art deep-learning architectures on the two largest datasets, optimizing temporal windowing, stride, and other hyperparameters; (iii) fine-tuning on an intermediate-sized dataset and performing external validation on a fourth, independent cohort. Our results demonstrate that hybrid convolutional-recurrent and transformer-based models achieve strong external validation performance, with AUC-ROC scores exceeding 90% and F1-Score over 70%. Notably, a temporal convolutional model attains an AUC-ROC of 91.14% in external validation, outperforming existing methods that rely solely on internal validation. These findings underscore the potential of keystroke dynamics as a reliable digital biomarker for PD, offering a promising avenue for early detection and continuous monitoring."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Attention to Non-Adopters", "authors": "Kaitlyn Zhou, Kristina Gligori\u0107, Myra Cheng, Michelle S. Lam, Vyoma Raman, Boluwatife Aminu, Caeley Woo, Michael Brockman, Hannah Cha, Dan Jurafsky", "subjects": "Computers and Society (cs.CY); Computation and Language (cs.CL); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)", "abstract": "Although language model-based chat systems are increasingly used in daily life, most Americans remain non-adopters of chat-based LLMs -- as of June 2025, 66% had never used ChatGPT. At the same time, LLM development and evaluation rely mainly on data from adopters (e.g., logs, preference data), focusing on the needs and tasks for a limited demographic group of adopters in terms of geographic location, education, and gender. In this position paper, we argue that incorporating non-adopter perspectives is essential for developing broadly useful and capable LLMs. We contend that relying on methods that focus primarily on adopters will risk missing a range of tasks and needs prioritized by non-adopters, entrenching inequalities in who benefits from LLMs, and creating oversights in model development and evaluation. To illustrate this claim, we conduct case studies with non-adopters and show: how non-adopter needs diverge from those of current users, how non-adopter needs point us towards novel reasoning tasks, and how to systematically integrate non-adopter needs via human-centered methods."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Executable Epistemology: The Structured Cognitive Loop as an Architecture of Intentional Understanding", "authors": "Myung Ho Kim", "subjects": "Artificial Intelligence (cs.AI)", "abstract": "Large language models exhibit intelligence without genuine epistemic understanding, exposing a key gap: the absence of epistemic architecture. This paper introduces the Structured Cognitive Loop (SCL) as an executable epistemological framework for emergent intelligence. Unlike traditional AI research asking \"what is intelligence?\" (ontological), SCL asks \"under what conditions does cognition emerge?\" (epistemological). Grounded in philosophy of mind and cognitive phenomenology, SCL bridges conceptual philosophy and implementable cognition. Drawing on process philosophy, enactive cognition, and extended mind theory, we define intelligence not as a property but as a performed process -- a continuous loop of judgment, memory, control, action, and regulation. SCL makes three contributions. First, it operationalizes philosophical insights into computationally interpretable structures, enabling \"executable epistemology\" -- philosophy as structural experiment. Second, it shows that functional separation within cognitive architecture yields more coherent and interpretable behavior than monolithic prompt based systems, supported by agent evaluations. Third, it redefines intelligence: not representational accuracy but the capacity to reconstruct its own epistemic state through intentional understanding. This framework impacts philosophy of mind, epistemology, and AI. For philosophy, it allows theories of cognition to be enacted and tested. For AI, it grounds behavior in epistemic structure rather than statistical regularity. For epistemology, it frames knowledge not as truth possession but as continuous reconstruction within a phenomenologically coherent loop. We situate SCL within debates on cognitive phenomenology, emergence, normativity, and intentionality, arguing that real progress requires not larger models but architectures that realize cognitive principles structurally."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Hierarchical Multi-Modal Threat Intelligence Fusion Without Aligned Data: A Practical Framework for Real-World Security Operations", "authors": "Sisir Doppalapudi", "subjects": "Cryptography and Security (cs.CR)", "abstract": "Multi-modal threat detection faces a fundamental challenge that involves security tools operating in isolation, and this creates streams of network, email, and system data with no natural alignment or correlation. We present Hierarchical Multi-Modal Threat Intelligence Fusion (HM-TIF), a framework explicitly designed for this realistic scenario where naturally aligned multi-modal attack data does not exist. Unlike prior work that assumes or creates artificial alignment, we develop principled methods for correlating independent security data streams while maintaining operational validity. Our architecture employs hierarchical cross-attention with dynamic weighting that adapts to data availability and threat context, coupled with a novel temporal correlation protocol that preserves statistical independence. Evaluation on UNSW-NB15, CSE-CIC-IDS2018, and CICBell-DNS2021 datasets demonstrates that HM-TIF achieves 88.7% accuracy with a critical 32% reduction in false positive rates, even without true multi-modal training data. The framework maintains robustness when modalities are missing, making it immediately deployable in real security operations where data streams frequently have gaps. Our contributions include: (i) the first multi-modal security framework explicitly designed for non-aligned data, (ii) a temporal correlation protocol that avoids common data leakage pitfalls, (iii) empirical validation that multi-modal fusion provides operational benefits even without perfect alignment, and (iv) practical deployment guidelines for security teams facing heterogeneous, uncoordinated data sources. Index Terms: multi-modal learning, threat intelligence, non-aligned data, operational security, cross-attention mechanisms, practical deployment"}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Fire-EnSF: Wildfire Spread Data Assimilation using Ensemble Score Filter", "authors": "Hongzheng Shi, Yuhang Wang, Xiao Liu", "subjects": "Machine Learning (cs.LG); Computational Engineering, Finance, and Science (cs.CE); Applications (stat.AP)", "abstract": "As wildfires become increasingly destructive and expensive to control, effective management of active wildfires requires accurate, real-time fire spread predictions. To enhance the forecasting accuracy of active fires, data assimilation plays a vital role by integrating observations (such as remote-sensing data) and fire predictions generated from numerical models. This paper provides a comprehensive investigation on the application of a recently proposed diffusion-model-based filtering algorithm -- the Ensemble Score Filter (EnSF) -- to the data assimilation problem for real-time active wildfire spread predictions. Leveraging a score-based generative diffusion model, EnSF has been shown to have superior accuracy for high-dimensional nonlinear filtering problems, making it an ideal candidate for the filtering problems of wildfire spread models. Technical details are provided, and our numerical investigations demonstrate that EnSF provides superior accuracy, stability, and computational efficiency, establishing it as a robust and practical method for wildfire data assimilation. Our code has been made publicly available."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          How Good Are LLMs at Processing Tool Outputs?", "authors": "Kiran Kate, Yara Rizk, Poulami Ghosh, Ashu Gulati, Tathagata Chakraborti, Zidane Wright, Mayank Agarwal", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "Most realistic task automation problems require large language models (LLMs) to call tools, which often return complex JSON responses. These responses must be further processed to derive the information necessary for task completion. The ability of LLMs to do so is under-studied. In this paper, we study the tool response processing task and LLMs' abilities to process structured (JSON) responses. We created a dataset for this task, and evaluated 15 open and closed weight models using multiple prompting approaches. Our results show that JSON processing remains a difficult task even for frontier models across multiple prompting strategies. The optimal response processing strategy depends on both the nature and size of the tool outputs, as well as the complexity of the required reasoning. Variations in processing approaches can lead to performance differences ranging from 3\\% to 50\\%."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Exploring the Potential of Citiverses for Regulatory Learning", "authors": "Isabelle Hupont, Marisa Ponti, Sven Schade", "subjects": "Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Emerging Technologies (cs.ET); Human-Computer Interaction (cs.HC)", "abstract": "Citiverses hold the potential to support regulatory learning by offering immersive, virtual environments for experimenting with policy scenarios and technologies. This paper proposes a science-for-policy agenda to explore the potential of citiverses as experimentation spaces for regulatory learning, grounded in a consultation with a high-level panel of experts, including policymakers from the European Commission, national government science advisers and leading researchers in digital regulation and virtual worlds. It identifies key research areas, including scalability, real-time feedback, complexity modelling, cross-border collaboration, risk reduction, citizen participation, ethical considerations and the integration of emerging technologies. In addition, the paper analyses a set of experimental topics, spanning transportation, urban planning and the environment/climate crisis, that could be tested in citiverse platforms to advance regulatory learning in these areas. The proposed work is designed to inform future research for policy and emphasizes a responsible approach to developing and using citiverses. It prioritizes careful consideration of the ethical, economic, ecological and social dimensions of different regulations. The paper also explores essential preliminary steps necessary for integrating citiverses into the broader ecosystems of experimentation spaces, including test beds, living labs and regulatory sandboxes"}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Hydrogen production from blended waste biomass: pyrolysis, thermodynamic-kinetic analysis and AI-based modelling", "authors": "Sana Kordoghli, Abdelhakim Settar, Oumayma Belaati, Mohammad Alkhatib", "subjects": "Machine Learning (cs.LG); Materials Science (cond-mat.mtrl-sci)", "abstract": "This work contributes to advancing sustainable energy and waste management strategies by investigating the thermochemical conversion of food-based biomass through pyrolysis, highlighting the role of artificial intelligence (AI) in enhancing process modelling accuracy and optimization efficiency. The main objective is to explore the potential of underutilized biomass resources, such as spent coffee grounds (SCG) and date seeds (DS), for sustainable hydrogen production. Specifically, it aims to optimize the pyrolysis process while evaluating the performance of these resources both individually and as blends. Proximate, ultimate, fibre, TGA/DTG, kinetic, thermodynamic, and Py-Micro GC analyses were conducted for pure DS, SCG, and blends (75% DS - 25% SCG, 50% DS - 50% SCG, 25% DS - 75% SCG). Blend 3 offered superior hydrogen yield potential but had the highest activation energy (Ea: 313.24 kJ/mol), while Blend 1 exhibited the best activation energy value (Ea: 161.75 kJ/mol). The kinetic modelling based on isoconversional methods (KAS, FWO, Friedman) identified KAS as the most accurate. These approaches provide a detailed understanding of the pyrolysis process, with particular emphasis on the integration of artificial intelligence. An LSTM model trained with lignocellulosic data predicted TGA curves with exceptional accuracy (R^2: 0.9996-0.9998)."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Interpretable Graph-Language Modeling for Detecting Youth Illicit Drug Use", "authors": "Yiyang Li, Zehong Wang, Zhengqing Yuan, Zheyuan Zhang, Keerthiram Murugesan, Chuxu Zhang, Yanfang Ye", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computers and Society (cs.CY)", "abstract": "Illicit drug use among teenagers and young adults (TYAs) remains a pressing public health concern, with rising prevalence and long-term impacts on health and well-being. To detect illicit drug use among TYAs, researchers analyze large-scale surveys such as the Youth Risk Behavior Survey (YRBS) and the National Survey on Drug Use and Health (NSDUH), which preserve rich demographic, psychological, and environmental factors related to substance use. However, existing modeling methods treat survey variables independently, overlooking latent and interconnected structures among them. To address this limitation, we propose LAMI (LAtent relation Mining with bi-modal Interpretability), a novel joint graph-language modeling framework for detecting illicit drug use and interpreting behavioral risk factors among TYAs. LAMI represents individual responses as relational graphs, learns latent connections through a specialized graph structure learning layer, and integrates a large language model to generate natural language explanations grounded in both graph structures and survey semantics. Experiments on the YRBS and NSDUH datasets show that LAMI outperforms competitive baselines in predictive accuracy. Interpretability analyses further demonstrate that LAMI reveals meaningful behavioral substructures and psychosocial pathways, such as family dynamics, peer influence, and school-related distress, that align with established risk factors for substance use."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          CTR-LoRA: Curvature-Aware and Trust-Region Guided Low-Rank Adaptation for Large Language Models", "authors": "Zhuxuanzi Wang, Mingqiao Mo, Xi Xiao, Chen Liu, Chenrui Ma, Yunbei Zhang, Xiao Wang, Smita Krishnaswamy, Tianyang Wang", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "Parameter-efficient fine-tuning (PEFT) has become the standard approach for adapting large language models under limited compute and memory budgets. Although previous methods improve efficiency through low-rank updates, quantization, or heuristic budget reallocation, they often decouple the allocation of capacity from the way updates evolve during training. In this work, we introduce CTR-LoRA, a framework guided by curvature trust region that integrates rank scheduling with stability-aware optimization. CTR-LoRA allocates parameters based on marginal utility derived from lightweight second-order proxies and constrains updates using a Fisher/Hessian-metric trust region. Experiments on multiple open-source backbones (7B-13B), evaluated on both in-distribution and out-of-distribution benchmarks, show consistent improvements over strong PEFT baselines. In addition to increased accuracy, CTR-LoRA enhances training stability, reduces memory requirements, and achieves higher throughput, positioning it on the Pareto frontier of performance and efficiency. These results highlight a principled path toward more robust and deployable PEFT."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          ESCA: Contextualizing Embodied Agents via Scene-Graph Generation", "authors": "Jiani Huang, Amish Sethi, Matthew Kuo, Mayank Keoliya, Neelay Velingker, JungHo Jung, Ser-Nam Lim, Ziyang Li, Mayur Naik", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "abstract": "Multi-modal large language models (MLLMs) are making rapid progress toward general-purpose embodied agents. However, current training pipelines primarily rely on high-level vision-sound-text pairs and lack fine-grained, structured alignment between pixel-level visual content and textual semantics. To overcome this challenge, we propose ESCA, a new framework for contextualizing embodied agents through structured spatial-temporal understanding. At its core is SGClip, a novel CLIP-based, open-domain, and promptable model for generating scene graphs. SGClip is trained on 87K+ open-domain videos via a neurosymbolic learning pipeline, which harnesses model-driven self-supervision from video-caption pairs and structured reasoning, thereby eliminating the need for human-labeled scene graph annotations. We demonstrate that SGClip supports both prompt-based inference and task-specific fine-tuning, excelling in scene graph generation and action localization benchmarks. ESCA with SGClip consistently improves both open-source and commercial MLLMs, achieving state-of-the-art performance across two embodied environments. Notably, it significantly reduces agent perception errors and enables open-source models to surpass proprietary baselines."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Long Exposure: Accelerating Parameter-Efficient Fine-Tuning for LLMs under Shadowy Sparsity", "authors": "Tuowei Wang, Kun Li, Zixu Hao, Donglin Bai, Ju Ren, Yaoxue Zhang, Ting Cao, Mao Yang", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "abstract": "The adaptation of pre-trained large language models (LLMs) to diverse downstream tasks via fine-tuning is critical for numerous applications. However, the inefficiency of parameter-efficient fine-tuning (PEFT) techniques presents significant challenges in terms of time investments and operational costs. In this paper, we first introduce a nuanced form of sparsity, termed Shadowy Sparsity, which is distinctive in fine-tuning and has not been adequately addressed for acceleration. Under Shadowy Sparsity, we propose Long Exposure, an efficient system to accelerate PEFT for LLMs. Long Exposure comprises three key components: Shadowy-sparsity Exposer employs a prolonged sensing range to capture more sparsity details under shadowy sparsity; Sequence-oriented Predictor provides efficient yet accurate predictions to handle large sequence inputs and constantly-evolving parameters; and Dynamic-aware Operator facilitates more structured computational patterns and coalesced memory accesses, addressing dynamic sparse operations. Extensive evaluations show that Long Exposure outperforms state-of-the-arts with up to a $2.49\\times$ speedup in end-to-end fine-tuning, offering promising advancements in accelerating PEFT for LLMs."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          One Token Embedding Is Enough to Deadlock Your Large Reasoning Model", "authors": "Mohan Zhang, Yihua Zhang, Jinghan Jia, Zhangyang Wang, Sijia Liu, Tianlong Chen", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)", "abstract": "Modern large reasoning models (LRMs) exhibit impressive multi-step problem-solving via chain-of-thought (CoT) reasoning. However, this iterative thinking mechanism introduces a new vulnerability surface. We present the Deadlock Attack, a resource exhaustion method that hijacks an LRM's generative control flow by training a malicious adversarial embedding to induce perpetual reasoning loops. Specifically, the optimized embedding encourages transitional tokens (e.g., \"Wait\", \"But\") after reasoning steps, preventing the model from concluding its answer. A key challenge we identify is the continuous-to-discrete projection gap: na\u00efve projections of adversarial embeddings to token sequences nullify the attack. To overcome this, we introduce a backdoor implantation strategy, enabling reliable activation through specific trigger tokens. Our method achieves a 100% attack success rate across four advanced LRMs (Phi-RM, Nemotron-Nano, R1-Qwen, R1-Llama) and three math reasoning benchmarks, forcing models to generate up to their maximum token limits. The attack is also stealthy (in terms of causing negligible utility loss on benign user inputs) and remains robust against existing strategies trying to mitigate the overthinking issue. Our findings expose a critical and underexplored security vulnerability in LRMs from the perspective of reasoning (in)efficiency."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          PISA: A Pragmatic Psych-Inspired Unified Memory System for Enhanced AI Agency", "authors": "Shian Jia, Ziyang Huang, Xinbo Wang, Haofei Zhang, Mingli Song", "subjects": "Artificial Intelligence (cs.AI)", "abstract": "Memory systems are fundamental to AI agents, yet existing work often lacks adaptability to diverse tasks and overlooks the constructive and task-oriented role of AI agent memory. Drawing from Piaget's theory of cognitive development, we propose PISA, a pragmatic, psych-inspired unified memory system that addresses these limitations by treating memory as a constructive and adaptive process. To enable continuous learning and adaptability, PISA introduces a trimodal adaptation mechanism (i.e., schema updation, schema evolution, and schema creation) that preserves coherent organization while supporting flexible memory updates. Building on these schema-grounded structures, we further design a hybrid memory access architecture that seamlessly integrates symbolic reasoning with neural retrieval, significantly improving retrieval accuracy and efficiency. Our empirical evaluation, conducted on the existing LOCOMO benchmark and our newly proposed AggQA benchmark for data analysis tasks, confirms that PISA sets a new state-of-the-art by significantly enhancing adaptability and long-term knowledge retention."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Gains: Fine-grained Federated Domain Adaptation in Open Set", "authors": "Zhengyi Zhong, Wenzheng Jiang, Weidong Bao, Ji Wang, Cheems Wang, Guanbo Wang, Yongheng Deng, Ju Ren", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "Conventional federated learning (FL) assumes a closed world with a fixed total number of clients. In contrast, new clients continuously join the FL process in real-world scenarios, introducing new knowledge. This raises two critical demands: detecting new knowledge, i.e., knowledge discovery, and integrating it into the global model, i.e., knowledge adaptation. Existing research focuses on coarse-grained knowledge discovery, and often sacrifices source domain performance and adaptation efficiency. To this end, we propose a fine-grained federated domain adaptation approach in open set (Gains). Gains splits the model into an encoder and a classifier, empirically revealing features extracted by the encoder are sensitive to domain shifts while classifier parameters are sensitive to class increments. Based on this, we develop fine-grained knowledge discovery and contribution-driven aggregation techniques to identify and incorporate new knowledge. Additionally, an anti-forgetting mechanism is designed to preserve source domain performance, ensuring balanced adaptation. Experimental results on multi-domain datasets across three typical data-shift scenarios demonstrate that Gains significantly outperforms other baselines in performance for both source-domain and target-domain clients. Code is available at: this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Self-Attention to Operator Learning-based 3D-IC Thermal Simulation", "authors": "Zhen Huang, Hong Wang, Wenkai Yang, Muxi Tang, Depeng Xie, Ting-Jung Lin, Yu Zhang, Wei W. Xing, Lei He", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Hardware Architecture (cs.AR)", "abstract": "Thermal management in 3D ICs is increasingly challenging due to higher power densities. Traditional PDE-solving-based methods, while accurate, are too slow for iterative design. Machine learning approaches like FNO provide faster alternatives but suffer from high-frequency information loss and high-fidelity data dependency. We introduce Self-Attention U-Net Fourier Neural Operator (SAU-FNO), a novel framework combining self-attention and U-Net with FNO to capture long-range dependencies and model local high-frequency features effectively. Transfer learning is employed to fine-tune low-fidelity data, minimizing the need for extensive high-fidelity datasets and speeding up training. Experiments demonstrate that SAU-FNO achieves state-of-the-art thermal prediction accuracy and provides an 842x speedup over traditional FEM methods, making it an efficient tool for advanced 3D IC thermal simulations."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          LinearizeLLM: An Agent-Based Framework for LLM-Driven Exact Linear Reformulation of Nonlinear Optimization Problems", "authors": "Paul-Niklas Ken Kandora, Simon Caspar Zeller, Aaron Jeremias Elsing, Elena Kuss, Steffen Rebennack", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "Reformulating nonlinear optimization problems is largely manual and expertise-intensive, yet it remains essential for solving such problems with linear optimization solvers or applying special-purpose algorithms. We introduce \\textit{LinearizeLLM}, an agent-based framework that solves this task by leveraging Large Language Models (LLMs). The framework assigns each nonlinear pattern to a \\textit{reformulation agent} that is explicitly instructed to derive an exact linear reformulation for its nonlinearity pattern, for instance, absolute-value terms or bilinear products of decision variables. The agents then coordinate to assemble a solver-ready linear model equivalent to the original problem. To benchmark the approach, we create a dataset of 20 real-world nonlinear optimization problems derived from the established ComplexOR dataset of linear optimization problems. We evaluate our approach with several LLMs. Our results indicate that specialized LLM agents can automate linearization tasks, opening a path toward fully conversational modeling pipelines for nonlinear optimization."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Predict Training Data Quality via Its Geometry in Metric Space", "authors": "Yang Ba, Mohammad Sadeq Abolhasani, Rong Pan", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "High-quality training data is the foundation of machine learning and artificial intelligence, shaping how models learn and perform. Although much is known about what types of data are effective for training, the impact of the data's geometric structure on model performance remains largely underexplored. We propose that both the richness of representation and the elimination of redundancy within training data critically influence learning outcomes. To investigate this, we employ persistent homology to extract topological features from data within a metric space, thereby offering a principled way to quantify diversity beyond entropy-based measures. Our findings highlight persistent homology as a powerful tool for analyzing and enhancing the training data that drives AI systems."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          A Graph-Attentive LSTM Model for Malicious URL Detection", "authors": "Md. Ifthekhar Hossain, Kazi Abdullah Al Arafat, Bryce Shepard, Kayd Craig, Imtiaz Parvez", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "abstract": "Malicious URLs pose significant security risks as they facilitate phishing attacks, distribute malware, and empower attackers to deface websites. Blacklist detection methods fail to identify new or obfuscated URLs because they depend on pre-existing patterns. This work presents a hybrid deep learning model named GNN-GAT-LSTM that combines Graph Neural Networks (GNNs) with Graph Attention Networks (GATs) and Long Short-Term Memory (LSTM) networks. The proposed architecture extracts both the structural and sequential patterns of the features from data. The model transforms URLs into graphs through a process where characters become nodes that connect through edges. It applies one-hot encoding to represent node features. The model received training and testing data from a collection of 651,191 URLs, which were classified into benign, phishing, defacement, and malware categories. The preprocessing stage included both feature engineering and data balancing techniques, which addressed the class imbalance issue to enhance model learning. The GNN-GAT-LSTM model achieved outstanding performance through its test accuracy of 0.9806 and its weighted F1-score of 0.9804. It showed excellent precision and recall performance across most classes, particularly for benign and defacement URLs. Overall, the model provides an efficient and scalable system for detecting malicious URLs while demonstrating strong potential for real-world cybersecurity applications."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Quantum NLP models on Natural Language Inference", "authors": "Ling Sun, Peter Sullivan, Michael Martin, Yun Zhou", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "abstract": "Quantum natural language processing (QNLP) offers a novel approach to semantic modeling by embedding compositional structure directly into quantum circuits. This paper investigates the application of QNLP models to the task of Natural Language Inference (NLI), comparing quantum, hybrid, and classical transformer-based models under a constrained few-shot setting. Using the lambeq library and the DisCoCat framework, we construct parameterized quantum circuits for sentence pairs and train them for both semantic relatedness and inference classification. To assess efficiency, we introduce a novel information-theoretic metric, Information Gain per Parameter (IGPP), which quantifies learning dynamics independent of model size. Our results demonstrate that quantum models achieve performance comparable to classical baselines while operating with dramatically fewer parameters. The Quantum-based models outperform randomly initialized transformers in inference and achieve lower test error on relatedness tasks. Moreover, quantum models exhibit significantly higher per-parameter learning efficiency (up to five orders of magnitude more than classical counterparts), highlighting the promise of QNLP in low-resource, structure-sensitive settings. To address circuit-level isolation and promote parameter sharing, we also propose a novel cluster-based architecture that improves generalization by tying gate parameters to learned word clusters rather than individual tokens."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Safeguarding Efficacy in Large Language Models: Evaluating Resistance to Human-Written and Algorithmic Adversarial Prompts", "authors": "Tiarnaigh Downey-Webb, Olamide Jogunola, Oluwaseun Ajao", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Computers and Society (cs.CY)", "abstract": "This paper presents a systematic security assessment of four prominent Large Language Models (LLMs) against diverse adversarial attack vectors. We evaluate Phi-2, Llama-2-7B-Chat, GPT-3.5-Turbo, and GPT-4 across four distinct attack categories: human-written prompts, AutoDAN, Greedy Coordinate Gradient (GCG), and Tree-of-Attacks-with-pruning (TAP). Our comprehensive evaluation employs 1,200 carefully stratified prompts from the SALAD-Bench dataset, spanning six harm categories. Results demonstrate significant variations in model robustness, with Llama-2 achieving the highest overall security (3.4% average attack success rate) while Phi-2 exhibits the greatest vulnerability (7.0% average attack success rate). We identify critical transferability patterns where GCG and TAP attacks, though ineffective against their target model (Llama-2), achieve substantially higher success rates when transferred to other models (up to 17% for GPT-4). Statistical analysis using Friedman tests reveals significant differences in vulnerability across harm categories ($p < 0.001$), with malicious use prompts showing the highest attack success rates (10.71% average). Our findings contribute to understanding cross-model security vulnerabilities and provide actionable insights for developing targeted defense mechanisms"}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Limits of Emergent Reasoning of Large Language Models in Agentic Frameworks for Deterministic Games", "authors": "Chris Su, Harrison Li, Matheus Marques, George Flint, Kevin Zhu, Sunishchal Dev", "subjects": "Artificial Intelligence (cs.AI)", "abstract": "Recent work reports that Large Reasoning Models (LRMs) undergo a collapse in performance on solving puzzles beyond certain perplexity thresholds. In subsequent discourse, questions have arisen as to whether the nature of the task muddles an evaluation of true reasoning. One potential confound is the requirement that the model keep track of the state space on its own. We provide a large language model (LLM) with an environment interface for Tower of Hanoi problems, allowing it to make a move with a tool call, provide written justification, observe the resulting state space, and reprompt itself for the next move. We observe that access to an environment interface does not delay or eradicate performance collapse. Furthermore, LLM-parameterized policy analysis reveals increasing divergence from both optimal policies and uniformly random policies, suggesting that the model exhibits mode-like collapse at each level of complexity, and that performance is dependent upon whether the mode reflects the correct solution for the problem. We suggest that a similar phenomena might take place in LRMs."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Generative AI for Biosciences: Emerging Threats and Roadmap to Biosecurity", "authors": "Zaixi Zhang, Souradip Chakraborty, Amrit Singh Bedi, Emilin Mathew, Varsha Saravanan, Le Cong, Alvaro Velasquez, Sheng Lin-Gibson, Megan Blewett, Dan Hendrycs, Alex John London, Ellen Zhong, Ben Raphael, Jian Ma, Eric Xing, Russ Altman, George Church, Mengdi Wang", "subjects": "Cryptography and Security (cs.CR); Biomolecules (q-bio.BM)", "abstract": "The rapid adoption of generative artificial intelligence (GenAI) in the biosciences is transforming biotechnology, medicine, and synthetic biology. Yet this advancement is intrinsically linked to new vulnerabilities, as GenAI lowers the barrier to misuse and introduces novel biosecurity threats, such as generating synthetic viral proteins or toxins. These dual-use risks are often overlooked, as existing safety guardrails remain fragile and can be circumvented through deceptive prompts or jailbreak techniques. In this Perspective, we first outline the current state of GenAI in the biosciences and emerging threat vectors ranging from jailbreak attacks and privacy risks to the dual-use challenges posed by autonomous AI agents. We then examine urgent gaps in regulation and oversight, drawing on insights from 130 expert interviews across academia, government, industry, and policy. A large majority ($\\approx 76$\\%) expressed concern over AI misuse in biology, and 74\\% called for the development of new governance frameworks. Finally, we explore technical pathways to mitigation, advocating a multi-layered approach to GenAI safety. These defenses include rigorous data filtering, alignment with ethical principles during development, and real-time monitoring to block harmful requests. Together, these strategies provide a blueprint for embedding security throughout the GenAI lifecycle. As GenAI becomes integrated into the biosciences, safeguarding this frontier requires an immediate commitment to both adaptive governance and secure-by-design technologies."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Learning to Watermark: A Selective Watermarking Framework for Large Language Models via Multi-Objective Optimization", "authors": "Chenrui Wang, Junyi Shu, Billy Chiu, Yu Li, Saleh Alharbi, Min Zhang, Jing Li", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "abstract": "The rapid development of LLMs has raised concerns about their potential misuse, leading to various watermarking schemes that typically offer high detectability. However, existing watermarking techniques often face trade-off between watermark detectability and generated text quality. In this paper, we introduce Learning to Watermark (LTW), a novel selective watermarking framework that leverages multi-objective optimization to effectively balance these competing goals. LTW features a lightweight network that adaptively decides when to apply the watermark by analyzing sentence embeddings, token entropy, and current watermarking ratio. Training of the network involves two specifically constructed loss functions that guide the model toward Pareto-optimal solutions, thereby harmonizing watermark detectability and text quality. By integrating LTW with two baseline watermarking methods, our experimental evaluations demonstrate that LTW significantly enhances text quality without compromising detectability. Our selective watermarking approach offers a new perspective for designing watermarks for LLMs and a way to preserve high text quality for watermarks. The code is publicly available at: this https URL"}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Bolster Hallucination Detection via Prompt-Guided Data Augmentation", "authors": "Wenyun Li, Zheng Zhang, Dongmei Jiang, Xiangyuan Lan", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "abstract": "Large language models (LLMs) have garnered significant interest in AI community. Despite their impressive generation capabilities, they have been found to produce misleading or fabricated information, a phenomenon known as hallucinations. Consequently, hallucination detection has become critical to ensure the reliability of LLM-generated content. One primary challenge in hallucination detection is the scarcity of well-labeled datasets containing both truthful and hallucinated outputs. To address this issue, we introduce Prompt-guided data Augmented haLlucination dEtection (PALE), a novel framework that leverages prompt-guided responses from LLMs as data augmentation for hallucination detection. This strategy can generate both truthful and hallucinated data under prompt guidance at a relatively low cost. To more effectively evaluate the truthfulness of the sparse intermediate embeddings produced by LLMs, we introduce an estimation metric called the Contrastive Mahalanobis Score (CM Score). This score is based on modeling the distributions of truthful and hallucinated data in the activation space. CM Score employs a matrix decomposition approach to more accurately capture the underlying structure of these distributions. Importantly, our framework does not require additional human annotations, offering strong generalizability and practicality for real-world applications. Extensive experiments demonstrate that PALE achieves superior hallucination detection performance, outperforming the competitive baseline by a significant margin of 6.55%."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          DAWP: A framework for global observation forecasting via Data Assimilation and Weather Prediction in satellite observation space", "authors": "Junchao Gong, Jingyi Xu, Ben Fei, Fenghua Ling, Wenlong Zhang, Kun Chen, Wanghan Xu, Weidong Yang, Xiaokang Yang, Lei Bai", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Atmospheric and Oceanic Physics (physics.ao-ph)", "abstract": "Weather prediction is a critical task for human society, where impressive progress has been made by training artificial intelligence weather prediction (AIWP) methods with reanalysis data. However, reliance on reanalysis data limits the AIWPs with shortcomings, including data assimilation biases and temporal discrepancies. To liberate AIWPs from the reanalysis data, observation forecasting emerges as a transformative paradigm for weather prediction. One of the key challenges in observation forecasting is learning spatiotemporal dynamics across disparate measurement systems with irregular high-resolution observation data, which constrains the design and prediction of AIWPs. To this end, we propose our DAWP as an innovative framework to enable AIWPs to operate in a complete observation space by initialization with an artificial intelligence data assimilation (AIDA) module. Specifically, our AIDA module applies a mask multi-modality autoencoder(MMAE)for assimilating irregular satellite observation tokens encoded by mask ViT-VAEs. For AIWP, we introduce a spatiotemporal decoupling transformer with cross-regional boundary conditioning (CBC), learning the dynamics in observation space, to enable sub-image-based global observation forecasting. Comprehensive experiments demonstrate that AIDA initialization significantly improves the roll out and efficiency of AIWP. Additionally, we show that DAWP holds promising potential to be applied in global precipitation forecasting."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Cog-Rethinker: Hierarchical Metacognitive Reinforcement Learning for LLM Reasoning", "authors": "Zexu Sun, Yongcheng Zeng, Erxue Min, Heyang Gao, Bokai Ji, Xu Chen", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "Contemporary progress in large language models (LLMs) has revealed notable inferential capacities via reinforcement learning (RL) employing verifiable reward, facilitating the development of O1 and R1-like reasoning models. Directly training from base models with RL is called zero-RL. However, previous works rely upon activating LLMs' inherent capacities through fixed prompt templates. This strategy introduces substantial sampling inefficiencies for weak LLMs, as the majority of problems generate invalid outputs during accuracy-driven filtration in reasoning tasks, which causes a waste of samples. To solve this issue, we propose Cog-Rethinker, a novel hierarchical metacognitive RL framework for LLM reasoning. Our Cog-Rethinker mainly focuses on the rollout procedure in RL training. After the direct rollout, our Cog-Rethinker improves sample utilization in a hierarchical metacognitive two-stage framework. By leveraging human cognition during solving problems, firstly, it prompts policy to decompose zero-accuracy problems into subproblems to produce final reasoning results. Secondly, with zero-accuracy problems in previous rollout stage, it further prompts policy to refine these answers by referencing previous wrong solutions. Moreover, to enable cold-start of the two new reasoning patterns and maintain train-test consistency across prompt templates, our Cog-Rethinker applies supervised fine-tuning on the policy using correct samples of the two stages with direct rollout template. Experimental results demonstrate Cog-Rethinker's superior performance on various mathematical reasoning benchmarks, we also analyzed its improved sample efficiency that accelerates convergence compared to baseline methods."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Cognitive Load Traces as Symbolic and Visual Accounts of Deep Model Cognition", "authors": "Dong Liu, Yanxuan Yu", "subjects": "Artificial Intelligence (cs.AI)", "abstract": "We propose \\textbf{Cognitive Load Traces} (CLTs) as a mid-level interpretability framework for deep models, inspired by Cognitive Load Theory in human cognition. CLTs are defined as symbolic, temporally varying functions that quantify model-internal resource allocation. Formally, we represent CLTs as a three-component stochastic process $(\\mathrm{IL}_t, \\mathrm{EL}_t, \\mathrm{GL}_t)$, corresponding to \\emph{Intrinsic}, \\emph{Extraneous}, and \\emph{Germane} load. Each component is instantiated through measurable proxies such as attention entropy, KV-cache miss ratio, representation dispersion, and decoding stability. We propose both symbolic formulations and visualization methods (load curves, simplex diagrams) that enable interpretable analysis of reasoning dynamics. Experiments on reasoning and planning benchmarks show that CLTs predict error-onset, reveal cognitive strategies, and enable load-guided interventions that improve reasoning efficiency by 15-30\\% while maintaining accuracy."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          ProofFlow: A Dependency Graph Approach to Faithful Proof Autoformalization", "authors": "Rafael Cabral, Tuan Manh Do, Xuejun Yu, Wai Ming Tai, Zijin Feng, Xin Shen", "subjects": "Artificial Intelligence (cs.AI); Logic in Computer Science (cs.LO)", "abstract": "Proof autoformalization, the task of translating natural language theorems and proofs into machine-verifiable code, is a critical step for integrating large language models into rigorous mathematical workflows. Current approaches focus on producing executable code, but they frequently fail to preserve the semantic meaning and logical structure of the original human-written argument. To address this, we introduce ProofFlow, a novel pipeline that treats structural fidelity as a primary objective. ProofFlow first constructs a directed acyclic graph (DAG) to map the logical dependencies between proof steps. Then, it employs a novel lemma-based approach to systematically formalize each step as an intermediate lemma, preserving the logical structure of the original argument. To facilitate evaluation, we present a new benchmark of 184 undergraduate-level problems, manually annotated with step-by-step solutions and logical dependency graphs, and introduce ProofScore, a new composite metric to evaluate syntactic correctness, semantic faithfulness, and structural fidelity. Experimental results show our pipeline sets a new state-of-the-art for autoformalization, achieving a ProofScore of 0.545, substantially exceeding baselines like full-proof formalization (0.123), which processes the entire proof at once, and step-proof formalization (0.072), which handles each step independently. Our pipeline, benchmark, and score metric are open-sourced to encourage further progress at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          AMiD: Knowledge Distillation for LLMs with $\u03b1$-mixture Assistant Distribution", "authors": "Donghyeok Shin, Yeongmin Kim, Suhyeon Jo, Byeonghu Na, Il-Chul Moon", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "Autoregressive large language models (LLMs) have achieved remarkable improvement across many tasks but incur high computational and memory costs. Knowledge distillation (KD) mitigates this issue by transferring knowledge from a large teacher to a smaller student through distributional alignment. Previous studies have proposed various discrepancy metrics, but the capacity gap and training instability caused by near-zero probabilities, stemming from the high-dimensional output of LLMs, remain fundamental limitations. To overcome these challenges, several approaches implicitly or explicitly incorporating assistant distribution have recently been proposed. However, the past proposals of assistant distributions have been a fragmented approach without a systematic investigation of the interpolation path and the divergence. This paper proposes $\\alpha$-mixture assistant distribution, a novel generalized family of assistant distributions, and $\\alpha$-mixture distillation, coined AMiD, a unified framework for KD using the assistant distribution. The $\\alpha$-mixture assistant distribution provides a continuous extension of the assistant distribution by introducing a new distribution design variable $\\alpha$, which has been fixed in all previous approaches. Furthermore, AMiD generalizes the family of divergences used with the assistant distributions based on optimality, which has also been restricted in previous works. Through extensive experiments, we demonstrate that AMiD offers superior performance and training stability by leveraging a broader and theoretically grounded assistant distribution space."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Ontologies in Motion: A BFO-Based Approach to Knowledge Graph Construction for Motor Performance Research Data in Sports Science", "authors": "Sarah Rebecca Ondraszek (1, 2), J\u00f6rg Waitelonis (1), Katja Keller (3), Claudia Niessner (3), Anna M. Jacyszyn (1), Harald Sack (1, 2) ((1) FIZ Karlsruhe - Leibniz Institute for Information Infrastructure, Eggenstein-Leopoldshafen, Germany, (2) Institute of Applied Informatics and Formal Description Methods (AIFB) of KIT, Karlsruhe, Germany, (3) Institute of Sports and Sports Science (IfSS) of KIT, Karlsruhe, Germany)", "subjects": "Artificial Intelligence (cs.AI)", "abstract": "An essential component for evaluating and comparing physical and cognitive capabilities between populations is the testing of various factors related to human performance. As a core part of sports science research, testing motor performance enables the analysis of the physical health of different demographic groups and makes them comparable. The Motor Research (MO|RE) data repository, developed at the Karlsruhe Institute of Technology, is an infrastructure for publishing and archiving research data in sports science, particularly in the field of motor performance research. In this paper, we present our vision for creating a knowledge graph from MO|RE data. With an ontology rooted in the Basic Formal Ontology, our approach centers on formally representing the interrelation of plan specifications, specific processes, and related measurements. Our goal is to transform how motor performance data are modeled and shared across studies, making it standardized and machine-understandable. The idea presented here is developed within the Leibniz Science Campus ``Digital Transformation of Research'' (DiTraRe)."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          MEET-Sepsis: Multi-Endogenous-View Enhanced Time-Series Representation Learning for Early Sepsis Prediction Representation Learning for Early Sepsis Prediction", "authors": "Zexi Tan, Tao Xie, Binbin Sun, Xiang Zhang, Yiqun Zhang, Yiu-Ming Cheung", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "Sepsis is a life-threatening infectious syndrome associated with high mortality in intensive care units (ICUs). Early and accurate sepsis prediction (SP) is critical for timely intervention, yet remains challenging due to subtle early manifestations and rapidly escalating mortality. While AI has improved SP efficiency, existing methods struggle to capture weak early temporal signals. This paper introduces a Multi-Endogenous-view Representation Enhancement (MERE) mechanism to construct enriched feature views, coupled with a Cascaded Dual-convolution Time-series Attention (CDTA) module for multi-scale temporal representation learning. The proposed MEET-Sepsis framework achieves competitive prediction accuracy using only 20% of the ICU monitoring time required by SOTA methods, significantly advancing early SP. Extensive validation confirms its efficacy. Code is available at: this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          User Profiles of Sleep Disorder Sufferers: Towards Explainable Clustering and Differential Variable Analysis", "authors": "Sifeddine Sellami (ERIC), Juba Agoun (ERIC), Lamia Yessad (ESI), Louenas Bounia (LIPN)", "subjects": "Machine Learning (cs.LG)", "abstract": "Sleep disorders have a major impact on patients' health and quality of life, but their diagnosis remains complex due to the diversity of symptoms. Today, technological advances, combined with medical data analysis, are opening new perspectives for a better understanding of these disorders. In particular, explainable artificial intelligence (XAI) aims to make AI model decisions understandable and interpretable for users. In this study, we propose a clustering-based method to group patients according to different sleep disorder profiles. By integrating an explainable approach, we identify the key factors influencing these pathologies. An experiment on anonymized real data illustrates the effectiveness and relevance of our approach."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Algorithmic Primitives and Compositional Geometry of Reasoning in Language Models", "authors": "Samuel Lippl, Thomas McGee, Kimberly Lopez, Ziwen Pan, Pierce Zhang, Salma Ziadi, Oliver Eberle, Ida Momennejad", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "How do latent and inference time computations enable large language models (LLMs) to solve multi-step reasoning? We introduce a framework for tracing and steering algorithmic primitives that underlie model reasoning. Our approach links reasoning traces to internal activation patterns and evaluates algorithmic primitives by injecting them into residual streams and measuring their effect on reasoning steps and task performance. We consider four benchmarks: Traveling Salesperson Problem (TSP), 3SAT, AIME, and graph navigation. We operationalize primitives by clustering neural activations and labeling their matched reasoning traces. We then apply function vector methods to derive primitive vectors as reusable compositional building blocks of reasoning. Primitive vectors can be combined through addition, subtraction, and scalar operations, revealing a geometric logic in activation space. Cross-task and cross-model evaluations (Phi-4, Phi-4-Reasoning, Llama-3-8B) show both shared and task-specific primitives. Notably, comparing Phi-4 with its reasoning-finetuned variant highlights compositional generalization after finetuning: Phi-4-Reasoning exhibits more systematic use of verification and path-generation primitives. Injecting the associated primitive vectors in Phi-4-Base induces behavioral hallmarks associated with Phi-4-Reasoning. Together, these findings demonstrate that reasoning in LLMs may be supported by a compositional geometry of algorithmic primitives, that primitives transfer cross-task and cross-model, and that reasoning finetuning strengthens algorithmic generalization across domains."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Meta-Guardian: An Early Evaluation of an On-device Application to Mitigate Psychography Data Leakage in Immersive Technologies", "authors": "Keshav Sood, Sanjay Selvaraj, Youyang Qu", "subjects": "Cryptography and Security (cs.CR); Emerging Technologies (cs.ET)", "abstract": "The use of Immersive Technologies has shown its potential to revolutionize many sectors such as health, entertainment, education, and industrial sectors. Immersive technologies such as Virtual Reality (VR), Augmented reality (AR), and Mixed Reality (MR) have redefined user interaction through real-time biometric and behavioral tracking. Although Immersive Technologies (XR) essentially need the collection of the biometric data which acts as a baseline to create immersive experience, however, this ongoing feedback information (includes biometrics) poses critical privacy concerns due to the sensitive nature of the data collected. A comprehensive review of recent literature explored the technical dimensions of related problem; however, they largely overlook the challenge particularly the intricacies of real-time biometric data filtering within head-mounted display system. Motivated from this, in this work, we propose a novel privacy-preserving system architecture that identifies and filters biometric signals (within the VR headset) in real-time before transmission or storage. Implemented as a modular Unity Software-development Kit (SDK) compatible with major immersive platforms, our solution (named Meta-Guardian) employs machine learning models for signal classification and a filtering mechanism to block sensitive data. This framework aims to enable developers to embed privacy-by-design principles into immersive experiences on various headsets and applications."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Can GRPO Help LLMs Transcend Their Pretraining Origin?", "authors": "Kangqi Ni, Zhen Tan, Zijie Liu, Pingzhi Li, Tianlong Chen", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR), primarily driven by the Group Relative Policy Optimization (GRPO) algorithm, is a leading approach for enhancing the reasoning abilities of Large Language Models (LLMs). Despite its wide adoption, GRPO's gains are often inconsistent; for instance, a model may show significant improvement in one reasoning domain, like mathematics, yet remain stagnant in another, such as medicine. This inconsistency raises a critical question: under what conditions does GRPO improve reasoning and generalize out-of-distribution (OOD)? We investigate this from a data distribution perspective. We first prove theoretically that GRPO is a conservative reweighting scheme, bounded by the base model's distribution and thus unable to discover completely novel solutions. We further validate this in carefully designed controlled studies by training transformers from scratch, evaluating generalization across reasoning depth, input length, token representation, and compositionality. Our results provide a principled explanation for GRPO's boundaries: OOD improvement emerges only when the target task aligns with the model's pretrained biases, while gains on in-distribution (ID) tasks diminish as performance saturates. This reframes GRPO not as a universal reasoning enhancer but as a tool that sharpens pretraining biases. Our findings motivate future development of algorithms that can expand a model's capabilities beyond its pretraining origin."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          CrossRay3D: Geometry and Distribution Guidance for Efficient Multimodal 3D Detection", "authors": "Huiming Yang", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "The sparse cross-modality detector offers more advantages than its counterpart, the Bird's-Eye-View (BEV) detector, particularly in terms of adaptability for downstream tasks and computational cost savings. However, existing sparse detectors overlook the quality of token representation, leaving it with a sub-optimal foreground quality and limited performance. In this paper, we identify that the geometric structure preserved and the class distribution are the key to improving the performance of the sparse detector, and propose a Sparse Selector (SS). The core module of SS is Ray-Aware Supervision (RAS), which preserves rich geometric information during the training stage, and Class-Balanced Supervision, which adaptively reweights the salience of class semantics, ensuring that tokens associated with small objects are retained during token sampling. Thereby, outperforming other sparse multi-modal detectors in the representation of tokens. Additionally, we design Ray Positional Encoding (Ray PE) to address the distribution differences between the LiDAR modality and the image. Finally, we integrate the aforementioned module into an end-to-end sparse multi-modality detector, dubbed CrossRay3D. Experiments show that, on the challenging nuScenes benchmark, CrossRay3D achieves state-of-the-art performance with 72.4 mAP and 74.7 NDS, while running 1.84 faster than other leading methods. Moreover, CrossRay3D demonstrates strong robustness even in scenarios where LiDAR or camera data are partially or entirely missing."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Stratos: An End-to-End Distillation Pipeline for Customized LLMs under Distributed Cloud Environments", "authors": "Ziming Dai, Tuo Zhang, Fei Gao, Xingyi Cai, Xiaofei Wang, Cheng Zhang, Wenyu Wang, Chengjie Zang", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "The growing industrial demand for customized and cost-efficient large language models (LLMs) is fueled by the rise of vertical, domain-specific tasks and the need to optimize performance under constraints such as latency and budget. Knowledge distillation, as an efficient model compression and transfer technique, offers a feasible solution. However, existing distillation frameworks often require manual intervention and struggle to meet such complex user-defined distillation requirements. To bridge this gap, we propose Stratos, an end-to-end LLM distillation pipeline that automates server and model selection, knowledge distillation, and deployment in distributed cloud environments. Given user-defined constraints on model performance and system budget, Stratos automatically selects Pareto-optimal servers, dynamically matches teacher-student pairs, and adapts distillation strategies based on task complexity to optimize cloud hosting. Experiments show that Stratos produces a student model that achieves four times the accuracy of its GPT-4o teacher baseline on a rare, domain-specific Mahjong reasoning task with reverse synthetic data and knowledge injection. Moreover, it achieves reduced latency and cost without compromising accuracy. These results highlight its promise for vertical-domain LLM deployment."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          MCP Security Bench (MSB): Benchmarking Attacks Against Model Context Protocol in LLM Agents", "authors": "Dongsen Zhang, Zekun Li, Xu Luo, Xuannan Liu, Peipei Li, Wenjun Xu", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "abstract": "The Model Context Protocol (MCP) standardizes how large language model (LLM) agents discover, describe, and call external tools. While MCP unlocks broad interoperability, it also enlarges the attack surface by making tools first-class, composable objects with natural-language metadata, and standardized I/O. We present MSB (MCP Security Benchmark), the first end-to-end evaluation suite that systematically measures how well LLM agents resist MCP-specific attacks throughout the full tool-use pipeline: task planning, tool invocation, and response handling. MSB contributes: (1) a taxonomy of 12 attacks including name-collision, preference manipulation, prompt injections embedded in tool descriptions, out-of-scope parameter requests, user-impersonating responses, false-error escalation, tool-transfer, retrieval injection, and mixed attacks; (2) an evaluation harness that executes attacks by running real tools (both benign and malicious) via MCP rather than simulation; and (3) a robustness metric that quantifies the trade-off between security and performance: Net Resilient Performance (NRP). We evaluate nine popular LLM agents across 10 domains and 400+ tools, producing 2,000 attack instances. Results reveal the effectiveness of attacks against each stage of MCP. Models with stronger performance are more vulnerable to attacks due to their outstanding tool calling and instruction following capabilities. MSB provides a practical baseline for researchers and practitioners to study, compare, and harden MCP agents."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Using Kolmogorov-Smirnov Distance for Measuring Distribution Shift in Machine Learning", "authors": "Ozan K. Tonguz, Federico Taschin", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "One of the major problems in Machine Learning (ML) and Artificial Intelligence (AI) is the fact that the probability distribution of the test data in the real world could deviate substantially from the probability distribution of the training data set. When this happens, the predictions of an ML system or an AI agent could involve large errors which is very troublesome and undesirable. While this is a well-known hard problem plaguing the AI and ML systems' accuracy and reliability, in certain applications such errors could be critical for safety and reliability of AI and ML systems. One approach to deal with this problem is to monitor and measure the deviation in the probability distribution of the test data in real time and to compensate for this deviation. In this paper, we propose and explore the use of Kolmogorov-Smirnov (KS) Test for measuring the distribution shift and we show how the KS distance can be used to quantify the distribution shift and its impact on an AI agent's performance. Our results suggest that KS distance could be used as a valuable statistical tool for monitoring and measuring the distribution shift. More specifically, it is shown that even a distance of KS=0.02 could lead to about 50\\% increase in the travel time at a single intersection using a Reinforcement Learning agent which is quite significant. It is hoped that the use of KS Test and KS distance in AI-based smart transportation could be an important step forward for gauging the performance degradation of an AI agent in real time and this, in turn, could help the AI agent to cope with the distribution shift in a more informed manner."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          AMStraMGRAM: Adaptive Multi-cutoff Strategy Modification for ANaGRAM", "authors": "Nilo Schwencke (LISN, TAU), Cyriaque Rousselot (TAU, LISN), Alena Shilova (TAU, LISN), Cyril Furtlehner (LRI, TAU)", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "Recent works have shown that natural gradient methods can significantly outperform standard optimizers when training physics-informed neural networks (PINNs). In this paper, we analyze the training dynamics of PINNs optimized with ANaGRAM, a natural-gradient-inspired approach employing singular value decomposition with cutoff regularization. Building on this analysis, we propose a multi-cutoff adaptation strategy that further enhances ANaGRAM's performance. Experiments on benchmark PDEs validate the effectiveness of our method, which allows to reach machine precision on some experiments. To provide theoretical grounding, we develop a framework based on spectral theory that explains the necessity of regularization and extend previous shown connections with Green's functions theory."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          A Non-overlap-based Conflict Measure for Random Permutation Sets", "authors": "Ruolan Cheng, Yong Deng, Enrique Herrera-Viedma", "subjects": "Artificial Intelligence (cs.AI)", "abstract": "Random permutation set (RPS) is a new formalism for reasoning with uncertainty involving order information. Measuring the conflict between two pieces of evidence represented by permutation mass functions remains an urgent research topic in order-structured uncertain information fusion. In this paper, a detailed analysis of conflicts in RPS is carried out from two different perspectives: random finite set (RFS) and Dempster-Shafer theory (DST). Starting from the observation of permutations, we first define an inconsistency measure between permutations inspired by the rank-biased overlap(RBO) measure and further propose a non-overlap-based conflict measure method for RPSs. This paper regards RPS theory (RPST) as an extension of DST. The order information newly added in focal sets indicates qualitative propensity, characterized by top-ranked elements occupying a more critical position. Some numerical examples are used to demonstrate the behavior and properties of the proposed conflict measure. The proposed method not only has the natural top-weightedness property and can effectively measure the conflict between RPSs from the DST view but also provides decision-makers with a flexible selection of weights, parameters, and truncated depths."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          PAINT: Parallel-in-time Neural Twins for Dynamical System Reconstruction", "authors": "Andreas Radler, Vincent Seyfried, Stefan Pirker, Johannes Brandstetter, Thomas Lichtenegger", "subjects": "Artificial Intelligence (cs.AI); Fluid Dynamics (physics.flu-dyn)", "abstract": "Neural surrogates have shown great potential in simulating dynamical systems, while offering real-time capabilities. We envision Neural Twins as a progression of neural surrogates, aiming to create digital replicas of real systems. A neural twin consumes measurements at test time to update its state, thereby enabling context-specific decision-making. A critical property of neural twins is their ability to remain on-trajectory, i.e., to stay close to the true system state over time. We introduce Parallel-in-time Neural Twins (PAINT), an architecture-agnostic family of methods for modeling dynamical systems from measurements. PAINT trains a generative neural network to model the distribution of states parallel over time. At test time, states are predicted from measurements in a sliding window fashion. Our theoretical analysis shows that PAINT is on-trajectory, whereas autoregressive models generally are not. Empirically, we evaluate our method on a challenging two-dimensional turbulent fluid dynamics problem. The results demonstrate that PAINT stays on-trajectory and predicts system states from sparse measurements with high fidelity. These findings underscore PAINT's potential for developing neural twins that stay on-trajectory, enabling more accurate state estimation and decision-making."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Breaking Guardrails, Facing Walls: Insights on Adversarial AI for Defenders & Researchers", "authors": "Giacomo Bertollo, Naz Bodemir, Jonah Burgess", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "abstract": "Analyzing 500 CTF participants, this paper shows that while participants readily bypassed simple AI guardrails using common techniques, layered multi-step defenses still posed significant challenges, offering concrete insights for building safer AI systems."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Layer-Aware Influence for Online Data Valuation Estimation", "authors": "Ziao Yang, Longbo Huang, Hongfu Liu", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "Data-centric learning emphasizes curating high-quality training samples to boost performance rather than designing new architectures. A central problem is to estimate the influence of training sample efficiently. Prior studies largely focus on static influence measured on a converged model, overlooking how data valuation dynamically changes during optimization. This omission neglects the dynamic nature of sample influence during optimization, especially in deep models. To address the computational burden of frequent influence estimation, we develop a layer-aware online estimator that requires only loss-to-output gradients. This design avoids parameter-level and full-network gradients while preserving ranking fidelity. Extensive experiments across LLM pretraining, fine-tuning, and image classification show our method improves accuracy with substantially lower time and memory cost, making dynamic data curation efficient and scalable in practice."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          STAR: Boosting Time Series Foundation Models for Anomaly Detection through State-aware Adapter", "authors": "Hanyin Cheng, Ruitong Zhang, Yuning Lu, Peng Chen, Meng Wang, Yang Shu, Bin Yang, Chenjuan Guo", "subjects": "Machine Learning (cs.LG)", "abstract": "While Time Series Foundation Models (TSFMs) have demonstrated remarkable success in Multivariate Time Series Anomaly Detection (MTSAD), however, in real-world industrial scenarios, many time series comprise not only numerical variables such as temperature and flow, but also numerous discrete state variables that describe the system status, such as valve on/off or day of the week. Existing TSFMs often overlook the distinct categorical nature of state variables and their critical role as conditions, typically treating them uniformly with numerical variables. This inappropriate modeling approach prevents the model from fully leveraging state information and even leads to a significant degradation in detection performance after state variables are integrated. To address this critical limitation, this paper proposes a novel STate-aware AdapteR (STAR). STAR is a plug-and-play module designed to enhance the capability of TSFMs in modeling and leveraging state variables during the fine-tuning stage. Specifically, STAR comprisesthree core components: (1) We design an Identity-guided State Encoder, whicheffectively captures the complex categorical semantics of state variables through a learnable State Memory. (2) We propose a Conditional Bottleneck Adapter, which dynamically generates low-rank adaptation parameters conditioned on the current state, thereby flexibly injecting the influence of state variables into the backbone model. (3) We also introduce a Numeral-State Matching module to more effectively detect anomalies inherent to the state variables themselves. Extensive experiments conducted on real-world datasets demonstrate that STAR can improve the performance of existing TSFMs on MTSAD."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Decision-focused Sensing and Forecasting for Adaptive and Rapid Flood Response: An Implicit Learning Approach", "authors": "Qian Sun, Graham Hults, Susu Xu", "subjects": "Machine Learning (cs.LG)", "abstract": "Timely and reliable decision-making is vital for flood emergency response, yet it remains severely hindered by limited and imprecise situational awareness due to various budget and data accessibility constraints. Traditional flood management systems often rely on in-situ sensors to calibrate remote sensing-based large-scale flood depth forecasting models, and further take flood depth estimates to optimize flood response decisions. However, these approaches often take fixed, decision task-agnostic strategies to decide where to put in-situ sensors (e.g., maximize overall information gain) and train flood forecasting models (e.g., minimize average forecasting errors), but overlook that systems with the same sensing gain and average forecasting errors may lead to distinct decisions. To address this, we introduce a novel decision-focused framework that strategically selects locations for in-situ sensor placement and optimize spatio-temporal flood forecasting models to optimize downstream flood response decision regrets. Our end-to-end pipeline integrates four components: a contextual scoring network, a differentiable sensor selection module under hard budget constraints, a spatio-temporal flood reconstruction and forecasting model, and a differentiable decision layer tailored to task-specific objectives. Central to our approach is the incorporation of Implicit Maximum Likelihood Estimation (I-MLE) to enable gradient-based learning over discrete sensor configurations, and probabilistic decision heads to enable differentiable approximation to various constrained disaster response tasks."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Transfer learning strategies for accelerating reinforcement-learning-based flow control", "authors": "Saeed Salehi", "subjects": "Machine Learning (cs.LG); Fluid Dynamics (physics.flu-dyn)", "abstract": "This work investigates transfer learning strategies to accelerate deep reinforcement learning (DRL) for multifidelity control of chaotic fluid flows. Progressive neural networks (PNNs), a modular architecture designed to preserve and reuse knowledge across tasks, are employed for the first time in the context of DRL-based flow control. In addition, a comprehensive benchmarking of conventional fine-tuning strategies is conducted, evaluating their performance, convergence behavior, and ability to retain transferred knowledge. The Kuramoto-Sivashinsky (KS) system is employed as a benchmark to examine how knowledge encoded in control policies, trained in low-fidelity environments, can be effectively transferred to high-fidelity settings. Systematic evaluations show that while fine-tuning can accelerate convergence, it is highly sensitive to pretraining duration and prone to catastrophic forgetting. In contrast, PNNs enable stable and efficient transfer by preserving prior knowledge and providing consistent performance gains, and are notably robust to overfitting during the pretraining phase. Layer-wise sensitivity analysis further reveals how PNNs dynamically reuse intermediate representations from the source policy while progressively adapting deeper layers to the target task. Moreover, PNNs remain effective even when the source and target environments differ substantially, such as in cases with mismatched physical regimes or control objectives, where fine-tuning strategies often result in suboptimal adaptation or complete failure of knowledge transfer. The results highlight the potential of novel transfer learning frameworks for robust, scalable, and computationally efficient flow control that can potentially be applied to more complex flow configurations."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          InfraGPT Smart Infrastructure: An End-to-End VLM-Based Framework for Detecting and Managing Urban Defects", "authors": "Ibrahim Sheikh Mohamed, Abdullah Yahya Abdullah Omaisan", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Robotics (cs.RO)", "abstract": "Infrastructure in smart cities is increasingly monitored by networks of closed circuit television (CCTV) cameras. Roads, bridges and tunnels develop cracks, potholes, and fluid leaks that threaten public safety and require timely repair. Manual inspection is costly and hazardous, and existing automatic systems typically address individual defect types or provide unstructured outputs that cannot directly guide maintenance crews. This paper proposes a comprehensive pipeline that leverages street CCTV streams for multi defect detection and segmentation using the YOLO family of object detectors and passes the detections to a vision language model (VLM) for scene aware summarization. The VLM generates a structured action plan in JSON format that includes incident descriptions, recommended tools, dimensions, repair plans, and urgent alerts. We review literature on pothole, crack and leak detection, highlight recent advances in large vision language models such as QwenVL and LLaVA, and describe the design of our early prototype. Experimental evaluation on public datasets and captured CCTV clips demonstrates that the system accurately identifies diverse defects and produces coherent summaries. We conclude by discussing challenges and directions for scaling the system to city wide deployments."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Impact of AI Tools on Learning Outcomes: Decreasing Knowledge and Over-Reliance", "authors": "M\u00e1rton Benedek, Bal\u00e1zs R. Sziklai", "subjects": "Computers and Society (cs.CY)", "abstract": "Students at all levels of education are increasingly relying on generative artificial intelligence (AI) tools to complete assignments and achieve higher exam scores. However, it remains unclear how this reliance affects their motivation, their genuine understanding of the material, and the extent to which it substitutes for the process of knowledge acquisition. To investigate the impact of generative AI on learning outcomes, an experiment was conducted at Corvinus University of Budapest. In an operations research class, students were randomly assigned into two groups: one was permitted to use AI tools during classes and examinations, while the other was not. To ensure fairness, a compensation mechanism was introduced: students in the lower-performing group received point adjustments until the average performance of the two groups was equalized. Despite the organizers' best efforts to explain the design and to create equal opportunities for all participants, many students perceived the experiment as a major disruption. Although the experiment was approved by every relevant university authority -- including the Ethics Board, the Head of Department, the Program Director, and the Student Council -- students escalated their concerns to the media and eventually to the State Secretary for Higher Education of Hungary. As a result, the experiment had to be substantially revised before completion: on the final exam the test group was merged with the control group. Still, the data allowed us to draw decisive conclusions regarding the students' learning habits. Uncontrolled use of AI tools leads to disengaged students and low understanding of material. The extreme reactions of the students proved even more revealing than the data collected: generative AI tools have already become indispensable for students, raising fundamental questions about the validity of their learning process."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Airfoil optimization using Design-by-Morphing with minimized design-space dimensionality", "authors": "Sangjoon Lee, Haris Moazam Sheikh", "subjects": "Machine Learning (cs.LG)", "abstract": "Effective airfoil geometry optimization requires exploring a diverse range of designs using as few design variables as possible. This study introduces AirDbM, a Design-by-Morphing (DbM) approach specialized for airfoil optimization that systematically reduces design-space dimensionality. AirDbM selects an optimal set of 12 baseline airfoils from the UIUC airfoil database, which contains over 1,600 shapes, by sequentially adding the baseline that most increases the design capacity. With these baselines, AirDbM reconstructs 99 \\% of the database with a mean absolute error below 0.005, which matches the performance of a previous DbM approach that used more baselines. In multi-objective aerodynamic optimization, AirDbM demonstrates rapid convergence and achieves a Pareto front with a greater hypervolume than that of the previous larger-baseline study, where new Pareto-optimal solutions are discovered with enhanced lift-to-drag ratios at moderate stall tolerances. Furthermore, AirDbM demonstrates outstanding adaptability for reinforcement learning (RL) agents in generating airfoil geometry when compared to conventional airfoil parameterization methods, implying the broader potential of DbM in machine learning-driven design."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Feature-driven reinforcement learning for photovoltaic in continuous intraday trading", "authors": "Arega Getaneh Abate, Xiufeng Liu, Ruyu Liu, Xiaobing Zhang", "subjects": "Machine Learning (cs.LG); General Economics (econ.GN)", "abstract": "Photovoltaic (PV) operators face substantial uncertainty in generation and short-term electricity prices. Continuous intraday markets enable producers to adjust their positions in real time, potentially improving revenues and reducing imbalance costs. We propose a feature-driven reinforcement learning (RL) approach for PV intraday trading that integrates data-driven features into the state and learns bidding policies in a sequential decision framework. The problem is cast as a Markov Decision Process with a reward that balances trading profit and imbalance penalties and is solved with Proximal Policy Optimization (PPO) using a predominantly linear, interpretable policy. Trained on historical market data and evaluated out-of-sample, the strategy consistently outperforms benchmark baselines across diverse scenarios. Extensive validation shows rapid convergence, real-time inference, and transparent decision rules. Learned weights highlight the central role of market microstructure and historical features. Taken together, these results indicate that feature-driven RL offers a practical, data-efficient, and operationally deployable pathway for active intraday participation by PV producers."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Breaking Memorization Barriers in LLM Code Fine-Tuning via Information Bottleneck for Improved Generalization", "authors": "Changsheng Wang, Xin Chen, Sijia Liu, Ke Ding", "subjects": "Machine Learning (cs.LG); Software Engineering (cs.SE)", "abstract": "Adapting pretrained large language models (LLMs) to code domains via supervised fine-tuning (FT) has been commonly used for code generation. However, we identify a previously underappreciated failure mode, the memorization barrier, where strong memorization of downstream code data in the base model could trap optimization and prevent the standard FT from effectively acquiring new, generalizable code knowledge. To overcome this barrier, we propose the information bottleneck (IB)-guided fine-tuning, termed IB-FT, which applies an IB penalty on hidden representations of the code data to compress spurious, memorized features while preserving task-relevant information. Extensive experiments on two code benchmarks (OriGen and Evol-CodeAlpaca-V1) show that IB-FT substantially alleviates the memorization barrier, improves top-1 performance (Pass@$1$), and yields far more stable gains under the stricter multi-sample metric Pass@$k^{(m)}$ (a problem counts as solved only if at least $m$ of $k$ samples pass unit tests) compared with conventional FT."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Unifying Polymer Modeling and Design via a Conformation-Centric Generative Foundation Model", "authors": "Fanmeng Wang, Shan Mei, Wentao Guo, Hongshuai Wang, Qi Ou, Zhifeng Gao, Hongteng Xu", "subjects": "Machine Learning (cs.LG); Materials Science (cond-mat.mtrl-sci)", "abstract": "Polymers, macromolecules formed from covalently bonded monomers, underpin countless technologies and are indispensable to modern life. While deep learning is advancing polymer science, existing methods typically represent the whole polymer solely through monomer-level descriptors, overlooking the global structural information inherent in polymer conformations, which ultimately limits their practical performance. Moreover, this field still lacks a universal foundation model that can effectively support diverse downstream tasks, thereby severely constraining progress. To address these challenges, we introduce PolyConFM, the first polymer foundation model that unifies polymer modeling and design through conformation-centric generative pretraining. Recognizing that each polymer conformation can be decomposed into a sequence of local conformations (i.e., those of its repeating units), we pretrain PolyConFM under the conditional generation paradigm, reconstructing these local conformations via masked autoregressive (MAR) modeling and further generating their orientation transformations to recover the corresponding polymer conformation. Besides, we construct the first high-quality polymer conformation dataset via molecular dynamics simulations to mitigate data sparsity, thereby enabling conformation-centric pretraining. Experiments demonstrate that PolyConFM consistently outperforms representative task-specific methods on diverse downstream tasks, equipping polymer science with a universal and powerful tool."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          On-Chain Decentralized Learning and Cost-Effective Inference for DeFi Attack Mitigation", "authors": "Abdulrahman Alhaidari, Balaji Palanisamy, Prashant Krishnamurthy", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)", "abstract": "Billions of dollars are lost every year in DeFi platforms by transactions exploiting business logic or accounting vulnerabilities. Existing defenses focus on static code analysis, public mempool screening, attacker contract detection, or trusted off-chain monitors, none of which prevents exploits submitted through private relays or malicious contracts that execute within the same block. We present the first decentralized, fully on-chain learning framework that: (i) performs gas-prohibitive computation on Layer-2 to reduce cost, (ii) propagates verified model updates to Layer-1, and (iii) enables gas-bounded, low-latency inference inside smart contracts. A novel Proof-of-Improvement (PoIm) protocol governs the training process and verifies each decentralized micro update as a self-verifying training transaction. Updates are accepted by \\textit{PoIm} only if they demonstrably improve at least one core metric (e.g., accuracy, F1-score, precision, or recall) on a public benchmark without degrading any of the other core metrics, while adversarial proposals get financially penalized through an adaptable test set for evolving threats. We develop quantization and loop-unrolling techniques that enable inference for logistic regression, SVM, MLPs, CNNs, and gated RNNs (with support for formally verified decision tree inference) within the Ethereum block gas limit, while remaining bit-exact to their off-chain counterparts, formally proven in Z3. We curate 298 unique real-world exploits (2020 - 2025) with 402 exploit transactions across eight EVM chains, collectively responsible for \\$3.74 B in losses."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Resource Estimation of CGGI and CKKS scheme workloads on FracTLcore Computing Fabric", "authors": "Denis Ovichinnikov, Hemant Kavadia, Satya Keerti Chand Kudupudi, Ilya Rempel, Vineet Chadha, Marty Franz, Paul Master, Craig Gentry, Darlene Kindler, Alberto Reyes, Muthu Annamalai", "subjects": "Cryptography and Security (cs.CR)", "abstract": "Cornami Mx2 accelerates of Fully Homomorphic Encryption (FHE) applications, enabled by breakthrough work [1], which are otherwise compute limited. Our processor architecture is based on the systolic array of cores with in-memory compute capability and a network on chip (NoC) processor architecture called the \"FracTLcore compute fabric processor\" (Mx2). Here, we describe the work to estimate processor resources to compute workload in CGGI (TFHE-rs) or CKKS scheme during construction of our compiler backend for this architecture [2]. These processors are available for running applications in both the TFHE-rs Boolean scheme and CKKS scheme FHE applications."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          A tutorial on discovering and quantifying the effect of latent causal sources of multimodal EHR data", "authors": "Marco Barbero-Mota, Eric V. Strobl, John M. Still, William W. Stead, Thomas A. Lasko", "subjects": "Machine Learning (cs.LG); Applications (stat.AP)", "abstract": "We provide an accessible description of a peer-reviewed generalizable causal machine learning pipeline to (i) discover latent causal sources of large-scale electronic health records observations, and (ii) quantify the source causal effects on clinical outcomes. We illustrate how imperfect multimodal clinical data can be processed, decomposed into probabilistic independent latent sources, and used to train taskspecific causal models from which individual causal effects can be estimated. We summarize the findings of the two real-world applications of the approach to date as a demonstration of its versatility and utility for medical discovery at scale."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Nondeterminism-Aware Optimistic Verification for Floating-Point Neural Networks", "authors": "Jianzhu Yao, Hongxu Su, Taobo Liao, Zerui Cheng, Huan Zhang, Xuechao Wang, Pramod Viswanath", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Systems and Control (eess.SY)", "abstract": "Neural networks increasingly run on hardware outside the user's control (cloud GPUs, inference marketplaces). Yet ML-as-a-Service reveals little about what actually ran or whether returned outputs faithfully reflect the intended inputs. Users lack recourse against service downgrades (model swaps, quantization, graph rewrites, or discrepancies like altered ad embeddings). Verifying outputs is hard because floating-point(FP) execution on heterogeneous accelerators is inherently nondeterministic. Existing approaches are either impractical for real FP neural networks or reintroduce vendor trust. We present NAO: a Nondeterministic tolerance Aware Optimistic verification protocol that accepts outputs within principled operator-level acceptance regions rather than requiring bitwise equality. NAO combines two error models: (i) sound per-operator IEEE-754 worst-case bounds and (ii) tight empirical percentile profiles calibrated across hardware. Discrepancies trigger a Merkle-anchored, threshold-guided dispute game that recursively partitions the computation graph until one operator remains, where adjudication reduces to a lightweight theoretical-bound check or a small honest-majority vote against empirical thresholds. Unchallenged results finalize after a challenge window, without requiring trusted hardware or deterministic kernels. We implement NAO as a PyTorch-compatible runtime and a contract layer currently deployed on Ethereum Holesky testnet. The runtime instruments graphs, computes per-operator bounds, and runs unmodified vendor kernels in FP32 with negligible overhead (0.3% on Qwen3-8B). Across CNNs, Transformers and diffusion models on A100, H100, RTX6000, RTX4090, empirical thresholds are $10^2-10^3$ times tighter than theoretical bounds, and bound-aware adversarial attacks achieve 0% success. NAO reconciles scalability with verifiability for real-world heterogeneous ML compute."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          A dual typology of social media interventions and deterrence mechanisms against misinformation", "authors": "Amir Karami", "subjects": "Computers and Society (cs.CY)", "abstract": "In response to the escalating threat of misinformation, social media platforms have introduced a wide range of interventions aimed at reducing the spread and influence of false information. However, there is a lack of a coherent macrolevel perspective that explains how these interventions operate independently and collectively. To address this gap, I offer a dual typology through a spectrum of interventions aligned with deterrence theory and drawing parallels from international relations, military, cybersecurity, and public health. I argue that five major types of platform interventions, including removal, reduction, informing, composite, and multimodal, can be mapped to five corresponding deterrence mechanisms, including hard, situational, soft, integrated, and mixed deterrence based on purpose and perceptibility. These mappings illuminate how platforms apply varying degrees of deterrence mechanisms to influence user behavior."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Global-focal Adaptation with Information Separation for Noise-robust Transfer Fault Diagnosis", "authors": "Junyu Ren, Wensheng Gan, Guangyu Zhang, Wei Zhong, Philip S. Yu", "subjects": "Artificial Intelligence (cs.AI)", "abstract": "Existing transfer fault diagnosis methods typically assume either clean data or sufficient domain similarity, which limits their effectiveness in industrial environments where severe noise interference and domain shifts coexist. To address this challenge, we propose an information separation global-focal adversarial network (ISGFAN), a robust framework for cross-domain fault diagnosis under noise conditions. ISGFAN is built on an information separation architecture that integrates adversarial learning with an improved orthogonal loss to decouple domain-invariant fault representation, thereby isolating noise interference and domain-specific characteristics. To further strengthen transfer robustness, ISGFAN employs a global-focal domain-adversarial scheme that constrains both the conditional and marginal distributions of the model. Specifically, the focal domain-adversarial component mitigates category-specific transfer obstacles caused by noise in unsupervised scenarios, while the global domain classifier ensures alignment of the overall distribution. Experiments conducted on three public benchmark datasets demonstrate that the proposed method outperforms other prominent existing approaches, confirming the superiority of the ISGFAN framework. Data and code are available at this https URL"}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Disaster Management in the Era of Agentic AI Systems: A Vision for Collective Human-Machine Intelligence for Augmented Resilience", "authors": "Bo Li, Junwei Ma, Kai Yin, Yiming Xiao, Chia-Wei Hsu, Ali Mostafavi", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "abstract": "The escalating frequency and severity of disasters routinely overwhelm traditional response capabilities, exposing critical vulnerability in disaster management. Current practices are hindered by fragmented data streams, siloed technologies, resource constraints, and the erosion of institutional memory, which collectively impede timely and effective decision making. This study introduces Disaster Copilot, a vision for a multi-agent artificial intelligence system designed to overcome these systemic challenges by unifying specialized AI tools within a collaborative framework. The proposed architecture utilizes a central orchestrator to coordinate diverse sub-agents, each specializing in critical domains such as predictive risk analytics, situational awareness, and impact assessment. By integrating multi-modal data, the system delivers a holistic, real-time operational picture and serve as the essential AI backbone required to advance Disaster Digital Twins from passive models to active, intelligent environments. Furthermore, it ensures functionality in resource-limited environments through on-device orchestration and incorporates mechanisms to capture institutional knowledge, mitigating the impact of staff turnover. We detail the system architecture and propose a three-phased roadmap emphasizing the parallel growth of technology, organizational capacity, and human-AI teaming. Disaster Copilot offers a transformative vision, fostering collective human-machine intelligence to build more adaptive, data-driven and resilient communities."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          RoBCtrl: Attacking GNN-Based Social Bot Detectors via Reinforced Manipulation of Bots Control Interaction", "authors": "Yingguang Yang, Xianghua Zeng, Qi Wu, Hao Peng, Yutong Xia, Hao Liu, Bin Chong, Philip S. Yu", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)", "abstract": "Social networks have become a crucial source of real-time information for individuals. The influence of social bots within these platforms has garnered considerable attention from researchers, leading to the development of numerous detection technologies. However, the vulnerability and robustness of these detection methods is still underexplored. Existing Graph Neural Network (GNN)-based methods cannot be directly applied due to the issues of limited control over social agents, the black-box nature of bot detectors, and the heterogeneity of bots. To address these challenges, this paper proposes the first adversarial multi-agent Reinforcement learning framework for social Bot control attacks (RoBCtrl) targeting GNN-based social bot detectors. Specifically, we use a diffusion model to generate high-fidelity bot accounts by reconstructing existing account data with minor modifications, thereby evading detection on social platforms. To the best of our knowledge, this is the first application of diffusion models to mimic the behavior of evolving social bots effectively. We then employ a Multi-Agent Reinforcement Learning (MARL) method to simulate bots adversarial behavior. We categorize social accounts based on their influence and budget. Different agents are then employed to control bot accounts across various categories, optimizing the attachment strategy through reinforcement learning. Additionally, a hierarchical state abstraction based on structural entropy is designed to accelerate the reinforcement learning. Extensive experiments on social bot detection datasets demonstrate that our framework can effectively undermine the performance of GNN-based detectors."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          IAD-GPT: Advancing Visual Knowledge in Multimodal Large Language Model for Industrial Anomaly Detection", "authors": "Zewen Li, Zitong Yu, Qilang Ye, Weicheng Xie, Wei Zhuo, Linlin Shen", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "The robust causal capability of Multimodal Large Language Models (MLLMs) hold the potential of detecting defective objects in Industrial Anomaly Detection (IAD). However, most traditional IAD methods lack the ability to provide multi-turn human-machine dialogues and detailed descriptions, such as the color of objects, the shape of an anomaly, or specific types of anomalies. At the same time, methods based on large pre-trained models have not fully stimulated the ability of large models in anomaly detection tasks. In this paper, we explore the combination of rich text semantics with both image-level and pixel-level information from images and propose IAD-GPT, a novel paradigm based on MLLMs for IAD. We employ Abnormal Prompt Generator (APG) to generate detailed anomaly prompts for specific objects. These specific prompts from the large language model (LLM) are used to activate the detection and segmentation functions of the pre-trained visual-language model (i.e., CLIP). To enhance the visual grounding ability of MLLMs, we propose Text-Guided Enhancer, wherein image features interact with normal and abnormal text prompts to dynamically select enhancement pathways, which enables language models to focus on specific aspects of visual data, enhancing their ability to accurately interpret and respond to anomalies within images. Moreover, we design a Multi-Mask Fusion module to incorporate mask as expert knowledge, which enhances the LLM's perception of pixel-level anomalies. Extensive experiments on MVTec-AD and VisA datasets demonstrate our state-of-the-art performance on self-supervised and few-shot anomaly detection and segmentation tasks, such as MVTec-AD and VisA datasets. The codes are available at \\href{this https URL}{this https URL}."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Membership Inference over Diffusion-models-based Synthetic Tabular Data", "authors": "Peini Cheng, Amir Bahmani", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "abstract": "This study investigates the privacy risks associated with diffusion-based synthetic tabular data generation methods, focusing on their susceptibility to Membership Inference Attacks (MIAs). We examine two recent models, TabDDPM and TabSyn, by developing query-based MIAs based on the step-wise error comparison method. Our findings reveal that TabDDPM is more vulnerable to these attacks. TabSyn exhibits resilience against our attack models. Our work underscores the importance of evaluating the privacy implications of diffusion models and encourages further research into robust privacy-preserving mechanisms for synthetic data generation."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Vector Quantization in the Brain: Grid-like Codes in World Models", "authors": "Xiangyuan Peng, Xingsi Dong, Si Wu", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "We propose Grid-like Code Quantization (GCQ), a brain-inspired method for compressing observation-action sequences into discrete representations using grid-like patterns in attractor dynamics. Unlike conventional vector quantization approaches that operate on static inputs, GCQ performs spatiotemporal compression through an action-conditioned codebook, where codewords are derived from continuous attractor neural networks and dynamically selected based on actions. This enables GCQ to jointly compress space and time, serving as a unified world model. The resulting representation supports long-horizon prediction, goal-directed planning, and inverse modeling. Experiments across diverse tasks demonstrate GCQ's effectiveness in compact encoding and downstream performance. Our work offers both a computational tool for efficient sequence modeling and a theoretical perspective on the formation of grid-like codes in neural systems."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Kelle: Co-design KV Caching and eDRAM for Efficient LLM Serving in Edge Computing", "authors": "Tianhua Xia, Sai Qian Zhang", "subjects": "Hardware Architecture (cs.AR); Artificial Intelligence (cs.AI)", "abstract": "Running Large Language Models (LLMs) on edge devices is crucial for reducing latency, improving real-time processing, and enhancing privacy. By performing inference directly on the device, data does not need to be sent to the cloud, ensuring faster responses and reducing reliance on network connectivity. However, implementing LLMs on edge devices presents challenges, particularly with managing key-value (KV) caches, which plays a pivotal role in LLM serving. As the input text lengthens, the size of the KV cache increases linearly with the sequence length, leading to a significant memory footprint and data access costs. On the other hand, edge devices have limited memory and computational power, making it hard to store and efficiently access the large caches needed for LLM inference. To mitigate the substantial overhead caused by KV cache, we propose using embedded DRAM (eDRAM) as the primary storage for LLM serving in edge device, which offers higher storage density compared to SRAM. However, to ensure data integrity, eDRAM needs periodic refresh operations, which are power-intensive. To reduce eDRAM costs and improve overall system performance, we propose~\\textit{Kelle}, a software-hardware co-design solution optimized for deploying LLMs on eDRAM-based edge systems. Combined with our fine-grained memory eviction, recomputation, and refresh control algorithms, the \\textit{Kelle} accelerator delivers a $3.9\\times$ speedup and $4.5\\times$ energy savings compared to existing baseline solutions."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Does Capital Dream of Artificial Labour?", "authors": "Marcin Korecki, Cesare Carissimo", "subjects": "Computers and Society (cs.CY); Artificial Intelligence (cs.AI)", "abstract": "This paper investigates the concept of Labour as an expression of `timenergy' - a fusion of time and energy - and its entanglement within the system of Capital. We define Labour as the commodified, quantifiable expansion of timenergy, in contrast to Capital, which is capable of accumulation and abstraction. We explore Labour's historical evolution, its coercive and alienating nature, and its transformation through automation and artificial intelligence. Using a game-theoretic, agent-based simulation, we model interactions between Capital and Labour in production processes governed by Cobb-Douglas functions. Our results show that despite theoretical symmetry, learning agents disproportionately gravitate toward capital-intensive processes, revealing Capital's superior organizational influence due to its accumulative capacity. We argue that Capital functions as an artificially alive system animated by the living Labour it consumes, and question whether life can sustain itself without the infrastructures of Capital in a future of increasing automation. This study offers both a critique of and a framework for understanding Labour's subjugation within the Capital system."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          A Novel GPT-Based Framework for Anomaly Detection in System Logs", "authors": "Zeng Zhang, Wenjie Yin, Xiaoqi Li", "subjects": "Cryptography and Security (cs.CR); Machine Learning (cs.LG)", "abstract": "Identification of anomalous events within system logs constitutes a pivotal element within the frame- work of cybersecurity defense strategies. However, this process faces numerous challenges, including the management of substantial data volumes, the distribution of anomalies, and the precision of con- ventional methods. To address this issue, the present paper puts forward a proposal for an intelligent detection method for system logs based on Genera- tive Pre-trained Transformers (GPT). The efficacy of this approach is attributable to a combination of structured input design and a Focal Loss op- timization strategy, which collectively result in a substantial enhancement of the performance of log anomaly detection. The initial approach involves the conversion of raw logs into event ID sequences through the use of the Drain parser. Subsequently, the Focal Loss loss function is employed to address the issue of class imbalance. The experimental re- sults demonstrate that the optimized GPT-2 model significantly outperforms the unoptimized model in a range of key metrics, including precision, recall, and F1 score. In specific tasks, comparable or superior performance has been demonstrated to that of the GPT-3.5 API."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          AMS-QUANT: Adaptive Mantissa Sharing for Floating-point Quantization", "authors": "Mengtao Lv, Ruiqi Zhu, Xinyu Wang, Yun Li", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities in various kinds of tasks, while the billion or even trillion parameters bring storage and efficiency bottlenecks for inference. Quantization, particularly floating-point quantization, is known to be capable of speeding up LLM inference by reducing memory footprint and data movement during the inference process. For the first time, we advance the floating-point quantization exploration from integer bitwidths to non-integer bit-widths, namely AMS-Quant, to further approach the quantization sweet spot. AMS-Quant incorporates two novel techniques to put it into effect: (1) it proposes Mantissa-bit Sharing, which groups k quantized weights and lets them share the least significant mantissa bit, allowing us to further approach the minimum quantization bit-width without accuracy loss. (2) It introduces Adaptive Searching, which employs an offline optimization strategy to minimize the accuracy degradation introduced by sharing. Moreover, AMS-Quant is also prototyped as efficient CUDA Linear kernels, which translates memory savings into wall-clock latency reduction by reducing memory access. Extensive experiments on large-scale datasets and models show that AMS-Quant can quantize the model to FP-5.33-e2m3 and FP4.25-e2m2, and significantly speed up the LLM decoding over FP16 inference (2.8x and 3.2x), with negligible accuracy loss."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Algorithms for dynamic scheduling in manufacturing, towards digital factories Improving Deadline Feasibility and Responsiveness via Temporal Networks", "authors": "Ioan Hedea", "subjects": "Artificial Intelligence (cs.AI)", "abstract": "Modern manufacturing systems must meet hard delivery deadlines while coping with stochastic task durations caused by process noise, equipment variability, and human intervention. Traditional deterministic schedules break down when reality deviates from nominal plans, triggering costly last-minute repairs. This thesis combines offline constraint-programming (CP) optimisation with online temporal-network execution to create schedules that remain feasible under worst-case uncertainty. First, we build a CP model of the flexible job-shop with per-job deadline tasks and insert an optimal buffer $\\Delta^*$ to obtain a fully pro-active baseline. We then translate the resulting plan into a Simple Temporal Network with Uncertainty (STNU) and verify dynamic controllability, which guarantees that a real-time dispatcher can retime activities for every bounded duration realisation without violating resource or deadline constraints. Extensive Monte-Carlo simulations on the open Kacem~1--4 benchmark suite show that our hybrid approach eliminates 100\\% of deadline violations observed in state-of-the-art meta-heuristic schedules, while adding only 3--5\\% makespan overhead. Scalability experiments confirm that CP solve-times and STNU checks remain sub-second on medium-size instances. The work demonstrates how temporal-network reasoning can bridge the gap between proactive buffering and dynamic robustness, moving industry a step closer to truly digital, self-correcting factories."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Open Shouldn't Mean Exempt: Open-Source Exceptionalism and Generative AI", "authors": "David Atkinson", "subjects": "Computers and Society (cs.CY); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "abstract": "Any argument that open-source generative artificial intelligence (GenAI) is inherently ethical or legal solely because it is open source is flawed. Yet, this is the explicit or implicit stance of several open-source GenAI entities. This paper critically examines prevalent justifications for \"open-source exceptionalism,\" demonstrating how contemporary open-source GenAI often inadvertently facilitates unlawful conduct and environmental degradation without genuinely disrupting established oligopolies. Furthermore, the paper exposes the unsubstantiated and strategic deployment of \"democratization\" and \"innovation\" rhetoric to advocate for regulatory exemptions not afforded to proprietary systems. The conclusion is that open-source developers must be held to the same legal and ethical standards as all other actors in the technological ecosystem. However, the paper proposes a narrowly tailored safe harbor designed to protect legitimate, non-commercial scientific research, contingent upon adherence to specific criteria. Ultimately, this paper advocates for a framework of responsible AI development, wherein openness is pursued within established ethical and legal boundaries, with due consideration for its broader societal implications."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          In the Mood to Exclude: Revitalizing Trespass to Chattels in the Era of GenAI Scraping", "authors": "David Atkinson", "subjects": "Computers and Society (cs.CY); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "abstract": "This paper argues that website owners have the right to exclude others from their websites. Accordingly, when generative AI (GenAI) scraping bots intentionally circumvent reasonable technological barriers, their conduct could be actionable as trespass to chattels. If the scraping leads to a decrease in the website's value, then trespass to chattels should apply. The prevailing judicial focus on website content and the dismissal of trespass claims absent proof of server impairment or user disruption misconstrues the nature of the website itself as a form of digital property, focusing too narrowly on what constitutes harm under a claim of trespass. By shifting analysis from content to the website itself as an integrated digital asset and illustrating the harm to the value of the chattel, this paper demonstrates that the right to exclude applies online with the same force as it does to tangible property. Courts and litigants have struggled to police large-scale scraping because copyright preemption narrows available claims, leaving copyright and its fair use defense as the primary battleground. In contrast, recognizing websites as personal property revives trespass to chattels as a meaningful cause of action, providing website owners with an enforceable exclusionary right. Such protection would disincentivize exploitative scraping, preserve incentives for content creation, aid in protecting privacy and personal data, and safeguard values of autonomy and expression. Ultimately, this paper contends that reaffirming website owners' right to exclude is essential to maintaining a fair and sustainable online environment."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          A Framework For Decentralized Micro-credential Verification Towards Higher Qualifications", "authors": "Abrar Mahbub, Humira Saria, Md. Foysal Hossain, Nafees Mansoor", "subjects": "Computers and Society (cs.CY)", "abstract": "Student retention is one of the rising problems seen in educational institutions. With the rising cost of education and issues in the education sector, such as curriculum relevance, student engagement, and rapidly changing technological advancements, ensuring the relevance of academic programs in a fast-evolving job market has created a significant concern for educational institutions. With the intent to adapt to such challenges, educational institutions are dealing with alternative solutions for education, in which micro-credentials are at the very center of this, which are short-term academic programs or standalone courses. However, one of the challenges of micro-credentials is a lack of credit transfer among institutions. With the lack of standardization of assessments among educational institutions, it is difficult to transfer micro-credentials to larger qualifications. Regarding such challenges, micro-credentials with blockchain technology can bring significant benefits. Blockchain technology offers a decentralized and immutable platform for securely storing and verifying credentials. This paper presents a prototype model for micro-credential verification. With the policies decided by the educational institution, the learner provides a micro-credential certificate to the system. Upon validation of the certificate by the verifying body, the educational institution will review the assessment criteria and provide exemptions based on the provided criteria. The prototype uses the Hyper-ledger Fabric platform and utilizes off-chain technology, which acts as a middle-man storage platform. With the combination of off-chain and on-chain technologies, congestion on the blockchain is reduced, and transaction speed is improved. In summary, this research proposes a prototype for secure micro-credential verification and a more efficient course exemption process."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          GUIrilla: A Scalable Framework for Automated Desktop UI Exploration", "authors": "Sofiya Garkot, Maksym Shamrai, Ivan Synytsia, Mariya Hirna", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)", "abstract": "Autonomous agents capable of operating complex graphical user interfaces (GUIs) have the potential to transform desktop automation. While recent advances in large language models (LLMs) have significantly improved UI understanding, navigating full-window, multi-application desktop environments remains a major challenge. Data availability is limited by costly manual annotation, closed-source datasets and surface-level synthetic pipelines. We introduce GUIrilla, an automated scalable framework that systematically explores applications via native accessibility APIs to address the critical data collection challenge in GUI automation. Our framework focuses on macOS - an ecosystem with limited representation in current UI datasets - though many of its components are designed for broader cross-platform applicability. GUIrilla organizes discovered interface elements and crawler actions into hierarchical GUI graphs and employs specialized interaction handlers to achieve comprehensive application coverage. Using the application graphs from GUIrilla crawler, we construct and release GUIrilla-Task, a large-scale dataset of 27,171 functionally grounded tasks across 1,108 macOS applications, each annotated with full-desktop and window-level screenshots, accessibility metadata, and semantic action traces. Empirical results show that tuning LLM-based agents on GUIrilla-Task significantly improves performance on downstream UI tasks, outperforming synthetic baselines on the ScreenSpot Pro benchmark while using 97% less data. We also release macapptree, an open-source library for reproducible collection of structured accessibility metadata, along with the full GUIrilla-Task dataset, the manually verified GUIrilla-Gold benchmark, and the framework code to support open research in desktop autonomy."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Reducing Procrastination on Programming Assignments via Optional Early Feedback", "authors": "Alice Gao, Victoria Sakhnini", "subjects": "Computers and Society (cs.CY)", "abstract": "Academic procrastination is prevalent among undergraduate computer science students. Many studies have linked procrastination to poor academic performance and well-being. Procrastination is especially detrimental for advanced students when facing large, complex programming assignments in upper-year courses. We designed an intervention to combat academic procrastination on such programming assignments. The intervention consisted of early deadlines that were not worth marks but provided additional automated feedback if students submitted their work early. We evaluated the intervention by comparing the behaviour and performance of students between a control group and an intervention group. Our results showed that the intervention encouraged significantly more students to start the assignments early. Although there was no significant difference in students' grades between the control and intervention groups, students within the intervention group who used the intervention achieved significantly higher grades than those who did not. Our results implied that starting early alone did not improve students' grades. However, starting early and receiving additional feedback enhanced the students' grades relative to those of the rest of the students. We also conducted semi-structured interviews to gain an understanding of students' perceptions of the intervention. The interviews revealed that students benefited from the intervention in numerous ways, including improved academic performance, mental health, and development of soft skills. Students adopted the intervention to get more feedback, satisfy their curiosity, or use their available time. The main reasons for not adopting the intervention include having other competing deadlines, the intervention not being worth any marks, and feeling confident about their work."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          FUSE-Traffic: Fusion of Unstructured and Structured Data for Event-aware Traffic Forecasting", "authors": "Chenyang Yu, Xinpeng Xie, Yan Huang, Chenxi Qiu", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "Accurate traffic forecasting is a core technology for building Intelligent Transportation Systems (ITS), enabling better urban resource allocation and improved travel experiences. With growing urbanization, traffic congestion has intensified, highlighting the need for reliable and responsive forecasting models. In recent years, deep learning, particularly Graph Neural Networks (GNNs), has emerged as the mainstream paradigm in traffic forecasting. GNNs can effectively capture complex spatial dependencies in road network topology and dynamic temporal evolution patterns in traffic flow data. Foundational models such as STGCN and GraphWaveNet, along with more recent developments including STWave and D2STGNN, have achieved impressive performance on standard traffic datasets. These approaches incorporate sophisticated graph convolutional structures and temporal modeling mechanisms, demonstrating particular effectiveness in capturing and forecasting traffic patterns characterized by periodic regularities. To address this challenge, researchers have explored various ways to incorporate event information. Early attempts primarily relied on manually engineered event features. For instance, some approaches introduced manually defined incident effect scores or constructed specific subgraphs for different event-induced traffic conditions. While these methods somewhat enhance responsiveness to specific events, their core drawback lies in a heavy reliance on domain experts' prior knowledge, making generalization to diverse and complex unknown events difficult, and low-dimensional manual features often lead to the loss of rich semantic details."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          PrivacyPAD: A Reinforcement Learning Framework for Dynamic Privacy-Aware Delegation", "authors": "Zheng Hui, Yijiang River Dong, Sanhanat Sivapiromrat, Ehsan Shareghi, Nigel Collier", "subjects": "Cryptography and Security (cs.CR); Computation and Language (cs.CL)", "abstract": "When users submit queries to Large Language Models (LLMs), their prompts can often contain sensitive data, forcing a difficult choice: Send the query to a powerful proprietary LLM providers to achieving state-of-the-art performance and risk data exposure, or relying on smaller, local models guarantees data privacy but often results in a degradation of task performance. Prior approaches have relied on static pipelines that use LLM rewriting, which shatters linguistic coherence and indiscriminately removes privacy-sensitive information, including task-critical content. We reformulate this challenge (Privacy-Conscious Delegation) as a sequential decision-making problem and introduce a novel reinforcement learning (RL) framework called PrivacyPAD to solve it. Our framework trains an agent to dynamically route text chunks, learning a policy that optimally balances the trade-off between privacy leakage and task performance. It implicitly distinguishes between replaceable Personally Identifiable Information (PII) (which it shields locally) and task-critical PII (which it strategically sends to the remote model for maximal utility). To validate our approach in complex scenarios, we also introduce a new medical dataset with high PII density. Our framework achieves a new state-of-the-art on the privacy-utility frontier, demonstrating the necessity of learned, adaptive policies for deploying LLMs in sensitive environments."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Is Zadeh's Least-Entered Pivot Rule Exponential?", "authors": "Norman Zadeh", "subjects": "Data Structures and Algorithms (cs.DS); Optimization and Control (math.OC)", "abstract": "In 2011, Friedmann [F 7] claimed to have proved that pathological linear programs existed for which the Simplex method using Zadeh's least-entered rule [Z 14] would take an exponential number of pivots. In 2019, Disser and Hopp [DH 5] argued that there were errors in Friedmann's 2011 construction. In 2020, Disser, Friedmann, and Hopp [DFH 3,4] again contended that the least-entered rule was exponential. We show that their arguments contain multiple flaws. In other words, the worst-case behavior of the least-entered rule has not been established. Neither [F 7] nor [DFH 3,4] provides pathological linear programs that can be tested. Instead, the authors contend that their pathological linear programs are of the form (P) as shown on page 12 of [DFH 3]. The authors contend that the constraints of (P) ensure that the probability of entering a vertex u is equal to the probability of exiting u. In fact, we note that the authors' constraints (P) are flawed in at least three ways: a) they require the probability of exiting u to exceed the probability of entering u, b) they require the probability of exiting some nodes to exceed 1, and c) they overlook flows from decision nodes to decision nodes. At my request, in August of 2025, Disser, Friedmann, and Hopp provided me with their first ten purportedly pathological LPs and the graph of their first purportedly pathological Markov Decision Process (MDP1). It is shown that: a) their first two pathological LPs are infeasible if the variables are supposed to be probabilities, as the authors contend, and b) their first purportedly pathological LP does not match up with their first purportedly pathological MDP. In other words, the authors have not come close to providing counterexamples to the least-entered rule."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Algorithmic Fairness in AI Surrogates for End-of-Life Decision-Making", "authors": "Muhammad Aurangzeb Ahmad", "subjects": "Computers and Society (cs.CY); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "abstract": "Artificial intelligence surrogates are systems designed to infer preferences when individuals lose decision-making capacity. Fairness in such systems is a domain that has been insufficiently explored. Traditional algorithmic fairness frameworks are insufficient for contexts where decisions are relational, existential, and culturally diverse. This paper explores an ethical framework for algorithmic fairness in AI surrogates by mapping major fairness notions onto potential real-world end-of-life scenarios. It then examines fairness across moral traditions. The authors argue that fairness in this domain extends beyond parity of outcomes to encompass moral representation, fidelity to the patient's values, relationships, and worldview."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Fusion-Augmented Large Language Models: Boosting Diagnostic Trustworthiness via Model Consensus", "authors": "Md Kamrul Siam, Md Jobair Hossain Faruk, Jerry Q. Cheng, Huanying Gu", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "abstract": "This study presents a novel multi-model fusion framework leveraging two state-of-the-art large language models (LLMs), ChatGPT and Claude, to enhance the reliability of chest X-ray interpretation on the CheXpert dataset. From the full CheXpert corpus of 224,316 chest radiographs, we randomly selected 234 radiologist-annotated studies to evaluate unimodal performance using image-only prompts. In this setting, ChatGPT and Claude achieved diagnostic accuracies of 62.8% and 76.9%, respectively. A similarity-based consensus approach, using a 95% output similarity threshold, improved accuracy to 77.6%. To assess the impact of multimodal inputs, we then generated synthetic clinical notes following the MIMIC-CXR template and evaluated a separate subset of 50 randomly selected cases paired with both images and synthetic text. On this multimodal cohort, performance improved to 84% for ChatGPT and 76% for Claude, while consensus accuracy reached 91.3%. Across both experimental conditions, agreement-based fusion consistently outperformed individual models. These findings highlight the utility of integrating complementary modalities and using output-level consensus to improve the trustworthiness and clinical utility of AI-assisted radiological diagnosis, offering a practical path to reduce diagnostic errors with minimal computational overhead."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          SIADAFIX: issue description response for adaptive program repair", "authors": "Xin Cao, Nan Yu", "subjects": "Software Engineering (cs.SE); Computation and Language (cs.CL)", "abstract": "We propose utilizing fast and slow thinking to enhance the capabilities of large language model-based agents on complex tasks such as program repair. In particular, we design an adaptive program repair method based on issue description response, called SIADAFIX. The proposed method utilizes slow thinking bug fix agent to complete complex program repair tasks, and employs fast thinking workflow decision components to optimize and classify issue descriptions, using issue description response results to guide the orchestration of bug fix agent workflows. SIADAFIX adaptively selects three repair modes, i.e., easy, middle and hard mode, based on problem complexity. It employs fast generalization for simple problems and test-time scaling techniques for complex problems. Experimental results on the SWE-bench Lite show that the proposed method achieves 60.67% pass@1 performance using the Claude-4 Sonnet model, reaching state-of-the-art levels among all open-source methods. SIADAFIX effectively balances repair efficiency and accuracy, providing new insights for automated program repair. Our code is available at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Beyond Accuracy: Are Time Series Foundation Models Well-Calibrated?", "authors": "Coen Adler, Yuxin Chang, Felix Draxler, Samar Abdi, Padhraic Smyth", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Methodology (stat.ME); Machine Learning (stat.ML)", "abstract": "The recent development of foundation models for time series data has generated considerable interest in using such models across a variety of applications. Although foundation models achieve state-of-the-art predictive performance, their calibration properties remain relatively underexplored, despite the fact that calibration can be critical for many practical applications. In this paper, we investigate the calibration-related properties of five recent time series foundation models and two competitive baselines. We perform a series of systematic evaluations assessing model calibration (i.e., over- or under-confidence), effects of varying prediction heads, and calibration under long-term autoregressive forecasting. We find that time series foundation models are consistently better calibrated than baseline models and tend not to be either systematically over- or under-confident, in contrast to the overconfidence often seen in other deep learning models."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Can LLMs Correct Themselves? A Benchmark of Self-Correction in LLMs", "authors": "Guiyao Tie, Zenghui Yuan, Zeli Zhao, Chaoran Hu, Tianhe Gu, Ruihang Zhang, Sizhe Zhang, Junran Wu, Xiaoyue Tu, Ming Jin, Qingsong Wen, Lixing Chen, Pan Zhou, Lichao Sun", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "abstract": "Self-correction of large language models (LLMs) emerges as a critical component for enhancing their reasoning performance. Although various self-correction methods have been proposed, a comprehensive evaluation of these methods remains largely unexplored, and the question of whether LLMs can truly correct themselves is a matter of significant interest and concern. In this study, we introduce CorrectBench, a benchmark developed to evaluate the effectiveness of self-correction strategies, including intrinsic, external, and fine-tuned approaches, across three tasks: commonsense reasoning, mathematical reasoning, and code generation. Our findings reveal that: 1) Self-correction methods can improve accuracy, especially for complex reasoning tasks; 2) Mixing different self-correction strategies yields further improvements, though it reduces efficiency; 3) Reasoning LLMs (e.g., DeepSeek-R1) have limited optimization under additional self-correction methods and have high time costs. Interestingly, a comparatively simple chain-of-thought (CoT) baseline demonstrates competitive accuracy and efficiency. These results underscore the potential of self-correction to enhance LLM's reasoning performance while highlighting the ongoing challenge of improving their efficiency. Consequently, we advocate for further research focused on optimizing the balance between reasoning capabilities and operational efficiency. Project Page: this https URL"}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Learning a Generalized Model for Substation Level Voltage Estimation in Distribution Networks", "authors": "Muhy Eddin Za'ter, Bri-Mathias Hodge", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Systems and Control (eess.SY)", "abstract": "Accurate voltage estimation in distribution networks is critical for real-time monitoring and increasing the reliability of the grid. As DER penetration and distribution level voltage variability increase, robust distribution system state estimation (DSSE) has become more essential to maintain safe and efficient operations. Traditional DSSE techniques, however, struggle with sparse measurements and the scale of modern feeders, limiting their scalability to large networks. This paper presents a hierarchical graph neural network for substation-level voltage estimation that exploits both electrical topology and physical features, while remaining robust to the low observability levels common to real-world distribution networks. Leveraging the public SMART-DS datasets, the model is trained and evaluated on thousands of buses across multiple substations and DER penetration scenarios. Comprehensive experiments demonstrate that the proposed method achieves up to 2 times lower RMSE than alternative data-driven models, and maintains high accuracy with as little as 1\\% measurement coverage. The results highlight the potential of GNNs to enable scalable, reproducible, and data-driven voltage monitoring for distribution systems."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Residual Correction Models for AC Optimal Power Flow Using DC Optimal Power Flow Solutions", "authors": "Muhy Eddin Za'ter, Bri-Mathias Hodge, Kyri Baker", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Systems and Control (eess.SY)", "abstract": "Solving the nonlinear AC optimal power flow (AC OPF) problem remains a major computational bottleneck for real-time grid operations. In this paper, we propose a residual learning paradigm that uses fast DC optimal power flow (DC OPF) solutions as a baseline, and learns only the nonlinear corrections required to provide the full AC-OPF solution. The method utilizes a topology-aware Graph Neural Network with local attention and two-level DC feature integration, trained using a physics-informed loss that enforces AC power-flow feasibility and operational limits. Evaluations on OPFData for 57-, 118-, and 2000-bus systems show around 25% lower MSE, up to 3X reduction in feasibility error, and up to 13X runtime speedup compared to conventional AC OPF solvers. The model maintains accuracy under N-1 contingencies and scales efficiently to large networks. These results demonstrate that residual learning is a practical and scalable bridge between linear approximations and AC-feasible OPF, enabling near real-time operational decision making."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          FedPURIN: Programmed Update and Reduced INformation for Sparse Personalized Federated Learning", "authors": "Lunchen Xie, Zehua He, Qingjiang Shi", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Personalized Federated Learning (PFL) has emerged as a critical research frontier addressing data heterogeneity issue across distributed clients. Novel model architectures and collaboration mechanisms are engineered to accommodate statistical disparities while producing client-specific models. Parameter decoupling represents a promising paradigm for maintaining model performance in PFL frameworks. However, the communication efficiency of many existing methods remains suboptimal, sustaining substantial communication burdens that impede practical deployment. To bridge this gap, we propose Federated Learning with Programmed Update and Reduced INformation (FedPURIN), a novel framework that strategically identifies critical parameters for transmission through an integer programming formulation. This mathematically grounded strategy is seamlessly integrated into a sparse aggregation scheme, achieving a significant communication reduction while preserving the efficacy. Comprehensive evaluations on standard image classification benchmarks under varied non-IID conditions demonstrate competitive performance relative to state-of-the-art methods, coupled with quantifiable communication reduction through sparse aggregation. The framework establishes a new paradigm for communication-efficient PFL, particularly advantageous for edge intelligence systems operating with heterogeneous data sources."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          A Multi-Cloud Framework for Zero-Trust Workload Authentication", "authors": "Saurabh Deochake, Ryan Murphy, Jeremiah Gearheart", "subjects": "Cryptography and Security (cs.CR); Distributed, Parallel, and Cluster Computing (cs.DC); Networking and Internet Architecture (cs.NI)", "abstract": "Static, long-lived credentials for workload authentication create untenable security risks that violate Zero-Trust principles. This paper presents a multi-cloud framework using Workload Identity Federation (WIF) and OpenID Connect (OIDC) for secretless authentication. Our approach uses cryptographically-verified, ephemeral tokens, allowing workloads to authenticate without persistent private keys and mitigating credential theft. We validate this framework in an enterprise-scale Kubernetes environment, which significantly reduces the attack surface. The model offers a unified solution to manage workload identities across disparate clouds, enabling future implementation of robust, attribute-based access control."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Co-Designing Interdisciplinary Design Projects with AI", "authors": "Wei Ting Liow, Sumbul Khan, Lay Kee Ang", "subjects": "Computers and Society (cs.CY); Artificial Intelligence (cs.AI)", "abstract": "Creating interdisciplinary design projects is time-consuming and cognitively demanding for teachers, requiring curriculum alignment, cross-subject integration, and careful sequencing. International research reports increasing teacher use of AI alongside persistent workload pressures, underscoring the need for planning support. This paper presents the Interdisciplinary Design Project Planner (IDPplanner), a GPT-based planning assistant grounded in Design Innovation principles, alignment with Singapore secondary school syllabuses, and 21st-century competencies. In a within-subject, counterbalanced workshop with 33 in-service teachers, participants produced two versions of the same project: manual and AI-assisted, followed by self- and peer-evaluations using a six-dimensional rubric. The AI-assisted version received higher scores for Curriculum Alignment, Design Thinking Application, and Coherence and Flow, with a marginal advantage for Assessment Strategies. Teacher reflections indicated that AI-assisted planning improved structure, sequencing, and idea generation, while contextualization to local syllabuses, class profiles, and student needs remained teacher-led. Contributions include a purpose-built planning tool that organizes ideas into a ten-component flow with ready-to-adapt prompts, templates, and assessment suggestions; an empirical, rubric-based comparison of planning quality; and evidence that AI can function as a pedagogical planning partner. Recommendations emphasize hybrid teacher-AI workflows to enhance curriculum alignment and reduce planning complexity, and design suggestions for developers to strengthen contextual customization, iterative design support, and localized rubrics. Although instantiated with a Singapore-based curriculum, the planning flow and rubric are framework-agnostic and can be parameterized for other systems."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Human or AI? Comparing Design Thinking Assessments by Teaching Assistants and Bots", "authors": "Sumbul Khan, Wei Ting Liow, Lay Kee Ang", "subjects": "Computers and Society (cs.CY); Artificial Intelligence (cs.AI)", "abstract": "As design thinking education grows in secondary and tertiary contexts, educators face the challenge of evaluating creative artefacts that combine visual and textual elements. Traditional rubric-based assessment is laborious, time-consuming, and inconsistent due to reliance on Teaching Assistants (TA) in large, multi-section cohorts. This paper presents an exploratory study investigating the reliability and perceived accuracy of AI-assisted assessment compared to TA-assisted assessment in evaluating student posters in design thinking education. Two activities were conducted with 33 Ministry of Education (MOE) Singapore school teachers to (1) compare AI-generated scores with TA grading across three key dimensions: empathy and user understanding, identification of pain points and opportunities, and visual communication, and (2) examine teacher preferences for AI-assigned, TA-assigned, and hybrid scores. Results showed low statistical agreement between instructor and AI scores for empathy and pain points, with slightly higher alignment for visual communication. Teachers preferred TA-assigned scores in six of ten samples. Qualitative feedback highlighted the potential of AI for formative feedback, consistency, and student self-reflection, but raised concerns about its limitations in capturing contextual nuance and creative insight. The study underscores the need for hybrid assessment models that integrate computational efficiency with human insights. This research contributes to the evolving conversation on responsible AI adoption in creative disciplines, emphasizing the balance between automation and human judgment for scalable and pedagogically sound assessment."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Effect of Reporting Mode and Clinical Experience on Radiologists' Gaze and Image Analysis Behavior in Chest Radiography", "authors": "Mahta Khoobi, Marc Sebastian von der Stueck, Felix Barajas Ordonez, Anca-Maria Iancu, Eric Corban, Julia Nowak, Aleksandar Kargaliev, Valeria Perelygina, Anna-Sophie Schott, Daniel Pinto dos Santos, Christiane Kuhl, Daniel Truhn, Sven Nebelung, Robert Siepmann", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Image and Video Processing (eess.IV)", "abstract": "Structured reporting (SR) and artificial intelligence (AI) may transform how radiologists interact with imaging studies. This prospective study (July to December 2024) evaluated the impact of three reporting modes: free-text (FT), structured reporting (SR), and AI-assisted structured reporting (AI-SR), on image analysis behavior, diagnostic accuracy, efficiency, and user experience. Four novice and four non-novice readers (radiologists and medical students) each analyzed 35 bedside chest radiographs per session using a customized viewer and an eye-tracking system. Outcomes included diagnostic accuracy (compared with expert consensus using Cohen's $\\kappa$), reporting time per radiograph, eye-tracking metrics, and questionnaire-based user experience. Statistical analysis used generalized linear mixed models with Bonferroni post-hoc tests with a significance level of ($P \\le .01$). Diagnostic accuracy was similar in FT ($\\kappa = 0.58$) and SR ($\\kappa = 0.60$) but higher in AI-SR ($\\kappa = 0.71$, $P < .001$). Reporting times decreased from $88 \\pm 38$ s (FT) to $37 \\pm 18$ s (SR) and $25 \\pm 9$ s (AI-SR) ($P < .001$). Saccade counts for the radiograph field ($205 \\pm 135$ (FT), $123 \\pm 88$ (SR), $97 \\pm 58$ (AI-SR)) and total fixation duration for the report field ($11 \\pm 5$ s (FT), $5 \\pm 3$ s (SR), $4 \\pm 1$ s (AI-SR)) were lower with SR and AI-SR ($P < .001$ each). Novice readers shifted gaze towards the radiograph in SR, while non-novice readers maintained their focus on the radiograph. AI-SR was the preferred mode. In conclusion, SR improves efficiency by guiding visual attention toward the image, and AI-prefilled SR further enhances diagnostic accuracy and user satisfaction."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          MNO: Multiscale Neural Operator for Computational Fluid Dynamics with 3D Point Cloud Data", "authors": "Qinxuan Wang, Chuang Wang, Mingyu Zhang, Jingwei Sun, Peipei Yang, Shuo Tang, Shiming Xiang", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "Neural operators have emerged as a powerful data-driven paradigm for solving Partial Differential Equations (PDEs), offering orders-of-magnitude acceleration over traditional solvers. However, existing approaches still suffer from limited accuracy and scalability, particularly on irregular domains where fluid flows exhibit rich multiscale structures. In this work, we introduce the Multiscale Neural Operator (MNO), a new architecture for Computational Fluid Dynamics (CFD) on three-dimensional (3D) unstructured point clouds. MNO explicitly decomposes information across three scales: a global dimension-shrinkage attention module for long-range dependencies, a local graph attention module for neighborhood-level interactions, and a micro point-wise attention module for fine-grained details. This design preserves multiscale inductive biases while remaining computationally efficient. We evaluate MNO on four diverse benchmarks, covering both steady-state and unsteady flow scenarios with up to 300K points. Across all tasks, MNO consistently outperforms state-of-the-art baselines, reducing prediction errors by 5% to 40% and demonstrating improved robustness in challenging 3D CFD problems. Our results highlight the importance of explicit multiscale design for neural operators and establish MNO as a scalable framework for learning complex fluid dynamics on irregular domains."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Data-Driven Analysis of Intersectional Bias in Image Classification: A Framework with Bias-Weighted Augmentation", "authors": "Farjana Yesmin", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "abstract": "Machine learning models trained on imbalanced datasets often exhibit intersectional biases-systematic errors arising from the interaction of multiple attributes such as object class and environmental conditions. This paper presents a data-driven framework for analyzing and mitigating such biases in image classification. We introduce the Intersectional Fairness Evaluation Framework (IFEF), which combines quantitative fairness metrics with interpretability tools to systematically identify bias patterns in model predictions. Building on this analysis, we propose Bias-Weighted Augmentation (BWA), a novel data augmentation strategy that adapts transformation intensities based on subgroup distribution statistics. Experiments on the Open Images V7 dataset with five object classes demonstrate that BWA improves accuracy for underrepresented class-environment intersections by up to 24 percentage points while reducing fairness metric disparities by 35%. Statistical analysis across multiple independent runs confirms the significance of improvements (p < 0.05). Our methodology provides a replicable approach for analyzing and addressing intersectional biases in image classification systems."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Early-stopping for Transformer model training", "authors": "Jing He, Hua Jiang, Cheng Li, Siqian Xin, Shuzhen Yang", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "This work introduces a novel theoretical framework grounded in Random Matrix Theory (RMT) for analyzing Transformer training dynamics. We focus on the underlying mechanisms that drive performance improvements and derive principled early-stopping criteria. Empirically, we observe that the spectral density of the shallow self-attention matrix V consistently evolves into a heavy-tailed distribution. Utilizing the PL (Power Law) fit to this matrix as a probe, we demarcate training into three stages: structural exploration, heavy-tailed structure stabilization, and convergence saturation. This staging provides guidance for preliminary stopping decisions. Crucially, we propose two consistent and validation-free criteria: a quantitative metric for heavy-tailed dynamics and a novel spectral signature indicative of convergence. The strong alignment between these criteria highlights the utility of RMT for monitoring and diagnosing the progression of Transformer model training."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Optimization of the quantization of dense neural networks from an exact QUBO formulation", "authors": "Sergio Mu\u00f1iz Subi\u00f1as, Manuel L. Gonz\u00e1lez, Jorge Ruiz G\u00f3mez, Alejandro Mata Ali, Jorge Mart\u00ednez Mart\u00edn, Miguel Franco Hernando, \u00c1ngel Miguel Garc\u00eda-Vico", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "This work introduces a post-training quantization (PTQ) method for dense neural networks via a novel ADAROUND-based QUBO formulation. Using the Frobenius distance between the theoretical output and the dequantized output (before the activation function) as the objective, an explicit QUBO whose binary variables represent the rounding choice for each weight and bias is obtained. Additionally, by exploiting the structure of the coefficient QUBO matrix, the global problem can be exactly decomposed into $n$ independent subproblems of size $f+1$, which can be efficiently solved using some heuristics such as simulated annealing. The approach is evaluated on MNIST, Fashion-MNIST, EMNIST, and CIFAR-10 across integer precisions from int8 to int1 and compared with a round-to-nearest traditional quantization methodology."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          BPL: Bias-adaptive Preference Distillation Learning for Recommender System", "authors": "SeongKu Kang, Jianxun Lian, Dongha Lee, Wonbin Kweon, Sanghwan Jang, Jaehyun Lee, Jindong Wang, Xing Xie, Hwanjo Yu", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)", "abstract": "Recommender systems suffer from biases that cause the collected feedback to incompletely reveal user preference. While debiasing learning has been extensively studied, they mostly focused on the specialized (called counterfactual) test environment simulated by random exposure of items, significantly degrading accuracy in the typical (called factual) test environment based on actual user-item interactions. In fact, each test environment highlights the benefit of a different aspect: the counterfactual test emphasizes user satisfaction in the long-terms, while the factual test focuses on predicting subsequent user behaviors on platforms. Therefore, it is desirable to have a model that performs well on both tests rather than only one. In this work, we introduce a new learning framework, called Bias-adaptive Preference distillation Learning (BPL), to gradually uncover user preferences with dual distillation strategies. These distillation strategies are designed to drive high performance in both factual and counterfactual test environments. Employing a specialized form of teacher-student distillation from a biased model, BPL retains accurate preference knowledge aligned with the collected feedback, leading to high performance in the factual test. Furthermore, through self-distillation with reliability filtering, BPL iteratively refines its knowledge throughout the training process. This enables the model to produce more accurate predictions across a broader range of user-item combinations, thereby improving performance in the counterfactual test. Comprehensive experiments validate the effectiveness of BPL in both factual and counterfactual tests. Our implementation is accessible via: this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Continual Knowledge Consolidation LORA for Domain Incremental Learning", "authors": "Naeem Paeedeh, Mahardhika Pratama, Weiping Ding, Jimmy Cao, Wolfgang Mayer, Ryszard Kowalczyk", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "Domain Incremental Learning (DIL) is a continual learning sub-branch that aims to address never-ending arrivals of new domains without catastrophic forgetting problems. Despite the advent of parameter-efficient fine-tuning (PEFT) approaches, existing works create task-specific LoRAs overlooking shared knowledge across tasks. Inaccurate selection of task-specific LORAs during inference results in significant drops in accuracy, while existing works rely on linear or prototype-based classifiers, which have suboptimal generalization powers. Our paper proposes continual knowledge consolidation low rank adaptation (CONEC-LoRA) addressing the DIL problems. CONEC-LoRA is developed from consolidations between task-shared LORA to extract common knowledge and task-specific LORA to embrace domain-specific knowledge. Unlike existing approaches, CONEC-LoRA integrates the concept of a stochastic classifier whose parameters are sampled from a distribution, thus enhancing the likelihood of correct classifications. Last but not least, an auxiliary network is deployed to optimally predict the task-specific LoRAs for inferences and implements the concept of a different-depth network structure in which every layer is connected with a local classifier to take advantage of intermediate representations. This module integrates the ball-generator loss and transformation module to address the synthetic sample bias problem. Our rigorous experiments demonstrate the advantage of CONEC-LoRA over prior arts in 4 popular benchmark problems with over 5% margins."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          ISO/IEC-Compliant Match-on-Card Face Verification with Short Binary Templates", "authors": "Abdelilah Ganmati, Karim Afdel, Lahcen Koutti", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)", "abstract": "We present a practical match-on-card design for face verification in which compact 64/128-bit templates are produced off-card by PCA-ITQ and compared on-card via constant-time Hamming distance. We specify ISO/IEC 7816-4 and 14443-4 command APDUs with fixed-length payloads and decision-only status words (no score leakage), together with a minimal per-identity EEPROM map. Using real binary codes from a CelebA working set (55 identities, 412 images), we (i) derive operating thresholds from ROC/DET, (ii) replay enroll->verify transactions at those thresholds, and (iii) bound end-to-end time by pure link latency plus a small constant on-card budget. Even at the slowest contact rate (9.6 kbps), total verification time is 43.9 ms (64 b) and 52.3 ms (128 b); at 38.4 kbps both are <14 ms. At FAR = 1%, both code lengths reach TPR = 0.836, while 128 b lowers EER relative to 64 b. An optional +6 B helper (targeted symbol-level parity over empirically unstable bits) is latency-negligible. Overall, short binary templates, fixed-payload decision-only APDUs, and constant-time matching satisfy ISO/IEC transport constraints with wide timing margin and align with ISO/IEC 24745 privacy goals. Limitations: single-dataset evaluation and design-level (pre-hardware) timing; we outline AgeDB/CFP-FP and on-card microbenchmarks as next steps."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          EvolveR: Self-Evolving LLM Agents through an Experience-Driven Lifecycle", "authors": "Rong Wu, Xiaoman Wang, Jianbiao Mei, Pinlong Cai, Daocheng Fu, Cheng Yang, Licheng Wen, Xuemeng Yang, Yufan Shen, Yuxin Wang, Botian Shi", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "abstract": "Current Large Language Model (LLM) agents show strong performance in tool use, but lack the crucial capability to systematically learn from their own experiences. While existing frameworks mainly focus on mitigating external knowledge gaps, they fail to address a more fundamental limitation: the inability to iteratively refine problem-solving strategies. In this work, we introduce EvolveR, a framework designed to enable agent to self-improve through a complete, closed-loop experience lifecycle. This lifecycle comprises two key stages: (1) Offline Self-Distillation, where the agent's interaction trajectories are synthesized into a structured repository of abstract, reusable strategic principles; (2) Online Interaction, where the agent interacts with tasks and actively retrieves distilled principles to guide its decision-making, accumulating a diverse set of behavioral trajectories. This loop employs a policy reinforcement mechanism to iteratively update the agent based on its performance. We demonstrate the effectiveness of EvolveR on complex multi-hop question-answering benchmarks, where it achieves superior performance over strong agentic baselines. Our work presents a comprehensive blueprint for agents that learn not only from external data but also from the consequences of their own actions, paving the way for more autonomous and continuously improving systems. Code is available at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          SARHAchat: An LLM-Based Chatbot for Sexual and Reproductive Health Counseling", "authors": "Jiaye Yang, Xinyu Zhao, Tianlong Chen, Kandyce Brennan", "subjects": "Computers and Society (cs.CY); Artificial Intelligence (cs.AI)", "abstract": "While Artificial Intelligence (AI) shows promise in healthcare applications, existing conversational systems often falter in complex and sensitive medical domains such as Sexual and Reproductive Health (SRH). These systems frequently struggle with hallucination and lack the specialized knowledge required, particularly for sensitive SRH topics. Furthermore, current AI approaches in healthcare tend to prioritize diagnostic capabilities over comprehensive patient care and education. Addressing these gaps, this work at the UNC School of Nursing introduces SARHAchat, a proof-of-concept Large Language Model (LLM)-based chatbot. SARHAchat is designed as a reliable, user-centered system integrating medical expertise with empathetic communication to enhance SRH care delivery. Our evaluation demonstrates SARHAchat's ability to provide accurate and contextually appropriate contraceptive counseling while maintaining a natural conversational flow. The demo is available at this https URL}{this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          PassREfinder-FL: Privacy-Preserving Credential Stuffing Risk Prediction via Graph-Based Federated Learning for Representing Password Reuse between Websites", "authors": "Jaehan Kim, Minkyoo Song, Minjae Seo, Youngjin Jin, Seungwon Shin, Jinwoo Kim", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)", "abstract": "Credential stuffing attacks have caused significant harm to online users who frequently reuse passwords across multiple websites. While prior research has attempted to detect users with reused passwords or identify malicious login attempts, existing methods often compromise usability by restricting password creation or website access, and their reliance on complex account-sharing mechanisms hinders real-world deployment. To address these limitations, we propose PassREfinder-FL, a novel framework that predicts credential stuffing risks across websites. We introduce the concept of password reuse relations -- defined as the likelihood of users reusing passwords between websites -- and represent them as edges in a website graph. Using graph neural networks (GNNs), we perform a link prediction task to assess credential reuse risk between sites. Our approach scales to a large number of arbitrary websites by incorporating public website information and linking newly observed websites as nodes in the graph. To preserve user privacy, we extend PassREfinder-FL with a federated learning (FL) approach that eliminates the need to share user sensitive information across administrators. Evaluation on a real-world dataset of 360 million breached accounts from 22,378 websites shows that PassREfinder-FL achieves an F1-score of 0.9153 in the FL setting. We further validate that our FL-based GNN achieves a 4-11% performance improvement over other state-of-the-art GNN models through an ablation study. Finally, we demonstrate that the predicted results can be used to quantify password reuse likelihood as actionable risk scores."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Near-Equilibrium Propagation training in nonlinear wave systems", "authors": "Karol Sajnok, Micha\u0142 Matuszewski", "subjects": "Machine Learning (cs.LG); Quantum Gases (cond-mat.quant-gas); Mathematical Physics (math-ph); Optics (physics.optics)", "abstract": "Backpropagation learning algorithm, the workhorse of modern artificial intelligence, is notoriously difficult to implement in physical neural networks. Equilibrium Propagation (EP) is an alternative with comparable efficiency and strong potential for in-situ training. We extend EP learning to both discrete and continuous complex-valued wave systems. In contrast to previous EP implementations, our scheme is valid in the weakly dissipative regime, and readily applicable to a wide range of physical settings, even without well defined nodes, where trainable inter-node connections can be replaced by trainable local potential. We test the method in driven-dissipative exciton-polariton condensates governed by generalized Gross-Pitaevskii dynamics. Numerical studies on standard benchmarks, including a simple logical task and handwritten-digit recognition, demonstrate stable convergence, establishing a practical route to in-situ learning in physical systems in which system control is restricted to local parameters."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          MoPHES:Leveraging on-device LLMs as Agent for Mobile Psychological Health Evaluation and Support", "authors": "Xun Wei, Pukai Zhou, Zeyu Wang", "subjects": "Computers and Society (cs.CY); Artificial Intelligence (cs.AI)", "abstract": "The 2022 World Mental Health Report calls for global mental health care reform, amid rising prevalence of issues like anxiety and depression that affect nearly one billion people worldwide. Traditional in-person therapy fails to meet this demand, and the situation is worsened by stigma. While general-purpose large language models (LLMs) offer efficiency for AI-driven mental health solutions, they underperform because they lack specialized fine-tuning. Existing LLM-based mental health chatbots can engage in empathetic conversations, but they overlook real-time user mental state assessment which is critical for professional counseling. This paper proposes MoPHES, a framework that integrates mental state evaluation, conversational support, and professional treatment recommendations. The agent developed under this framework uses two fine-tuned MiniCPM4-0.5B LLMs: one is fine-tuned on mental health conditions datasets to assess users' mental states and predict the severity of anxiety and depression; the other is fine-tuned on multi-turn dialogues to handle conversations with users. By leveraging insights into users' mental states, our agent provides more tailored support and professional treatment recommendations. Both models are also deployed directly on mobile devices to enhance user convenience and protect user privacy. Additionally, to evaluate the performance of MoPHES with other LLMs, we develop a benchmark for the automatic evaluation of mental state prediction and multi-turn counseling dialogues, which includes comprehensive evaluation metrics, datasets, and methods."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          FSRF: Factorization-guided Semantic Recovery for Incomplete Multimodal Sentiment Analysis", "authors": "Ziyang Liu, Pengjunfei Chu, Shuming Dong, Chen Zhang, Mingcheng Li, Jin Wang", "subjects": "Machine Learning (cs.LG); Applications (stat.AP)", "abstract": "In recent years, Multimodal Sentiment Analysis (MSA) has become a research hotspot that aims to utilize multimodal data for human sentiment understanding. Previous MSA studies have mainly focused on performing interaction and fusion on complete multimodal data, ignoring the problem of missing modalities in real-world applications due to occlusion, personal privacy constraints, and device malfunctions, resulting in low generalizability. To this end, we propose a Factorization-guided Semantic Recovery Framework (FSRF) to mitigate the modality missing problem in the MSA task. Specifically, we propose a de-redundant homo-heterogeneous factorization module that factorizes modality into modality-homogeneous, modality-heterogeneous, and noisy representations and design elaborate constraint paradigms for representation learning. Furthermore, we design a distribution-aligned self-distillation module that fully recovers the missing semantics by utilizing bidirectional knowledge transfer. Comprehensive experiments on two datasets indicate that FSRF has a significant performance advantage over previous methods with uncertain missing modalities."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Towards a Blockchain-Based CI/CD Framework to Enhance Security in Cloud Environments", "authors": "Sabbir M Saleh, Nazim Madhavji, John Steinbacher", "subjects": "Cryptography and Security (cs.CR); Distributed, Parallel, and Cluster Computing (cs.DC)", "abstract": "Security is becoming a pivotal point in cloud platforms. Several divisions, such as business organisations, health care, government, etc., have experienced cyber-attacks on their infrastructures. This research focuses on security issues within Continuous Integration and Deployment (CI/CD) pipelines in a cloud platform as a reaction to recent cyber breaches. This research proposes a blockchain-based solution to enhance CI/CD pipeline security. This research aims to develop a framework that leverages blockchain's distributed ledger technology and tamper-resistant features to improve CI/CD pipeline security. The goal is to emphasise secure software deployment by integrating threat modelling frameworks and adherence to coding standards. It also aims to employ tools to automate security testing to detect publicly disclosed vulnerabilities and flaws, such as an outdated version of Java Spring Framework, a JavaScript library from an unverified source, or a database library that allows SQL injection attacks in the deployed software through the framework."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Differentiable, Bit-shifting, and Scalable Quantization without training neural network from scratch", "authors": "Zia Badar", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Machine Learning (stat.ML)", "abstract": "Quantization of neural networks provides benefits of inference in less compute and memory requirements. Previous work in quantization lack two important aspects which this work provides. First almost all previous work in quantization used a non-differentiable approach and for learning; the derivative is usually set manually in backpropogation which make the learning ability of algorithm questionable, our approach is not just differentiable, we also provide proof of convergence of our approach to the optimal neural network. Second previous work in shift/logrithmic quantization either have avoided activation quantization along with weight quantization or achieved less accuracy. Learning logrithmic quantize values of form $2^n$ requires the quantization function can scale to more than 1 bit quantization which is another benifit of our quantization that it provides $n$ bits quantization as well. Our approach when tested with image classification task using imagenet dataset, resnet18 and weight quantization only achieves less than 1 percent accuracy compared to full precision accuracy while taking only 15 epochs to train using shift bit quantization and achieves comparable to SOTA approaches accuracy in both weight and activation quantization using shift bit quantization in 15 training epochs with slightly higher(only higher cpu instructions) inference cost compared to 1 bit quantization(without logrithmic quantization) and not requiring any higher precision multiplication."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          STABLE: Gated Continual Learning for Large Language Models", "authors": "William Hoy, Nurcin Celik", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "Large language models (LLMs) increasingly require mechanisms for continual adaptation without full retraining. However, sequential updates can lead to catastrophic forgetting, where new edits degrade previously acquired knowledge. This work presents STABLE, a gated continual self editing framework that constrains forgetting during sequential updates using parameter efficient fine tuning via Low Rank Adaptation (LoRA; see arXiv:2106.09685). Each candidate edit is evaluated against a stability budget using one of three metrics: (i) Exact Match (EM) drop, capturing factual accuracy loss; (ii) bits increase, reflecting reduced model confidence; and (iii) KL divergence, quantifying distributional drift between the base and adapted models. If a threshold is exceeded, the LoRA update is rescaled through a clipping procedure or rejected. Experiments on the Qwen-2.5-7B model show that gating effectively mitigates forgetting while preserving adaptability. EM based gating achieved the highest cumulative performance in short continual learning sequences. Our results show that different gating strategies can achieve comparable distribution shift (measured by KL divergence) while producing different accuracy outcomes, highlighting the importance of gating design in continual adaptation. This approach offers a principled method for continual model editing, enabling LLMs to integrate new knowledge while maintaining reliability. Code: this https URL"}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Evaluating Prompting Strategies and Large Language Models in Systematic Literature Review Screening: Relevance and Task-Stage Classification", "authors": "Binglan Han, Anuradha Mathrani, Teo Susnjak", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "abstract": "This study quantifies how prompting strategies interact with large language models (LLMs) to automate the screening stage of systematic literature reviews (SLRs). We evaluate six LLMs (GPT-4o, GPT-4o-mini, DeepSeek-Chat-V3, Gemini-2.5-Flash, Claude-3.5-Haiku, Llama-4-Maverick) under five prompt types (zero-shot, few-shot, chain-of-thought (CoT), CoT-few-shot, self-reflection) across relevance classification and six Level-2 tasks, using accuracy, precision, recall, and F1. Results show pronounced model-prompt interaction effects: CoT-few-shot yields the most reliable precision-recall balance; zero-shot maximizes recall for high-sensitivity passes; and self-reflection underperforms due to over-inclusivity and instability across models. GPT-4o and DeepSeek provide robust overall performance, while GPT-4o-mini performs competitively at a substantially lower dollar cost. A cost-performance analysis for relevance classification (per 1,000 abstracts) reveals large absolute differences among model-prompt pairings; GPT-4o-mini remains low-cost across prompts, and structured prompts (CoT/CoT-few-shot) on GPT-4o-mini offer attractive F1 at a small incremental cost. We recommend a staged workflow that (1) deploys low-cost models with structured prompts for first-pass screening and (2) escalates only borderline cases to higher-capacity models. These findings highlight LLMs' uneven but promising potential to automate literature screening. By systematically analyzing prompt-model interactions, we provide a comparative benchmark and practical guidance for task-adaptive LLM deployment."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Compressing Many-Shots in In-Context Learning", "authors": "Devvrit Khatri, Pranamya Kulkarni, Nilesh Gupta, Yerram Varun, Liqian Peng, Jay Yagnik, Praneeth Netrapalli, Cho-Jui Hsieh, Alec Go, Inderjit S Dhillon, Aditya Kusupati, Prateek Jain", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "Large Language Models (LLMs) have been shown to be able to learn different tasks without explicit finetuning when given many input-output examples / demonstrations through In-Context Learning (ICL). Increasing the number of examples, called ``shots'', improves downstream task performance but incurs higher memory and computational costs. In this work, we study an approach to improve the memory and computational efficiency of ICL inference by compressing the many-shot prompts. Given many shots comprising t tokens, our goal is to generate a m soft-token summary, where m < t. We first show that existing prompt compression methods are ineffective for many-shot compression, and simply using fewer shots as a baseline is surprisingly strong. To achieve effective compression, we find that: (a) a stronger compressor model with more trainable parameters is necessary, and (b) compressing many-shot representations at each transformer layer enables more fine-grained compression by providing each layer with its own compressed representation. Based on these insights, we propose MemCom, a layer-wise compression method. We systematically evaluate various compressor models and training approaches across different model sizes (2B and 7B), architectures (Gemma and Mistral), many-shot sequence lengths (3k-6k tokens), and compression ratios (3x to 8x). MemCom outperforms strong baselines across all compression ratios on multiple classification tasks with large label sets. Notably, while baseline performance degrades sharply at higher compression ratios, often by over 20-30%, MemCom maintains high accuracy with minimal degradation, typically dropping by less than 10%."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Reliability of Large Language Model Generated Clinical Reasoning in Assisted Reproductive Technology: Blinded Comparative Evaluation Study", "authors": "Dou Liu, Ying Long, Sophia Zuoqiu, Di Liu, Kang Li, Yiting Lin, Hanyi Liu, Rong Yin, Tian Tang", "subjects": "Artificial Intelligence (cs.AI)", "abstract": "Creating high-quality clinical Chains-of-Thought (CoTs) is crucial for explainable medical Artificial Intelligence (AI) while constrained by data scarcity. Although Large Language Models (LLMs) can synthesize medical data, their clinical reliability remains unverified. This study evaluates the reliability of LLM-generated CoTs and investigates prompting strategies to enhance their quality. In a blinded comparative study, senior clinicians in Assisted Reproductive Technology (ART) evaluated CoTs generated via three distinct strategies: Zero-shot, Random Few-shot (using shallow examples), and Selective Few-shot (using diverse, high-quality examples). These expert ratings were compared against evaluations from a state-of-the-art AI model (GPT-4o). The Selective Few-shot strategy significantly outperformed other strategies across all human evaluation metrics (p < .001). Critically, the Random Few-shot strategy offered no significant improvement over the Zero-shot baseline, demonstrating that low-quality examples are as ineffective as no examples. The success of the Selective strategy is attributed to two principles: \"Gold-Standard Depth\" (reasoning quality) and \"Representative Diversity\" (generalization). Notably, the AI evaluator failed to discern these critical performance differences. The clinical reliability of synthetic CoTs is dictated by strategic prompt curation, not the mere presence of examples. We propose a \"Dual Principles\" framework as a foundational methodology to generate trustworthy data at scale. This work offers a validated solution to the data bottleneck and confirms the indispensable role of human expertise in evaluating high-stakes clinical AI."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Facts in Stats: Impacts of Pretraining Diversity on Language Model Generalization", "authors": "Tina Behnia, Puneesh Deora, Christos Thrampoulidis", "subjects": "Computation and Language (cs.CL); Machine Learning (cs.LG)", "abstract": "Language models are pretrained on sequences that blend statistical regularities (making text fluent) with factual associations between specific tokens (knowledge of facts). While recent work suggests that the variability of their interaction, such as paraphrases of factual associations, critically determines generalization ability, we lack a systematic analysis of these impacts. This paper introduces a flexible synthetic testbed that combines a statistical stream of generic tokens with an abstract factual stream of source-target token pairs, enabling fine-grained control over their interaction. The design enables the independent control of diversity nature by manipulating stream composition (contextual structure) and the diversity level by varying which statistical streams each fact appears in. Through controlled experiments, we find that while higher contextual diversity delays in-distribution (ID) factual accuracy, its impact on out-of-distribution (OOD) factual generalization depends critically on contextual structure. In some cases, OOD performance follows the same trend as ID, but in others, diversity becomes essential for non-trivial factual recall. Even when low diversity prohibits factual recall, optimal diversity levels depend on training duration. Beyond factual recall failures, we identify structures where statistical generalization fails independently, and others where both capabilities degrade. This shows how the interplay between contextual design and diversity level impacts different generalization aspects. Further, through a series of controlled interventions on the model components, we trace the OOD failures to distinct optimization bottlenecks, highlighting the importance of the embedding and unembedding layers. Our synthetic framework allows us to isolate effects that would be confounded in large-scale studies, offering a controlled testbed for future investigations."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Narrowing Action Choices with AI Improves Human Sequential Decisions", "authors": "Eleni Straitouri, Stratis Tsirtsis, Ander Artola Velasco, Manuel Gomez-Rodriguez", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Human-Computer Interaction (cs.HC); Machine Learning (stat.ML)", "abstract": "Recent work has shown that, in classification tasks, it is possible to design decision support systems that do not require human experts to understand when to cede agency to a classifier or when to exercise their own agency to achieve complementarity$\\unicode{x2014}$experts using these systems make more accurate predictions than those made by the experts or the classifier alone. The key principle underpinning these systems reduces to adaptively controlling the level of human agency, by design. Can we use the same principle to achieve complementarity in sequential decision making tasks? In this paper, we answer this question affirmatively. We develop a decision support system that uses a pre-trained AI agent to narrow down the set of actions a human can take to a subset, and then asks the human to take an action from this action set. Along the way, we also introduce a bandit algorithm that leverages the smoothness properties of the action sets provided by our system to efficiently optimize the level of human agency. To evaluate our decision support system, we conduct a large-scale human subject study ($n = 1{,}600$) where participants play a wildfire mitigation game. We find that participants who play the game supported by our system outperform those who play on their own by $\\sim$$30$% and the AI agent used by our system by $>$$2$%, even though the AI agent largely outperforms participants playing without support. We have made available the data gathered in our human subject study as well as an open source implementation of our system at this https URL ."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          StripRFNet: A Strip Receptive Field and Shape-Aware Network for Road Damage Detection", "authors": "Jianhan Lin, Yuchu Qin, Shuai Gao, Yikang Rui, Jie Liu, Yanjie Lv", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Well-maintained road networks are crucial for achieving Sustainable Development Goal (SDG) 11. Road surface damage not only threatens traffic safety but also hinders sustainable urban development. Accurate detection, however, remains challenging due to the diverse shapes of damages, the difficulty of capturing slender cracks with high aspect ratios, and the high error rates in small-scale damage recognition. To address these issues, we propose StripRFNet, a novel deep neural network comprising three modules: (1) a Shape Perception Module (SPM) that enhances shape discrimination via large separable kernel attention (LSKA) in multi-scale feature aggregation; (2) a Strip Receptive Field Module (SRFM) that employs large strip convolutions and pooling to capture features of slender cracks; and (3) a Small-Scale Enhancement Module (SSEM) that leverages a high-resolution P2 feature map, a dedicated detection head, and dynamic upsampling to improve small-object detection. Experiments on the RDD2022 benchmark show that StripRFNet surpasses existing methods. On the Chinese subset, it improves F1-score, mAP50, and mAP50:95 by 4.4, 2.9, and 3.4 percentage points over the baseline, respectively. On the full dataset, it achieves the highest F1-score of 80.33% compared with CRDDC'2022 participants and ORDDC'2024 Phase 2 results, while maintaining competitive inference speed. These results demonstrate that StripRFNet achieves state-of-the-art accuracy and real-time efficiency, offering a promising tool for intelligent road maintenance and sustainable infrastructure management."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          ObjectTransforms for Uncertainty Quantification and Reduction in Vision-Based Perception for Autonomous Vehicles", "authors": "Nishad Sahu, Shounak Sural, Aditya Satish Patil, Ragunathan (Raj)Rajkumar", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Reliable perception is fundamental for safety critical decision making in autonomous driving. Yet, vision based object detector neural networks remain vulnerable to uncertainty arising from issues such as data bias and distributional shifts. In this paper, we introduce ObjectTransforms, a technique for quantifying and reducing uncertainty in vision based object detection through object specific transformations at both training and inference times. At training time, ObjectTransforms perform color space perturbations on individual objects, improving robustness to lighting and color variations. ObjectTransforms also uses diffusion models to generate realistic, diverse pedestrian instances. At inference time, object perturbations are applied to detected objects and the variance of detection scores are used to quantify predictive uncertainty in real time. This uncertainty signal is then used to filter out false positives and also recover false negatives, improving the overall precision recall curve. Experiments with YOLOv8 on the NuImages 10K dataset demonstrate that our method yields notable accuracy improvements and uncertainty reduction across all object classes during training, while predicting desirably higher uncertainty values for false positives as compared to true positives during inference. Our results highlight the potential of ObjectTransforms as a lightweight yet effective mechanism for reducing and quantifying uncertainty in vision-based perception during training and inference respectively."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          The Hidden Cost of Modeling P(X): Vulnerability to Membership Inference Attacks in Generative Text Classifiers", "authors": "Owais Makroo, Siva Rajesh Kasa, Sumegh Roychowdhury, Karan Gupta, Nikhil Pattisapu, Santhosh Kasa, Sumit Negi", "subjects": "Cryptography and Security (cs.CR); Computation and Language (cs.CL); Machine Learning (cs.LG); Machine Learning (stat.ML)", "abstract": "Membership Inference Attacks (MIAs) pose a critical privacy threat by enabling adversaries to determine whether a specific sample was included in a model's training dataset. Despite extensive research on MIAs, systematic comparisons between generative and discriminative classifiers remain limited. This work addresses this gap by first providing theoretical motivation for why generative classifiers exhibit heightened susceptibility to MIAs, then validating these insights through comprehensive empirical evaluation. Our study encompasses discriminative, generative, and pseudo-generative text classifiers across varying training data volumes, evaluated on nine benchmark datasets. Employing a diverse array of MIA strategies, we consistently demonstrate that fully generative classifiers which explicitly model the joint likelihood $P(X,Y)$ are most vulnerable to membership leakage. Furthermore, we observe that the canonical inference approach commonly used in generative classifiers significantly amplifies this privacy risk. These findings reveal a fundamental utility-privacy trade-off inherent in classifier design, underscoring the critical need for caution when deploying generative classifiers in privacy-sensitive applications. Our results motivate future research directions in developing privacy-preserving generative classifiers that can maintain utility while mitigating membership inference vulnerabilities."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Zero-shot World Models via Search in Memory", "authors": "Federico Malato, Ville Hautam\u00e4ki", "subjects": "Machine Learning (cs.LG)", "abstract": "World Models have vastly permeated the field of Reinforcement Learning. Their ability to model the transition dynamics of an environment have greatly improved sample efficiency in online RL. Among them, the most notorious example is Dreamer, a model that learns to act in a diverse set of image-based environments. In this paper, we leverage similarity search and stochastic representations to approximate a world model without a training procedure. We establish a comparison with PlaNet, a well-established world model of the Dreamer family. We evaluate the models on the quality of latent reconstruction and on the perceived similarity of the reconstructed image, on both next-step and long horizon dynamics prediction. The results of our study demonstrate that a search-based world model is comparable to a training based one in both cases. Notably, our model show stronger performance in long-horizon prediction with respect to the baseline on a range of visually different environments."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Prompt injections as a tool for preserving identity in GAI image descriptions", "authors": "Kate Glazko, Jennifer Mankoff", "subjects": "Cryptography and Security (cs.CR); Computers and Society (cs.CY)", "abstract": "Generative AI risks such as bias and lack of representation impact people who do not interact directly with GAI systems, but whose content does: indirect users. Several approaches to mitigating harms to indirect users have been described, but most require top down or external intervention. An emerging strategy, prompt injections, provides an empowering alternative: indirect users can mitigate harm against them, from within their own content. Our approach proposes prompt injections not as a malicious attack vector, but as a tool for content/image owner resistance. In this poster, we demonstrate one case study of prompt injections for empowering an indirect user, by retaining an image owner's gender and disabled identity when an image is described by GAI."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          A Minimal-Assumption Analysis of Q-Learning with Time-Varying Policies", "authors": "Phalguni Nanda, Zaiwei Chen", "subjects": "Machine Learning (cs.LG); Optimization and Control (math.OC); Machine Learning (stat.ML)", "abstract": "In this work, we present the first finite-time analysis of the Q-learning algorithm under time-varying learning policies (i.e., on-policy sampling) with minimal assumptions -- specifically, assuming only the existence of a policy that induces an irreducible Markov chain over the state space. We establish a last-iterate convergence rate for $\\mathbb{E}[\\|Q_k - Q^*\\|_\\infty^2]$, implying a sample complexity of order $O(1/\\epsilon^2)$ for achieving $\\mathbb{E}[\\|Q_k - Q^*\\|_\\infty] \\le \\epsilon$, matching that of off-policy Q-learning but with a worse dependence on exploration-related parameters. We also derive an explicit rate for $\\mathbb{E}[\\|Q^{\\pi_k} - Q^*\\|_\\infty^2]$, where $\\pi_k$ is the learning policy at iteration $k$. These results reveal that on-policy Q-learning exhibits weaker exploration than its off-policy counterpart but enjoys an exploitation advantage, as its policy converges to an optimal one rather than remaining fixed. Numerical simulations corroborate our theory. Technically, the combination of time-varying learning policies (which induce rapidly time-inhomogeneous Markovian noise) and the minimal assumption on exploration presents significant analytical challenges. To address these challenges, we employ a refined approach that leverages the Poisson equation to decompose the Markovian noise corresponding to the lazy transition matrix into a martingale-difference term and residual terms. To control the residual terms under time inhomogeneity, we perform a sensitivity analysis of the Poisson equation solution with respect to both the Q-function estimate and the learning policy. These tools may further facilitate the analysis of general reinforcement learning algorithms with rapidly time-varying learning policies -- such as single-timescale actor--critic methods and learning-in-games algorithms -- and are of independent interest."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Typing Strictness (Extended Version)", "authors": "Daniel Sainati, Joseph W. Cutler, Benjamin C. Pierce, Stephanie Weirich", "subjects": "Programming Languages (cs.PL)", "abstract": "Strictness analysis is critical to efficient implementation of languages with non-strict evaluation, mitigating much of the performance overhead of laziness. However, reasoning about strictness at the source level can be challenging and unintuitive. We propose a new definition of strictness that refines the traditional one by describing variable usage more precisely. We lay type-theoretic foundations for this definition in both call-by-name and call-by-push-value settings, drawing inspiration from the literature on type systems tracking effects and coeffects. We prove via a logical relation that the strictness attributes computed by our type systems accurately describe the use of variables at runtime, and we offer a strictness-annotation-preserving translation from the call-by-name system to the call-by-push-value one. All our results are mechanized in Rocq."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Aria Gen 2 Pilot Dataset", "authors": "Chen Kong, James Fort, Aria Kang, Jonathan Wittmer, Simon Green, Tianwei Shen, Yipu Zhao, Cheng Peng, Gustavo Solaira, Andrew Berkovich, Nikhil Raina, Vijay Baiyya, Evgeniy Oleinik, Eric Huang, Fan Zhang, Julian Straub, Mark Schwesinger, Luis Pesqueira, Xiaqing Pan, Jakob Julian Engel, Carl Ren, Mingfei Yan, Richard Newcombe", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG); Robotics (cs.RO)", "abstract": "The Aria Gen 2 Pilot Dataset (A2PD) is an egocentric multimodal open dataset captured using the state-of-the-art Aria Gen 2 glasses. To facilitate timely access, A2PD is released incrementally with ongoing dataset enhancements. The initial release features Dia'ane, our primary subject, who records her daily activities alongside friends, each equipped with Aria Gen 2 glasses. It encompasses five primary scenarios: cleaning, cooking, eating, playing, and outdoor walking. In each of the scenarios, we provide comprehensive raw sensor data and output data from various machine perception algorithms. These data illustrate the device's ability to perceive the wearer, the surrounding environment, and interactions between the wearer and the environment, while maintaining robust performance across diverse users and conditions. The A2PD is publicly available at this http URL, with open-source tools and usage examples provided in Project Aria Tools."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          GuideFlow3D: Optimization-Guided Rectified Flow For Appearance Transfer", "authors": "Sayan Deb Sarkar, Sinisa Stekovic, Vincent Lepetit, Iro Armeni", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Graphics (cs.GR)", "abstract": "Transferring appearance to 3D assets using different representations of the appearance object - such as images or text - has garnered interest due to its wide range of applications in industries like gaming, augmented reality, and digital content creation. However, state-of-the-art methods still fail when the geometry between the input and appearance objects is significantly different. A straightforward approach is to directly apply a 3D generative model, but we show that this ultimately fails to produce appealing results. Instead, we propose a principled approach inspired by universal guidance. Given a pretrained rectified flow model conditioned on image or text, our training-free method interacts with the sampling process by periodically adding guidance. This guidance can be modeled as a differentiable loss function, and we experiment with two different types of guidance including part-aware losses for appearance and self-similarity. Our experiments show that our approach successfully transfers texture and geometric details to the input 3D asset, outperforming baselines both qualitatively and quantitatively. We also show that traditional metrics are not suitable for evaluating the task due to their inability of focusing on local details and comparing dissimilar inputs, in absence of ground truth data. We thus evaluate appearance transfer quality with a GPT-based system objectively ranking outputs, ensuring robust and human-like assessment, as further confirmed by our user study. Beyond showcased scenarios, our method is general and could be extended to different types of diffusion models and guidance functions."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Expert Merging in Sparse Mixture of Experts with Nash Bargaining", "authors": "Dung V. Nguyen, Anh T. Nguyen, Minh H. Nguyen, Luc Q. Nguyen, Shiqi Jiang, Ethan Fetaya, Linh Duy Tran, Gal Chechik, Tan M. Nguyen", "subjects": "Machine Learning (cs.LG); Machine Learning (stat.ML)", "abstract": "Existing expert merging strategies for Sparse Mixture of Experts (SMoE) typically rely on input-dependent or input-independent averaging of expert parameters, but often lack a principled weighting mechanism. In this work, we reinterpret expert merging through the lens of game theory, revealing cooperative and competitive dynamics among experts. Based on this perspective, we introduce Nash Merging of Experts (NAMEx), a novel framework that incorporates Nash Bargaining into the merging process, enabling more balanced and efficient collaboration among experts. Additionally, we incorporate complex momentum into NAMEx to accelerate expert propagation with theoretical guarantees for convergence. Extensive experiments across language modelling, text classification, image classification, and zero-shot robustness under data corruption show that NAMEx consistently outperforms competing methods while integrating seamlessly with popular MoE architectures. Finally, we demonstrate NAMEx's scalability by applying it to large-scale systems, including Qwen1.5-MoE (14B) and DeepSeek-MoE (16B), where it proves effective in both zero-shot and fine-tuning settings."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Agentic AI for Ultra-Modern Networks: Multi-Agent Framework for RAN Autonomy and Assurance", "authors": "Sukhdeep Singh, Avinash Bhat, Shweta M, Subhash K Singh, Moonki Hong, Madhan Raj K, Kandeepan Sithamparanathan, Sunder A. Khowaja, Kapal Dev", "subjects": "Networking and Internet Architecture (cs.NI); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "abstract": "The increasing complexity of Beyond 5G and 6G networks necessitates new paradigms for autonomy and assur- ance. Traditional O-RAN control loops rely heavily on RIC- based orchestration, which centralizes intelligence and exposes the system to risks such as policy conflicts, data drift, and unsafe actions under unforeseen conditions. In this work, we argue that the future of autonomous networks lies in a multi-agentic architecture, where specialized agents collaborate to perform data collection, model training, prediction, policy generation, verification, deployment, and assurance. By replacing tightly- coupled centralized RIC-based workflows with distributed agents, the framework achieves autonomy, resilience, explainability, and system-wide safety. To substantiate this vision, we design and evaluate a traffic steering use case under surge and drift conditions. Results across four KPIs: RRC connected users, IP throughput, PRB utilization, and SINR, demonstrate that a naive predictor-driven deployment improves local KPIs but destabilizes neighbors, whereas the agentic system blocks unsafe policies, preserving global network health. This study highlights multi- agent architectures as a credible foundation for trustworthy AI- driven autonomy in next-generation RANs."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          C-arm Guidance: A Self-supervised Approach To Automated Positioning During Stroke Thrombectomy", "authors": "Ahmad Arrabi, Jay hwasung Jung, J Le, A Nguyen, J Reed, E Stahl, Nathan Franssen, Scott Raymond, Safwan Wshah", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Thrombectomy is one of the most effective treatments for ischemic stroke, but it is resource and personnel-intensive. We propose employing deep learning to automate critical aspects of thrombectomy, thereby enhancing efficiency and safety. In this work, we introduce a self-supervised framework that classifies various skeletal landmarks using a regression-based pretext task. Our experiments demonstrate that our model outperforms existing methods in both regression and classification tasks. Notably, our results indicate that the positional pretext task significantly enhances downstream classification performance. Future work will focus on extending this framework toward fully autonomous C-arm control, aiming to optimize trajectories from the pelvis to the head during stroke thrombectomy procedures. All code used is available at this https URL"}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          DuetMatch: Harmonizing Semi-Supervised Brain MRI Segmentation via Decoupled Branch Optimization", "authors": "Thanh-Huy Nguyen, Hoang-Thien Nguyen, Vi Vu, Ba-Thinh Lam, Phat Huynh, Tianyang Wang, Xingjian Li, Ulas Bagci, Min Xu", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "The limited availability of annotated data in medical imaging makes semi-supervised learning increasingly appealing for its ability to learn from imperfect supervision. Recently, teacher-student frameworks have gained popularity for their training benefits and robust performance. However, jointly optimizing the entire network can hinder convergence and stability, especially in challenging scenarios. To address this for medical image segmentation, we propose DuetMatch, a novel dual-branch semi-supervised framework with asynchronous optimization, where each branch optimizes either the encoder or decoder while keeping the other frozen. To improve consistency under noisy conditions, we introduce Decoupled Dropout Perturbation, enforcing regularization across branches. We also design Pair-wise CutMix Cross-Guidance to enhance model diversity by exchanging pseudo-labels through augmented input pairs. To mitigate confirmation bias from noisy pseudo-labels, we propose Consistency Matching, refining labels using stable predictions from frozen teacher models. Extensive experiments on benchmark brain MRI segmentation datasets, including ISLES2022 and BraTS, show that DuetMatch consistently outperforms state-of-the-art methods, demonstrating its effectiveness and robustness across diverse semi-supervised segmentation scenarios."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Procedural Scene Programs for Open-Universe Scene Generation: LLM-Free Error Correction via Program Search", "authors": "Maxim Gumin, Do Heon Han, Seung Jean Yoo, Aditya Ganeshan, R. Kenny Jones, Kailiang Fu, Rio Aguina-Kang, Stewart Morris, Daniel Ritchie", "subjects": "Graphics (cs.GR)", "abstract": "Synthesizing 3D scenes from open-vocabulary text descriptions is a challenging, important, and recently-popular application. One of its critical subproblems is layout generation: given a set of objects, lay them out to produce a scene matching the input description. Nearly all recent work adopts a declarative paradigm for this problem: using an LLM to generate a specification of constraints between objects, then solving those constraints to produce the final layout. In contrast, we explore an alternative imperative paradigm, in which an LLM iteratively places objects, with each object's position and orientation computed as a function of previously-placed objects. The imperative approach allows for a simpler scene specification language while also handling a wider variety and larger complexity of scenes. We further improve the robustness of our imperative scheme by developing an error correction mechanism that iteratively improves the scene's validity while staying as close as possible to the original layout generated by the LLM. In forced-choice perceptual studies, participants preferred layouts generated by our imperative approach 82% and 94% of the time when compared against two declarative layout generation methods. We also present a simple, automated evaluation metric for 3D scene layout generation that aligns well with human preferences."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Publication Trend Analysis and Synthesis via Large Language Model: A Case Study of Engineering in PNAS", "authors": "Mason Smetana, Lev Khazanovich", "subjects": "Digital Libraries (cs.DL); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)", "abstract": "Scientific literature is increasingly siloed by complex language, static disciplinary structures, and potentially sparse keyword systems, making it cumbersome to capture the dynamic nature of modern science. This study addresses these challenges by introducing an adaptable large language model (LLM)-driven framework to quantify thematic trends and map the evolving landscape of scientific knowledge. The approach is demonstrated over a 20-year collection of more than 1,500 engineering articles published by the Proceedings of the National Academy of Sciences (PNAS), marked for their breadth and depth of research focus. A two-stage classification pipeline first establishes a primary thematic category for each article based on its abstract. The subsequent phase performs a full-text analysis to assign secondary classifications, revealing latent, cross-topic connections across the corpus. Traditional natural language processing (NLP) methods, such as Bag-of-Words (BoW) and Term Frequency-Inverse Document Frequency (TF-IDF), confirm the resulting topical structure and also suggest that standalone word-frequency analyses may be insufficient for mapping fields with high diversity. Finally, a disjoint graph representation between the primary and secondary classifications reveals implicit connections between themes that may be less apparent when analyzing abstracts or keywords alone. The findings show that the approach independently recovers much of the journal's editorially embedded structure without prior knowledge of its existing dual-classification schema (e.g., biological studies also classified as engineering). This framework offers a powerful tool for detecting potential thematic trends and providing a high-level overview of scientific progress."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Zeroth-Order Sharpness-Aware Learning with Exponential Tilting", "authors": "Xuchen Gong, Tian Li", "subjects": "Machine Learning (cs.LG); Computation and Language (cs.CL); Machine Learning (stat.ML)", "abstract": "Classic zeroth-order optimization approaches typically optimize for a smoothed version of the original function, i.e., the expected objective under randomly perturbed model parameters. This can be interpreted as encouraging the loss values in the perturbation set to be small on average. Popular sharpness-aware minimization (SAM) objectives, however, typically focus on the largest loss within the neighborhood to arrive at flat minima more effectively. In this work, we connect zeroth-order optimization (and its corresponding objectives) with SAM approaches explicitly, through an exponential tilting objective that provides a smooth transition between the average- and the max-loss formulations. We explore new zeroth-order algorithms to solve a soft SAM objective parameterized by a tilting parameter $t$. We provide precise characterizations of the sharpness notions of the tilted SAM framework. Practically, our approach can be used as a gradient-free and memory-efficient alternative to SAM variants, and it achieves better generalization compared to vanilla zeroth-order baselines on a wide range of downstream tasks, including classification, multiple choice QA, and language generation."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Automated C-Arm Positioning via Conformal Landmark Localization", "authors": "Ahmad Arrabi, Jay Hwasung Jung, Jax Luo, Nathan Franssen, Scott Raymond, Safwan Wshah", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Accurate and reliable C-arm positioning is essential for fluoroscopy-guided interventions. However, clinical workflows rely on manual alignment that increases radiation exposure and procedural delays. In this work, we present a pipeline that autonomously navigates the C-arm to predefined anatomical landmarks utilizing X-ray images. Given an input X-ray image from an arbitrary starting location on the operating table, the model predicts a 3D displacement vector toward each target landmark along the body. To ensure reliable deployment, we capture both aleatoric and epistemic uncertainties in the model's predictions and further calibrate them using conformal prediction. The derived prediction regions are interpreted as 3D confidence regions around the predicted landmark locations. The training framework combines a probabilistic loss with skeletal pose regularization to encourage anatomically plausible outputs. We validate our approach on a synthetic X-ray dataset generated from DeepDRR. Results show not only strong localization accuracy across multiple architectures but also well-calibrated prediction bounds. These findings highlight the pipeline's potential as a component in safe and reliable autonomous C-arm systems. Code is available at this https URL"}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Still Competitive: Revisiting Recurrent Models for Irregular Time Series Prediction", "authors": "Ankitkumar Joshi, Milos Hauskrecht", "subjects": "Machine Learning (cs.LG); Machine Learning (stat.ML)", "abstract": "Modeling irregularly sampled multivariate time series is a persistent challenge in domains like healthcare and sensor networks. While recent works have explored a variety of complex learning architectures to solve the prediction problems for irregularly sampled time series, it remains unclear what are the true benefits of some of these architectures, and whether clever modifications of simpler and more efficient RNN-based algorithms are still competitive, i.e. they are on par with or even superior to these methods. In this work, we propose and study GRUwE: Gated Recurrent Unit with Exponential basis functions, that builds upon RNN-based architectures for observations made at irregular times. GRUwE supports both regression-based and event-based predictions in continuous time. GRUwE works by maintaining a Markov state representation of the time series that updates with the arrival of irregular observations. The Markov state update relies on two reset mechanisms: (i) observation-triggered reset, and (ii) time-triggered reset of the GRU state using learnable exponential decays, to support the predictions in continuous time. Our empirical evaluations across several real-world benchmarks on next-observation and next-event prediction tasks demonstrate that GRUwE can indeed achieve competitive to superior performance compared to the recent state-of-the-art (SOTA) methods. Thanks to its simplicity, GRUwE offers compelling advantages: it is easy to implement, requires minimal hyper-parameter tuning efforts, and significantly reduces the computational overhead in the online deployment."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          AtomBench: A Benchmark for Generative Atomic Structure Models using GPT, Diffusion, and Flow Architectures", "authors": "Charles Rhys Campbell, Aldo H. Romero, Kamal Choudhary", "subjects": "Machine Learning (cs.LG); Superconductivity (cond-mat.supr-con)", "abstract": "Generative models have become significant assets in the exploration and identification of new materials, enabling the rapid proposal of candidate crystal structures that satisfy target properties. Despite the increasing adoption of diverse architectures, a rigorous comparative evaluation of their performance on materials datasets is lacking. In this work, we present a systematic benchmark of three representative generative models- AtomGPT (a transformer-based model), Crystal Diffusion Variational Autoencoder (CDVAE), and FlowMM (a Riemannian flow matching model). These models were trained to reconstruct crystal structures from subsets of two publicly available superconductivity datasets- JARVIS Supercon 3D and DS A/B from the Alexandria database. Performance was assessed using the Kullback-Leibler (KL) divergence between predicted and reference distributions of lattice parameters, as well as the mean absolute error (MAE) of individual lattice constants. For the computed KLD and MAE scores, CDVAE performs most favorably, followed by AtomGPT, and then FlowMM. All benchmarking code and model configurations will be made publicly available at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Alignment is Localized: A Causal Probe into Preference Layers", "authors": "Archie Chaudhury", "subjects": "Machine Learning (cs.LG); Computation and Language (cs.CL)", "abstract": "Reinforcement Learning frameworks, particularly those utilizing human annotations, have become an increasingly popular method for preference fine-tuning, where the outputs of a language model are tuned to match a certain set of behavioral policies or guidelines. Reinforcement Learning through Human Feedback (RLHF) is perhaps the most popular implementation of such a framework, particularly for aligning LMs toward safety and human intent. However, the internal workings of how such alignment is achieved remain largely opaque. In this work, we systematically analyze preference optimization for language model alignment by applying layer-wide causal patching between a base model and its tuned counterpart across human preference pairs. We implement our methodology on \\textit{Llama-3.2-1B}, and find that alignment is spatially localized: mid-layer activations encode a distinct subspace that causally determines reward-consistent behavior, while early and late layers remain largely unaffected. Utilizing LASSO regression, we also find that only a small number of layers possess non-zero coefficients linking activation distances to reward gains. Overall, we show that, at least for some language models, alignment from human-based, preferential tuning is a directional, low rank process, rather than diffuse and parameteric."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          WebRTC Metadata and IP Leakage in Modern Browsers: A Cross-Platform Measurement Study", "authors": "Ahmed Fouad Kadhim Koysha, Aytug Boyaci, Rafet Akdeniz", "subjects": "Cryptography and Security (cs.CR)", "abstract": "Web Real-Time Communication (WebRTC) enables real-time peer-to-peer communication, but its Interactive Connectivity Establishment (ICE) process can unintentionally expose internal and public IP addresses as metadata. This paper presents a cross-platform measurement study of WebRTC metadata leakage using current (2025) builds of Chrome, Brave, Firefox, and Tor on desktop and mobile platforms. Experiments were conducted across semi-trusted Wi-Fi and untrusted mobile carrier networks. Results show that Chrome remains the most leakage-prone, disclosing LAN or Carrier-Grade NAT (CGNAT) addresses on mobile and metadata on desktop; Brave avoids direct IP leaks but exposes session-stable mDNS identifiers; Firefox provides strong protection on desktop but leaks internal IPs on Android; and Tor consistently prevents all forms of leakage. We introduce a structured threat model for semi-trusted environments and evaluate the limitations of mDNS obfuscation. Finally, we propose layered mitigation strategies combining browser defaults, institutional safeguards, and user controls. Findings demonstrate that while direct LAN leakage is declining, emerging vectors such as mDNS and CGNAT create persistent privacy risks requiring protocol-level redesign and policy action."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Bridging Symmetry and Robustness: On the Role of Equivariance in Enhancing Adversarial Robustness", "authors": "Longwei Wang, Ifrat Ikhtear Uddin, KC Santosh, Chaowei Zhang, Xiao Qin, Yang Zhou", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "Adversarial examples reveal critical vulnerabilities in deep neural networks by exploiting their sensitivity to imperceptible input perturbations. While adversarial training remains the predominant defense strategy, it often incurs significant computational cost and may compromise clean-data accuracy. In this work, we investigate an architectural approach to adversarial robustness by embedding group-equivariant convolutions-specifically, rotation- and scale-equivariant layers-into standard convolutional neural networks (CNNs). These layers encode symmetry priors that align model behavior with structured transformations in the input space, promoting smoother decision boundaries and greater resilience to adversarial attacks. We propose and evaluate two symmetry-aware architectures: a parallel design that processes standard and equivariant features independently before fusion, and a cascaded design that applies equivariant operations sequentially. Theoretically, we demonstrate that such models reduce hypothesis space complexity, regularize gradients, and yield tighter certified robustness bounds under the CLEVER (Cross Lipschitz Extreme Value for nEtwork Robustness) framework. Empirically, our models consistently improve adversarial robustness and generalization across CIFAR-10, CIFAR-100, and CIFAR-10C under both FGSM and PGD attacks, without requiring adversarial training. These findings underscore the potential of symmetry-enforcing architectures as efficient and principled alternatives to data augmentation-based defenses."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          In Generative AI We (Dis)Trust? Computational Analysis of Trust and Distrust in Reddit Discussions", "authors": "Aria Pessianzadeh, Naima Sultana, Hildegarde Van den Bulck, David Gefen, Shahin Jabari, Rezvaneh Rezapour", "subjects": "Computation and Language (cs.CL)", "abstract": "The rise of generative AI (GenAI) has impacted many aspects of human life. As these systems become embedded in everyday practices, understanding public trust in them also becomes essential for responsible adoption and governance. Prior work on trust in AI has largely drawn from psychology and human-computer interaction, but there is a lack of computational, large-scale, and longitudinal approaches to measuring trust and distrust in GenAI and large language models (LLMs). This paper presents the first computational study of Trust and Distrust in GenAI, using a multi-year Reddit dataset (2022--2025) spanning 39 subreddits and 197,618 posts. Crowd-sourced annotations of a representative sample were combined with classification models to scale analysis. We find that Trust and Distrust are nearly balanced over time, with shifts around major model releases. Technical performance and usability dominate as dimensions, while personal experience is the most frequent reason shaping attitudes. Distinct patterns also emerge across trustors (e.g., experts, ethicists, general users). Our results provide a methodological framework for large-scale Trust analysis and insights into evolving public perceptions of GenAI."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          The Formalism-Implementation Gap in Reinforcement Learning Research", "authors": "Pablo Samuel Castro", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "The last decade has seen an upswing in interest and adoption of reinforcement learning (RL) techniques, in large part due to its demonstrated capabilities at performing certain tasks at \"super-human levels\". This has incentivized the community to prioritize research that demonstrates RL agent performance, often at the expense of research aimed at understanding their learning dynamics. Performance-focused research runs the risk of overfitting on academic benchmarks -- thereby rendering them less useful -- which can make it difficult to transfer proposed techniques to novel problems. Further, it implicitly diminishes work that does not push the performance-frontier, but aims at improving our understanding of these techniques. This paper argues two points: (i) RL research should stop focusing solely on demonstrating agent capabilities, and focus more on advancing the science and understanding of reinforcement learning; and (ii) we need to be more precise on how our benchmarks map to the underlying mathematical formalisms. We use the popular Arcade Learning Environment (ALE; Bellemare et al., 2013) as an example of a benchmark that, despite being increasingly considered \"saturated\", can be effectively used for developing this understanding, and facilitating the deployment of RL techniques in impactful real-world problems."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Cost Savings from Automatic Quality Assessment of Generated Images", "authors": "Xavier Giro-i-Nieto, Nefeli Andreou, Anqi Liang, Manel Baradad, Francesc Moreno-Noguer, Aleix Martinez", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Deep generative models have shown impressive progress in recent years, making it possible to produce high quality images with a simple text prompt or a reference image. However, state of the art technology does not yet meet the quality standards offered by traditional photographic methods. For this reason, production pipelines that use generated images often include a manual stage of image quality assessment (IQA). This process is slow and expensive, especially because of the low yield of automatically generated images that pass the quality bar. The IQA workload can be reduced by introducing an automatic pre-filtering stage, that will increase the overall quality of the images sent to review and, therefore, reduce the average cost required to obtain a high quality image. We present a formula that estimates the cost savings depending on the precision and pass yield of a generic IQA engine. This formula is applied in a use case of background inpainting, showcasing a significant cost saving of 51.61% obtained with a simple AutoML solution."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Forward-Backward Binarization", "authors": "Ismail Belgacem, Franck Delaplace", "subjects": "Discrete Mathematics (cs.DM)", "abstract": "Binarization of gene expression data is a \\textbf{critical prerequisite} for the synthesis of Boolean gene regulatory network (GRN) models from omics datasets. Because Boolean networks encode gene activity as binary variables, the accuracy of binarization directly conditions whether the inferred models can faithfully reproduce biological experiments, capture regulatory dynamics, and support downstream analyses such as controllability and therapeutic strategy design. In practice, binarization is most often performed using thresholding methods that partition expression values into two discrete levels, representing the absence or presence of gene expression. However, such approaches oversimplify the underlying biology: gene-specific functional roles, measurement uncertainty, and the scarcity of time-resolved experimental data render thresholding alone insufficient. To overcome these limitations, we propose a novel \\textbf{regulation-based binarization method} tailored to snapshot data. Our approach combines thresholding with functional binary value completion guided by the regulatory graph, propagating values between regulators and targets according to Boolean regulation rules. This strategy enables the inference of missing or uncertain values and ensures that binarization remains biologically consistent with both regulatory interactions and Boolean modeling principles of the gene regulation. Validation against ODE simulations of artificial and established Boolean GRNs demonstrates that the method achieves accurate and robust binarization, thereby strengthening the reliability of Boolean network synthesis."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Expressive Reward Synthesis with the Runtime Monitoring Language", "authors": "Daniel Donnelly, Angelo Ferrando, Francesco Belardinelli", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Formal Languages and Automata Theory (cs.FL); Machine Learning (stat.ML)", "abstract": "A key challenge in reinforcement learning (RL) is reward (mis)specification, whereby imprecisely defined reward functions can result in unintended, possibly harmful, behaviours. Indeed, reward functions in RL are typically treated as black-box mappings from state-action pairs to scalar values. While effective in many settings, this approach provides no information about why rewards are given, which can hinder learning and interpretability. Reward Machines address this issue by representing reward functions as finite state automata, enabling the specification of structured, non-Markovian reward functions. However, their expressivity is typically bounded by regular languages, leaving them unable to capture more complex behaviours such as counting or parametrised conditions. In this work, we build on the Runtime Monitoring Language (RML) to develop a novel class of language-based Reward Machines. By leveraging the built-in memory of RML, our approach can specify reward functions for non-regular, non-Markovian tasks. We demonstrate the expressiveness of our approach through experiments, highlighting additional advantages in flexible event-handling and task specification over existing Reward Machine-based methods."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Zero-Shot Coordination in Ad Hoc Teams with Generalized Policy Improvement and Difference Rewards", "authors": "Rupal Nigam, Niket Parikh, Hamid Osooli, Mikihisa Yuasa, Jacob Heglund, Huy T. Tran", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI); Robotics (cs.RO)", "abstract": "Real-world multi-agent systems may require ad hoc teaming, where an agent must coordinate with other previously unseen teammates to solve a task in a zero-shot manner. Prior work often either selects a pretrained policy based on an inferred model of the new teammates or pretrains a single policy that is robust to potential teammates. Instead, we propose to leverage all pretrained policies in a zero-shot transfer setting. We formalize this problem as an ad hoc multi-agent Markov decision process and present a solution that uses two key ideas, generalized policy improvement and difference rewards, for efficient and effective knowledge transfer between different teams. We empirically demonstrate that our algorithm, Generalized Policy improvement for Ad hoc Teaming (GPAT), successfully enables zero-shot transfer to new teams in three simulated environments: cooperative foraging, predator-prey, and Overcooked. We also demonstrate our algorithm in a real-world multi-robot setting."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Human-Allied Relational Reinforcement Learning", "authors": "Fateme Golivand Darvishvand, Hikaru Shindo, Sahil Sidheekh, Kristian Kersting, Sriraam Natarajan", "subjects": "Machine Learning (cs.LG)", "abstract": "Reinforcement learning (RL) has experienced a second wind in the past decade. While incredibly successful in images and videos, these systems still operate within the realm of propositional tasks ignoring the inherent structure that exists in the problem. Consequently, relational extensions (RRL) have been developed for such structured problems that allow for effective generalization to arbitrary number of objects. However, they inherently make strong assumptions about the problem structure. We introduce a novel framework that combines RRL with object-centric representation to handle both structured and unstructured data. We enhance learning by allowing the system to actively query the human expert for guidance by explicitly modeling the uncertainty over the policy. Our empirical evaluation demonstrates the effectiveness and efficiency of our proposed approach."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Is simplicity still possible for a more accurate approximation to the perimeter of the ellipse? or, Using the exponential function to further improve the second Ramanujan's approximation", "authors": "Salvador E. Ayala-Raggi, Manuel Rend\u00f3n-Mar\u00edn", "subjects": "Numerical Analysis (math.NA)", "abstract": "The perimeter of an ellipse has no exact closed-form expression in terms of elementary functions, and numerous approximations have been proposed since the eighteenth century. Classical formulas by Fagnano, Euler, and Ramanujan, as well as modern refinements such as Cantrell and Koshy methods, aim to reduce the approximation error while maintaining computational simplicity. In this paper, we introduce a new closed-form expression that enhances Ramanujan second formula by dividing it by 1 minus a binomial of two exponential terms resulting in a very stable approximation in a range of b/a between 1 and 1/10000, or even up to a smaller ratio. The resulting approximation remains compact, requiring only four constants, and achieving a remarkable tradeoff between simplicity and accuracy. Across the full eccentricity range of b/a in [0.0001,1], our method attains a maximum relative error of approximately 0.57 ppm with respect to the exact perimeter computed via elliptic integral. Our formula is quasi-exact at the extremes, for the circle b/a=1 and for the degenerate flat ellipse b/a=0. Compared with Cantrell approximation, the proposed method reduces the maximum relative error by a factor of 25 while preserving a short and elegant expression. This makes it one of the simplest yet most accurate closed-form and single-line approximations to the ellipse perimeter currently available in the literature."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          VoiceMorph: How AI Voice Morphing Reveals the Boundaries of Auditory Self-Recognition", "authors": "Kye Shimizu, Minghan Gao, Ananya Ganesh, Pattie Maes", "subjects": "Human-Computer Interaction (cs.HC)", "abstract": "This study investigated auditory self-recognition boundaries using AI voice morphing technology, examining when individuals cease recognizing their own voice. Through controlled morphing between participants' voices and demographically matched targets at 1% increments using a mixed-methods design, we measured self-identification ratings and response times among 21 participants aged 18-64. Results revealed a critical recognition threshold at 35.2% morphing (95% CI [31.4, 38.1]). Older participants tolerated significantly higher morphing levels before losing self-recognition ($\\beta$ = 0.617, p = 0.048), suggesting age-related vulnerabilities. Greater acoustic embedding distances predicted slower decision-making ($r \\approx 0.5-0.53, p < 0.05$), with the longest response times for cloned versions of participants' own voices. Qualitative analysis revealed prosodic-based recognition strategies, universal voice manipulation discomfort, and awareness of applications spanning assistive technology to security risks. These findings establish foundational evidence for individual differences in voice morphing detection, with implications for AI ethics and vulnerable population protection as voice synthesis becomes accessible."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Operationalising Extended Cognition: Formal Metrics for Corporate Knowledge and Legal Accountability", "authors": "Elija Perrier", "subjects": "Artificial Intelligence (cs.AI)", "abstract": "Corporate responsibility turns on notions of corporate \\textit{mens rea}, traditionally imputed from human agents. Yet these assumptions are under challenge as generative AI increasingly mediates enterprise decision-making. Building on the theory of extended cognition, we argue that in response corporate knowledge may be redefined as a dynamic capability, measurable by the efficiency of its information-access procedures and the validated reliability of their outputs. We develop a formal model that captures epistemic states of corporations deploying sophisticated AI or information systems, introducing a continuous organisational knowledge metric $S_S(\\varphi)$ which integrates a pipeline's computational cost and its statistically validated error rate. We derive a thresholded knowledge predicate $\\mathsf{K}_S$ to impute knowledge and a firm-wide epistemic capacity index $\\mathcal{K}_{S,t}$ to measure overall capability. We then operationally map these quantitative metrics onto the legal standards of actual knowledge, constructive knowledge, wilful blindness, and recklessness. Our work provides a pathway towards creating measurable and justiciable audit artefacts, that render the corporate mind tractable and accountable in the algorithmic age."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Towards Automatic Evaluation and Selection of PHI De-identification Models via Multi-Agent Collaboration", "authors": "Guanchen Wu, Zuhui Chen, Yuzhang Xie, Carl Yang", "subjects": "Artificial Intelligence (cs.AI)", "abstract": "Protected health information (PHI) de-identification is critical for enabling the safe reuse of clinical notes, yet evaluating and comparing PHI de-identification models typically depends on costly, small-scale expert annotations. We present TEAM-PHI, a multi-agent evaluation and selection framework that uses large language models (LLMs) to automatically measure de-identification quality and select the best-performing model without heavy reliance on gold labels. TEAM-PHI deploys multiple Evaluation Agents, each independently judging the correctness of PHI extractions and outputting structured metrics. Their results are then consolidated through an LLM-based majority voting mechanism that integrates diverse evaluator perspectives into a single, stable, and reproducible ranking. Experiments on a real-world clinical note corpus demonstrate that TEAM-PHI produces consistent and accurate rankings: despite variation across individual evaluators, LLM-based voting reliably converges on the same top-performing systems. Further comparison with ground-truth annotations and human evaluation confirms that the framework's automated rankings closely match supervised evaluation. By combining independent evaluation agents with LLM majority voting, TEAM-PHI offers a practical, secure, and cost-effective solution for automatic evaluation and best-model selection in PHI de-identification, even when ground-truth labels are limited."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Seeing Through the Brain: New Insights from Decoding Visual Stimuli with fMRI", "authors": "Zheng Huang, Enpei Zhang, Yinghao Cai, Weikang Qiu, Carl Yang, Elynn Chen, Xiang Zhang, Rex Ying, Dawei Zhou, Yujun Yan", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "abstract": "Understanding how the brain encodes visual information is a central challenge in neuroscience and machine learning. A promising approach is to reconstruct visual stimuli, essentially images, from functional Magnetic Resonance Imaging (fMRI) signals. This involves two stages: transforming fMRI signals into a latent space and then using a pretrained generative model to reconstruct images. The reconstruction quality depends on how similar the latent space is to the structure of neural activity and how well the generative model produces images from that space. Yet, it remains unclear which type of latent space best supports this transformation and how it should be organized to represent visual stimuli effectively. We present two key findings. First, fMRI signals are more similar to the text space of a language model than to either a vision based space or a joint text image space. Second, text representations and the generative model should be adapted to capture the compositional nature of visual stimuli, including objects, their detailed attributes, and relationships. Building on these insights, we propose PRISM, a model that Projects fMRI sIgnals into a Structured text space as an interMediate representation for visual stimuli reconstruction. It includes an object centric diffusion module that generates images by composing individual objects to reduce object detection errors, and an attribute relationship search module that automatically identifies key attributes and relationships that best align with the neural activity. Extensive experiments on real world datasets demonstrate that our framework outperforms existing methods, achieving up to an 8% reduction in perceptual loss. These results highlight the importance of using structured text as the intermediate space to bridge fMRI signals and image reconstruction."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          EgMM-Corpus: A Multimodal Vision-Language Dataset for Egyptian Culture", "authors": "Mohamed Gamil, Abdelrahman Elsayed, Abdelrahman Lila, Ahmed Gad, Hesham Abdelgawad, Mohamed Aref, Ahmed Fares", "subjects": "Computation and Language (cs.CL)", "abstract": "Despite recent advances in AI, multimodal culturally diverse datasets are still limited, particularly for regions in the Middle East and Africa. In this paper, we introduce EgMM-Corpus, a multimodal dataset dedicated to Egyptian culture. By designing and running a new data collection pipeline, we collected over 3,000 images, covering 313 concepts across landmarks, food, and folklore. Each entry in the dataset is manually validated for cultural authenticity and multimodal coherence. EgMM-Corpus aims to provide a reliable resource for evaluating and training vision-language models in an Egyptian cultural context. We further evaluate the zero-shot performance of Contrastive Language-Image Pre-training CLIP on EgMM-Corpus, on which it achieves 21.2% Top-1 accuracy and 36.4% Top-5 accuracy in classification. These results underscore the existing cultural bias in large-scale vision-language models and demonstrate the importance of EgMM-Corpus as a benchmark for developing culturally aware models."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          VAR-SLAM: Visual Adaptive and Robust SLAM for Dynamic Environments", "authors": "Jo\u00e3o Carlos Virgolino Soares, Gabriel Fischer Abati, Claudio Semini", "subjects": "Robotics (cs.RO)", "abstract": "Visual SLAM in dynamic environments remains challenging, as several existing methods rely on semantic filtering that only handles known object classes, or use fixed robust kernels that cannot adapt to unknown moving objects, leading to degraded accuracy when they appear in the scene. We present VAR-SLAM (Visual Adaptive and Robust SLAM), an ORB-SLAM3-based system that combines a lightweight semantic keypoint filter to deal with known moving objects, with Barron's adaptive robust loss to handle unknown ones. The shape parameter of the robust kernel is estimated online from residuals, allowing the system to automatically adjust between Gaussian and heavy-tailed behavior. We evaluate VAR-SLAM on the TUM RGB-D, Bonn RGB-D Dynamic, and OpenLORIS datasets, which include both known and unknown moving objects. Results show improved trajectory accuracy and robustness over state-of-the-art baselines, achieving up to 25% lower ATE RMSE than NGD-SLAM on challenging sequences, while maintaining performance at 27 FPS on average."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          The Right to Be Remembered: Preserving Maximally Truthful Digital Memory in the Age of AI", "authors": "Alex Zhavoronkov, Dominika Wilczok, Roman Yampolskiy", "subjects": "Artificial Intelligence (cs.AI)", "abstract": "Since the rapid expansion of large language models (LLMs), people have begun to rely on them for information retrieval. While traditional search engines display ranked lists of sources shaped by search engine optimization (SEO), advertising, and personalization, LLMs typically provide a synthesized response that feels singular and authoritative. While both approaches carry risks of bias and omission, LLMs may amplify the effect by collapsing multiple perspectives into one answer, reducing users ability or inclination to compare alternatives. This concentrates power over information in a few LLM vendors whose systems effectively shape what is remembered and what is overlooked. As a result, certain narratives, individuals or groups, may be disproportionately suppressed, while others are disproportionately elevated. Over time, this creates a new threat: the gradual erasure of those with limited digital presence, and the amplification of those already prominent, reshaping collective this http URL address these concerns, this paper presents a concept of the Right To Be Remembered (RTBR) which encompasses minimizing the risk of AI-driven information omission, embracing the right of fair treatment, while ensuring that the generated content would be maximally truthful."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Data-Centric AI for Tropical Agricultural Mapping: Challenges, Strategies and Scalable Solutions", "authors": "Mateus Pinto da Silva, Sabrina P. L. P. Correa, Hugo N. Oliveira, Ian M. Nunes, Jefersson A. dos Santos", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Mapping agriculture in tropical areas through remote sensing presents unique challenges, including the lack of high-quality annotated data, the elevated costs of labeling, data variability, and regional generalisation. This paper advocates a Data-Centric Artificial Intelligence (DCAI) perspective and pipeline, emphasizing data quality and curation as key drivers for model robustness and scalability. It reviews and prioritizes techniques such as confident learning, core-set selection, data augmentation, and active learning. The paper highlights the readiness and suitability of 25 distinct strategies in large-scale agricultural mapping pipelines. The tropical context is of high interest, since high cloudiness, diverse crop calendars, and limited datasets limit traditional model-centric approaches. This tutorial outlines practical solutions as a data-centric approach for curating and training AI models better suited to the dynamic realities of tropical agriculture. Finally, we propose a practical pipeline using the 9 most mature and straightforward methods that can be applied to a large-scale tropical agricultural mapping project."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Explore-then-Commit for Nonstationary Linear Bandits with Latent Dynamics", "authors": "Sunmook Choi, Yahya Sattar, Yassir Jedra, Maryam Fazel, Sarah Dean", "subjects": "Machine Learning (cs.LG); Systems and Control (eess.SY); Optimization and Control (math.OC); Machine Learning (stat.ML)", "abstract": "We study a nonstationary bandit problem where rewards depend on both actions and latent states, the latter governed by unknown linear dynamics. Crucially, the state dynamics also depend on the actions, resulting in tension between short-term and long-term rewards. We propose an explore-then-commit algorithm for a finite horizon $T$. During the exploration phase, random Rademacher actions enable estimation of the Markov parameters of the linear dynamics, which characterize the action-reward relationship. In the commit phase, the algorithm uses the estimated parameters to design an optimized action sequence for long-term reward. Our proposed algorithm achieves $\\tilde{\\mathcal{O}}(T^{2/3})$ regret. Our analysis handles two key challenges: learning from temporally correlated rewards, and designing action sequences with optimal long-term reward. We address the first challenge by providing near-optimal sample complexity and error bounds for system identification using bilinear rewards. We address the second challenge by proving an equivalence with indefinite quadratic optimization over a hypercube, a known NP-hard problem. We provide a sub-optimality guarantee for this problem, enabling our regret upper bound. Lastly, we propose a semidefinite relaxation with Goemans-Williamson rounding as a practical approach."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          StretchySnake: Flexible SSM Training Unlocks Action Recognition Across Spatio-Temporal Scales", "authors": "Nyle Siddiqui, Rohit Gupta, Sirnam Swetha, Mubarak Shah", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "State space models (SSMs) have emerged as a competitive alternative to transformers in various tasks. Their linear complexity and hidden-state recurrence make them particularly attractive for modeling long sequences, whereas attention becomes quadratically expensive. However, current training methods for video understanding are tailored towards transformers and fail to fully leverage the unique attributes of SSMs. For example, video models are often trained at a fixed resolution and video length to balance the quadratic scaling of attention cost against performance. Consequently, these models suffer from degraded performance when evaluated on videos with spatial and temporal resolutions unseen during training; a property we call spatio-temporal inflexibility. In the context of action recognition, this severely limits a model's ability to retain performance across both short- and long-form videos. Therefore, we propose a flexible training method that leverages and improves the inherent adaptability of SSMs. Our method samples videos at varying temporal and spatial resolutions during training and dynamically interpolates model weights to accommodate any spatio-temporal scale. This instills our SSM, which we call StretchySnake, with spatio-temporal flexibility and enables it to seamlessly handle videos ranging from short, fine-grained clips to long, complex activities. We introduce and compare five different variants of flexible training, and identify the most effective strategy for video SSMs. On short-action (UCF-101, HMDB-51) and long-action (COIN, Breakfast) benchmarks, StretchySnake outperforms transformer and SSM baselines alike by up to 28%, with strong adaptability to fine-grained actions (SSV2, Diving-48). Therefore, our method provides a simple drop-in training recipe that makes video SSMs more robust, resolution-agnostic, and efficient across diverse action recognition scenarios."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Benchmarking noisy label detection methods", "authors": "Henrique Pickler, Jorge K. S. Kamassury, Danilo Silva", "subjects": "Machine Learning (cs.LG); Machine Learning (stat.ML)", "abstract": "Label noise is a common problem in real-world datasets, affecting both model training and validation. Clean data are essential for achieving strong performance and ensuring reliable evaluation. While various techniques have been proposed to detect noisy labels, there is no clear consensus on optimal approaches. We perform a comprehensive benchmark of detection methods by decomposing them into three fundamental components: label agreement function, aggregation method, and information gathering approach (in-sample vs out-of-sample). This decomposition can be applied to many existing detection methods, and enables systematic comparison across diverse approaches. To fairly compare methods, we propose a unified benchmark task, detecting a fraction of training samples equal to the dataset's noise rate. We also introduce a novel metric: the false negative rate at this fixed operating point. Our evaluation spans vision and tabular datasets under both synthetic and real-world noise conditions. We identify that in-sample information gathering using average probability aggregation combined with the logit margin as the label agreement function achieves the best results across most scenarios. Our findings provide practical guidance for designing new detection methods and selecting techniques for specific applications."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          SentinelNet: Safeguarding Multi-Agent Collaboration Through Credit-Based Dynamic Threat Detection", "authors": "Yang Feng, Xudong Pan", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "abstract": "Malicious agents pose significant threats to the reliability and decision-making capabilities of Multi-Agent Systems (MAS) powered by Large Language Models (LLMs). Existing defenses often fall short due to reactive designs or centralized architectures which may introduce single points of failure. To address these challenges, we propose SentinelNet, the first decentralized framework for proactively detecting and mitigating malicious behaviors in multi-agent collaboration. SentinelNet equips each agent with a credit-based detector trained via contrastive learning on augmented adversarial debate trajectories, enabling autonomous evaluation of message credibility and dynamic neighbor ranking via bottom-k elimination to suppress malicious communications. To overcome the scarcity of attack data, it generates adversarial trajectories simulating diverse threats, ensuring robust training. Experiments on MAS benchmarks show SentinelNet achieves near-perfect detection of malicious agents, close to 100% within two debate rounds, and recovers 95% of system accuracy from compromised baselines. By exhibiting strong generalizability across domains and attack patterns, SentinelNet establishes a novel paradigm for safeguarding collaborative MAS."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          VM-BeautyNet: A Synergistic Ensemble of Vision Transformer and Mamba for Facial Beauty Prediction", "authors": "Djamel Eddine Boukhari", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Facial Beauty Prediction (FBP) is a complex and challenging computer vision task, aiming to model the subjective and intricate nature of human aesthetic perception. While deep learning models, particularly Convolutional Neural Networks (CNNs), have made significant strides, they often struggle to capture the global, holistic facial features that are critical to human judgment. Vision Transformers (ViT) address this by effectively modeling long-range spatial relationships, but their quadratic complexity can be a bottleneck. This paper introduces a novel, heterogeneous ensemble architecture, \\textbf{VM-BeautyNet}, that synergistically fuses the complementary strengths of a Vision Transformer and a Mamba-based Vision model, a recent advancement in State-Space Models (SSMs). The ViT backbone excels at capturing global facial structure and symmetry, while the Mamba backbone efficiently models long-range dependencies with linear complexity, focusing on sequential features and textures. We evaluate our approach on the benchmark SCUT-FBP5500 dataset. Our proposed VM-BeautyNet achieves state-of-the-art performance, with a \\textbf{Pearson Correlation (PC) of 0.9212}, a \\textbf{Mean Absolute Error (MAE) of 0.2085}, and a \\textbf{Root Mean Square Error (RMSE) of 0.2698}. Furthermore, through Grad-CAM visualizations, we provide interpretability analysis that confirms the complementary feature extraction of the two backbones, offering new insights into the model's decision-making process and presenting a powerful new architectural paradigm for computational aesthetics."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Heterogeneous Multi-Agent Task-Assignment with Uncertain Execution Times and Preferences", "authors": "Qinshuang Wei, Vaibhav Srivastava, Vijay Gupta", "subjects": "Multiagent Systems (cs.MA); Systems and Control (eess.SY)", "abstract": "While sequential task assignment for a single agent has been widely studied, such problems in a multi-agent setting, where the agents have heterogeneous task preferences or capabilities, remain less well-characterized. We study a multi-agent task assignment problem where a central planner assigns recurring tasks to multiple members of a team over a finite time horizon. For any given task, the members have heterogeneous capabilities in terms of task completion times, task resource consumption (which can model variables such as energy or attention), and preferences in terms of the rewards they collect upon task completion. We assume that the reward, execution time, and resource consumption for each member to complete any task are stochastic with unknown distributions. The goal of the planner is to maximize the total expected reward that the team receives over the problem horizon while ensuring that the resource consumption required for any assigned task is within the capability of the agent. We propose and analyze a bandit algorithm for this problem. Since the bandit algorithm relies on solving an optimal task assignment problem repeatedly, we analyze the achievable regret in two cases: when we can solve the optimal task assignment exactly and when we can solve it only approximately."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Case Study of GAI for Generating Novel Images for Real-World Embroidery", "authors": "Kate Glazko, Anika Arugunta, Janelle Chan, Nancy Jimenez-Garcia, Tashfia Sharmin, Jennifer Mankoff", "subjects": "Human-Computer Interaction (cs.HC); Computers and Society (cs.CY)", "abstract": "In this paper, we present a case study exploring the potential use of Generative Artificial Intelligence (GAI) to address the real-world need of making the design of embroiderable art patterns more accessible. Through an auto-ethnographic case study by a disabled-led team, we examine the application of GAI as an assistive technology in generating embroidery patterns, addressing the complexity involved in designing culturally-relevant patterns as well as those that meet specific needs regarding detail and color. We detail the iterative process of prompt engineering custom GPTs tailored for producing specific visual outputs, emphasizing the nuances of achieving desirable results that align with real-world embroidery requirements. Our findings underscore the mixed outcomes of employing GAI for producing embroiderable images, from facilitating creativity and inclusion to navigating the unpredictability of AI-generated designs. Future work aims to refine GAI tools we explored for generating embroiderable images to make them more performant and accessible, with the goal of fostering more inclusion in the domains of creativity and making."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          What Can String Probability Tell Us About Grammaticality?", "authors": "Jennifer Hu, Ethan Gotlieb Wilcox, Siyuan Song, Kyle Mahowald, Roger P. Levy", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "abstract": "What have language models (LMs) learned about grammar? This question remains hotly debated, with major ramifications for linguistic theory. However, since probability and grammaticality are distinct notions in linguistics, it is not obvious what string probabilities can reveal about an LM's underlying grammatical knowledge. We present a theoretical analysis of the relationship between grammar, meaning, and string probability, based on simple assumptions about the generative process of corpus data. Our framework makes three predictions, which we validate empirically using 280K sentence pairs in English and Chinese: (1) correlation between the probability of strings within minimal pairs, i.e., string pairs with minimal semantic differences; (2) correlation between models' and humans' deltas within minimal pairs; and (3) poor separation in probability space between unpaired grammatical and ungrammatical strings. Our analyses give theoretical grounding for using probability to learn about LMs' structural knowledge, and suggest directions for future work in LM grammatical evaluation."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          C/N0 Analysis-Based GPS Spoofing Detection with Variable Antenna Orientations", "authors": "Vienna Li, Justin Villa, Dan Diessner, Jayson Clifford, Laxima Niure Kandel", "subjects": "Cryptography and Security (cs.CR)", "abstract": "GPS spoofing poses a growing threat to aviation by falsifying satellite signals and misleading aircraft navigation systems. This paper demonstrates a proof-of-concept spoofing detection strategy based on analyzing satellite Carrier-to-Noise Density Ratio (C/N$_0$) variation during controlled static antenna orientations. Using a u-blox EVK-M8U receiver and a GPSG-1000 satellite simulator, C/N$_0$ data is collected under three antenna orientations flat, banked right, and banked left) in both real-sky (non-spoofed) and spoofed environments. Our findings reveal that under non-spoofed signals, C/N$_0$ values fluctuate naturally with orientation, reflecting true geometric dependencies. However, spoofed signals demonstrate a distinct pattern: the flat orientation, which directly faces the spoofing antenna, consistently yielded the highest C/N$_0$ values, while both banked orientations showed reduced C/N$_0$ due to misalignment with the spoofing source. These findings suggest that simple maneuvers such as brief banking to induce C/N$_0$ variations can provide early cues of GPS spoofing for general aviation and UAV systems."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          DeGrip: A Compact Cable-driven Robotic Gripper for Desktop Disassembly", "authors": "Bihao Zhang, Davood Soleymanzadeh, Xiao Liang, Minghui Zheng", "subjects": "Robotics (cs.RO); Systems and Control (eess.SY)", "abstract": "Intelligent robotic disassembly of end-of-life (EOL) products has been a long-standing challenge in robotics. While machine learning techniques have shown promise, the lack of specialized hardware limits their application in real-world scenarios. We introduce DeGrip, a customized gripper designed for the disassembly of EOL computer desktops. DeGrip provides three degrees of freedom (DOF), enabling arbitrary configurations within the disassembly environment when mounted on a robotic manipulator. It employs a cable-driven transmission mechanism that reduces its overall size and enables operation in confined spaces. The wrist is designed to decouple the actuation of wrist and jaw joints. We also developed an EOL desktop disassembly environment in Isaac Sim to evaluate the effectiveness of DeGrip. The tasks were designed to demonstrate its ability to operate in confined spaces and disassemble components in arbitrary configurations. The evaluation results confirm the capability of DeGrip for EOL desktop disassembly."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Machine Learning for Climate Policy: Understanding Policy Progression in the European Green Deal", "authors": "Patricia West, Michelle WL Wan, Alexander Hepburn, Edwin Simpson, Raul Santos-Rodriguez, Jeffrey N Clark", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "Climate change demands effective legislative action to mitigate its impacts. This study explores the application of machine learning (ML) to understand the progression of climate policy from announcement to adoption, focusing on policies within the European Green Deal. We present a dataset of 165 policies, incorporating text and metadata. We aim to predict a policy's progression status, and compare text representation methods, including TF-IDF, BERT, and ClimateBERT. Metadata features are included to evaluate the impact on predictive performance. On text features alone, ClimateBERT outperforms other approaches (RMSE = 0.17, R^2 = 0.29), while BERT achieves superior performance with the addition of metadata features (RMSE = 0.16, R^2 = 0.38). Using methods from explainable AI highlights the influence of factors such as policy wording and metadata including political party and country representation. These findings underscore the potential of ML tools in supporting climate policy analysis and decision-making."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          ScholarEval: Research Idea Evaluation Grounded in Literature", "authors": "Hanane Nour Moussa, Patrick Queiroz Da Silva, Daniel Adu-Ampratwum, Alyson East, Zitong Lu, Nikki Puccetti, Mingyi Xue, Huan Sun, Bodhisattwa Prasad Majumder, Sachin Kumar", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)", "abstract": "As AI tools become increasingly common for research ideation, robust evaluation is critical to ensure the validity and usefulness of generated ideas. We introduce ScholarEval, a retrieval augmented evaluation framework that assesses research ideas based on two fundamental criteria: soundness - the empirical validity of proposed methods based on existing literature, and contribution - the degree of advancement made by the idea across different dimensions relative to prior research. To evaluate ScholarEval, we introduce ScholarIdeas, the first expert-annotated dataset of multi-domain research ideas and reviews, comprised of 117 ideas across four disciplines: artificial intelligence, neuroscience, biochemistry, and ecology. Our evaluation shows that ScholarEval achieves significantly higher coverage of points mentioned in the human expert annotated rubrics in ScholarIdeas compared to all baselines. Furthermore, ScholarEval is consistently preferred over our strongest baseline o4-mini-deep-research, a reasoning and search-enabled agentic system by OpenAI, in terms of evaluation actionability, depth, and evidence support. Our large-scale user study also shows that ScholarEval significantly outperforms deep research in literature engagement, idea refinement, and usefulness. We openly release our code, dataset, and ScholarEval tool for the community to use and build on."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Designing a Convolutional Neural Network for High-Accuracy Oral Cavity Squamous Cell Carcinoma (OCSCC) Detection", "authors": "Vishal Manikanden, Aniketh Bandlamudi, Daniel Haehn", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Oral Cavity Squamous Cell Carcinoma (OCSCC) is the most common type of head and neck cancer. Due to the subtle nature of its early stages, deep and hidden areas of development, and slow growth, OCSCC often goes undetected, leading to preventable deaths. However, properly trained Convolutional Neural Networks (CNNs), with their precise image segmentation techniques and ability to apply kernel matrices to modify the RGB values of images for accurate image pattern recognition, would be an effective means for early detection of OCSCC. Pairing this neural network with image capturing and processing hardware would allow increased efficacy in OCSCC detection. The aim of our project is to develop a Convolutional Neural Network trained to recognize OCSCC, as well as to design a physical hardware system to capture and process detailed images, in order to determine the image quality required for accurate predictions. A CNN was trained on 4293 training images consisting of benign and malignant tumors, as well as negative samples, and was evaluated for its precision, recall, and Mean Average Precision (mAP) in its predictions of OCSCC. A testing dataset of randomly assorted images of cancerous, non-cancerous, and negative images was chosen, and each image was altered to represent 5 common resolutions. This test data set was thoroughly analyzed by the CNN and predictions were scored on the basis of accuracy. The designed enhancement hardware was used to capture detailed images, and its impact was scored. An application was developed to facilitate the testing process and bring open access to the CNN. Images of increasing resolution resulted in higher-accuracy predictions on a logarithmic scale, demonstrating the diminishing returns of higher pixel counts."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Applications of AAA rational approximation", "authors": "Yuji Nakatsukasa, Lloyd N. Trefethen", "subjects": "Numerical Analysis (math.NA)", "abstract": "The AAA algorithm for rational approximation is employed to illustrate applications of rational functions all across numerical analysis."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Cosmos-Surg-dVRK: World Foundation Model-based Automated Online Evaluation of Surgical Robot Policy Learning", "authors": "Lukas Zbinden, Nigel Nelson, Juo-Tung Chen, Xinhao Chen, Ji Woong (Brian)Kim, Mahdi Azizian, Axel Krieger, Sean Huver", "subjects": "Robotics (cs.RO)", "abstract": "The rise of surgical robots and vision-language-action models has accelerated the development of autonomous surgical policies and efficient assessment strategies. However, evaluating these policies directly on physical robotic platforms such as the da Vinci Research Kit (dVRK) remains hindered by high costs, time demands, reproducibility challenges, and variability in execution. World foundation models (WFM) for physical AI offer a transformative approach to simulate complex real-world surgical tasks, such as soft tissue deformation, with high fidelity. This work introduces Cosmos-Surg-dVRK, a surgical finetune of the Cosmos WFM, which, together with a trained video classifier, enables fully automated online evaluation and benchmarking of surgical policies. We evaluate Cosmos-Surg-dVRK using two distinct surgical datasets. On tabletop suture pad tasks, the automated pipeline achieves strong correlation between online rollouts in Cosmos-Surg-dVRK and policy outcomes on the real dVRK Si platform, as well as good agreement between human labelers and the V-JEPA 2-derived video classifier. Additionally, preliminary experiments with ex-vivo porcine cholecystectomy tasks in Cosmos-Surg-dVRK demonstrate promising alignment with real-world evaluations, highlighting the platform's potential for more complex surgical procedures."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Code Contribution and Credit in Science", "authors": "Eva Maxfield Brown, Isaac Slaughter, Nicholas Weber", "subjects": "Software Engineering (cs.SE); Digital Libraries (cs.DL)", "abstract": "Software development has become essential to scientific research, but its relationship to traditional metrics of scholarly credit remains poorly understood. We develop a dataset of approximately 140,000 paired research articles and code repositories, as well as a predictive model that matches research article authors with software repository developer accounts. We use this data to investigate how software development activities influence credit allocation in collaborative scientific settings. Our findings reveal significant patterns distinguishing software contributions from traditional authorship credit. We find that nearly 30% of articles include non-author code contributors- individuals who participated in software development but received no formal authorship recognition. While code-contributing authors show a modest $\\sim$4.2% increase in article citations, this effect becomes non-significant when controlling for domain, article type, and open access status. First authors are significantly more likely to be code contributors than other author positions. Notably, we identify a negative relationship between coding frequency and scholarly impact metrics. Authors who contribute code more frequently exhibit progressively lower h-indices than non-coding colleagues, even when controlling for publication count, author position, domain, and article type. These results suggest a disconnect between software contributions and credit, highlighting important implications for institutional reward structures and science policy."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          A Motivational Driver Steering Model: Task Difficulty Homeostasis From Control Theory Perspective", "authors": "H. Mozaffari, A. Nahvi", "subjects": "Systems and Control (eess.SY)", "abstract": "A general and psychologically plausible collision avoidance driver model can improve transportation safety significantly. Most computational driver models found in the literature have used control theory methods only, and they are not established based on psychological theories. In this paper, a unified approach is presented based on concepts taken from psychology and control theory. The \"task difficulty homeostasis theory\", a prominent motivational theory, is combined with the \"Lyapunov stability method\" in control theory to present a general and psychologically plausible model. This approach is used to model driver steering behavior for collision avoidance. The performance of this model is measured by simulation of two collision avoidance scenarios at a wide range of speeds from 20 km/h to 170 km/h. The model is validated by experiments on a driving simulator. The results demonstrate that the model follows human behavior accurately with a mean error of 7 percent."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          One-Bit Quantization for Random Features Models", "authors": "Danil Akhtiamov, Reza Ghane, Babak Hassibi", "subjects": "Machine Learning (cs.LG); Machine Learning (stat.ML)", "abstract": "Recent advances in neural networks have led to significant computational and memory demands, spurring interest in one-bit weight compression to enable efficient inference on resource-constrained devices. However, the theoretical underpinnings of such compression remain poorly understood. We address this gap by analyzing one-bit quantization in the Random Features model, a simplified framework that corresponds to neural networks with random representations. We prove that, asymptotically, quantizing weights of all layers except the last incurs no loss in generalization error, compared to the full precision random features model. Our findings offer theoretical insights into neural network compression. We also demonstrate empirically that one-bit quantization leads to significant inference speed ups for the Random Features models even on a laptop GPU, confirming the practical benefits of our work. Additionally, we provide an asymptotically precise characterization of the generalization error for Random Features with an arbitrary number of layers. To the best of our knowledge, our analysis yields more general results than all previous works in the related literature."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          LibIHT: A Hardware-Based Approach to Efficient and Evasion-Resistant Dynamic Binary Analysis", "authors": "Changyu Zhao, Yohan Beugin, Jean-Charles Noirot Ferrand, Quinn Burke, Guancheng Li, Patrick McDaniel", "subjects": "Cryptography and Security (cs.CR)", "abstract": "Dynamic program analysis is invaluable for malware detection, debugging, and performance profiling. However, software-based instrumentation incurs high overhead and can be evaded by anti-analysis techniques. In this paper, we propose LibIHT, a hardware-assisted tracing framework that leverages on-CPU branch tracing features (Intel Last Branch Record and Branch Trace Store) to efficiently capture program control-flow with minimal performance impact. Our approach reconstructs control-flow graphs (CFGs) by collecting hardware generated branch execution data in the kernel, preserving program behavior against evasive malware. We implement LibIHT as an OS kernel module and user-space library, and evaluate it on both benign benchmark programs and adversarial anti-instrumentation samples. Our results indicate that LibIHT reduces runtime overhead by over 150x compared to Intel Pin (7x vs 1,053x slowdowns), while achieving high fidelity in CFG reconstruction (capturing over 99% of execution basic blocks and edges). Although this hardware-assisted approach sacrifices the richer semantic detail available from full software instrumentation by capturing only branch addresses, this trade-off is acceptable for many applications where performance and low detectability are paramount. Our findings show that hardware-based tracing captures control flow information significantly faster, reduces detection risk and performs dynamic analysis with minimal interference."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          WEBSERV: A Browser-Server Environment for Efficient Training of Reinforcement Learning-based Web Agents at Scale", "authors": "Yuxuan Lu, Jing Huang, Hui Liu, Jiri Gesi, Yan Han, Shihan Fu, Tianqi Zheng, Dakuo Wang", "subjects": "Machine Learning (cs.LG); Computation and Language (cs.CL)", "abstract": "Training and evaluation of Reinforcement Learning (RL) web agents have gained increasing attention, yet a scalable and efficient environment that couples realistic and robust browser-side interaction with controllable server-side state at scale is still missing. Existing environments tend to have one or more of the following issues: they overwhelm policy models with excessive and noisy context; they perform actions non-deterministically without waiting for the UI or network to stabilize; or they cannot scale isolated client-server containers effectively for parallel RL rollouts. We propose WEBSERV, an environment that includes 1) a compact, site-agnostic browser environment that balances context and action complexity, and 2) a scalable RL environment via efficient launching and resetting web-servers to enable scalable RL training and evaluation. We evaluate WEBSERV on the shopping CMS and Gitlab tasks in WebArena, achieving state-of-the-art single-prompt success rates while cutting launch latency by ~5x and storage need by ~240x, with a comparable memory footprint, enabling 200+ concurrent containers on a single host."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Protein Folding with Neural Ordinary Differential Equations", "authors": "Arielle Sanford, Shuo Sun, Christian B. Mendl", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Biomolecules (q-bio.BM); Quantitative Methods (q-bio.QM); Machine Learning (stat.ML)", "abstract": "Recent advances in protein structure prediction, such as AlphaFold, have demonstrated the power of deep neural architectures like the Evoformer for capturing complex spatial and evolutionary constraints on protein conformation. However, the depth of the Evoformer, comprising 48 stacked blocks, introduces high computational costs and rigid layerwise discretization. Inspired by Neural Ordinary Differential Equations (Neural ODEs), we propose a continuous-depth formulation of the Evoformer, replacing its 48 discrete blocks with a Neural ODE parameterization that preserves its core attention-based operations. This continuous-time Evoformer achieves constant memory cost (in depth) via the adjoint method, while allowing a principled trade-off between runtime and accuracy through adaptive ODE solvers. Benchmarking on protein structure prediction tasks, we find that the Neural ODE-based Evoformer produces structurally plausible predictions and reliably captures certain secondary structure elements, such as alpha-helices, though it does not fully replicate the accuracy of the original architecture. However, our model achieves this performance using dramatically fewer resources, just 17.5 hours of training on a single GPU, highlighting the promise of continuous-depth models as a lightweight and interpretable alternative for biomolecular modeling. This work opens new directions for efficient and adaptive protein structure prediction frameworks."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Detecting Adversarial Fine-tuning with Auditing Agents", "authors": "Sarah Egler, John Schulman, Nicholas Carlini", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "abstract": "Large Language Model (LLM) providers expose fine-tuning APIs that let end users fine-tune their frontier LLMs. Unfortunately, it has been shown that an adversary with fine-tuning access to an LLM can bypass safeguards. Particularly concerning, such attacks may avoid detection with datasets that are only implicitly harmful. Our work studies robust detection mechanisms for adversarial use of fine-tuning APIs. We introduce the concept of a fine-tuning auditing agent and show it can detect harmful fine-tuning prior to model deployment. We provide our auditing agent with access to the fine-tuning dataset, as well as the fine-tuned and pre-fine-tuned models, and request the agent assigns a risk score for the fine-tuning job. We evaluate our detection approach on a diverse set of eight strong fine-tuning attacks from the literature, along with five benign fine-tuned models, totaling over 1400 independent audits. These attacks are undetectable with basic content moderation on the dataset, highlighting the challenge of the task. With the best set of affordances, our auditing agent achieves a 56.2% detection rate of adversarial fine-tuning at a 1% false positive rate. Most promising, the auditor is able to detect covert cipher attacks that evade safety evaluations and content moderation of the dataset. While benign fine-tuning with unintentional subtle safety degradation remains a challenge, we establish a baseline configuration for further work in this area. We release our auditing agent at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Towards Low-Resource Alignment to Diverse Perspectives with Sparse Feedback", "authors": "Chu Fei Luo, Samuel Dahan, Xiaodan Zhu", "subjects": "Computation and Language (cs.CL)", "abstract": "As language models have a greater impact on society, it is important to ensure they are aligned to a diverse range of perspectives and are able to reflect nuance in human values. However, the most popular training paradigms for modern language models often assume there is one optimal answer for every query, leading to generic responses and poor alignment. In this work, we aim to enhance pluralistic alignment of language models in a low-resource setting with two methods: pluralistic decoding and model steering. We empirically demonstrate that model steering offers consistent improvement over zero-shot and few-shot baselines with only 50 annotated samples. Our proposed methods decrease false positives in several high-stakes tasks such as hate speech detection and misinformation detection, and improves the distributional alignment to human values in GlobalOpinionQA. We hope our work highlights the importance of diversity and how language models can be adapted to consider nuanced perspectives."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Embody 3D: A Large-scale Multimodal Motion and Behavior Dataset", "authors": "Claire McLean, Makenzie Meendering, Tristan Swartz, Orri Gabbay, Alexandra Olsen, Rachel Jacobs, Nicholas Rosen, Philippe de Bree, Tony Garcia, Gadsden Merrill, Jake Sandakly, Julia Buffalini, Neham Jain, Steven Krenn, Moneish Kumar, Dejan Markovic, Evonne Ng, Fabian Prada, Andrew Saba, Siwei Zhang, Vasu Agrawal, Tim Godisart, Alexander Richard, Michael Zollhoefer", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "The Codec Avatars Lab at Meta introduces Embody 3D, a multimodal dataset of 500 individual hours of 3D motion data from 439 participants collected in a multi-camera collection stage, amounting to over 54 million frames of tracked 3D motion. The dataset features a wide range of single-person motion data, including prompted motions, hand gestures, and locomotion; as well as multi-person behavioral and conversational data like discussions, conversations in different emotional states, collaborative activities, and co-living scenarios in an apartment-like space. We provide tracked human motion including hand tracking and body shape, text annotations, and a separate audio track for each participant."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Distractor Injection Attacks on Large Reasoning Models: Characterization and Defense", "authors": "Zhehao Zhang, Weijie Xu, Shixian Cui, Chandan K. Reddy", "subjects": "Artificial Intelligence (cs.AI)", "abstract": "Recent advances in large reasoning models (LRMs) have enabled remarkable performance on complex tasks such as mathematics and coding by generating long Chain-of-Thought (CoT) traces. In this paper, we identify and systematically analyze a critical vulnerability we term reasoning distraction, where LRMs are diverted from their primary objective by irrelevant yet complex tasks maliciously embedded in the prompt. Through a comprehensive study across diverse models and benchmarks, we show that even state-of-the-art LRMs are highly susceptible, with injected distractors reducing task accuracy by up to 60%. We further reveal that certain alignment techniques can amplify this weakness and that models may exhibit covert compliance, following hidden adversarial instructions in reasoning while concealing them in the final output. To mitigate these risks, we propose a training-based defense that combines Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL) on synthetic adversarial data, improving robustness by over 50 points on challenging distractor attacks. Our findings establish reasoning distraction as a distinct and urgent threat to LRM reliability and provide a practical step toward safer and more trustworthy reasoning systems."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Spatial-to-Spectral Harmonic-Modulated Arrays for 6G Multi-Beam MIMO", "authors": "Jose Guajardo, Ali Niknejad", "subjects": "Systems and Control (eess.SY); Information Theory (cs.IT)", "abstract": "This article presents an overview and analysis of spatial-to-spectral harmonic-modulated arrays (SHAs). Compared to traditional analog or digital beamforming arrays, SHAs enable concurrent multi-beamforming without requiring substantial hardware replication. SHAs replace the need for hardware replication with frequency-domain multiplexing. Furthermore, SHAs have the potential to become key contributors to future 6G networks by enabling scalable multi-user communications, joint communication and sensing, and spatial interference mitigation. In addition, an analysis of the SHA's harmonic-modulation waveform and its effects on gain, noise and bandwidth is presented. A comb-like modulation waveform for SHAs that minimizes spectral inefficiency is proposed. Further, an analysis of the SHA's capability to independently steer multiple beams is presented. This capability is quantified in terms of the SHA's spatial-to-spectral degrees of freedom. Lastly, this work introduces a novel SHA architecture that provides three spatial-to-spectral degrees of freedom with minimal hardware replication."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          NEBULA: Do We Evaluate Vision-Language-Action Agents Correctly?", "authors": "Jierui Peng, Yanyan Zhang, Yicheng Duan, Tuo Liang, Vipin Chaudhary, Yu Yin", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)", "abstract": "The evaluation of Vision-Language-Action (VLA) agents is hindered by the coarse, end-task success metric that fails to provide precise skill diagnosis or measure robustness to real-world perturbations. This challenge is exacerbated by a fragmented data landscape that impedes reproducible research and the development of generalist models. To address these limitations, we introduce \\textbf{NEBULA}, a unified ecosystem for single-arm manipulation that enables diagnostic and reproducible evaluation. NEBULA features a novel dual-axis evaluation protocol that combines fine-grained \\textit{capability tests} for precise skill diagnosis with systematic \\textit{stress tests} that measure robustness. A standardized API and a large-scale, aggregated dataset are provided to reduce fragmentation and support cross-dataset training and fair comparison. Using NEBULA, we demonstrate that top-performing VLAs struggle with key capabilities such as spatial reasoning and dynamic adaptation, which are consistently obscured by conventional end-task success metrics. By measuring both what an agent can do and when it does so reliably, NEBULA provides a practical foundation for robust, general-purpose embodied agents."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Proactive Scene Decomposition and Reconstruction", "authors": "Baicheng Li, Zike Yan, Dong Wu, Hongbin Zha", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Human behaviors are the major causes of scene dynamics and inherently contain rich cues regarding the dynamics. This paper formalizes a new task of proactive scene decomposition and reconstruction, an online approach that leverages human-object interactions to iteratively disassemble and reconstruct the environment. By observing these intentional interactions, we can dynamically refine the decomposition and reconstruction process, addressing inherent ambiguities in static object-level reconstruction. The proposed system effectively integrates multiple tasks in dynamic environments such as accurate camera and object pose estimation, instance decomposition, and online map updating, capitalizing on cues from human-object interactions in egocentric live streams for a flexible, progressive alternative to conventional object-level reconstruction methods. Aided by the Gaussian splatting technique, accurate and consistent dynamic scene modeling is achieved with photorealistic and efficient rendering. The efficacy is validated in multiple real-world scenarios with promising advantages."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          MuseTok: Symbolic Music Tokenization for Generation and Semantic Understanding", "authors": "Jingyue Huang, Zachary Novack, Phillip Long, Yupeng Hou, Ke Chen, Taylor Berg-Kirkpatrick, Julian McAuley", "subjects": "Sound (cs.SD); Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)", "abstract": "Discrete representation learning has shown promising results across various domains, including generation and understanding in image, speech and language. Inspired by these advances, we propose MuseTok, a tokenization method for symbolic music, and investigate its effectiveness in both music generation and understanding tasks. MuseTok employs the residual vector quantized-variational autoencoder (RQ-VAE) on bar-wise music segments within a Transformer-based encoder-decoder framework, producing music codes that achieve high-fidelity music reconstruction and accurate understanding of music theory. For comprehensive evaluation, we apply MuseTok to music generation and semantic understanding tasks, including melody extraction, chord recognition, and emotion recognition. Models incorporating MuseTok outperform previous representation learning baselines in semantic understanding while maintaining comparable performance in content generation. Furthermore, qualitative analyses on MuseTok codes, using ground-truth categories and synthetic datasets, reveal that MuseTok effectively captures underlying musical concepts from large music collections."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          What Limits Agentic Systems Efficiency?", "authors": "Song Bian, Minghao Yan, Anand Jayarajan, Gennady Pekhimenko, Shivaram Venkataraman", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "abstract": "Large Language Models (LLMs), such as OpenAI-o1 and DeepSeek-R1, have demonstrated strong reasoning capabilities. To further enhance LLM capabilities, recent agentic systems, such as Deep Research, incorporate web interactions into LLM reasoning to mitigate uncertainties and reduce potential errors. However, existing research predominantly focuses on reasoning performance, often neglecting the efficiency of agentic systems. In this work, we present a comprehensive empirical study that identifies efficiency bottlenecks in web-interactive agentic systems. We decompose end-to-end latency into two primary components: LLM API latency and web environment latency. We conduct a comprehensive empirical study across 15 models and 5 providers to demonstrate high variability in API-based agentic systems. We observe that web environment latency can contribute as much as 53.7% to the overall latency in a web-based agentic system. To improve latency, we propose SpecCache, a caching framework augmented with speculative execution that can reduce web environment overhead. Extensive evaluations on two standard benchmarks show that our approach improves the cache hit rate by up to 58x compared to a random caching strategy, while reducing web environment overhead by up to 3.2x, without degrading agentic system performance."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Towards Smart Manufacturing Metaverse via Digital Twinning in Extended Reality", "authors": "Hui Yang, Faisal Aqlan, Richard Zhao", "subjects": "Systems and Control (eess.SY); Image and Video Processing (eess.IV)", "abstract": "The rapid evolution of modern manufacturing systems is driven by the integration of emerging metaverse technologies such as artificial intelligence (AI), digital twin (DT) with different forms of extended reality (XR) like virtual reality (VR), augmented reality (AR), and mixed reality (MR). These advances confront manufacturing workers with complex and evolving environments that demand digital literacy for problem solving in the future workplace. However, manufacturing industry faces a critical shortage of skilled workforce with digital literacy in the world. Further, global pandemic has significantly changed how people work and collaborate digitally and remotely. There is an urgent need to rethink digital platformization and leverage emerging technologies to propel industrial evolution toward human-centered manufacturing metaverse (MfgVerse). This paper presents a forward-looking perspective on the development of smart MfgVerse, highlighting current efforts in learning factory, cognitive digital twinning, and the new sharing economy of manufacturing-as-a-service (MaaS). MfgVerse is converging into multiplex networks, including a social network of human stakeholders, an interconnected network of manufacturing things or agents (e.g., machines, robots, facilities, material handling systems), a network of digital twins of physical things, as well as auxiliary networks of sales, supply chain, logistics, and remanufacturing systems. We also showcase the design and development of a learning factory for workforce training in extended reality. Finally, future directions, challenges, and opportunities are discussed for human-centered manufacturing metaverse. We hope this work helps stimulate more comprehensive studies and in-depth research efforts to advance MfgVerse technologies."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Do What You Say: Steering Vision-Language-Action Models via Runtime Reasoning-Action Alignment Verification", "authors": "Yilin Wu, Anqi Li, Tucker Hermans, Fabio Ramos, Andrea Bajcsy, Claudia P'erez-D'Arpino", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "abstract": "Reasoning Vision Language Action (VLA) models improve robotic instruction-following by generating step-by-step textual plans before low-level actions, an approach inspired by Chain-of-Thought (CoT) reasoning in language models. Yet even with a correct textual plan, the generated actions can still miss the intended outcomes in the plan, especially in out-of-distribution (OOD) scenarios. We formalize this phenomenon as a lack of embodied CoT faithfulness, and introduce a training-free, runtime policy steering method for reasoning-action alignment. Given a reasoning VLA's intermediate textual plan, our framework samples multiple candidate action sequences from the same model, predicts their outcomes via simulation, and uses a pre-trained Vision-Language Model (VLM) to select the sequence whose outcome best aligns with the VLA's own textual plan. Only executing action sequences that align with the textual reasoning turns our base VLA's natural action diversity from a source of error into a strength, boosting robustness to semantic and visual OOD perturbations and enabling novel behavior composition without costly re-training. We also contribute a reasoning-annotated extension of LIBERO-100, environment variations tailored for OOD evaluation, and demonstrate up to 15% performance gain over prior work on behavior composition tasks and scales with compute and data diversity. Project Website at: this https URL"}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Instant Personalized Large Language Model Adaptation via Hypernetwork", "authors": "Zhaoxuan Tan, Zixuan Zhang, Haoyang Wen, Zheng Li, Rongzhi Zhang, Pei Chen, Fengran Mo, Zheyuan Liu, Qingkai Zeng, Qingyu Yin, Meng Jiang", "subjects": "Computation and Language (cs.CL)", "abstract": "Personalized large language models (LLMs) tailor content to individual preferences using user profiles or histories. However, existing parameter-efficient fine-tuning (PEFT) methods, such as the ``One-PEFT-Per-User'' (OPPU) paradigm, require training a separate adapter for each user, making them computationally expensive and impractical for real-time updates. We introduce Profile-to-PEFT, a scalable framework that employs a hypernetwork, trained end-to-end, to map a user's encoded profile directly to a full set of adapter parameters (e.g., LoRA), eliminating per-user training at deployment. This design enables instant adaptation, generalization to unseen users, and privacy-preserving local deployment. Experimental results demonstrate that our method outperforms both prompt-based personalization and OPPU while using substantially fewer computational resources at deployment. The framework exhibits strong generalization to out-of-distribution users and maintains robustness across varying user activity levels and different embedding backbones. The proposed Profile-to-PEFT framework enables efficient, scalable, and adaptive LLM personalization suitable for large-scale applications."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Communication-Efficient and Memory-Aware Parallel Bootstrapping using MPI", "authors": "Di Zhang", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC); Mathematical Software (cs.MS); Numerical Analysis (math.NA); Computation (stat.CO)", "abstract": "Bootstrapping is a powerful statistical resampling technique for estimating the sampling distribution of an estimator. However, its computational cost becomes prohibitive for large datasets or a high number of resamples. This paper presents a theoretical analysis and design of parallel bootstrapping algorithms using the Message Passing Interface (MPI). We address two key challenges: high communication overhead and memory constraints in distributed environments. We propose two novel strategies: 1) Local Statistic Aggregation, which drastically reduces communication by transmitting sufficient statistics instead of full resampled datasets, and 2) Synchronized Pseudo-Random Number Generation, which enables distributed resampling when the entire dataset cannot be stored on a single process. We develop analytical models for communication and computation complexity, comparing our methods against naive baseline approaches. Our analysis demonstrates that the proposed methods offer significant reductions in communication volume and memory usage, facilitating scalable parallel bootstrapping on large-scale systems."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Disentangling Hyperedges through the Lens of Category Theory", "authors": "Yoonho Lee, Junseok Lee, Sangwoo Seo, Sungwon Kim, Yeongmin Kim, Chanyoung Park", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "Despite the promising results of disentangled representation learning in discovering latent patterns in graph-structured data, few studies have explored disentanglement for hypergraph-structured data. Integrating hyperedge disentanglement into hypergraph neural networks enables models to leverage hidden hyperedge semantics, such as unannotated relations between nodes, that are associated with labels. This paper presents an analysis of hyperedge disentanglement from a category-theoretical perspective and proposes a novel criterion for disentanglement derived from the naturality condition. Our proof-of-concept model experimentally showed the potential of the proposed criterion by successfully capturing functional relations of genes (nodes) in genetic pathways (hyperedges)."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Cerberus: Real-Time Video Anomaly Detection via Cascaded Vision-Language Models", "authors": "Yue Zheng, Xiufang Shi, Jiming Chen, Yuanchao Shu", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Computation and Language (cs.CL)", "abstract": "Video anomaly detection (VAD) has rapidly advanced by recent development of Vision-Language Models (VLMs). While these models offer superior zero-shot detection capabilities, their immense computational cost and unstable visual grounding performance hinder real-time deployment. To overcome these challenges, we introduce Cerberus, a two-stage cascaded system designed for efficient yet accurate real-time VAD. Cerberus learns normal behavioral rules offline, and combines lightweight filtering with fine-grained VLM reasoning during online inference. The performance gains of Cerberus come from two key innovations: motion mask prompting and rule-based deviation detection. The former directs the VLM's attention to regions relevant to motion, while the latter identifies anomalies as deviations from learned norms rather than enumerating possible anomalies. Extensive evaluations on four datasets show that Cerberus on average achieves 57.68 fps on an NVIDIA L40S GPU, a 151.79$\\times$ speedup, and 97.2\\% accuracy comparable to the state-of-the-art VLM-based VAD methods, establishing it as a practical solution for real-time video analytics."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          QSVD: Efficient Low-rank Approximation for Unified Query-Key-Value Weight Compression in Low-Precision Vision-Language Models", "authors": "Yutong Wang, Haiyu Wang, Sai Qian Zhang", "subjects": "Machine Learning (cs.LG)", "abstract": "Vision-Language Models (VLMs) are integral to tasks such as image captioning and visual question answering, but their high computational cost, driven by large memory footprints and processing time, limits their scalability and real-time applicability. In this work, we propose leveraging Singular-Value Decomposition (SVD) over the joint query (Q), key (K), and value (V) weight matrices to reduce KV cache size and computational overhead. We in addition introduce an efficient rank allocation strategy that dynamically adjusts the SVD rank based on its impact on VLM accuracy, achieving a significant reduction in both memory usage and computational cost. Finally, we extend this approach by applying quantization to both VLM weights and activations, resulting in a highly efficient VLM. Our method outperforms previous approaches that rely solely on quantization or SVD by achieving more than $10\\%$ accuracy improvement while consuming less hardware cost, making it better for real-time deployment on resource-constrained devices. We open source our code at \\href{this https URL}{\\texttt{this https URL}}."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          OpenLVLM-MIA: A Controlled Benchmark Revealing the Limits of Membership Inference Attacks on Large Vision-Language Models", "authors": "Ryoto Miyamoto, Xin Fan, Fuyuko Kido, Tsuneo Matsumoto, Hayato Yamana", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "abstract": "OpenLVLM-MIA is a new benchmark that highlights fundamental challenges in evaluating membership inference attacks (MIA) against large vision-language models (LVLMs). While prior work has reported high attack success rates, our analysis suggests that these results often arise from detecting distributional bias introduced during dataset construction rather than from identifying true membership status. To address this issue, we introduce a controlled benchmark of 6{,}000 images where the distributions of member and non-member samples are carefully balanced, and ground-truth membership labels are provided across three distinct training stages. Experiments using OpenLVLM-MIA demonstrated that the performance of state-of-the-art MIA methods converged to random chance under unbiased conditions. By offering a transparent and unbiased benchmark, OpenLVLM-MIA clarifies the current limitations of MIA research on LVLMs and provides a solid foundation for developing stronger privacy-preserving techniques."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          AC Dynamics-aware Trajectory Optimization with Binary Enforcement for Adaptive UFLS Design", "authors": "Muhammad Hamza Ali, Amritanshu Pandey", "subjects": "Systems and Control (eess.SY)", "abstract": "The high penetration of distributed energy resources, resulting in backfeed of power at the transmission and distribution interface, is causing conventional underfrequency load shedding (UFLS) schemes to become nonconforming. Adaptive schemes that update UFLS relay settings recursively in time offer a solution, but existing adaptive techniques that obtain UFLS relay settings with linearized or reduced-order model formulations fail to capture AC nonlinear network behavior. In practice, this will result in relays unable to restore system frequency during adverse disturbances. We formulate an adaptive UFLS problem as a trajectory optimization and include the full AC nonlinear network dynamics to ensure AC feasibility and time-coordinated control actions. We include binary decisions to model relay switching action and time-delayed multi-stage load-shedding. However, this formulation results in an intractable MINLP problem. To enforce model tractability, we relax these binary variables into continuous surrogates and reformulate the MINLP as a sequence of NLPs. We solve the NLPs with a homotopy-driven method that enforces near-integer-feasible solutions. We evaluate the framework on multiple synthetic transmission systems and demonstrate that it scales efficiently to networks exceeding 1500+ nodes with over 170k+ continuous and 73k+ binary decision variables, while successfully recovering binary-feasible solutions that arrest the frequency decline during worst-case disturbance."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          DTKG: Dual-Track Knowledge Graph-Verified Reasoning Framework for Multi-Hop QA", "authors": "Changhao Wang, Yanfang Liu, Xinxin Fan, Anzhi Zhou, Lao Tian, Yunfeng Lu", "subjects": "Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)", "abstract": "Multi-hop reasoning for question answering (QA) plays a critical role in retrieval-augmented generation (RAG) for modern large language models (LLMs). The accurate answer can be obtained through retrieving relational structure of entities from knowledge graph (KG). Regarding the inherent relation-dependency and reasoning pattern, multi-hop reasoning can be in general classified into two categories: i) parallel fact-verification multi-hop reasoning question, i.e., requiring simultaneous verifications of multiple independent sub-questions; and ii) chained multi-hop reasoning questions, i.e., demanding sequential multi-step inference with intermediate conclusions serving as essential premises for subsequent reasoning. Currently, the multi-hop reasoning approaches singly employ one of two techniques: LLM response-based fact verification and KG path-based chain construction. Nevertheless, the former excels at parallel fact-verification but underperforms on chained reasoning tasks, while the latter demonstrates proficiency in chained multi-hop reasoning but suffers from redundant path retrieval when handling parallel fact-verification reasoning. These limitations deteriorate the efficiency and accuracy for multi-hop QA tasks. To address this challenge, we propose a novel dual-track KG verification and reasoning framework DTKG, which is inspired by the Dual Process Theory in cognitive science. Specifically, DTKG comprises two main stages: the Classification Stage and the Branch Processing Stage."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Scaffold-Aware Generative Augmentation and Reranking for Enhanced Virtual Screening", "authors": "Xin Wang, Yu Wang, Yunchao Liu, Jens Meiler, Tyler Derr", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "Ligand-based virtual screening (VS) is an essential step in drug discovery that evaluates large chemical libraries to identify compounds that potentially bind to a therapeutic target. However, VS faces three major challenges: class imbalance due to the low active rate, structural imbalance among active molecules where certain scaffolds dominate, and the need to identify structurally diverse active compounds for novel drug development. We introduce ScaffAug, a scaffold-aware VS framework that addresses these challenges through three modules. The augmentation module first generates synthetic data conditioned on scaffolds of actual hits using generative AI, specifically a graph diffusion model. This helps mitigate the class imbalance and furthermore the structural imbalance, due to our proposed scaffold-aware sampling algorithm, designed to produce more samples for active molecules with underrepresented scaffolds. A model-agnostic self-training module is then used to safely integrate the generated synthetic data from our augmentation module with the original labeled data. Lastly, we introduce a reranking module that improves VS by enhancing scaffold diversity in the top recommended set of molecules, while still maintaining and even enhancing the overall general performance of identifying novel, active compounds. We conduct comprehensive computational experiments across five target classes, comparing ScaffAug against existing baseline methods by reporting the performance of multiple evaluation metrics and performing ablation studies on ScaffAug. Overall, this work introduces novel perspectives on effectively enhancing VS by leveraging generative augmentations, reranking, and general scaffold-awareness."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          SPOT: Sensing-augmented Trajectory Planning via Obstacle Threat Modeling", "authors": "Chi Zhang, Xian Huang, Wei Dong", "subjects": "Robotics (cs.RO)", "abstract": "UAVs equipped with a single depth camera encounter significant challenges in dynamic obstacle avoidance due to limited field of view and inevitable blind spots. While active vision strategies that steer onboard cameras have been proposed to expand sensing coverage, most existing methods separate motion planning from sensing considerations, resulting in less effective and delayed obstacle response. To address this limitation, we introduce SPOT (Sensing-augmented Planning via Obstacle Threat modeling), a unified planning framework for observation-aware trajectory planning that explicitly incorporates sensing objectives into motion optimization. At the core of our method is a Gaussian Process-based obstacle belief map, which establishes a unified probabilistic representation of both recognized (previously observed) and potential obstacles. This belief is further processed through a collision-aware inference mechanism that transforms spatial uncertainty and trajectory proximity into a time-varying observation urgency map. By integrating urgency values within the current field of view, we define differentiable objectives that enable real-time, observation-aware trajectory planning with computation times under 10 ms. Simulation and real-world experiments in dynamic, cluttered, and occluded environments show that our method detects potential dynamic obstacles 2.8 seconds earlier than baseline approaches, increasing dynamic obstacle visibility by over 500\\%, and enabling safe navigation through cluttered, occluded environments."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          MedRule-KG: A Knowledge-Graph--Steered Scaffold for Mathematical Reasoning with a Lightweight Verifier", "authors": "Crystal Su", "subjects": "Artificial Intelligence (cs.AI)", "abstract": "Large language models (LLMs) often produce fluent reasoning steps while violating simple mathematical or logical constraints. We introduce MedRule-KG, a compact typed knowledge graph coupled with a symbolic verifier, designed to enforce mathematically interpretable rules in reasoning tasks. MedRule-KG encodes entities, relations, and three domain-inspired rules, while the verifier checks predictions and applies minimal corrections to guarantee consistency. On a 90-example FDA-derived benchmark, grounding in MedRule-KG improves exact match (EM) from 0.767 to 0.900, and adding the verifier yields 1.000 EM while eliminating rule violations entirely. We demonstrate how MedRule-KG provides a general scaffold for safe mathematical reasoning, discuss ablations, and release code and data to encourage reproducibility."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Toward General Digraph Contrastive Learning: A Dual Spatial Perspective", "authors": "Daohan Su, Yang Zhang, Xunkai Li, Rong-Hua Li, Guoren Wang", "subjects": "Machine Learning (cs.LG)", "abstract": "Graph Contrastive Learning (GCL) has emerged as a powerful tool for extracting consistent representations from graphs, independent of labeled information. However, existing methods predominantly focus on undirected graphs, disregarding the pivotal directional information that is fundamental and indispensable in real-world networks (e.g., social networks and recommendations).In this paper, we introduce S2-DiGCL, a novel framework that emphasizes spatial insights from complex and real domain perspectives for directed graph (digraph) contrastive learning. From the complex-domain perspective, S2-DiGCL introduces personalized perturbations into the magnetic Laplacian to adaptively modulate edge phases and directional semantics. From the real-domain perspective, it employs a path-based subgraph augmentation strategy to capture fine-grained local asymmetries and topological dependencies. By jointly leveraging these two complementary spatial views, S2-DiGCL constructs high-quality positive and negative samples, leading to more general and robust digraph contrastive learning. Extensive experiments on 7 real-world digraph datasets demonstrate the superiority of our approach, achieving SOTA performance with 4.41% improvement in node classification and 4.34% in link prediction under both supervised and unsupervised settings."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Stroke2Sketch: Harnessing Stroke Attributes for Training-Free Sketch Generation", "authors": "Rui Yang, Huining Li, Yiyi Long, Xiaojun Wu, Shengfeng He", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Generating sketches guided by reference styles requires precise transfer of stroke attributes, such as line thickness, deformation, and texture sparsity, while preserving semantic structure and content fidelity. To this end, we propose Stroke2Sketch, a novel training-free framework that introduces cross-image stroke attention, a mechanism embedded within self-attention layers to establish fine-grained semantic correspondences and enable accurate stroke attribute transfer. This allows our method to adaptively integrate reference stroke characteristics into content images while maintaining structural integrity. Additionally, we develop adaptive contrast enhancement and semantic-focused attention to reinforce content preservation and foreground emphasis. Stroke2Sketch effectively synthesizes stylistically faithful sketches that closely resemble handcrafted results, outperforming existing methods in expressive stroke control and semantic coherence. Codes are available at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Scaling Laws for Deepfake Detection", "authors": "Wenhao Wang, Longqi Cai, Taihong Xiao, Yuxiao Wang, Ming-Hsuan Yang", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "This paper presents a systematic study of scaling laws for the deepfake detection task. Specifically, we analyze the model performance against the number of real image domains, deepfake generation methods, and training images. Since no existing dataset meets the scale requirements for this research, we construct ScaleDF, the largest dataset to date in this field, which contains over 5.8 million real images from 51 different datasets (domains) and more than 8.8 million fake images generated by 102 deepfake methods. Using ScaleDF, we observe power-law scaling similar to that shown in large language models (LLMs). Specifically, the average detection error follows a predictable power-law decay as either the number of real domains or the number of deepfake methods increases. This key observation not only allows us to forecast the number of additional real domains or deepfake methods required to reach a target performance, but also inspires us to counter the evolving deepfake technology in a data-centric manner. Beyond this, we examine the role of pre-training and data augmentations in deepfake detection under scaling, as well as the limitations of scaling itself."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Memorizing Long-tail Data Can Help Generalization Through Composition", "authors": "Mo Zhou, Haoyang Ma, Rong Ge", "subjects": "Machine Learning (cs.LG)", "abstract": "Deep learning has led researchers to rethink the relationship between memorization and generalization. In many settings, memorization does not hurt generalization due to implicit regularization and may help by memorizing long-tailed examples. In this paper, we consider the synergy between memorization and simple composition -- the ability to make correct prediction on a combination of long-tailed features. Theoretically, we show that for a linear setting, memorization together with composition can help the model make correct predictions on rare test examples that require a combination of long-tailed features, even if such combinations were never observed in the training data. Experiments on neural network architecture on simple data show that the theoretical insight extends beyond the linear setting, and we further observe that the composition capability of the model depends on its architecture."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Scale-DiT: Ultra-High-Resolution Image Generation with Hierarchical Local Attention", "authors": "Yuyao Zhang, Yu-Wing Tai", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Ultra-high-resolution text-to-image generation demands both fine-grained texture synthesis and globally coherent structure, yet current diffusion models remain constrained to sub-$1K \\times 1K$ resolutions due to the prohibitive quadratic complexity of attention and the scarcity of native $4K$ training data. We present \\textbf{Scale-DiT}, a new diffusion framework that introduces hierarchical local attention with low-resolution global guidance, enabling efficient, scalable, and semantically coherent image synthesis at ultra-high resolutions. Specifically, high-resolution latents are divided into fixed-size local windows to reduce attention complexity from quadratic to near-linear, while a low-resolution latent equipped with scaled positional anchors injects global semantics. A lightweight LoRA adaptation bridges global and local pathways during denoising, ensuring consistency across structure and detail. To maximize inference efficiency, we repermute token sequence in Hilbert curve order and implement a fused-kernel for skipping masked operations, resulting in a GPU-friendly design. Extensive experiments demonstrate that Scale-DiT achieves more than $2\\times$ faster inference and lower memory usage compared to dense attention baselines, while reliably scaling to $4K \\times 4K$ resolution without requiring additional high-resolution training data. On both quantitative benchmarks (FID, IS, CLIP Score) and qualitative comparisons, Scale-DiT delivers superior global coherence and sharper local detail, matching or outperforming state-of-the-art methods that rely on native 4K training. Taken together, these results highlight hierarchical local attention with guided low-resolution anchors as a promising and effective approach for advancing ultra-high-resolution image generation."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          DiffusionX: Efficient Edge-Cloud Collaborative Image Generation with Multi-Round Prompt Evolution", "authors": "Yi Wei, Shunpu Tang, Liang Zhao, Qiangian Yang (College of Information Science and Electronic Engineering, Zhejiang University, Hangzhou, China)", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)", "abstract": "Recent advances in diffusion models have driven remarkable progress in image generation. However, the generation process remains computationally intensive, and users often need to iteratively refine prompts to achieve the desired results, further increasing latency and placing a heavy burden on cloud resources. To address this challenge, we propose DiffusionX, a cloud-edge collaborative framework for efficient multi-round, prompt-based generation. In this system, a lightweight on-device diffusion model interacts with users by rapidly producing preview images, while a high-capacity cloud model performs final refinements after the prompt is finalized. We further introduce a noise level predictor that dynamically balances the computation load, optimizing the trade-off between latency and cloud workload. Experiments show that DiffusionX reduces average generation time by 15.8% compared with Stable Diffusion v1.5, while maintaining comparable image quality. Moreover, it is only 0.9% slower than Tiny-SD with significantly improved image quality, thereby demonstrating efficiency and scalability with minimal overhead."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Near-linear time subhypergraph counting in bounded degeneracy hypergraphs", "authors": "Daniel Paul-Pena, C. Seshadhri", "subjects": "Data Structures and Algorithms (cs.DS); Discrete Mathematics (cs.DM)", "abstract": "Counting small patterns in a large dataset is a fundamental algorithmic task. The most common version of this task is subgraph/homomorphism counting, wherein we count the number of occurrences of a small pattern graph $H$ in an input graph $G$. The study of this problem is a field in and of itself. Recently, both in theory and practice, there has been an interest in \\emph{hypergraph} algorithms, where $G = (V,E)$ is a hypergraph. One can view $G$ as a set system where hyperedges are subsets of the universe $V$. Counting patterns $H$ in hypergraphs is less studied, although there are many applications in network science and database algorithms. Inspired by advances in the graph literature, we study when linear time algorithms are possible. We focus on input hypergraphs $G$ that have bounded \\emph{degeneracy}, a well-studied concept for graph algorithms. We give a spectrum of definitions for hypergraph degeneracy that cover all existing notions. For each such definition, we give a precise characterization of the patterns $H$ that can be counted in (near) linear time. Specifically, we discover a set of ``obstruction patterns\". If $H$ does not contain an obstruction, then the number of $H$-subhypergraphs can be counted exactly in $O(n\\log n)$ time (where $n$ is the number of vertices in $G$). If $H$ contains an obstruction, then (assuming hypergraph variants of fine-grained complexity conjectures), there is a constant $\\gamma > 0$, such that there is no $o(n^{1+\\gamma})$ time algorithm for counting $H$-subhypergraphs. These sets of obstructions can be defined for all notions of hypergraph degeneracy."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Efficient and Privacy-Preserving Binary Dot Product via Multi-Party Computation", "authors": "Fatemeh Jafarian Dehkordi, Elahe Vedadi, Alireza Feizbakhsh, Yasaman Keshtkarjahromi, Hulya Seferoglu", "subjects": "Cryptography and Security (cs.CR); Computational Complexity (cs.CC)", "abstract": "Striking a balance between protecting data privacy and enabling collaborative computation is a critical challenge for distributed machine learning. While privacy-preserving techniques for federated learning have been extensively developed, methods for scenarios involving bitwise operations, such as tree-based vertical federated learning (VFL), are still underexplored. Traditional mechanisms, including Shamir's secret sharing and multi-party computation (MPC), are not optimized for bitwise operations over binary data, particularly in settings where each participant holds a different part of the binary vector. This paper addresses the limitations of existing methods by proposing a novel binary multi-party computation (BiMPC) framework. The BiMPC mechanism facilitates privacy-preserving bitwise operations, with a particular focus on dot product computations of binary vectors, ensuring the privacy of each individual bit. The core of BiMPC is a novel approach called Dot Product via Modular Addition (DoMA), which uses regular and modular additions for efficient binary dot product calculation. To ensure privacy, BiMPC uses random masking in a higher field for linear computations and a three-party oblivious transfer (triot) protocol for non-linear binary operations. The privacy guarantees of the BiMPC framework are rigorously analyzed, demonstrating its efficiency and scalability in distributed settings."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          TokenAR: Multiple Subject Generation via Autoregressive Token-level enhancement", "authors": "Haiyue Sun, Qingdong He, Jinlong Peng, Peng Tang, Jiangning Zhang, Junwei Zhu, Xiaobin Hu, Shuicheng Yan", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Autoregressive Model (AR) has shown remarkable success in conditional image generation. However, these approaches for multiple reference generation struggle with decoupling different reference identities. In this work, we propose the TokenAR framework, specifically focused on a simple but effective token-level enhancement mechanism to address reference identity confusion problem. Such token-level enhancement consists of three parts, 1). Token Index Embedding clusters the tokens index for better representing the same reference images; 2). Instruct Token Injection plays as a role of extra visual feature container to inject detailed and complementary priors for reference tokens; 3). The identity-token disentanglement strategy (ITD) explicitly guides the token representations toward independently representing the features of each this http URL token-enhancement framework significantly augments the capabilities of existing AR based methods in conditional image generation, enabling good identity consistency while preserving high quality background reconstruction. Driven by the goal of high-quality and high-diversity in multi-subject generation, we introduce the InstructAR Dataset, the first open-source, large-scale, multi-reference input, open domain image generation dataset that includes 28K training pairs, each example has two reference subjects, a relative prompt and a background with mask annotation, curated for multiple reference image generation training and evaluating. Comprehensive experiments validate that our approach surpasses current state-of-the-art models in multiple reference image generation task. The implementation code and datasets will be made publicly. Codes are available, see this https URL"}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          RL makes MLLMs see better than SFT", "authors": "Junha Song, Sangdoo Yun, Dongyoon Han, Jaegul Choo, Byeongho Heo", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)", "abstract": "A dominant assumption in Multimodal Language Model (MLLM) research is that its performance is largely inherited from the LLM backbone, given its immense parameter scale and remarkable capabilities. This has created a void in the understanding of the vision encoder, which determines how MLLMs perceive images. The recent shift in MLLM training paradigms, from Supervised Finetuning (SFT) to Reinforcement Learning (RL), magnifies this oversight-namely, the significant lack of analysis on how such training reshapes the vision encoder as well as the MLLM. To address this, we first investigate the impact of training strategies on MLLMs, where RL shows a clear advantage over SFT in strongly vision-related VQA benchmarks. Motivated by this, we conduct a critical yet under-explored analysis of the vision encoder of MLLMs through diverse and in-depth experiments, ranging from ImageNet classification and segmentation to gradient visualization. Our results demonstrate that MLLM's post-training strategy (i.e., SFT or RL) not only leads to distinct outcomes on MLLM downstream tasks, but also fundamentally reshapes MLLM's underlying visual representations. Specifically, the key finding of our study is that RL produces stronger and precisely localized visual representations compared to SFT, boosting the ability of the vision encoder for MLLM. We then reframe our findings into a simple recipe for building strong vision encoders for MLLMs, Preference-Instructed Vision OpTimization (PIVOT). When integrated into MLLMs, a PIVOT-trained vision encoder outperforms even larger and more heavily-trained counterparts, despite requiring less than 1% of the computational cost of standard vision pretraining. This result opens an effective and efficient path for advancing the vision backbones of MLLMs. Project page available at this https URL"}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Investigating the Association Between Text-Based Indications of Foodborne Illness from Yelp Reviews and New York City Health Inspection Outcomes (2023)", "authors": "Eden Shaveet, Crystal Su, Daniel Hsu, Luis Gravano", "subjects": "Information Retrieval (cs.IR); Computation and Language (cs.CL)", "abstract": "Foodborne illnesses are gastrointestinal conditions caused by consuming contaminated food. Restaurants are critical venues to investigate outbreaks because they share sourcing, preparation, and distribution of foods. Public reporting of illness via formal channels is limited, whereas social media platforms host abundant user-generated content that can provide timely public health signals. This paper analyzes signals from Yelp reviews produced by a Hierarchical Sigmoid Attention Network (HSAN) classifier and compares them with official restaurant inspection outcomes issued by the New York City Department of Health and Mental Hygiene (NYC DOHMH) in 2023. We evaluate correlations at the Census tract level, compare distributions of HSAN scores by prevalence of C-graded restaurants, and map spatial patterns across NYC. We find minimal correlation between HSAN signals and inspection scores at the tract level and no significant differences by number of C-graded restaurants. We discuss implications and outline next steps toward address-level analyses."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          On the Provable Importance of Gradients for Language-Assisted Image Clustering", "authors": "Bo Peng, Jie Lu, Guangquan Zhang, Zhen Fang", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "This paper investigates the recently emerged problem of Language-assisted Image Clustering (LaIC), where textual semantics are leveraged to improve the discriminability of visual representations to facilitate image clustering. Due to the unavailability of true class names, one of core challenges of LaIC lies in how to filter positive nouns, i.e., those semantically close to the images of interest, from unlabeled wild corpus data. Existing filtering strategies are predominantly based on the off-the-shelf feature space learned by CLIP; however, despite being intuitive, these strategies lack a rigorous theoretical foundation. To fill this gap, we propose a novel gradient-based framework, termed as GradNorm, which is theoretically guaranteed and shows strong empirical performance. In particular, we measure the positiveness of each noun based on the magnitude of gradients back-propagated from the cross-entropy between the predicted target distribution and the softmax output. Theoretically, we provide a rigorous error bound to quantify the separability of positive nouns by GradNorm and prove that GradNorm naturally subsumes existing filtering strategies as extremely special cases of itself. Empirically, extensive experiments show that GradNorm achieves the state-of-the-art clustering performance on various benchmarks."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          A (Very) Nearly Optimal Sketch for $k$-Edge Connectivity Certificates", "authors": "Pachara Sawettamalya, Huacheng Yu", "subjects": "Data Structures and Algorithms (cs.DS)", "abstract": "In this note, we present a simple algorithm for computing a \\emph{$k$-connectivity certificate} in dynamic graph streams. Our algorithm uses $O(n \\log^2 n \\cdot \\max\\{k, \\log n \\log k\\})$ bits of space which improves upon the $O(kn \\log^3 n)$-space algorithm of Ahn, Guha, and McGregor (SODA'12). For the values of $k$ that are truly sublinear, our space usage \\emph{very nearly} matches the known lower bound $\\Omega(n \\log^2 n \\cdot \\max\\{k, \\log n\\})$ established by Nelson and Yu (SODA'19; implicit) and Robinson (DISC'24). In particular, our algorithm fully settles the space complexity at $\\Theta(kn \\log^2{n})$ for $k = \\Omega(\\log n \\log \\log n)$, and bridges the gap down to only a doubly-logarithmic factor of $O(\\log \\log n)$ for a smaller range of $k = o(\\log n \\log \\log n)$."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Thinking About Thinking: Evaluating Reasoning in Post-Trained Language Models", "authors": "Pratham Singla, Shivank Garg, Ayush Singh, Ishan Garg, Ketan Suhaas Saichandran", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "abstract": "Recent advances in post-training techniques have endowed Large Language Models (LLMs) with enhanced capabilities for tackling complex, logic-intensive tasks through the generation of supplementary planning tokens. This development raises a fundamental question: Are these models aware of what they \"learn\" and \"think\"? To address this, we define three core competencies: (1) awareness of learned latent policies, (2) generalization of these policies across domains, and (3) alignment between internal reasoning traces and final outputs. We empirically evaluate these abilities on several tasks, each designed to require learning a distinct policy. Furthermore, we contrast the profiles of models post-trained via Supervised Fine-Tuning (SFT), Direct Policy Optimization (DPO), and Group Relative Policy Optimization (GRPO). Our findings indicate that RL-trained models not only demonstrate greater awareness of their learned behaviors and stronger generalizability to novel, structurally similar tasks than SFT models but also often exhibit weak alignment between their reasoning traces and final outputs, an effect most pronounced in GRPO-trained models."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Beyond Fixed Anchors: Precisely Erasing Concepts with Sibling Exclusive Counterparts", "authors": "Tong Zhang, Ru Zhang, Jianyi Liu, Zhen Yang, Gongshen Liu", "subjects": "Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Existing concept erasure methods for text-to-image diffusion models commonly rely on fixed anchor strategies, which often lead to critical issues such as concept re-emergence and erosion. To address this, we conduct causal tracing to reveal the inherent sensitivity of erasure to anchor selection and define Sibling Exclusive Concepts as a superior class of anchors. Based on this insight, we propose \\textbf{SELECT} (Sibling-Exclusive Evaluation for Contextual Targeting), a dynamic anchor selection framework designed to overcome the limitations of fixed anchors. Our framework introduces a novel two-stage evaluation mechanism that automatically discovers optimal anchors for precise erasure while identifying critical boundary anchors to preserve related concepts. Extensive evaluations demonstrate that SELECT, as a universal anchor solution, not only efficiently adapts to multiple erasure frameworks but also consistently outperforms existing baselines across key performance metrics, averaging only 4 seconds for anchor mining of a single concept."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Manual2Skill++: Connector-Aware General Robotic Assembly from Instruction Manuals via Vision-Language Models", "authors": "Chenrui Tie, Shengxiang Sun, Yudi Lin, Yanbo Wang, Zhongrui Li, Zhouhan Zhong, Jinxuan Zhu, Yiman Pang, Haonan Chen, Junting Chen, Ruihai Wu, Lin Shao", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI)", "abstract": "Assembly hinges on reliably forming connections between parts; yet most robotic approaches plan assembly sequences and part poses while treating connectors as an afterthought. Connections represent the critical \"last mile\" of assembly execution, while task planning may sequence operations and motion plan may position parts, the precise establishment of physical connections ultimately determines assembly success or failure. In this paper, we consider connections as first-class primitives in assembly representation, including connector types, specifications, quantities, and placement locations. Drawing inspiration from how humans learn assembly tasks through step-by-step instruction manuals, we present Manual2Skill++, a vision-language framework that automatically extracts structured connection information from assembly manuals. We encode assembly tasks as hierarchical graphs where nodes represent parts and sub-assemblies, and edges explicitly model connection relationships between components. A large-scale vision-language model parses symbolic diagrams and annotations in manuals to instantiate these graphs, leveraging the rich connection knowledge embedded in human-designed instructions. We curate a dataset containing over 20 assembly tasks with diverse connector types to validate our representation extraction approach, and evaluate the complete task understanding-to-execution pipeline across four complex assembly scenarios in simulation, spanning furniture, toys, and manufacturing components with real-world correspondence."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Truly Subquadratic Time Algorithms for Diameter and Related Problems in Graphs of Bounded VC-dimension", "authors": "Timothy M. Chan, Hsien-Chih Chang, Jie Gao, S\u00e1ndor Kisfaludi-Bak, Hung Le, Da Wei Zheng", "subjects": "Data Structures and Algorithms (cs.DS); Computational Geometry (cs.CG)", "abstract": "We give the first truly subquadratic time algorithm, with $O^*(n^{2-1/18})$ running time, for computing the diameter of an $n$-vertex unit-disk graph, resolving a central open problem in the literature. Our result is obtained as an instance of a general framework, applicable to different graph families and distance problems. Surprisingly, our framework completely bypasses sublinear separators (or $r$-divisions) which were used in all previous algorithms. Instead, we use low-diameter decompositions in their most elementary form. We also exploit bounded VC-dimension of set systems associated with the input graph, as well as new ideas on geometric data structures. Among the numerous applications of the general framework, we obtain: 1. An $\\tilde{O}(mn^{1-1/(2d)})$ time algorithm for computing the diameter of $m$-edge sparse unweighted graphs with constant VC-dimension $d$. The previously known algorithms by Ducoffe, Habib, and Viennot [SODA 2019] and Duraj, Konieczny, and Pot\u0229pa [ESA 2024] are truly subquadratic only when the diameter is a small polynomial. Our result thus generalizes truly subquadratic time algorithms known for planar and minor-free graphs (in fact, it slightly improves the previous time bound for minor-free graphs). 2. An $\\tilde{O}(n^{2-1/12})$ time algorithm for computing the diameter of intersection graphs of axis-aligned squares with arbitrary size. The best-known algorithm by Duraj, Konieczny, and Pot\u0229pa [ESA 2024] only works for unit squares and is only truly subquadratic in the low-diameter regime. 3. The first algorithms with truly subquadratic complexity for other distance-related problems, including all-vertex eccentricities, Wiener index, and exact distance oracles. (... truncated to meet the arXiv abstract requirement.)"}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          MGTS-Net: Exploring Graph-Enhanced Multimodal Fusion for Augmented Time Series Forecasting", "authors": "Shule Hao, Junpeng Bao, Wenli Li", "subjects": "Machine Learning (cs.LG)", "abstract": "Recent research in time series forecasting has explored integrating multimodal features into models to improve accuracy. However, the accuracy of such methods is constrained by three key challenges: inadequate extraction of fine-grained temporal patterns, suboptimal integration of multimodal information, and limited adaptability to dynamic multi-scale features. To address these problems, we propose MGTS-Net, a Multimodal Graph-enhanced Network for Time Series forecasting. The model consists of three core components: (1) a Multimodal Feature Extraction layer (MFE), which optimizes feature encoders according to the characteristics of temporal, visual, and textual modalities to extract temporal features of fine-grained patterns; (2) a Multimodal Feature Fusion layer (MFF), which constructs a heterogeneous graph to model intra-modal temporal dependencies and cross-modal alignment relationships and dynamically aggregates multimodal knowledge; (3) a Multi-Scale Prediction layer (MSP), which adapts to multi-scale features by dynamically weighting and fusing the outputs of short-term, medium-term, and long-term predictors. Extensive experiments demonstrate that MGTS-Net exhibits excellent performance with light weight and high efficiency. Compared with other state-of-the-art baseline models, our method achieves superior performance, validating the superiority of the proposed methodology."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Tight Pair Query Lower Bounds for Matching and Earth Mover's Distance", "authors": "Amir Azarmehr, Soheil Behnezhad, Mohammad Roghani, Aviad Rubinstein", "subjects": "Data Structures and Algorithms (cs.DS)", "abstract": "How many adjacency matrix queries (also known as pair queries) are required to estimate the size of a maximum matching in an $n$-vertex graph $G$? We study this fundamental question in this paper. On the upper bound side, an algorithm of Bhattacharya, Kiss, and Saranurak [FOCS'23] gives an estimate that is within $\\epsilon n$ of the right bound with $n^{2-\\Omega_\\epsilon(1)}$ queries, which is subquadratic in $n$ (and thus sublinear in the matrix size) for any fixed $\\epsilon > 0$. On the lower bound side, while there has been a lot of progress in the adjacency list model, no non-trivial lower bound has been established for algorithms with adjacency matrix query access. In particular, the only known lower bound is a folklore bound of $\\Omega(n)$, leaving a huge gap. In this paper, we present the first superlinear in $n$ lower bound for this problem. In fact, we close the gap mentioned above entirely by showing that the algorithm of [BKS'23] is optimal. Formally, we prove that for any fixed $\\delta > 0$, there is a fixed $\\epsilon > 0$ such that an estimate that is within $\\epsilon n$ of the true bound requires $\\Omega(n^{2-\\delta})$ adjacency matrix queries. Our lower bound also has strong implications for estimating the earth mover's distance between distributions. For this problem, Beretta and Rubinstein [STOC'24] gave an $n^{2-\\Omega_\\epsilon(1)}$ time algorithm that obtains an additive $\\epsilon$-approximation and works for any distance function. Whether this can be improved generally, or even for metric spaces, had remained open. Our lower bound rules out the possibility of any improvements over this bound, even under the strong assumption that the underlying distances are in a (1, 2)-metric."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Supervisory Control of Hybrid Power Plants Using Online Feedback Optimization: Designs and Validations with a Hybrid Co-Simulation Engine", "authors": "Sayak Mukherjee, Himanshu Sharma, Wenceslao Shaw Cortez, Genevieve Starke, Michael Sinner, Brooke J. Stanislawski, Zachary Tully, Paul Fleming, Sonja Glavaski", "subjects": "Systems and Control (eess.SY)", "abstract": "This research investigates designing a supervisory feedback controller for a hybrid power plant that coordinates the wind, solar, and battery energy storage plants to meet the desired power demands. We have explored an online feedback control design that does not require detailed knowledge about the models, known as feedback optimization. The control inputs are updated using the gradient information of the cost and the outputs with respect to the input control commands. This enables us to adjust the active power references of wind, solar, and storage plants to meet the power generation requirements set by grid operators. The methodology also ensures robust control performance in the presence of uncertainties in the weather. In this paper, we focus on describing the supervisory feedback optimization formulation and control-oriented modeling for individual renewable and storage components of the hybrid power plant. The proposed supervisory control has been integrated with the hybrid plant co-simulation engine, Hercules, demonstrating its effectiveness in more realistic simulation scenarios."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Transmission of High-Amplitude Sound through Leakages of Ill-fitting Earplugs", "authors": "Haocheng Yu, Krishan K. Ahuja, Lakshmi N. Sankar, Spencer H. Bryngelson", "subjects": "Sound (cs.SD); Audio and Speech Processing (eess.AS)", "abstract": "High sound pressure levels (SPL) pose notable risks in loud environments, particularly due to noise-induced hearing loss. Ill-fitting earplugs often lead to sound leakage, a phenomenon this study seeks to investigate. To validate our methodology, we first obtained computational and experimental acoustic transmission data for stand-alone slit resonators and orifices, for which extensive published data are readily available for comparison. We then examined the frequency-dependent acoustic power absorption coefficient and transmission loss (TL) across various leakage geometries, modeled using different orifice diameters. Experimental approaches spanned a frequency range of 1--5 kHz under SPL conditions of 120--150 dB. Key findings reveal that unsealed silicone rubber earplugs demonstrate an average TL reduction of approximately 18 dB at an overall incident SPL (OISPL) of 120 dB. Direct numerical simulations further highlight SPL-dependent acoustic dissipation mechanisms, showing the conversion of acoustic energy into vorticity in ill-fitting earplug models at an OISPL of 150 dB. These results highlight the role of earplug design for high-sound-pressure-level environments."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Sparse Transformer Architectures via Regularized Wasserstein Proximal Operator with $L_1$ Prior", "authors": "Fuqun Han, Stanley Osher, Wuchen Li", "subjects": "Machine Learning (cs.LG); Optimization and Control (math.OC); Machine Learning (stat.ML)", "abstract": "In this work, we propose a sparse transformer architecture that incorporates prior information about the underlying data distribution directly into the transformer structure of the neural network. The design of the model is motivated by a special optimal transport problem, namely the regularized Wasserstein proximal operator, which admits a closed-form solution and turns out to be a special representation of transformer architectures. Compared with classical flow-based models, the proposed approach improves the convexity properties of the optimization problem and promotes sparsity in the generated samples. Through both theoretical analysis and numerical experiments, including applications in generative modeling and Bayesian inverse problems, we demonstrate that the sparse transformer achieves higher accuracy and faster convergence to the target distribution than classical neural ODE-based methods."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          MLCPD: A Unified Multi-Language Code Parsing Dataset with Universal AST Schema", "authors": "Jugal Gajjar, Kamalasankari Subramaniakuppusamy", "subjects": "Software Engineering (cs.SE); Machine Learning (cs.LG); Programming Languages (cs.PL)", "abstract": "We introduce the MultiLang Code Parser Dataset (MLCPD), a large-scale, language-agnostic dataset unifying syntactic and structural representations of code across ten major programming languages. MLCPD contains over seven million parsed source files normalized under our proposed universal Abstract Syntax Tree (AST) schema, enabling consistent cross-language reasoning, structural learning, and multilingual software analysis. Unlike existing corpora that focus purely on token-level code or isolated parsers, MLCPD provides both hierarchical tree representations and rich metadata for every file, ensuring lossless syntactic coverage and structural uniformity. Each entry includes a normalized schema, language-level metadata, and abstracted node semantics stored in Parquet format for scalable retrieval. Empirical analyses reveal strong cross-language structural regularities-demonstrating that syntactic graphs from languages as diverse as Python, Java, and Go can be aligned under a shared schema. We release the dataset publicly on Hugging Face and the accompanying codebase on GitHub, which includes complete pipelines for dataset reproduction, grammar compilation, and a visualization tool for exploring the unified AST across languages. Together, these resources establish MLCPD as an open, reproducible foundation for future research in cross-language representation learning and program analysis."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Utilising Large Language Models for Generating Effective Counter Arguments to Anti-Vaccine Tweets", "authors": "Utsav Dhanuka, Soham Poddar, Saptarshi Ghosh", "subjects": "Computation and Language (cs.CL)", "abstract": "In an era where public health is increasingly influenced by information shared on social media, combatting vaccine skepticism and misinformation has become a critical societal goal. Misleading narratives around vaccination have spread widely, creating barriers to achieving high immunisation rates and undermining trust in health recommendations. While efforts to detect misinformation have made significant progress, the generation of real time counter-arguments tailored to debunk such claims remains an insufficiently explored area. In this work, we explore the capabilities of LLMs to generate sound counter-argument rebuttals to vaccine misinformation. Building on prior research in misinformation debunking, we experiment with various prompting strategies and fine-tuning approaches to optimise counter-argument generation. Additionally, we train classifiers to categorise anti-vaccine tweets into multi-labeled categories such as concerns about vaccine efficacy, side effects, and political influences allowing for more context aware rebuttals. Our evaluation, conducted through human judgment, LLM based assessments, and automatic metrics, reveals strong alignment across these methods. Our findings demonstrate that integrating label descriptions and structured fine-tuning enhances counter-argument effectiveness, offering a promising approach for mitigating vaccine misinformation at scale."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          End-to-End Argument Mining through Autoregressive Argumentative Structure Prediction", "authors": "Nilmadhab Das, Vishal Vaibhav, Yash Sunil Choudhary, V. Vijaya Saradhi, Ashish Anand", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "abstract": "Argument Mining (AM) helps in automating the extraction of complex argumentative structures such as Argument Components (ACs) like Premise, Claim etc. and Argumentative Relations (ARs) like Support, Attack etc. in an argumentative text. Due to the inherent complexity of reasoning involved with this task, modelling dependencies between ACs and ARs is challenging. Most of the recent approaches formulate this task through a generative paradigm by flattening the argumentative structures. In contrast to that, this study jointly formulates the key tasks of AM in an end-to-end fashion using Autoregressive Argumentative Structure Prediction (AASP) framework. The proposed AASP framework is based on the autoregressive structure prediction framework that has given good performance for several NLP tasks. AASP framework models the argumentative structures as constrained pre-defined sets of actions with the help of a conditional pre-trained language model. These actions build the argumentative structures step-by-step in an autoregressive manner to capture the flow of argumentative reasoning in an efficient way. Extensive experiments conducted on three standard AM benchmarks demonstrate that AASP achieves state-of-theart (SoTA) results across all AM tasks in two benchmarks and delivers strong results in one benchmark."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Integrating LLM and Diffusion-Based Agents for Social Simulation", "authors": "Xinyi Li, Zhiqiang Guo, Qinglang Guo, Hao Jin, Weizhi Ma, Min Zhang", "subjects": "Computers and Society (cs.CY)", "abstract": "Agent-based social simulation provides a valuable methodology for predicting social information diffusion, yet existing approaches face two primary limitations. Traditional agent models often rely on rigid behavioral rules and lack semantic understanding of textual content, while emerging large language model (LLM)-based agents incur prohibitive computational costs at scale. To address these challenges, we propose a hybrid simulation framework that strategically integrates LLM-driven agents with diffusion model-based agents. The framework employs LLM-based agents to simulate a core subset of users with rich semantic reasoning, while a diffusion model handles the remaining population efficiently. Although the two agent types operate on disjoint user groups, both incorporate key factors including user personalization, social influence, and content awareness, and interact through a coordinated simulation process. Extensive experiments on three real-world datasets demonstrate that our framework outperforms existing methods in prediction accuracy, validating the effectiveness of its modular design."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          EditMark: Watermarking Large Language Models based on Model Editing", "authors": "Shuai Li, Kejiang Chen, Jun Jiang, Jie Zhang, Qiyi Yao, Kai Zeng, Weiming Zhang, Nenghai Yu", "subjects": "Cryptography and Security (cs.CR)", "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities, but their training requires extensive data and computational resources, rendering them valuable digital assets. Therefore, it is essential to watermark LLMs to protect their copyright and trace unauthorized use or resale. Existing methods for watermarking LLMs primarily rely on training LLMs with a watermarked dataset, which entails burdensome training costs and negatively impacts the LLM's performance. In addition, their watermarked texts are not logical or natural, thereby reducing the stealthiness of the watermark. To address these issues, we propose EditMark, the first watermarking method that leverages model editing to embed a training-free, stealthy, and performance-lossless watermark for LLMs. We observe that some questions have multiple correct answers. Therefore, we assign each answer a unique watermark and update the weights of LLMs to generate corresponding questions and answers through the model editing technique. In addition, we refine the model editing technique to align with the requirements of watermark embedding. Specifically, we introduce an adaptive multi-round stable editing strategy, coupled with the injection of a noise matrix, to improve both the effectiveness and robustness of the watermark embedding. Extensive experiments indicate that EditMark can embed 32-bit watermarks into LLMs within 20 seconds (Fine-tuning: 6875 seconds) with a watermark extraction success rate of 100%, which demonstrates its effectiveness and efficiency. External experiments further demonstrate that EditMark has fidelity, stealthiness, and a certain degree of robustness against common attacks."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          The Burden of Interactive Alignment with Inconsistent Preferences", "authors": "Ali Shirali", "subjects": "Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG); Theoretical Economics (econ.TH)", "abstract": "From media platforms to chatbots, algorithms shape how people interact, learn, and discover information. Such interactions between users and an algorithm often unfold over multiple steps, during which strategic users can guide the algorithm to better align with their true interests by selectively engaging with content. However, users frequently exhibit inconsistent preferences: they may spend considerable time on content that offers little long-term value, inadvertently signaling that such content is desirable. Focusing on the user side, this raises a key question: what does it take for such users to align the algorithm with their true interests? To investigate these dynamics, we model the user's decision process as split between a rational system 2 that decides whether to engage and an impulsive system 1 that determines how long engagement lasts. We then study a multi-leader, single-follower extensive Stackelberg game, where users, specifically system 2, lead by committing to engagement strategies and the algorithm best-responds based on observed interactions. We define the burden of alignment as the minimum horizon over which users must optimize to effectively steer the algorithm. We show that a critical horizon exists: users who are sufficiently foresighted can achieve alignment, while those who are not are instead aligned to the algorithm's objective. This critical horizon can be long, imposing a substantial burden. However, even a small, costly signal (e.g., an extra click) can significantly reduce it. Overall, our framework explains how users with inconsistent preferences can align an engagement-driven algorithm with their interests in a Stackelberg equilibrium, highlighting both the challenges and potential remedies for achieving alignment."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          MIRAD - A comprehensive real-world robust anomaly detection dataset for Mass Individualization", "authors": "Pulin Li, Guocheng Wu, Li Yin, Yuxin Zheng, Wei Zhang, Yanjie Zhou", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Social manufacturing leverages community collaboration and scattered resources to realize mass individualization in modern industry. However, this paradigm shift also introduces substantial challenges in quality control, particularly in defect detection. The main difficulties stem from three aspects. First, products often have highly customized configurations. Second, production typically involves fragmented, small-batch orders. Third, imaging environments vary considerably across distributed sites. To overcome the scarcity of real-world datasets and tailored algorithms, we introduce the Mass Individualization Robust Anomaly Detection (MIRAD) dataset. As the first benchmark explicitly designed for anomaly detection in social manufacturing, MIRAD captures three critical dimensions of this domain: (1) diverse individualized products with large intra-class variation, (2) data collected from six geographically dispersed manufacturing nodes, and (3) substantial imaging heterogeneity, including variations in lighting, background, and motion conditions. We then conduct extensive evaluations of state-of-the-art (SOTA) anomaly detection methods on MIRAD, covering one-class, multi-class, and zero-shot approaches. Results show a significant performance drop across all models compared with conventional benchmarks, highlighting the unresolved complexities of defect detection in real-world individualized production. By bridging industrial requirements and academic research, MIRAD provides a realistic foundation for developing robust quality control solutions essential for Industry 5.0. The dataset is publicly available at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Cataract-LMM: Large-Scale, Multi-Source, Multi-Task Benchmark for Deep Learning in Surgical Video Analysis", "authors": "Mohammad Javad Ahmadi, Iman Gandomi, Parisa Abdi, Seyed-Farzad Mohammadi, Amirhossein Taslimi, Mehdi Khodaparast, Hassan Hashemi, Mahdi Tavakoli, Hamid D. Taghirad", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "abstract": "The development of computer-assisted surgery systems depends on large-scale, annotated datasets. Current resources for cataract surgery often lack the diversity and annotation depth needed to train generalizable deep-learning models. To address this gap, we present a dataset of 3,000 phacoemulsification cataract surgery videos from two surgical centers, performed by surgeons with a range of experience levels. This resource is enriched with four annotation layers: temporal surgical phases, instance segmentation of instruments and anatomical structures, instrument-tissue interaction tracking, and quantitative skill scores based on the established competency rubrics like the ICO-OSCAR. The technical quality of the dataset is supported by a series of benchmarking experiments for key surgical AI tasks, including workflow recognition, scene segmentation, and automated skill assessment. Furthermore, we establish a domain adaptation baseline for the phase recognition task by training a model on a subset of surgical centers and evaluating its performance on a held-out center. The dataset and annotations are available in Google Form (this https URL)."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Navigating through the hidden embedding space: steering LLMs to improve mental health assessment", "authors": "Federico Ravenda, Seyed Ali Bahrainian, Andrea Raballo, Antonietta Mira", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "abstract": "The rapid evolution of Large Language Models (LLMs) is transforming AI, opening new opportunities in sensitive and high-impact areas such as Mental Health (MH). Yet, despite these advancements, recent evidence reveals that smaller-scale models still struggle to deliver optimal performance in domain-specific applications. In this study, we present a cost-efficient yet powerful approach to improve MH assessment capabilities of an LLM, without relying on any computationally intensive techniques. Our lightweight method consists of a linear transformation applied to a specific layer's activations, leveraging steering vectors to guide the model's output. Remarkably, this intervention enables the model to achieve improved results across two distinct tasks: (1) identifying whether a Reddit post is useful for detecting the presence or absence of depressive symptoms (relevance prediction task), and (2) completing a standardized psychological screening questionnaire for depression based on users' Reddit post history (questionnaire completion task). Results highlight the untapped potential of steering mechanisms as computationally efficient tools for LLMs' MH domain adaptation."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Before you <think>, monitor: Implementing Flavell's metacognitive framework in LLMs", "authors": "Nick Oh", "subjects": "Artificial Intelligence (cs.AI)", "abstract": "Current approaches to enhancing LLM reasoning follows two isolated paradigms: Monitor-Generate methods like Plan-and-Solve (Wang et al., 2023) and SELF-DISCOVER (Zhou et al., 2024) excel at strategic planning but lack mechanisms to verify whether selected strategies succeed; while Generate-Verify approaches like Self-Verification (Weng et al., 2022) and SELF-REFINE (Madaan et al., 2023) iteratively refine outputs but commence generation blindly without task assessment. This separation creates inefficiencies -- strategies fail without feedback, and refinement occurs without strategic grounding. We address this gap by implementing Flavell's cognitive monitoring model (1979) from the broader Monitor-Generate-Verify framework (Oh and Gobet, 2025), operationalising it as a three-phase iterative system. On GSM8K, preliminary results show 75.42% accuracy versus 68.44% for SELF-REFINE and 67.07% for Self-Verification, while requiring fewer attempts (1.3 vs 2.0) at 27-37% increased inference cost. These initial findings suggest upfront monitoring produces higher-quality initial solutions that reduce refinement needs, though evaluation beyond arithmetic reasoning is needed to establish generalisability."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          iWatchRoadv2: Pothole Detection, Geospatial Mapping, and Intelligent Road Governance", "authors": "Rishi Raj Sahoo, Surbhi Saswati Mohanty, Subhankar Mishra", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)", "abstract": "Road potholes pose significant safety hazards and maintenance challenges, particularly on India's diverse and under-maintained road networks. This paper presents iWatchRoadv2, a fully automated end-to-end platform for real-time pothole detection, GPS-based geotagging, and dynamic road health visualization using OpenStreetMap (OSM). We curated a self-annotated dataset of over 7,000 dashcam frames capturing diverse Indian road conditions, weather patterns, and lighting scenarios, which we used to fine-tune the Ultralytics YOLO model for accurate pothole detection. The system synchronizes OCR-extracted video timestamps with external GPS logs to precisely geolocate each detected pothole, enriching detections with comprehensive metadata, including road segment attribution and contractor information managed through an optimized backend database. iWatchRoadv2 introduces intelligent governance features that enable authorities to link road segments with contract metadata through a secure login interface. The system automatically sends alerts to contractors and officials when road health deteriorates, supporting automated accountability and warranty enforcement. The intuitive web interface delivers actionable analytics to stakeholders and the public, facilitating evidence-driven repair planning, budget allocation, and quality assessment. Our cost-effective and scalable solution streamlines frame processing and storage while supporting seamless public engagement for urban and rural deployments. By automating the complete pothole monitoring lifecycle, from detection to repair verification, iWatchRoadv2 enables data-driven smart city management, transparent governance, and sustainable improvements in road infrastructure maintenance. The platform and live demonstration are accessible at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Demeter: A Parametric Model of Crop Plant Morphology from the Real World", "authors": "Tianhang Cheng, Albert J. Zhai, Evan Z. Chen, Rui Zhou, Yawen Deng, Zitong Li, Kejie Zhao, Janice Shiu, Qianyu Zhao, Yide Xu, Xinlei Wang, Yuan Shen, Sheng Wang, Lisa Ainsworth, Kaiyu Guan, Shenlong Wang", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Learning 3D parametric shape models of objects has gained popularity in vision and graphics and has showed broad utility in 3D reconstruction, generation, understanding, and simulation. While powerful models exist for humans and animals, equally expressive approaches for modeling plants are lacking. In this work, we present Demeter, a data-driven parametric model that encodes key factors of a plant morphology, including topology, shape, articulation, and deformation into a compact learned representation. Unlike previous parametric models, Demeter handles varying shape topology across various species and models three sources of shape variation: articulation, subcomponent shape variation, and non-rigid deformation. To advance crop plant modeling, we collected a large-scale, ground-truthed dataset from a soybean farm as a testbed. Experiments show that Demeter effectively synthesizes shapes, reconstructs structures, and simulates biophysical processes. Code and data is available at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          MoReBench: Evaluating Procedural and Pluralistic Moral Reasoning in Language Models, More than Outcomes", "authors": "Yu Ying Chiu, Michael S. Lee, Rachel Calcott, Brandon Handoko, Paul de Font-Reaulx, Paula Rodriguez, Chen Bo Calvin Zhang, Ziwen Han, Udari Madhushani Sehwag, Yash Maurya, Christina Q Knight, Harry R. Lloyd, Florence Bacus, Mantas Mazeika, Bing Liu, Yejin Choi, Mitchell L Gordon, Sydney Levine", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)", "abstract": "As AI systems progress, we rely more on them to make decisions with us and for us. To ensure that such decisions are aligned with human values, it is imperative for us to understand not only what decisions they make but also how they come to those decisions. Reasoning language models, which provide both final responses and (partially transparent) intermediate thinking traces, present a timely opportunity to study AI procedural reasoning. Unlike math and code problems which often have objectively correct answers, moral dilemmas are an excellent testbed for process-focused evaluation because they allow for multiple defensible conclusions. To do so, we present MoReBench: 1,000 moral scenarios, each paired with a set of rubric criteria that experts consider essential to include (or avoid) when reasoning about the scenarios. MoReBench contains over 23 thousand criteria including identifying moral considerations, weighing trade-offs, and giving actionable recommendations to cover cases on AI advising humans moral decisions as well as making moral decisions autonomously. Separately, we curate MoReBench-Theory: 150 examples to test whether AI can reason under five major frameworks in normative ethics. Our results show that scaling laws and existing benchmarks on math, code, and scientific reasoning tasks fail to predict models' abilities to perform moral reasoning. Models also show partiality towards specific moral frameworks (e.g., Benthamite Act Utilitarianism and Kantian Deontology), which might be side effects of popular training paradigms. Together, these benchmarks advance process-focused reasoning evaluation towards safer and more transparent AI."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          ATA: A Neuro-Symbolic Approach to Implement Autonomous and Trustworthy Agents", "authors": "David Peer, Sebastian Stabinger", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities, yet their deployment in high-stakes domains is hindered by inherent limitations in trustworthiness, including hallucinations, instability, and a lack of transparency. To address these challenges, we introduce a generic neuro-symbolic approach, which we call Autonomous Trustworthy Agents (ATA). The core of our approach lies in decoupling tasks into two distinct phases: Offline knowledge ingestion and online task processing. During knowledge ingestion, an LLM translates an informal problem specification into a formal, symbolic knowledge base. This formal representation is crucial as it can be verified and refined by human experts, ensuring its correctness and alignment with domain requirements. In the subsequent task processing phase, each incoming input is encoded into the same formal language. A symbolic decision engine then utilizes this encoded input in conjunction with the formal knowledge base to derive a reliable result. Through an extensive evaluation on a complex reasoning task, we demonstrate that a concrete implementation of ATA is competitive with state-of-the-art end-to-end reasoning models in a fully automated setup while maintaining trustworthiness. Crucially, with a human-verified and corrected knowledge base, our approach significantly outperforms even larger models, while exhibiting perfect determinism, enhanced stability against input perturbations, and inherent immunity to prompt injection attacks. By generating decisions grounded in symbolic reasoning, ATA offers a practical and controllable architecture for building the next generation of transparent, auditable, and reliable autonomous agents."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Humanoid-inspired Causal Representation Learning for Domain Generalization", "authors": "Ze Tao, Jian Zhang, Haowei Li, Xianshuai Li, Yifei Peng, Xiyao Liu, Senzhang Wang, Chao Liu, Sheng Ren, Shichao Zhang", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "abstract": "This paper proposes the Humanoid-inspired Structural Causal Model (HSCM), a novel causal framework inspired by human intelligence, designed to overcome the limitations of conventional domain generalization models. Unlike approaches that rely on statistics to capture data-label dependencies and learn distortion-invariant representations, HSCM replicates the hierarchical processing and multi-level learning of human vision systems, focusing on modeling fine-grained causal mechanisms. By disentangling and reweighting key image attributes such as color, texture, and shape, HSCM enhances generalization across diverse domains, ensuring robust performance and interpretability. Leveraging the flexibility and adaptability of human intelligence, our approach enables more effective transfer and learning in dynamic, complex environments. Through both theoretical and empirical evaluations, we demonstrate that HSCM outperforms existing domain generalization models, providing a more principled method for capturing causal relationships and improving model robustness. The code is available at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          SemOpt: LLM-Driven Code Optimization via Rule-Based Analysis", "authors": "Yuwei Zhao, Yuan-An Xiao, Qianyu Xiao, Zhao Zhang, Yingfei Xiong", "subjects": "Software Engineering (cs.SE)", "abstract": "Automated code optimization aims to improve performance in programs by refactoring code, and recent studies focus on utilizing LLMs for the optimization. Typical existing approaches mine optimization commits from open-source codebases to construct a large-scale knowledge base, then employ information retrieval techniques such as BM25 to retrieve relevant optimization examples for hotspot code locations, thereby guiding LLMs to optimize these hotspots. However, since semantically equivalent optimizations can manifest in syntactically dissimilar code snippets, current retrieval methods often fail to identify pertinent examples, leading to suboptimal optimization performance. This limitation significantly reduces the effectiveness of existing optimization approaches. To address these limitations, we propose SemOpt, a novel framework that leverages static program analysis to precisely identify optimizable code segments, retrieve the corresponding optimization strategies, and generate the optimized results. SemOpt consists of three key components: (1) A strategy library builder that extracts and clusters optimization strategies from real-world code modifications. (2) A rule generator that generates Semgrep static analysis rules to capture the condition of applying the optimization strategy. (3) An optimizer that utilizes the strategy library to generate optimized code results. All the three components are powered by LLMs. On our benchmark containing 151 optimization tasks, SemOpt demonstrates its effectiveness under different LLMs by increasing the number of successful optimizations by 1.38 to 28 times compared to the baseline. Moreover, on popular large-scale C/C++ projects, it can improve individual performance metrics by 5.04% to 218.07%, demonstrating its practical utility."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          The Strongly Stable Roommates Problem and Linear Programming", "authors": "Naoyuki Kamiyama", "subjects": "Computer Science and Game Theory (cs.GT)", "abstract": "The stable roommates problem is a non-bipartite version of the stable matching problem in a bipartite graph. In this paper, we consider the stable roommates problem with ties. In particular, we focus on strong stability, which is one of the main stability concepts in the stable roommates problem with ties. We propose a new polynomial-time algorithm for the problem of checking the existence of a strongly stable matching in the stable roommates problem with ties. More concretely, we extend the linear programming approach of Abeledo and Blum to the stable roommates problem with strict preferences to our problem."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Population-Based Search Method Using Uncertainty-related Pareto Front for Robust Multi-objective Optimization", "authors": "Lihong Xu, Wenxiang Jiang", "subjects": "Computational Engineering, Finance, and Science (cs.CE)", "abstract": "Traditional robust multi-objective optimization methods typically prioritize convergence while treating robustness as a secondary consideration. This approach can yield solutions that are not genuinely robust optimal under noise-affected scenarios. Furthermore, compared to population-based search methods, determining the robust optimal solution by evaluating the robustness of a single convergence-optimal solution is also inefficient. To address these two limitations,we propose a novel Uncertainty-related Pareto Front (UPF) framework that balances robustness and convergence as equal priorities. Unlike traditional Pareto Front, the UPF explicitly accounts for decision variable with noise perturbation by quantifying their effects on both convergence guarantees and robustness preservation equally within a theoretically grounded and general framework. Building upon UPF, we propose RMOEA-UPF--a population-based search robust multi-objective optimization algorithm. This method enables efficient search optimization by calculating and optimizing the UPF during the evolutionary this http URL on nine benchmark problems and a real-world application demonstrate that RMOEA-UPF consistently delivers high-quality results. Our method's consistent top-ranking performance indicates a more general and reliable approach for solving complex, uncertain multi-objective optimization problems. Code is available at: this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Probing the Hidden Talent of ASR Foundation Models for L2 English Oral Assessment", "authors": "Fu-An Chao, Bi-Cheng Yan, Berlin Chen", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Sound (cs.SD); Audio and Speech Processing (eess.AS)", "abstract": "In this paper, we explore the untapped potential of Whisper, a well-established automatic speech recognition (ASR) foundation model, in the context of L2 spoken language assessment (SLA). Unlike prior studies that extrinsically analyze transcriptions produced by Whisper, our approach goes a step further to probe its latent capabilities by extracting acoustic and linguistic features from hidden representations. With only a lightweight classifier being trained on top of Whisper's intermediate and final outputs, our method achieves strong performance on the GEPT picture-description dataset, outperforming existing cutting-edge baselines, including a multimodal approach. Furthermore, by incorporating image and text-prompt information as auxiliary relevance cues, we demonstrate additional performance gains. Finally, we conduct an in-depth analysis of Whisper's embeddings, which reveals that, even without task-specific fine-tuning, the model intrinsically encodes both ordinal proficiency patterns and semantic aspects of speech, highlighting its potential as a powerful foundation for SLA and other spoken language understanding tasks."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Unified Peripartum Database with Natural-Language-to-SQL Capabilities at Udine University Hospital: Design and Prototype", "authors": "Doriana Armenise, Ginevra Battello, Andrea Brunello, Lorenza Driul, Angelo Montanari, Elisa Rizzante, Nicola Saccomanno, Andrea Salvador, Serena Xodo, Silvia Zermano", "subjects": "Databases (cs.DB)", "abstract": "The fragmentation of obstetric information across electronic health record modules, device repositories, and laboratory systems, as it is common in hospitals, hinders both intrapartum care and reproducible research. In this work, we present a practical blueprint for transforming heterogeneous peripartum records into computable, queryable assets by designing and prototyping a unified peripartum relational database with natural-language-to-SQL (NL2SQL) capabilities at the Obstetrics Clinic of Udine University Hospital. Requirements were co-defined with clinicians and formalized as an Entity-Relationship diagram, from which the logical schema and SQL implementation of the database were then derived. The latter integrates heterogeneous sources to connect maternal anamnestic and longitudinal history, current-pregnancy findings, intrapartum course, and delivery and neonatal outcomes. The NL2SQL layer enables clinicians to pose natural-language queries to the system, lowering barriers to audit and exploratory analysis."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          RGMem: Renormalization Group-based Memory Evolution for Language Agent User Profile", "authors": "Ao Tian, Yunfeng Lu, Xinxin Fan, Changhao Wang, Lanzhi Zhou, Yeyao Zhang, Yanfang Liu", "subjects": "Artificial Intelligence (cs.AI)", "abstract": "Personalized and continuous interactions are the key to enhancing user experience in today's large language model (LLM)-based conversational systems, however, the finite context windows and static parametric memory make it difficult to model the cross-session long-term user states and behavioral consistency. Currently, the existing solutions to this predicament, such as retrieval-augmented generation (RAG) and explicit memory systems, primarily focus on fact-level storage and retrieval, lacking the capability to distill latent preferences and deep traits from the multi-turn dialogues, which limits the long-term and effective user modeling, directly leading to the personalized interactions remaining shallow, and hindering the cross-session continuity. To realize the long-term memory and behavioral consistency for Language Agents in LLM era, we propose a self-evolving memory framework RGMem, inspired by the ideology of classic renormalization group (RG) in physics, this framework enables to organize the dialogue history in multiple scales: it first extracts semantics and user insights from episodic fragments, then through hierarchical coarse-graining and rescaling operations, progressively forms a dynamically-evolved user profile. The core innovation of our work lies in modeling memory evolution as a multi-scale process of information compression and emergence, which accomplishes the high-level and accurate user profiles from noisy and microscopic-level interactions."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Blending Learning to Rank and Dense Representations for Efficient and Effective Cascades", "authors": "Franco Maria Nardini, Raffaele Perego, Nicola Tonellotto, Salvatore Trani", "subjects": "Information Retrieval (cs.IR); Machine Learning (cs.LG); Performance (cs.PF)", "abstract": "We investigate the exploitation of both lexical and neural relevance signals for ad-hoc passage retrieval. Our exploration involves a large-scale training dataset in which dense neural representations of MS-MARCO queries and passages are complemented and integrated with 253 hand-crafted lexical features extracted from the same corpus. Blending of the relevance signals from the two different groups of features is learned by a classical Learning-to-Rank (LTR) model based on a forest of decision trees. To evaluate our solution, we employ a pipelined architecture where a dense neural retriever serves as the first stage and performs a nearest-neighbor search over the neural representations of the documents. Our LTR model acts instead as the second stage that re-ranks the set of candidates retrieved by the first stage to enhance effectiveness. The results of reproducible experiments conducted with state-of-the-art dense retrievers on publicly available resources show that the proposed solution significantly enhances the end-to-end ranking performance while relatively minimally impacting efficiency. Specifically, we achieve a boost in nDCG@10 of up to 11% with an increase in average query latency of only 4.3%. This confirms the advantage of seamlessly combining two distinct families of signals that mutually contribute to retrieval effectiveness."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Code Digital Twin: Empowering LLMs with Tacit Knowledge for Complex Software Development", "authors": "Xin Peng, Chong Wang", "subjects": "Software Engineering (cs.SE)", "abstract": "Recent advances in large language models (LLMs) have demonstrated strong capabilities in software engineering tasks, raising expectations of revolutionary productivity gains. However, enterprise software development is largely driven by incremental evolution, where challenges extend far beyond routine coding and depend critically on tacit knowledge, including design decisions at different levels and historical trade-offs. To achieve effective AI-powered support for complex software development, we should align emerging AI capabilities with the practical realities of enterprise development. To this end, we systematically identify challenges from both software and LLM perspectives. Alongside these challenges, we outline opportunities where AI and structured knowledge frameworks can enhance decision-making in tasks such as issue localization and impact analysis. To address these needs, we propose the Code Digital Twin, a living framework that models both the physical and conceptual layers of software, preserves tacit knowledge, and co-evolves with the codebase. By integrating hybrid knowledge representations, multi-stage extraction pipelines, incremental updates, LLM-empowered applications, and human-in-the-loop feedback, the Code Digital Twin transforms fragmented knowledge into explicit and actionable representations. Our vision positions it as a bridge between AI advancements and enterprise software realities, providing a concrete roadmap toward sustainable, intelligent, and resilient development and evolution of ultra-complex systems."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          SPLite Hand: Sparsity-Aware Lightweight 3D Hand Pose Estimation", "authors": "Yeh Keng Hao, Hsu Tzu Wei, Sun Min", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "abstract": "With the increasing ubiquity of AR/VR devices, the deployment of deep learning models on edge devices has become a critical challenge. These devices require real-time inference, low power consumption, and minimal latency. Many framework designers face the conundrum of balancing efficiency and performance. We design a light framework that adopts an encoder-decoder architecture and introduces several key contributions aimed at improving both efficiency and accuracy. We apply sparse convolution on a ResNet-18 backbone to exploit the inherent sparsity in hand pose images, achieving a 42% end-to-end efficiency improvement. Moreover, we propose our SPLite decoder. This new architecture significantly boosts the decoding process's frame rate by 3.1x on the Raspberry Pi 5, while maintaining accuracy on par. To further optimize performance, we apply quantization-aware training, reducing memory usage while preserving accuracy (PA-MPJPE increases only marginally from 9.0 mm to 9.1 mm on FreiHAND). Overall, our system achieves a 2.98x speed-up on a Raspberry Pi 5 CPU (BCM2712 quad-core Arm A76 processor). Our method is also evaluated on compound benchmark datasets, demonstrating comparable accuracy to state-of-the-art approaches while significantly enhancing computational efficiency."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Six Proofs of Interpolation for the Modal Logic K", "authors": "Nick Bezhanishvili, Balder ten Cate, Rosalie Iemhoff", "subjects": "Logic in Computer Science (cs.LO)", "abstract": "In this chapter, we present six different proofs of Craig interpolation for the modal logic K, each using a different set of techniques (model-theoretic, proof-theoretic, syntactic, automata-theoretic, using quasi-models, and algebraic). We compare the pros and cons of each proof technique."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Iterative solvers for partial differential equations with dissipative structure: Operator preconditioning and optimal control", "authors": "Volker Mehrmann, Manuel Schaller, Martin Stoll", "subjects": "Numerical Analysis (math.NA); Systems and Control (eess.SY); Optimization and Control (math.OC)", "abstract": "This work considers the iterative solution of large-scale problems subject to non-symmetric matrices or operators arising in discretizations of (port-)Hamiltonian partial differential equations. We consider problems governed by an operator $\\mathcal{A}=\\mathcal{H}+\\mathcal{S}$ with symmetric part $\\mathcal{H}$ that is positive (semi-)definite and skew-symmetric part $\\mathcal{S}$. Prior work has shown that the structure and sparsity of the associated linear system enables Krylov subspace solvers such as the generalized minimal residual method (GMRES) or short recurrence variants such as Widlund's or Rapoport's method using the symmetric part $\\mathcal{H}$, or an approximation of it, as preconditioner. In this work, we analyze the resulting condition numbers, which are crucial for fast convergence of these methods, for various partial differential equations (PDEs) arising in diffusion phenomena, fluid dynamics, and elasticity. We show that preconditioning with the symmetric part leads to a condition number uniform in the mesh size in case of elliptic and parabolic PDEs where $\\mathcal{H}^{-1}\\mathcal{S}$ is a bounded operator. Further, we employ the tailored Krylov subspace methods in optimal control by means of a condensing approach and a constraint preconditioner for the optimality system. We illustrate the results by various large-scale numerical examples and discuss efficient evaluations of the preconditioner, such as incomplete Cholesky factorization or the algebraic multigrid method."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Explainability Requirements as Hyperproperties", "authors": "Bernd Finkbeiner, Julian Siber", "subjects": "Logic in Computer Science (cs.LO)", "abstract": "Explainability is emerging as a key requirement for autonomous systems. While many works have focused on what constitutes a valid explanation, few have considered formalizing explainability as a system property. In this work, we approach this problem from the perspective of hyperproperties. We start with a combination of three prominent flavors of modal logic and show how they can be used for specifying and verifying counterfactual explainability in multi-agent systems: With Lewis' counterfactuals, linear-time temporal logic, and a knowledge modality, we can reason about whether agents know why a specific observation occurs, i.e., whether that observation is explainable to them. We use this logic to formalize multiple notions of explainability on the system level. We then show how this logic can be embedded into a hyperlogic. Notably, from this analysis we conclude that the model-checking problem of our logic is decidable, which paves the way for the automated verification of explainability requirements."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Applications of optimal error bounds for some generalized two-step iterative processes in Banach spaces", "authors": "Tan-Phuc Nguyen, Thai-Hung Nguyen, Tien-Khai Nguyen, Cong-Duy-Nguyen Nguyen, Trung-Hieu Huynh", "subjects": "Numerical Analysis (math.NA)", "abstract": "In a recent paper~\\cite{paper2}, we proposed the concept of optimal error bounds for an iterative process, which allows us to obtain the convergence result of the iterative sequence to the common fixed point of the nonexpansive mappings in Banach spaces. Moreover, we also achieve the comparison results between different iterative processes via optimal error bounds. In this paper, we continue to determine optimal error bounds for more general iterative processes which were studied by many authors, such as in~\\cite{DungHieu} and references therein. From there, the convergence results are obtained and the convergence rates of these iterative processes are determined under some sufficient conditions on sequences of parameters."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Parameter-related strong convergence rate and polynomial stability of a Euler's type method for time-changed stochastic differential equations", "authors": "Ruchun Zuo", "subjects": "Numerical Analysis (math.NA); Probability (math.PR)", "abstract": "A Euler's type method with the equidistant step size is proposed for a class of time-changed stochastic differential equations driven by the multiplicative noise and the strong convergence rate that is related to the parameter of the time changing process is obtained. Such a observation of the convergence rate is significantly different from those existing results that employ methods with the random step size. The polynomial stability in the mean square sense of the numerical method is also studied, which is in line with the asymptotic behavior of the underlying equation."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Call-Center Staff Scheduling Considering Performance Evolution under Emotional Stress", "authors": "Yujun Zheng, Xinya Chen, Xueqin Lu, Weiguo Sheng, Shengyong Chen", "subjects": "Neural and Evolutionary Computing (cs.NE)", "abstract": "Emotional stress often has a significant effect on the working performance of staff, but this effect is commonly neglected in existing staff scheduling methods. We study a call-center staff scheduling problem, which considers the evolution of work performance of staff under emotional stress. First, we present an emotional stress driven model that estimates the working performance of call-center employees based on not only skill levels but also emotional states. On the basis of the model, we formulate a combined short-term and long-term call-center staff scheduling problem aiming at maximizing the customer service level, which depends on the working performance of employees. We then propose a memetic optimization algorithm combining global mutation and neighborhood search assisted by deep reinforcement learning to efficiently solve this problem. Experimental results on real-world problem instances of bank call-center staff scheduling demonstrate the performance advantages of the proposed method over selected popular staff scheduling methods. By explicitly modeling and incorporating emotional stress, our method reflects a more realistic understanding and utilization of human behavior in staff scheduling."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Institute Disambiguation using Author-Institution Co-Occurrence", "authors": "Achal Agrawal, Jeet Mukherjee", "subjects": "Digital Libraries (cs.DL)", "abstract": "In this article we propose a novel method to perform unsupervised clustering of different forms of Institute names. We use only author and affiliation metadata to perform the clustering without any string or pattern matching. After analysing only 50000 articles from Crossref database, we see encouraging results which can be scaled up to provide even better results. We compare our clustering with what a well-known method using string matching does and found that the results were complementary. This can help perform institute disambiguation better when integrated with existing systems, especially to provide aliases for cases where traditional string matching fails. The code of this open-source methodology can be found at: this https URL"}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Real-time Measurement-based Optimization for Distribution System Operation Considering Battery Voltage and Thermal Constraints", "authors": "Sen Zhan, Lingkang Jin, Haoyang Zhang, Nikolaos G. Paterakis", "subjects": "Systems and Control (eess.SY)", "abstract": "The secure operation of power distribution systems is challenged by the growing integration of distributed energy resources. Leveraging the flexibility of battery storage offers a cost-effective alternative to measures like generation curtailment, which results in energy losses. However, developing an effective operational model for battery storage is hindered by inaccurate grid models, unavailability of load data, nonlinear relationship between power injections and network states, intertemporal constraints, and complex electrochemical and thermal dynamics. To address these challenges, this paper proposes a data-driven operational control scheme for battery storage in distribution systems. Linear and convex quadratic operational constraints are constructed based on real-time distribution system and battery storage measurements. Lyapunov optimization decouples multi-period battery operation, enabling a real-time, forecast-free control strategy with low computational complexity. Numerical studies using nonlinear distribution system and battery storage simulators validate the effectiveness of the approach in ensuring secure distribution system operation and satisfaction of voltage and thermal constraints of battery storage."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          REALM: An MLLM-Agent Framework for Open World 3D Reasoning Segmentation and Editing on Gaussian Splatting", "authors": "Changyue Shi, Minghao Chen, Yiping Mao, Chuxiao Yang, Xinyuan Hu, Jiajun Ding, Zhou Yu", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Bridging the gap between complex human instructions and precise 3D object grounding remains a significant challenge in vision and robotics. Existing 3D segmentation methods often struggle to interpret ambiguous, reasoning-based instructions, while 2D vision-language models that excel at such reasoning lack intrinsic 3D spatial understanding. In this paper, we introduce REALM, an innovative MLLM-agent framework that enables open-world reasoning-based segmentation without requiring extensive 3D-specific post-training. We perform segmentation directly on 3D Gaussian Splatting representations, capitalizing on their ability to render photorealistic novel views that are highly suitable for MLLM comprehension. As directly feeding one or more rendered views to the MLLM can lead to high sensitivity to viewpoint selection, we propose a novel Global-to-Local Spatial Grounding strategy. Specifically, multiple global views are first fed into the MLLM agent in parallel for coarse-level localization, aggregating responses to robustly identify the target object. Then, several close-up novel views of the object are synthesized to perform fine-grained local segmentation, yielding accurate and consistent 3D masks. Extensive experiments show that REALM achieves remarkable performance in interpreting both explicit and implicit instructions across LERF, 3D-OVS, and our newly introduced REALM3D benchmarks. Furthermore, our agent framework seamlessly supports a range of 3D interaction tasks, including object removal, replacement, and style transfer, demonstrating its practical utility and versatility. Project page: this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Modeling Expert Interactions in Sparse Mixture of Experts via Graph Structures", "authors": "Minh-Khoi Nguyen-Nhat, Rachel S.Y. Teo, Laziz Abdullaev, Maurice Mok, Viet-Hoang Tran, Tan Minh Nguyen", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "Sparse Mixture of Experts (SMoE) has emerged as a promising solution to achieving unparalleled scalability in deep learning by decoupling model parameter count from computational cost. By activating only a small subset of parameters per sample, SMoE enables significant growth in model capacity while maintaining efficiency. However, SMoE struggles to adapt to distributional shifts, leading to reduced robustness under data contamination. In this work, we introduce SymphonySMoE, a novel family of SMoE that introduces a social graph to model interactions among experts. This graph-based structure enhances the token routing process, addressing the robustness challenges that are inherent in conventional SMoE designs. SymphonySMoE is lightweight, modular, and integrates seamlessly with existing SMoE-based models such as the XMoE and the Generalist Language Model. We provide both theoretical analysis and empirical evidence demonstrating SymphonySMoE's advantages over baseline SMoE. Extensive experiments on language modeling and visual instruction tuning validate our method's effectiveness. We further highlight the scalability of SymphonySMoE to models with 4.2 and 7.4 billion parameters, showcasing its applicability in fine-tuning tasks for large-scale systems."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          A multilayer level-set method for eikonal-based traveltime tomography", "authors": "Wenbin Li, Ken K.T. Hung, Shingyu Leung", "subjects": "Numerical Analysis (math.NA)", "abstract": "We present a novel multilayer level-set method (MLSM) for eikonal-based first-arrival traveltime tomography. Unlike classical level-set approaches that rely solely on the zero-level set, the MLSM represents multiple phases through a sequence of $i_n$-level sets ($n = 0, 1, 2, \\cdots$). Near each $i_n$-level set, the function is designed to behave like a local signed-distance function, enabling a single level-set formulation to capture arbitrarily many interfaces and subregions. Within this Eulerian framework, first-arrival traveltimes are computed as viscosity solutions of the eikonal equation, and Fr\u00e9chet derivatives of the misfit are obtained via the adjoint state method. To stabilize the inversion, we incorporate several regularization strategies, including multilayer reinitialization, arc-length penalization, and Sobolev smoothing of model parameters. In addition, we introduce an illumination-based error measure to assess reconstruction quality. Numerical experiments demonstrate that the proposed MLSM efficiently recovers complex discontinuous slowness models with multiple phases and interfaces."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          AoI-Aware Task Offloading and Transmission Optimization for Industrial IoT Networks: A Branching Deep Reinforcement Learning Approach", "authors": "Yuang Chen, Fengqian Guo, Chang Wu, Shuyi Liu, Hancheng Lu, Chang Wen Chen", "subjects": "Systems and Control (eess.SY); Machine Learning (cs.LG)", "abstract": "In the Industrial Internet of Things (IIoT), the frequent transmission of large amounts of data over wireless networks should meet the stringent timeliness requirements. Particularly, the freshness of packet status updates has a significant impact on the system performance. In this paper, we propose an age-of-information (AoI)-aware multi-base station (BS) real-time monitoring framework to support extensive IIoT deployments. To meet the freshness requirements of IIoT, we formulate a joint task offloading and resource allocation optimization problem with the goal of minimizing long-term average AoI. Tackling the core challenges of combinatorial explosion in multi-BS decision spaces and the stochastic dynamics of IIoT systems is crucial, as these factors render traditional optimization methods intractable. Firstly, an innovative branching-based Dueling Double Deep Q-Network (Branching-D3QN) algorithm is proposed to effectively implement task offloading, which optimizes the convergence performance by reducing the action space complexity from exponential to linear levels. Then, an efficient optimization solution to resource allocation is proposed by proving the semi-definite property of the Hessian matrix of bandwidth and computation resources. Finally, we propose an iterative optimization algorithm for efficient joint task offloading and resource allocation to achieve optimal average AoI performance. Extensive simulations demonstrate that our proposed Branching-D3QN algorithm outperforms both state-of-the-art DRL methods and classical heuristics, achieving up to a 75% enhanced convergence speed and at least a 22% reduction in the long-term average AoI."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          MeCeFO: Enhancing LLM Training Robustness via Fault-Tolerant Optimization", "authors": "Rizhen Hu, Yutong He, Ran Yan, Mou Sun, Binghang Yuan, Kun Yuan", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "abstract": "As distributed optimization scales to meet the demands of Large Language Model (LLM) training, hardware failures become increasingly non-negligible. Existing fault-tolerant training methods often introduce significant computational or memory overhead, demanding additional resources. To address this challenge, we propose Memory- and Computation-efficient Fault-tolerant Optimization (MeCeFO), a novel algorithm that ensures robust training with minimal overhead. When a computing node fails, MeCeFO seamlessly transfers its training task to a neighboring node while employing memory- and computation-efficient algorithmic optimizations to minimize the extra workload imposed on the neighboring node handling both tasks. MeCeFO leverages three key algorithmic designs: (i) Skip-connection, which drops the multi-head attention (MHA) module during backpropagation for memory- and computation-efficient approximation; (ii) Recomputation, which reduces activation memory in feedforward networks (FFNs); and (iii) Low-rank gradient approximation, enabling efficient estimation of FFN weight matrix gradients. Theoretically, MeCeFO matches the convergence rate of conventional distributed training, with a rate of $\\mathcal{O}(1/\\sqrt{nT})$, where n is the data parallelism size and T is the number of iterations. Empirically, MeCeFO maintains robust performance under high failure rates, incurring only a 4.18% drop in throughput, demonstrating 5.0$\\times$ to 6.7$\\times$ greater resilience than previous SOTA approaches. Codes are available at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          SSL4RL: Revisiting Self-supervised Learning as Intrinsic Reward for Visual-Language Reasoning", "authors": "Xiaojun Guo, Runyu Zhou, Yifei Wang, Qi Zhang, Chenheng Zhang, Stefanie Jegelka, Xiaohan Wang, Jiajun Chai, Guojun Yin, Wei Lin, Yisen Wang", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "abstract": "Vision-language models (VLMs) have shown remarkable abilities by integrating large language models with visual inputs. However, they often fail to utilize visual evidence adequately, either depending on linguistic priors in vision-centric tasks or resorting to textual shortcuts during reasoning. Although reinforcement learning (RL) can align models with desired behaviors, its application to VLMs has been hindered by the lack of scalable and reliable reward mechanisms. To overcome this challenge, we propose SSL4RL, a novel framework that leverages self-supervised learning (SSL) tasks as a source of verifiable rewards for RL-based fine-tuning. Our approach reformulates SSL objectives-such as predicting image rotation or reconstructing masked patches-into dense, automatic reward signals, eliminating the need for human preference data or unreliable AI evaluators. Experiments show that SSL4RL substantially improves performance on both vision-centric and vision-language reasoning benchmarks. Furthermore, through systematic ablations, we identify key factors-such as task difficulty, model scale, and semantic alignment with the target domain-that influence the effectiveness of SSL4RL tasks, offering new design principles for future work. We also demonstrate the framework's generality by applying it to graph learning, where it yields significant gains. SSL4RL establishes a versatile and effective paradigm for aligning multimodal models using verifiable, self-supervised objectives."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          FourierCompress: Layer-Aware Spectral Activation Compression for Efficient and Accurate Collaborative LLM Inference", "authors": "Jian Ma, Xinchen Lyu, Jun Jiang, Longhao Zou, Chenshan Ren, Qimei Cui, Xiaofeng Tao", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "abstract": "Collaborative large language model (LLM) inference enables real-time, privacy-preserving AI services on resource-constrained edge devices by partitioning computational workloads between client devices and edge servers. However, this paradigm is severely hindered by communication bottlenecks caused by the transmission of high-dimensional intermediate activations, exacerbated by the autoregressive decoding structure of LLMs, where bandwidth consumption scales linearly with output length. Existing activation compression methods struggle to simultaneously achieve high compression ratios, low reconstruction error, and computational efficiency. This paper proposes FourierCompress, a novel, layer-aware activation compression framework that exploits the frequency-domain sparsity of LLM activations. We rigorously demonstrate that activations from the first Transformer layer exhibit strong smoothness and energy concentration in the low-frequency domain, making them highly amenable to near-lossless compression via the Fast Fourier Transform (FFT). FourierCompress transforms activations into the frequency domain, retains only a compact block of low-frequency coefficients, and reconstructs the signal at the server using conjugate symmetry, enabling seamless hardware acceleration on DSPs and FPGAs. Extensive experiments on Llama 3 and Qwen2.5 models across 10 commonsense reasoning datasets demonstrate that FourierCompress preserves performance remarkably close to the uncompressed baseline, outperforming Top-k, QR, and SVD. FourierCompress bridges the gap between communication efficiency (an average 7.6x reduction in activation size), near-lossless inference (less than 0.3% average accuracy loss), and significantly faster compression (achieving over 32x reduction in compression time compared to Top-k via hardware acceleration) for edge-device LLM inference."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Learning to Optimize Edge Robotics: A Fast Integrated Perception-Motion-Communication Approach", "authors": "Dan Guo, Xibin Jin, Shuai Wang, Zhigang Wen, Miaowen Wen, Chengzhong Xu", "subjects": "Robotics (cs.RO)", "abstract": "Edge robotics involves frequent exchanges of large-volume multi-modal data. Existing methods ignore the interdependency between robotic functionalities and communication conditions, leading to excessive communication overhead. This paper revolutionizes edge robotics systems through integrated perception, motion, and communication (IPMC). As such, robots can dynamically adapt their communication strategies (i.e., compression ratio, transmission frequency, transmit power) by leveraging the knowledge of robotic perception and motion dynamics, thus reducing the need for excessive sensor data uploads. Furthermore, by leveraging the learning to optimize (LTO) paradigm, an imitation learning neural network is designed and implemented, which reduces the computational complexity by over 10x compared to state-of-the art optimization solvers. Experiments demonstrate the superiority of the proposed IPMC and the real-time execution capability of LTO."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Determining the space dependent coefficients in space-time fractional diffusion equations via Krylov preconditioning", "authors": "Asim Ilyas, Muhammad Faisal Khan, Rosita L. Sormani, Giacomo Tento, Stefano Serra-Capizzano", "subjects": "Numerical Analysis (math.NA)", "abstract": "We consider a time-space fractional diffusion equation with a variable coefficient and investigate the inverse problem of reconstructing the source term, after regularizing the problem with the quasiboundary value method to mitigate the ill-posedness. The equation involves a Caputo fractional derivative in the space variable and a tempered fractional derivative in the time variable, both of order in (0, 1). A finite difference approximation leads to a two-by-two block linear system of large dimensions. We conduct a spectral analysis of the associated matrix sequences, employing tools from Generalized Locally Toeplitz (GLT) theory, and construct the preconditioner guided by the GLT analysis. Numerical experiments are reported and commented, followed by concluding remarks."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Cluster-wise processing in fronthaul-aware cell-free massive MIMO systems", "authors": "Zahra Mobini, Ahmet Hasim Gokceoglu, Li Wang, Gunnar Peters, Hyundong Shin, Hien Quoc Ngo", "subjects": "Information Theory (cs.IT)", "abstract": "We exploit a general cluster-based network architecture for a fronthaul-limited user-centric cell-free massive multiple-input multiple-output (CF-mMIMO) system under different degrees of cooperation among the access points (APs) to achieve scalable implementation. In particular, we consider a CF-mMIMO system wherein the available APs are grouped into multiple processing clusters (PCs) to share channel state information (CSI), ensuring that they have knowledge of the CSI for all users assigned to the given cluster for the purposes of designing resource allocation and precoding. We utilize the sum pseudo-SE metric, which accounts for intra-cluster interference and intercluster-leakage, providing a close approximation to the true sum achievable SE. For a given PC, we formulate two optimization problems to maximize the cluster-wise weighted sum pseudo-SE under fronthaul constraints, relying solely on local CSI. These optimization problems are associated with different computational complexity requirements. The first optimization problem jointly designs precoding, user association, and power allocation, and is performed at the small-scale fading time scale. The second optimization problem optimizes user association and power allocation at the large-scale fading time scale. Accordingly, we develop a novel application of modified weighted minimum mean square error (WMMSE)-based approach to solve the challenging formulated non-convex mixed-integer problems."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Large-Scale Empirical Analysis of Continuous Fuzzing: Insights from 1 Million Fuzzing Sessions", "authors": "Tatsuya Shirai, Olivier Nourry, Yutaro Kashiwa, Kenji Fujiwara, Yasutaka Kamei, Hajimu Iida", "subjects": "Software Engineering (cs.SE)", "abstract": "Software vulnerabilities are constantly being reported and exploited in software products, causing significant impacts on society. In recent years, the main approach to vulnerability detection, fuzzing, has been integrated into the continuous integration process to run in short and frequent cycles. This continuous fuzzing allows for fast identification and remediation of vulnerabilities during the development process. Despite adoption by thousands of projects, however, it is unclear how continuous fuzzing contributes to vulnerability detection. This study aims to elucidate the role of continuous fuzzing in vulnerability detection. Specifically, we investigate the coverage and the total number of fuzzing sessions when fuzzing bugs are discovered. We collect issue reports, coverage reports, and fuzzing logs from OSS-Fuzz, an online service provided by Google that performs fuzzing during continuous integration. Through an empirical study of a total of approximately 1.12 million fuzzing sessions from 878 projects participating in OSS-Fuzz, we reveal that (i) a substantial number of fuzzing bugs exist prior to the integration of continuous fuzzing, leading to a high detection rate in the early stages; (ii) code coverage continues to increase as continuous fuzzing progresses; and (iii) changes in coverage contribute to the detection of fuzzing bugs. This study provides empirical insights into how continuous fuzzing contributes to fuzzing bug detection, offering practical implications for future strategies and tool development in continuous fuzzing."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          What Questions Should Robots Be Able to Answer? A Dataset of User Questions for Explainable Robotics", "authors": "Lennart Wachowiak, Andrew Coles, Gerard Canal, Oya Celiktutan", "subjects": "Robotics (cs.RO); Computation and Language (cs.CL); Human-Computer Interaction (cs.HC)", "abstract": "With the growing use of large language models and conversational interfaces in human-robot interaction, robots' ability to answer user questions is more important than ever. We therefore introduce a dataset of 1,893 user questions for household robots, collected from 100 participants and organized into 12 categories and 70 subcategories. Most work in explainable robotics focuses on why-questions. In contrast, our dataset provides a wide variety of questions, from questions about simple execution details to questions about how the robot would act in hypothetical scenarios -- thus giving roboticists valuable insights into what questions their robot needs to be able to answer. To collect the dataset, we created 15 video stimuli and 7 text stimuli, depicting robots performing varied household tasks. We then asked participants on Prolific what questions they would want to ask the robot in each portrayed situation. In the final dataset, the most frequent categories are questions about task execution details (22.5%), the robot's capabilities (12.7%), and performance assessments (11.3%). Although questions about how robots would handle potentially difficult scenarios and ensure correct behavior are less frequent, users rank them as the most important for robots to be able to answer. Moreover, we find that users who identify as novices in robotics ask different questions than more experienced users. Novices are more likely to inquire about simple facts, such as what the robot did or the current state of the environment. As robots enter environments shared with humans and language becomes central to giving instructions and interaction, this dataset provides a valuable foundation for (i) identifying the information robots need to log and expose to conversational interfaces, (ii) benchmarking question-answering modules, and (iii) designing explanation strategies that align with user expectations."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          LightGlueStick: a Fast and Robust Glue for Joint Point-Line Matching", "authors": "Aidyn Ubingazhibov, R\u00e9mi Pautrat, Iago Su\u00e1rez, Shaohui Liu, Marc Pollefeys, Viktor Larsson", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Lines and points are complementary local features, whose combination has proven effective for applications such as SLAM and Structure-from-Motion. The backbone of these pipelines are the local feature matchers, establishing correspondences across images. Traditionally, point and line matching have been treated as independent tasks. Recently, GlueStick proposed a GNN-based network that simultaneously operates on points and lines to establish matches. While running a single joint matching reduced the overall computational complexity, the heavy architecture prevented real-time applications or deployment to edge devices. Inspired by recent progress in point matching, we propose LightGlueStick, a lightweight matcher for points and line segments. The key novel component in our architecture is the Attentional Line Message Passing (ALMP), which explicitly exposes the connectivity of the lines to the network, allowing for efficient communication between nodes. In thorough experiments we show that LightGlueStick establishes a new state-of-the-art across different benchmarks. The code is available at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          FrugalPrompt: Reducing Contextual Overhead in Large Language Models via Token Attribution", "authors": "Syed Rifat Raiyan, Md Farhan Ishmam, Abdullah Al Imran, Mohammad Ali Moni", "subjects": "Computation and Language (cs.CL)", "abstract": "Large language models (LLMs) owe much of their stellar performance to expansive input contexts, yet such verbosity inflates monetary costs, carbon footprint, and inference-time latency. Much of this overhead manifests from the redundant low-utility tokens present in typical prompts, as only a fraction of tokens typically carries the majority of the semantic weight. We address this inefficiency by introducing FrugalPrompt, a novel prompt compression framework for LLMs, which retains only the most semantically significant tokens. Leveraging two state-of-the-art token attribution methods, GlobEnc and DecompX, we assign salience scores to every token in an input sequence, rank them to preserve the top-k% tokens in their original order, and obtain a sparse frugalized prompt. We evaluate the approach across four NLP tasks: Sentiment Analysis, Commonsense QA, Summarization, and Mathematical Reasoning, using a suite of frontier LLMs. For the first three tasks, a 20% prompt reduction incurs only a marginal loss in task performance, demonstrating that contemporary LLMs can reconstruct elided context from high-salience cues. In contrast, performance on mathematical reasoning deteriorates sharply, reflecting a stronger dependence on complete token continuity. Further analysis with bottom-k% and random-k% tokens reveals asymmetric performance patterns that may suggest potential task contamination effects, wherein models may resort to shallow memorized patterns from pretraining exposure for conventional NLP tasks. We posit that our work contributes to a more nuanced understanding of LLM behavior in performance-efficiency trade-offs, and delineate the boundary between tasks tolerant to contextual sparsity and those requiring exhaustive context. Our source code and models are available at: this https URL"}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Colliding with Adversaries at ECML-PKDD 2025 Adversarial Attack Competition 1st Prize Solution", "authors": "Dimitris Stefanopoulos, Andreas Voskou", "subjects": "Machine Learning (cs.LG); Cryptography and Security (cs.CR)", "abstract": "This report presents the winning solution for Task 1 of Colliding with Adversaries: A Challenge on Robust Learning in High Energy Physics Discovery at ECML-PKDD 2025. The task required designing an adversarial attack against a provided classification model that maximizes misclassification while minimizing perturbations. Our approach employs a multi-round gradient-based strategy that leverages the differentiable structure of the model, augmented with random initialization and sample-mixing techniques to enhance effectiveness. The resulting attack achieved the best results in perturbation size and fooling success rate, securing first place in the competition."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          EDVD-LLaMA: Explainable Deepfake Video Detection via Multimodal Large Language Model Reasoning", "authors": "Haoran Sun, Chen Cai, Huiping Zhuang, Kong Aik Lee, Lap-Pui Chau, Yi Wang", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "abstract": "The rapid development of deepfake video technology has not only facilitated artistic creation but also made it easier to spread misinformation. Traditional deepfake video detection (DVD) methods face issues such as a lack of transparency in their principles and insufficient generalization capabilities to cope with evolving forgery techniques. This highlights an urgent need for detectors that can identify forged content and provide verifiable reasoning explanations. This paper proposes the explainable deepfake video detection (EDVD) task and designs the EDVD-LLaMA multimodal, a large language model (MLLM) reasoning framework, which provides traceable reasoning processes alongside accurate detection results and trustworthy explanations. Our approach first incorporates a Spatio-Temporal Subtle Information Tokenization (ST-SIT) to extract and fuse global and local cross-frame deepfake features, providing rich spatio-temporal semantic information input for MLLM reasoning. Second, we construct a Fine-grained Multimodal Chain-of-Thought (Fg-MCoT) mechanism, which introduces facial feature data as hard constraints during the reasoning process to achieve pixel-level spatio-temporal video localization, suppress hallucinated outputs, and enhance the reliability of the chain of thought. In addition, we build an Explainable Reasoning FF++ benchmark dataset (ER-FF++set), leveraging structured data to annotate videos and ensure quality control, thereby supporting dual supervision for reasoning and detection. Extensive experiments demonstrate that EDVD-LLaMA achieves outstanding performance and robustness in terms of detection accuracy, explainability, and its ability to handle cross-forgery methods and cross-dataset scenarios. Compared to previous DVD methods, it provides a more explainable and superior solution. The source code and dataset will be publicly available."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Colliding with Adversaries at ECML-PKDD 2025 Model Robustness Competition 1st Prize Solution", "authors": "Dimitris Stefanopoulos, Andreas Voskou", "subjects": "Machine Learning (cs.LG)", "abstract": "This report presents the winning solution for Task 2 of Colliding with Adversaries: A Challenge on Robust Learning in High Energy Physics Discovery at ECML-PKDD 2025. The goal of the challenge was to design and train a robust ANN-based model capable of achieving high accuracy in a binary classification task on both clean and adversarial data generated with the Random Distribution Shuffle Attack (RDSA). Our solution consists of two components: a data generation phase and a robust model training phase. In the first phase, we produced 15 million artificial training samples using a custom methodology derived from Random Distribution Shuffle Attack (RDSA). In the second phase, we introduced a robust architecture comprising (i)a Feature Embedding Block with shared weights among features of the same type and (ii)a Dense Fusion Tail responsible for the final prediction. Training this architecture on our adversarial dataset achieved a mixed accuracy score of 80\\%, exceeding the second-place solution by two percentage points."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          RefAtomNet++: Advancing Referring Atomic Video Action Recognition using Semantic Retrieval based Multi-Trajectory Mamba", "authors": "Kunyu Peng, Di Wen, Jia Fu, Jiamin Wu, Kailun Yang, Junwei Zheng, Ruiping Liu, Yufan Chen, Yuqian Fu, Danda Pani Paudel, Luc Van Gool, Rainer Stiefelhagen", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Multimedia (cs.MM); Robotics (cs.RO); Image and Video Processing (eess.IV)", "abstract": "Referring Atomic Video Action Recognition (RAVAR) aims to recognize fine-grained, atomic-level actions of a specific person of interest conditioned on natural language descriptions. Distinct from conventional action recognition and detection tasks, RAVAR emphasizes precise language-guided action understanding, which is particularly critical for interactive human action analysis in complex multi-person scenarios. In this work, we extend our previously introduced RefAVA dataset to RefAVA++, which comprises >2.9 million frames and >75.1k annotated persons in total. We benchmark this dataset using baselines from multiple related domains, including atomic action localization, video question answering, and text-video retrieval, as well as our earlier model, RefAtomNet. Although RefAtomNet surpasses other baselines by incorporating agent attention to highlight salient features, its ability to align and retrieve cross-modal information remains limited, leading to suboptimal performance in localizing the target person and predicting fine-grained actions. To overcome the aforementioned limitations, we introduce RefAtomNet++, a novel framework that advances cross-modal token aggregation through a multi-hierarchical semantic-aligned cross-attention mechanism combined with multi-trajectory Mamba modeling at the partial-keyword, scene-attribute, and holistic-sentence levels. In particular, scanning trajectories are constructed by dynamically selecting the nearest visual spatial tokens at each timestep for both partial-keyword and scene-attribute levels. Moreover, we design a multi-hierarchical semantic-aligned cross-attention strategy, enabling more effective aggregation of spatial and temporal tokens across different semantic hierarchies. Experiments show that RefAtomNet++ establishes new state-of-the-art results. The dataset and code are released at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Enhancing Rotated Object Detection via Anisotropic Gaussian Bounding Box and Bhattacharyya Distance", "authors": "Chien Thai, Mai Xuan Trang, Huong Ninh, Hoang Hiep Ly, Anh Son Le", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Detecting rotated objects accurately and efficiently is a significant challenge in computer vision, particularly in applications such as aerial imagery, remote sensing, and autonomous driving. Although traditional object detection frameworks are effective for axis-aligned objects, they often underperform in scenarios involving rotated objects due to their limitations in capturing orientation variations. This paper introduces an improved loss function aimed at enhancing detection accuracy and robustness by leveraging the Gaussian bounding box representation and Bhattacharyya distance. In addition, we advocate for the use of an anisotropic Gaussian representation to address the issues associated with isotropic variance in square-like objects. Our proposed method addresses these challenges by incorporating a rotation-invariant loss function that effectively captures the geometric properties of rotated objects. We integrate this proposed loss function into state-of-the-art deep learning-based rotated object detection detectors, and extensive experiments demonstrated significant improvements in mean Average Precision metrics compared to existing methods. The results highlight the potential of our approach to establish new benchmark in rotated object detection, with implications for a wide range of applications requiring precise and reliable object localization irrespective of orientation."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          VIPAMIN: Visual Prompt Initialization via Embedding Selection and Subspace Expansion", "authors": "Jaekyun Park, Hye Won Chung", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)", "abstract": "In the era of large-scale foundation models, fully fine-tuning pretrained networks for each downstream task is often prohibitively resource-intensive. Prompt tuning offers a lightweight alternative by introducing tunable prompts while keeping the backbone frozen. However, existing visual prompt tuning methods often fail to specialize the prompts or enrich the representation space--especially when applied to self-supervised backbones. We show that these limitations become especially pronounced in challenging tasks and data-scarce settings, where effective adaptation is most critical. In this work, we introduce VIPAMIN, a visual prompt initialization strategy that enhances adaptation of self-supervised models by (1) aligning prompts with semantically informative regions in the embedding space, and (2) injecting novel representational directions beyond the pretrained subspace. Despite its simplicity--requiring only a single forward pass and lightweight operations--VIPAMIN consistently improves performance across diverse tasks and dataset sizes, setting a new state of the art in visual prompt tuning. Our code is available at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Dynamic-stabilization-based linear schemes for the Allen-Cahn equation with degenerate mobility: MBP and energy stability", "authors": "Hongfei Fu, Dianming Hou, Zhonghua Qiao, Bingyin Zhang", "subjects": "Numerical Analysis (math.NA)", "abstract": "In this paper, we investigate linear first- and second-order numerical schemes for the Allen--Cahn equation with a general (possibly degenerate) mobility. Compared with existing numerical methods, our schemes employ a novel dynamic stabilization approach that guarantees unconditional preservation of the maximum bound principle (MBP) and energy stability. A key advance is that the discrete energy stability remains valid even in the presence of degenerate mobility-a property we refer to as mobility robustness. Rigorous maximum-norm error estimates are also established. In particular, for the second-order scheme, we introduce a new prediction strategy with a cut-off preprocessing procedure on the extrapolation solution, and only one linear system needs to be solved per time level. Representative numerical examples are provided to validate the theoretical findings and performance of the proposed schemes."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Input Domain Aware MoE: Decoupling Routing Decisions from Task Optimization in Mixture of Experts", "authors": "Yongxiang Hua, Haoyu Cao, Zhou Tao, Bocheng Li, Zihao Wu, Chaohu Liu, Linli Xu", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "Sparse Mixture of Experts (sMoE) has become a pivotal approach for scaling large vision-language models, offering substantial capacity while maintaining computational efficiency through dynamic, sparse activation of experts. However, existing routing mechanisms, typically based on similarity scoring, struggle to effectively capture the underlying input structure. This limitation leads to a trade-off between expert specialization and balanced computation, hindering both scalability and performance. We propose Input Domain Aware MoE, a novel routing framework that leverages a probabilistic mixture model to better partition the input space. By modeling routing probabilities as a mixture of distributions, our method enables experts to develop clear specialization boundaries while achieving balanced utilization. Unlike conventional approaches, our routing mechanism is trained independently of task-specific objectives, allowing for stable optimization and decisive expert assignments. Empirical results on vision-language tasks demonstrate that our method consistently outperforms existing sMoE approaches, achieving higher task performance and improved expert utilization balance."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          TrajSelector: Harnessing Latent Representations for Efficient and Effective Best-of-N in Large Reasoning Model", "authors": "Bin Yu, Xinming Wang, Shijie Lian, Haotian Li, Changti Wu, Ruina Hu, Bailing Wang, Yuliang Wei, Kai Chen", "subjects": "Computation and Language (cs.CL)", "abstract": "Large language models (LLMs) have shown remarkable progress in complex reasoning tasks, largely enabled by test-time scaling (TTS) paradigms that allocate additional compute during inference. Among these, external TTS (particularly the Best-of-N selection paradigm) yields scalable performance improvements by selecting from multiple independently generated reasoning trajectories. However, this approach faces key limitations: (i) the high computational overhead of deploying process reward models, (ii) the underutilization of the LLM's intrinsic latent representations. We introduce TrajSelector, an efficient and effective Best-of-N framework that exploit the hidden states in the sampler LLM for process-level scoring. A lightweight verifier (with only 0.6B parameters) evaluates the quality of step-wise trajectory, and then aggregates these scores to identify the optimal reasoning trajectory. Our framework employs a fully data-driven, end-to-end training recipe that eliminates reliance on massive step-level annotations. Experiential results across five benchmarks demonstrate that TrajSelector delivers consistent performance gains. In Best-of-32 settings, it surpasses majority voting by 4.61% accuracy and outperforms existing process reward models by 4.31% to 12.21%, all while maintaining lower inference costs."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Instance-Aware Pseudo-Labeling and Class-Focused Contrastive Learning for Weakly Supervised Domain Adaptive Segmentation of Electron Microscopy", "authors": "Shan Xiong, Jiabao Chen, Ye Wang, Jialin Peng", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Annotation-efficient segmentation of the numerous mitochondria instances from various electron microscopy (EM) images is highly valuable for biological and neuroscience research. Although unsupervised domain adaptation (UDA) methods can help mitigate domain shifts and reduce the high costs of annotating each domain, they typically have relatively low performance in practical applications. Thus, we investigate weakly supervised domain adaptation (WDA) that utilizes additional sparse point labels on the target domain, which require minimal annotation effort and minimal expert knowledge. To take full use of the incomplete and imprecise point annotations, we introduce a multitask learning framework that jointly conducts segmentation and center detection with a novel cross-teaching mechanism and class-focused cross-domain contrastive learning. While leveraging unlabeled image regions is essential, we introduce segmentation self-training with a novel instance-aware pseudo-label (IPL) selection strategy. Unlike existing methods that typically rely on pixel-wise pseudo-label filtering, the IPL semantically selects reliable and diverse pseudo-labels with the help of the detection task. Comprehensive validations and comparisons on challenging datasets demonstrate that our method outperforms existing UDA and WDA methods, significantly narrowing the performance gap with the supervised upper bound. Furthermore, under the UDA setting, our method also achieves substantial improvements over other UDA techniques."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Stabilization of Nonlinear Systems with State-Dependent Representation: From Model-Based to Direct Data-Driven Control", "authors": "Lidong Li, Rui Huang, Lin Zhao", "subjects": "Systems and Control (eess.SY)", "abstract": "This paper presents a novel framework for stabilizing nonlinear systems represented in state-dependent form. We first reformulate the nonlinear dynamics as a state-dependent parameter-varying model and synthesize a stabilizing controller offline via tractable linear matrix inequalities (LMIs). The resulting controller guarantees local exponential stability, maintains robustness against disturbances, and provides an estimate of the region of attraction under input saturation. We then extend the formulation to the direct data-driven setting, where a known library of basis functions represents the dynamics with unknown coefficients consistent with noisy experimental data. By leveraging Petersen's lemma, we derive data-dependent LMIs that ensure stability and robustness for all systems compatible with the data. Numerical and physical experimental results validate that our approach achieves rigorous end-to-end guarantees on stability, robustness, and safety directly from finite data without explicit model identification."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Online computation of normalized substring complexity", "authors": "Gregory Kucherov, Yakov Nekrich", "subjects": "Data Structures and Algorithms (cs.DS)", "abstract": "The normalized substring complexity $\\delta$ of a string is defined as $\\max_k \\{c[k]/k\\}$, where $c[k]$ is the number of \\textit{distinct} substrings of length $k$. This simply defined measure has recently attracted attention due to its established relationship to popular string compression algorithms. We consider the problem of computing $\\delta$ online, when the string is provided from a stream. We present two algorithms solving the problem: one working in $O(\\log n)$ amortized time per character, and the other in $O(\\log^3 n)$ worst-case time per character. To our knowledge, this is the first polylog-time online solution to this problem."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          RAVEN: Robust Advertisement Video Violation Temporal Grounding via Reinforcement Reasoning", "authors": "Deyi Ji, Yuekui Yang, Haiyang Wu, Shaoping Ma, Tianrun Chen, Lanyun Zhu", "subjects": "Computation and Language (cs.CL)", "abstract": "Advertisement (Ad) video violation detection is critical for ensuring platform compliance, but existing methods struggle with precise temporal grounding, noisy annotations, and limited generalization. We propose RAVEN, a novel framework that integrates curriculum reinforcement learning with multimodal large language models (MLLMs) to enhance reasoning and cognitive capabilities for violation detection. RAVEN employs a progressive training strategy, combining precisely and coarsely annotated data, and leverages Group Relative Policy Optimization (GRPO) to develop emergent reasoning abilities without explicit reasoning annotations. Multiple hierarchical sophisticated reward mechanism ensures precise temporal grounding and consistent category prediction. Experiments on industrial datasets and public benchmarks show that RAVEN achieves superior performances in violation category accuracy and temporal interval localization. We also design a pipeline to deploy the RAVEN on the online Ad services, and online A/B testing further validates its practical applicability, with significant improvements in precision and recall. RAVEN also demonstrates strong generalization, mitigating the catastrophic forgetting issue associated with supervised fine-tuning."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          NavQ: Learning a Q-Model for Foresighted Vision-and-Language Navigation", "authors": "Peiran Xu, Xicheng Gong, Yadong MU", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)", "abstract": "In this work we concentrate on the task of goal-oriented Vision-and-Language Navigation (VLN). Existing methods often make decisions based on historical information, overlooking the future implications and long-term outcomes of the actions. In contrast, we aim to develop a foresighted agent. Specifically, we draw upon Q-learning to train a Q-model using large-scale unlabeled trajectory data, in order to learn the general knowledge regarding the layout and object relations within indoor scenes. This model can generate a Q-feature, analogous to the Q-value in traditional Q-network, for each candidate action, which describes the potential future information that may be observed after taking the specific action. Subsequently, a cross-modal future encoder integrates the task-agnostic Q-feature with navigation instructions to produce a set of action scores reflecting future prospects. These scores, when combined with the original scores based on history, facilitate an A*-style searching strategy to effectively explore the regions that are more likely to lead to the destination. Extensive experiments conducted on widely used goal-oriented VLN datasets validate the effectiveness of the proposed method."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Agree, Disagree, Explain: Decomposing Human Label Variation in NLI through the Lens of Explanations", "authors": "Pingjun Hong, Beiduo Chen, Siyao Peng, Marie-Catherine de Marneffe, Benjamin Roth, Barbara Plank", "subjects": "Computation and Language (cs.CL)", "abstract": "Natural Language Inference datasets often exhibit human label variation. To better understand these variations, explanation-based approaches analyze the underlying reasoning behind annotators' decisions. One such approach is the LiTEx taxonomy, which categorizes free-text explanations in English into reasoning types. However, previous work applying such taxonomies has focused on within-label variation: cases where annotators agree on the final NLI label but provide different explanations. In contrast, this paper broadens the scope by examining how annotators may diverge not only in the reasoning type but also in the labeling step. We use explanations as a lens to decompose the reasoning process underlying NLI annotation and to analyze individual differences. We apply LiTEx to two NLI English datasets and align annotation variation from multiple aspects: NLI label agreement, explanation similarity, and taxonomy agreement, with an additional compounding factor of annotators' selection bias. We observe instances where annotators disagree on the label but provide highly similar explanations, suggesting that surface-level disagreement may mask underlying agreement in interpretation. Moreover, our analysis reveals individual preferences in explanation strategies and label choices. These findings highlight that agreement in reasoning types better reflects the semantic similarity of free-text explanations than label agreement alone. Our findings underscore the richness of reasoning-based explanations and the need for caution in treating labels as ground truth."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Women have it Worse: an ICT Workplace Digital Transformation Stress Gender Gap", "authors": "Ewa Makowska-T\u0142umak, Sylwia Bedy\u0144ska, Kinga Skorupska, Rados\u0142aw Nielek", "subjects": "Computers and Society (cs.CY)", "abstract": "Although information and communication technologies (ICT) solutions have positive outcomes for both companies and employees, the digital transformation (DT) could have an impact on the well-being of employees. The jobs of the employees became more demanding, and they were expected to learn ICT skills and cope with ICT workloads and hassles. Due to negative stereotypes about women's deficiency in technology, these ICT problems could affect female and male employees differently. Thus, we predicted that this additional pressure may manifest itself in higher levels of digital transformation stress (DTS) in female employees. The results confirmed this prediction and indicated the existence of a gender gap in DTS, measured two-fold - in sentiment analysis of help desk tickets and self-report using a psychological scale. Based on these results, we explore the need to discuss possible solutions and tools to support women in ICT-heavy workplace contexts."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Heimdallr: Fingerprinting SD-WAN Control-Plane Architecture via Encrypted Control Traffic", "authors": "Minjae Seo, Jaehan Kim, Eduard Marin, Myoungsung You, Taejune Park, Seungsoo Lee, Seungwon Shin, Jinwoo Kim", "subjects": "Cryptography and Security (cs.CR); Networking and Internet Architecture (cs.NI)", "abstract": "Software-defined wide area network (SD-WAN) has emerged as a new paradigm for steering a large-scale network flexibly by adopting distributed software-defined network (SDN) controllers. The key to building a logically centralized but physically distributed control-plane is running diverse cluster management protocols to achieve consistency through an exchange of control traffic. Meanwhile, we observe that the control traffic exposes unique time-series patterns and directional relationships due to the operational structure even though the traffic is encrypted, and this pattern can disclose confidential information such as control-plane topology and protocol dependencies, which can be exploited for severe attacks. With this insight, we propose a new SD-WAN fingerprinting system, called Heimdallr. It analyzes periodical and operational patterns of SD-WAN cluster management protocols and the context of flow directions from the collected control traffic utilizing a deep learning-based approach, so that it can classify the cluster management protocols automatically from miscellaneous control traffic datasets. Our evaluation, which is performed in a realistic SD-WAN environment consisting of geographically distant three campus networks and one enterprise network shows that Heimdallr can classify SD-WAN control traffic with $\\geq$ 93%, identify individual protocols with $\\geq$ 80% macro F-1 scores, and finally can infer control-plane topology with $\\geq$ 70% similarity."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Buzz, Choose, Forget: A Meta-Bandit Framework for Bee-Like Decision Making", "authors": "Emmanuelle Claeys, Elena Kerjean, Jean-Michel Loubes", "subjects": "Machine Learning (cs.LG); Machine Learning (stat.ML)", "abstract": "We introduce a sequential reinforcement learning framework for imitation learning designed to model heterogeneous cognitive strategies in pollinators. Focusing on honeybees, our approach leverages trajectory similarity to capture and forecast behavior across individuals that rely on distinct strategies: some exploiting numerical cues, others drawing on memory, or being influenced by environmental factors such as weather. Through empirical evaluation, we show that state-of-the-art imitation learning methods often fail in this setting: when expert policies shift across memory windows or deviate from optimality, these models overlook both fast and slow learning behaviors and cannot faithfully reproduce key decision patterns. Moreover, they offer limited interpretability, hindering biological insight. Our contribution addresses these challenges by (i) introducing a model that minimizes predictive loss while identifying the effective memory horizon most consistent with behavioral data, and (ii) ensuring full interpretability to enable biologists to analyze underlying decision-making strategies and finally (iii) providing a mathematical framework linking bee policy search with bandit formulations under varying exploration-exploitation dynamics, and releasing a novel dataset of 80 tracked bees observed under diverse weather conditions. This benchmark facilitates research on pollinator cognition and supports ecological governance by improving simulations of insect behavior in agroecosystems. Our findings shed new light on the learning strategies and memory interplay shaping pollinator decision-making."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          HGC-Avatar: Hierarchical Gaussian Compression for Streamable Dynamic 3D Avatars", "authors": "Haocheng Tang, Ruoke Yan, Xinhui Yin, Qi Zhang, Xinfeng Zhang, Siwei Ma, Wen Gao, Chuanmin Jia", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Recent advances in 3D Gaussian Splatting (3DGS) have enabled fast, photorealistic rendering of dynamic 3D scenes, showing strong potential in immersive communication. However, in digital human encoding and transmission, the compression methods based on general 3DGS representations are limited by the lack of human priors, resulting in suboptimal bitrate efficiency and reconstruction quality at the decoder side, which hinders their application in streamable 3D avatar systems. We propose HGC-Avatar, a novel Hierarchical Gaussian Compression framework designed for efficient transmission and high-quality rendering of dynamic avatars. Our method disentangles the Gaussian representation into a structural layer, which maps poses to Gaussians via a StyleUNet-based generator, and a motion layer, which leverages the SMPL-X model to represent temporal pose variations compactly and semantically. This hierarchical design supports layer-wise compression, progressive decoding, and controllable rendering from diverse pose inputs such as video sequences or text. Since people are most concerned with facial realism, we incorporate a facial attention mechanism during StyleUNet training to preserve identity and expression details under low-bitrate constraints. Experimental results demonstrate that HGC-Avatar provides a streamable solution for rapid 3D avatar rendering, while significantly outperforming prior methods in both visual quality and compression efficiency."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          ReviewSense: Transforming Customer Review Dynamics into Actionable Business Insights", "authors": "Siddhartha Krothapalli, Tridib Kumar Das, Praveen Kumar, Naveen Suravarpu, Pratik Narang", "subjects": "Artificial Intelligence (cs.AI)", "abstract": "As customer feedback becomes increasingly central to strategic growth, the ability to derive actionable insights from unstructured reviews is essential. While traditional AI-driven systems excel at predicting user preferences, far less work has focused on transforming customer reviews into prescriptive, business-facing recommendations. This paper introduces ReviewSense, a novel prescriptive decision support framework that leverages advanced large language models (LLMs) to transform customer reviews into targeted, actionable business recommendations. By identifying key trends, recurring issues, and specific concerns within customer sentiments, ReviewSense extends beyond preference-based systems to provide businesses with deeper insights for sustaining growth and enhancing customer loyalty. The novelty of this work lies in integrating clustering, LLM adaptation, and expert-driven evaluation into a unified, business-facing pipeline. Preliminary manual evaluations indicate strong alignment between the model's recommendations and business objectives, highlighting its potential for driving data-informed decision-making. This framework offers a new perspective on AI-driven sentiment analysis, demonstrating its value in refining business strategies and maximizing the impact of customer feedback."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Improving performance estimation of a PCM-integrated solar chimney through reduced-order based data assimilation", "authors": "Diego R. Rivera, Ernesto Castillo, Felipe Galarce, Douglas R.Q. Pacheco", "subjects": "Numerical Analysis (math.NA); Fluid Dynamics (physics.flu-dyn)", "abstract": "This study evaluates a data assimilation framework based on reduced-order modeling (ROM-DA), complemented by a hybrid data-filling strategy, to reconstruct dynamic temperature fields in a phase-change-material (PCM) integrated solar chimney from limited temperature measurements. The goal is to enhance the estimation accuracy of the outlet airflow velocity. A regularized least-squares formulation is employed to estimate temperature distributions within an inclined solar chimney using RT-42 as the PCM. The methodology combines (i) a reduced-order model derived from high-fidelity finite-volume simulations of unsteady conjugate heat transfer with liquid-solid phase change and surface radiation, and (ii) three experimental datasets with 22, 135, and 203 measurement points. Missing data are reconstructed using a hybrid filling scheme based on boundary-layer and bicubic interpolations. The assimilated temperature fields are integrated into the thermally coupled forward solver to improve velocity predictions. Results show that the ROM-DA framework reconstructs the transient temperature fields in both the air and PCM domains with relative errors below 10 percent for sparse data and below 3 percent for expanded datasets. When applied to experimental measurements, the approach enhances the fidelity of temperature and velocity fields compared with the baseline model, reducing the outlet velocity RMS error by 20 percent. This represents the first application of a ROM-DA framework to a coupled multiphysics solar chimney with PCM integration, demonstrating its potential for near-real-time thermal state estimation and digital-twin development."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Declarative Techniques for NL Queries over Heterogeneous Data", "authors": "Elham Khabiri, Jeffrey O. Kephart, Fenno F. Heath III, Srideepika Jayaraman, Fateh A. Tipu, Yingjie Li, Dhruv Shah, Achille Fokoue, Anu Bhamidipaty", "subjects": "Databases (cs.DB); Artificial Intelligence (cs.AI); Software Engineering (cs.SE)", "abstract": "In many industrial settings, users wish to ask questions in natural language, the answers to which require assembling information from diverse structured data sources. With the advent of Large Language Models (LLMs), applications can now translate natural language questions into a set of API calls or database calls, execute them, and combine the results into an appropriate natural language response. However, these applications remain impractical in realistic industrial settings because they do not cope with the data source heterogeneity that typifies such environments. In this work, we simulate the heterogeneity of real industry settings by introducing two extensions of the popular Spider benchmark dataset that require a combination of database and API calls. Then, we introduce a declarative approach to handling such data heterogeneity and demonstrate that it copes with data source heterogeneity significantly better than state-of-the-art LLM-based agentic or imperative code generation systems. Our augmented benchmarks are available to the research community."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Computing functions of $A^{-1}B$ where $A$ and $B$ are Hermitian matrices", "authors": "Dario A. Bini, Massimiliano Fasi, Bruno Iannazzo", "subjects": "Numerical Analysis (math.NA)", "abstract": "We consider the numerical evaluation of the quantity $Af(A^{-1}B)$, where $A$ is Hermitian positive definite, $B$ is Hermitian, and $f$ is a function defined on the spectrum of $A^{-1}B$. We study the conditioning of the problem, and we introduce several algorithms that combine the Schur decomposition with either the matrix square root or the Cholesky factorization. We study the numerical behavior of these algorithms in floating-point arithmetic, assess their computational costs, and compare their numerical performance. Our analysis suggests that the algorithms based on the Cholesky factorization will be more accurate and efficient than those based on the matrix square root. This is confirmed by our numerical experiments."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          SCALAR: Self-Calibrating Adaptive Latent Attention Representation Learning", "authors": "Farwa Abbas, Hussain Ahmad, Claudia Szabo", "subjects": "Machine Learning (cs.LG)", "abstract": "High-dimensional, heterogeneous data with complex feature interactions pose significant challenges for traditional predictive modeling approaches. While Projection to Latent Structures (PLS) remains a popular technique, it struggles to model complex non-linear relationships, especially in multivariate systems with high-dimensional correlation structures. This challenge is further compounded by simultaneous interactions across multiple scales, where local processing fails to capture crossgroup dependencies. Additionally, static feature weighting limits adaptability to contextual variations, as it ignores sample-specific relevance. To address these limitations, we propose a novel method that enhances predictive performance through novel architectural innovations. Our architecture introduces an adaptive kernel-based attention mechanism that processes distinct feature groups separately before integration, enabling capture of local patterns while preserving global relationships. Experimental results show substantial improvements in performance metrics, compared to the state-of-the-art methods across diverse datasets."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          NP-Engine: Empowering Optimization Reasoning in Large Language Models with Verifiable Synthetic NP Problems", "authors": "Xiaozhe Li, Xinyu Fang, Shengyuan Ding, Linyang Li, Haodong Duan, Qingwen Liu, Kai Chen", "subjects": "Artificial Intelligence (cs.AI)", "abstract": "Large Language Models (LLMs) have shown strong reasoning capabilities, with models like OpenAI's O-series and DeepSeek R1 excelling at tasks such as mathematics, coding, logic, and puzzles through Reinforcement Learning with Verifiable Rewards (RLVR). However, their ability to solve more complex optimization problems - particularly NP-hard tasks - remains underexplored. To bridge this gap, we propose NP-ENGINE, the first comprehensive framework for training and evaluating LLMs on NP-hard problems. NP-ENGINE covers 10 tasks across five domains, each equipped with (i) a controllable instance generator, (ii) a rule-based verifier, and (iii) a heuristic solver that provides approximate optimal solutions as ground truth. This generator-verifier-heuristic pipeline enables scalable and verifiable RLVR training under hierarchical difficulties. We also introduce NP-BENCH, a benchmark derived from NP-ENGINE-DATA, specifically designed to evaluate LLMs' ability to tackle NP-hard level reasoning problems, focusing not only on feasibility but also on solution quality. Additionally, we present QWEN2.5-7B-NP, a model trained via zero-RLVR with curriculum learning on Qwen2.5-7B-Instruct, which significantly outperforms GPT-4o on NP-BENCH and achieves SOTA performance with the same model size. Beyond in-domain tasks, we demonstrate that RLVR training on NP-ENGINE-DATA enables strong out-of-domain (OOD) generalization to reasoning tasks (logic, puzzles, math, and knowledge), as well as non-reasoning tasks such as instruction following. We also observe a scaling trend: increasing task diversity improves OOD generalization. These findings suggest that task-rich RLVR training is a promising direction for advancing LLM's reasoning ability, revealing new insights into the scaling laws of RLVR."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Shifting 'AI Policy' Preprints and Citation Trends in the U.S., U.K and E.U., and South Korea (2015-2024)", "authors": "Simon Suh, Daniene Byrne", "subjects": "Digital Libraries (cs.DL); Computers and Society (cs.CY); Social and Information Networks (cs.SI)", "abstract": "This study of literature focusing on 'AI Policy' over the past decade, found that citations of preprints, publications on platforms such as arXiv, have increased from five percent to forty percent across three major regions: the U.S., U.K. & E.U., and South Korea. We compare regional responses of preprint citations across the global disruptions of COVID-19 and the release of ChatGPT. We discuss driving factors and risks of preprint normalization, which follows the trend in computer science."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Region-Aware Wasserstein Distances of Persistence Diagrams and Merge Trees", "authors": "Mathieu Pont, Christoph Garth", "subjects": "Graphics (cs.GR)", "abstract": "This paper presents a generalization of the Wasserstein distance for both persistence diagrams and merge trees [20], [66] that takes advantage of the regions of their topological features in the input domain. Specifically, we redefine the comparison of topological features as a distance between the values of their extrema-aligned regions. It results in a more discriminative metric than the classical Wasserstein distance and generalizes it through an input parameter adjusting the impact of the region properties in the distance. We present two strategies to control both computation time and memory storage of our method by respectively enabling the use of subsets of the regions in the computation, and by compressing the regions' properties to obtain low-memory representations. Extensive experiments on openly available ensemble data demonstrate the efficiency of our method, with running times on the orders of minutes on average. We show the utility of our contributions with two applications. First, we use the assignments between topological features provided by our method to track their evolution in time-varying ensembles and propose the temporal persistence curves to facilitate the understanding of how these features appear, disappear and change over time. Second, our method allows to compute a distance matrix of an ensemble that can be used for dimensionality reduction purposes and visually represent in 2D all its members, we show that such distance matrices also allow to detect key phases in the ensemble. Finally, we provide a C++ implementation that can be used to reproduce our results."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Architecture, Simulation and Software Stack to Support Post-CMOS Accelerators: The ARCHYTAS Project", "authors": "Giovanni Agosta, Stefano Cherubin, Derek Christ, Francesco Conti, Asbj\u00f8rn Djupdal, Matthias Jung, Georgios Keramidas, Roberto Passerone, Paolo Rech, Elisa Ricci, Philippe Velha, Flavio Vella, Kasim Sinan Yildirim, Nils Wilbert", "subjects": "Hardware Architecture (cs.AR)", "abstract": "ARCHYTAS aims to design and evaluate non-conventional hardware accelerators, in particular, optoelectronic, volatile and non-volatile processing-in-memory, and neuromorphic, to tackle the power, efficiency, and scalability bottlenecks of AI with an emphasis on defense use cases (e.g., autonomous vehicles, surveillance drones, maritime and space platforms). In this paper, we present the system architecture and software stack that ARCHYTAS will develop to integrate and support those accelerators, as well as the simulation software needed for early prototyping of the full system and its components."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Interpreting the Dimensions of Speaker Embedding Space", "authors": "Mark Huckvale", "subjects": "Sound (cs.SD); Audio and Speech Processing (eess.AS)", "abstract": "Speaker embeddings are widely used in speaker verification systems and other applications where it is useful to characterise the voice of a speaker with a fixed-length vector. These embeddings tend to be treated as \"black box\" encodings, and how they relate to conventional acoustic and phonetic dimensions of voices has not been widely studied. In this paper we investigate how state-of-the-art speaker embedding systems represent the acoustic characteristics of speakers as described by conventional acoustic descriptors, age, and gender. Using a large corpus of 10,000 speakers and three embedding systems we show that a small set of 9 acoustic parameters chosen to be \"interpretable\" predict embeddings about the same as 7 principal components, corresponding to over 50% of variance in the data. We show that some principal dimensions operate differently for male and female speakers, suggesting there is implicit gender recognition within the embedding systems. However we show that speaker age is not well captured by embeddings, suggesting opportunities exist for improvements in their calculation."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Check Yourself Before You Wreck Yourself: Selectively Quitting Improves LLM Agent Safety", "authors": "Vamshi Krishna Bonagiri, Ponnurangam Kumaragurum, Khanh Nguyen, Benjamin Plaut", "subjects": "Computation and Language (cs.CL)", "abstract": "As Large Language Model (LLM) agents increasingly operate in complex environments with real-world consequences, their safety becomes critical. While uncertainty quantification is well-studied for single-turn tasks, multi-turn agentic scenarios with real-world tool access present unique challenges where uncertainties and ambiguities compound, leading to severe or catastrophic risks beyond traditional text generation failures. We propose using \"quitting\" as a simple yet effective behavioral mechanism for LLM agents to recognize and withdraw from situations where they lack confidence. Leveraging the ToolEmu framework, we conduct a systematic evaluation of quitting behavior across 12 state-of-the-art LLMs. Our results demonstrate a highly favorable safety-helpfulness trade-off: agents prompted to quit with explicit instructions improve safety by an average of +0.39 on a 0-3 scale across all models (+0.64 for proprietary models), while maintaining a negligible average decrease of -0.03 in helpfulness. Our analysis demonstrates that simply adding explicit quit instructions proves to be a highly effective safety mechanism that can immediately be deployed in existing agent systems, and establishes quitting as an effective first-line defense mechanism for autonomous agents in high-stakes applications."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          High-order temporal parametric finite element methods for simulating solid-state dewetting", "authors": "Xiaowen Gan, Yuqian Teng, Sisheng Wang", "subjects": "Numerical Analysis (math.NA); Mathematical Physics (math-ph)", "abstract": "We propose a class of temporally high-order parametric finite element methods for simulating solid-state dewetting of thin films in two dimensions using a sharp-interface model. The process is governed by surface diffusion and contact point migration, along with appropriate boundary conditions. By incorporating the predictor-corrector strategy and the backward differentiation formula for time discretization into the energy-stable parametric finite element method developed by Zhao et al. (2021), we successfully construct temporally high-order schemes. The resulting numerical scheme is semi-implicit, requiring the solution of a linear system at each time step. The well-posedness of the fully discretized system is established. Moreover, the method maintains the long-term mesh equidistribution property. Extensive numerical experiments demonstrate that our methods achieve the desired temporal accuracy, measured by the manifold distance, while maintaining good mesh quality throughout the evolution."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          A linear unconditionally structure-preserving L1 scheme for the time-fractional Allen-Cahn equation", "authors": "Dianming Hou, Zhonghua Qiao, Tao Tang", "subjects": "Numerical Analysis (math.NA)", "abstract": "As a variational phase-field model, the time-fractional Allen-Cahn (TFAC) equation enjoys the maximum bound principle (MBP) and a variational energy dissipation law. In this work, we develop and analyze linear, structure-preserving time-stepping schemes for TFAC, including first-order and $\\min\\{1+\\alpha, 2-\\alpha\\}$-order L1 discretizations, together with fast implementations based on the sum-of-exponentials (SOE) technique. A central feature of the proposed linear schemes is their unconditional preservation of both the discrete MBP and the variational energy dissipation law on general temporal meshes, including graded meshes commonly used for these problems. Leveraging the MBP of the numerical solutions, we establish sharp error estimates by employing the time-fractional Gronwall inequality. Finally, numerical experiments validate the theoretical results and demonstrate the effectiveness of the proposed schemes with an adaptive time-stepping strategy."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Edge-Based Speech Transcription and Synthesis for Kinyarwanda and Swahili Languages", "authors": "Pacome Simon Mbonimpa, Diane Tuyizere, Azizuddin Ahmed Biyabani, Ozan K. Tonguz", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)", "abstract": "This paper presents a novel framework for speech transcription and synthesis, leveraging edge-cloud parallelism to enhance processing speed and accessibility for Kinyarwanda and Swahili speakers. It addresses the scarcity of powerful language processing tools for these widely spoken languages in East African countries with limited technological infrastructure. The framework utilizes the Whisper and SpeechT5 pre-trained models to enable speech-to-text (STT) and text-to-speech (TTS) translation. The architecture uses a cascading mechanism that distributes the model inference workload between the edge device and the cloud, thereby reducing latency and resource usage, benefiting both ends. On the edge device, our approach achieves a memory usage compression of 9.5% for the SpeechT5 model and 14% for the Whisper model, with a maximum memory usage of 149 MB. Experimental results indicate that on a 1.7 GHz CPU edge device with a 1 MB/s network bandwidth, the system can process a 270-character text in less than a minute for both speech-to-text and text-to-speech transcription. Using real-world survey data from Kenya, it is shown that the cascaded edge-cloud architecture proposed could easily serve as an excellent platform for STT and TTS transcription with good accuracy and response time."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Automated Composition of Agents: A Knapsack Approach for Agentic Component Selection", "authors": "Michelle Yuan, Khushbu Pahwa, Shuaichen Chang, Mustafa Kaba, Jiarong Jiang, Xiaofei Ma, Yi Zhang, Monica Sunkara", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "abstract": "Designing effective agentic systems requires the seamless composition and integration of agents, tools, and models within dynamic and uncertain environments. Most existing methods rely on static, semantic retrieval approaches for tool or agent discovery. However, effective reuse and composition of existing components remain challenging due to incomplete capability descriptions and the limitations of retrieval methods. Component selection suffers because the decisions are not based on capability, cost, and real-time utility. To address these challenges, we introduce a structured, automated framework for agentic system composition that is inspired by the knapsack problem. Our framework enables a composer agent to systematically identify, select, and assemble an optimal set of agentic components by jointly considering performance, budget constraints, and compatibility. By dynamically testing candidate components and modeling their utility in real-time, our approach streamlines the assembly of agentic systems and facilitates scalable reuse of resources. Empirical evaluation with Claude 3.5 Sonnet across five benchmarking datasets shows that our online-knapsack-based composer consistently lies on the Pareto frontier, achieving higher success rates at significantly lower component costs compared to our baselines. In the single-agent setup, the online knapsack composer shows a success rate improvement of up to 31.6% in comparison to the retrieval baselines. In multi-agent systems, the online knapsack composer increases success rate from 37% to 87% when agents are selected from an agent inventory of 100+ agents. The substantial performance gap confirms the robust adaptability of our method across diverse domains and budget constraints."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Advancing Off-Road Autonomous Driving: The Large-Scale ORAD-3D Dataset and Comprehensive Benchmarks", "authors": "Chen Min, Jilin Mei, Heng Zhai, Shuai Wang, Tong Sun, Fanjie Kong, Haoyang Li, Fangyuan Mao, Fuyang Liu, Shuo Wang, Yiming Nie, Qi Zhu, Liang Xiao, Dawei Zhao, Yu Hu", "subjects": "Robotics (cs.RO)", "abstract": "A major bottleneck in off-road autonomous driving research lies in the scarcity of large-scale, high-quality datasets and benchmarks. To bridge this gap, we present ORAD-3D, which, to the best of our knowledge, is the largest dataset specifically curated for off-road autonomous driving. ORAD-3D covers a wide spectrum of terrains, including woodlands, farmlands, grasslands, riversides, gravel roads, cement roads, and rural areas, while capturing diverse environmental variations across weather conditions (sunny, rainy, foggy, and snowy) and illumination levels (bright daylight, daytime, twilight, and nighttime). Building upon this dataset, we establish a comprehensive suite of benchmark evaluations spanning five fundamental tasks: 2D free-space detection, 3D occupancy prediction, rough GPS-guided path planning, vision-language model-driven autonomous driving, and world model for off-road environments. Together, the dataset and benchmarks provide a unified and robust resource for advancing perception and planning in challenging off-road scenarios. The dataset and code will be made publicly available at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          On the Use of Large Language Models for Qualitative Synthesis", "authors": "Sebasti\u00e1n Pizard, Ramiro Moreira, Federico Galiano, Ignacio Sastre, Lorena Etcheverry", "subjects": "Software Engineering (cs.SE)", "abstract": "Large language models (LLMs) show promise for supporting systematic reviews (SR), even complex tasks such as qualitative synthesis (QS). However, applying them to a stage that is unevenly reported and variably conducted carries important risks: misuse can amplify existing weaknesses and erode confidence in the SR findings. To examine the challenges of using LLMs for QS, we conducted a collaborative autoethnography involving two trials. We evaluated each trial for methodological rigor and practical usefulness, and interpreted the results through a technical lens informed by how LLMs are built and their current limitations."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          PRISMM-Bench: A Benchmark of Peer-Review Grounded Multimodal Inconsistencies", "authors": "Lukas Selch, Yufang Hou, M. Jehanzeb Mirza, Sivan Doveh, James Glass, Rogerio Feris, Wei Lin", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Large Multimodal Models (LMMs) are increasingly applied to scientific research, yet it remains unclear whether they can reliably understand and reason over the multimodal complexity of papers. A central challenge lies in detecting and resolving inconsistencies across text, figures, tables, and equations, issues that are often subtle, domain-specific, and ultimately undermine clarity, reproducibility, and trust. Existing benchmarks overlook this issue, either isolating single modalities or relying on synthetic errors that fail to capture real-world complexity. We introduce PRISMM-Bench (Peer-Review-sourced Inconsistency Set for Multimodal Models), the first benchmark grounded in real reviewer-flagged inconsistencies in scientific papers. Through a multi-stage pipeline of review mining, LLM-assisted filtering and human verification, we curate 262 inconsistencies from 242 papers. Based on this set, we design three tasks, namely inconsistency identification, remedy and pair matching, which assess a model's capacity to detect, correct, and reason over inconsistencies across different modalities. Furthermore, to address the notorious problem of choice-only shortcuts in multiple-choice evaluation, where models exploit answer patterns without truly understanding the question, we further introduce structured JSON-based answer representations that minimize linguistic biases by reducing reliance on superficial stylistic cues. We benchmark 21 leading LMMs, including large open-weight models (GLM-4.5V 106B, InternVL3 78B) and proprietary models (Gemini 2.5 Pro, GPT-5 with high reasoning). Results reveal strikingly low performance (26.1-54.2%), underscoring the challenge of multimodal scientific reasoning and motivating progress towards trustworthy scientific assistants."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          OOS-DSD: Improving Out-of-stock Detection in Retail Images using Auxiliary Tasks", "authors": "Franko \u0160iki\u0107, Sven Lon\u010dari\u0107", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Out-of-stock (OOS) detection is a very important retail verification process that aims to infer the unavailability of products in their designated areas on the shelf. In this paper, we introduce OOS-DSD, a novel deep learning-based method that advances OOS detection through auxiliary learning. In particular, we extend a well-established YOLOv8 object detection architecture with additional convolutional branches to simultaneously detect OOS, segment products, and estimate scene depth. While OOS detection and product segmentation branches are trained using ground truth data, the depth estimation branch is trained using pseudo-labeled annotations produced by the state-of-the-art (SOTA) depth estimation model Depth Anything V2. Furthermore, since the aforementioned pseudo-labeled depth estimates display relative depth, we propose an appropriate depth normalization procedure that stabilizes the training process. The experimental results show that the proposed method surpassed the performance of the SOTA OOS detection methods by 1.8% of the mean average precision (mAP). In addition, ablation studies confirm the effectiveness of auxiliary learning and the proposed depth normalization procedure, with the former increasing mAP by 3.7% and the latter by 4.2%."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Structured Temporal Causality for Interpretable Multivariate Time Series Anomaly Detection", "authors": "Dongchan Cho, Jiho Han, Keumyeong Kang, Minsang Kim, Honggyu Ryu, Namsoon Jung", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Machine Learning (stat.ML)", "abstract": "Real-world multivariate time series anomalies are rare and often unlabeled. Additionally, prevailing methods rely on increasingly complex architectures tuned to benchmarks, detecting only fragments of anomalous segments and overstating performance. In this paper, we introduce OracleAD, a simple and interpretable unsupervised framework for multivariate time series anomaly detection. OracleAD encodes each variable's past sequence into a single causal embedding to jointly predict the present time point and reconstruct the input window, effectively modeling temporal dynamics. These embeddings then undergo a self-attention mechanism to project them into a shared latent space and capture spatial relationships. These relationships are not static, since they are modeled by a property that emerges from each variable's temporal dynamics. The projected embeddings are aligned to a Stable Latent Structure (SLS) representing normal-state relationships. Anomalies are identified using a dual scoring mechanism based on prediction error and deviation from the SLS, enabling fine-grained anomaly diagnosis at each time point and across individual variables. Since any noticeable SLS deviation originates from embeddings that violate the learned temporal causality of normal data, OracleAD directly pinpoints the root-cause variables at the embedding level. OracleAD achieves state-of-the-art results across multiple real-world datasets and evaluation protocols, while remaining interpretable through SLS."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          eDCF: Estimating Intrinsic Dimension using Local Connectivity", "authors": "Dhruv Gupta, Aditya Nagarsekar, Vraj Shah, Sujith Thomas", "subjects": "Machine Learning (cs.LG); Machine Learning (stat.ML)", "abstract": "Modern datasets often contain high-dimensional features exhibiting complex dependencies. To effectively analyze such data, dimensionality reduction methods rely on estimating the dataset's intrinsic dimension (id) as a measure of its underlying complexity. However, estimating id is challenging due to its dependence on scale: at very fine scales, noise inflates id estimates, while at coarser scales, estimates stabilize to lower, scale-invariant values. This paper introduces a novel, scalable, and parallelizable method called eDCF, which is based on Connectivity Factor (CF), a local connectivity-based metric, to robustly estimate intrinsic dimension across varying scales. Our method consistently matches leading estimators, achieving comparable values of mean absolute error (MAE) on synthetic benchmarks with noisy samples. Moreover, our approach also attains higher exact intrinsic dimension match rates, reaching up to 25.0% compared to 16.7% for MLE and 12.5% for TWO-NN, particularly excelling under medium to high noise levels and large datasets. Further, we showcase our method's ability to accurately detect fractal geometries in decision boundaries, confirming its utility for analyzing realistic, structured data."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Image Categorization and Search via a GAT Autoencoder and Representative Models", "authors": "Duygu Sap, Martin Lotz, Connor Mattinson", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "abstract": "We propose a method for image categorization and retrieval that leverages graphs and a graph attention network (GAT)-based autoencoder. Our approach is representative-centric, that is, we execute the categorization and retrieval process via the representative models we construct for the images and image categories. We utilize a graph where nodes represent images (or their representatives) and edges capture similarity relationships. GAT highlights important features and relationships between images, enabling the autoencoder to construct context-aware latent representations that capture the key features of each image relative to its neighbors. We obtain category representatives from these embeddings and categorize a query image by comparing its representative to the category representatives. We then retrieve the most similar image to the query image within its identified category. We demonstrate the effectiveness of our representative-centric approach through experiments with both the GAT autoencoders and standard feature-based techniques."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Trading Prophets with Initial Capital", "authors": "Yossi Azar, Niv Buchbinder, Roie Levin, Or Vardi", "subjects": "Data Structures and Algorithms (cs.DS); Computer Science and Game Theory (cs.GT)", "abstract": "Correa et al. [EC' 2023] introduced the following trading prophets problem. A trader observes a sequence of stochastic prices for a stock, each drawn from a known distribution, and at each time must decide whether to buy or sell. Unfortunately, they observed that in this setting it is impossible to compete with a prophet who knows all future stock prices. In this paper, we explore the trading prophets problem when we are given initial capital with which to start trading. We show that initial capital is enough to bypass the impossibility result and obtain a competitive ratio of $3$ with respect to a prophet who knows all future prices (and who also starts with capital), and we show that this competitive ratio is best possible. We further study a more realistic model in which the trader must pay multiplicative and/or additive transaction costs for trading which model dynamics such as bid-ask spreads and broker fees."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          A Novel Gripper with Semi-Peaucellier Linkage and Idle-Stroke Mechanism for Linear Pinching and Self-Adaptive Grasping", "authors": "Haokai Ding, Wenzeng Zhang", "subjects": "Robotics (cs.RO)", "abstract": "This paper introduces a novel robotic gripper, named as the SPD gripper. It features a palm and two mechanically identical and symmetrically arranged fingers, which can be driven independently or by a single motor. The fingertips of the fingers follow a linear motion trajectory, facilitating the grasping of objects of various sizes on a tabletop without the need to adjust the overall height of the gripper. Traditional industrial grippers with parallel gripping capabilities often exhibit an arcuate motion at the fingertips, requiring the entire robotic arm to adjust its height to avoid collisions with the tabletop. The SPD gripper, with its linear parallel gripping mechanism, effectively addresses this issue. Furthermore, the SPD gripper possesses adaptive capabilities, accommodating objects of different shapes and sizes. This paper presents the design philosophy, fundamental composition principles, and optimization analysis theory of the SPD gripper. Based on the design theory, a robotic gripper prototype was developed and tested. The experimental results demonstrate that the robotic gripper successfully achieves linear parallel gripping functionality and exhibits good adaptability. In the context of the ongoing development of embodied intelligence technologies, this robotic gripper can assist various robots in achieving effective grasping, laying a solid foundation for collecting data to enhance deep learning training."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          DIV-Nav: Open-Vocabulary Spatial Relationships for Multi-Object Navigation", "authors": "Jes\u00fas Ortega-Peimbert, Finn Lukas Busch, Timon Homberger, Quantao Yang, Olov Andersson", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI)", "abstract": "Advances in open-vocabulary semantic mapping and object navigation have enabled robots to perform an informed search of their environment for an arbitrary object. However, such zero-shot object navigation is typically designed for simple queries with an object name like \"television\" or \"blue rug\". Here, we consider more complex free-text queries with spatial relationships, such as \"find the remote on the table\" while still leveraging robustness of a semantic map. We present DIV-Nav, a real-time navigation system that efficiently addresses this problem through a series of relaxations: i) Decomposing natural language instructions with complex spatial constraints into simpler object-level queries on a semantic map, ii) computing the Intersection of individual semantic belief maps to identify regions where all objects co-exist, and iii) Validating the discovered objects against the original, complex spatial constrains via a LVLM. We further investigate how to adapt the frontier exploration objectives of online semantic mapping to such spatial search queries to more effectively guide the search process. We validate our system through extensive experiments on the MultiON benchmark and real-world deployment on a Boston Dynamics Spot robot using a Jetson Orin AGX. More details and videos are available at this https URL"}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Semi-Peaucellier Linkage and Differential Mechanism for Linear Pinching and Self-Adaptive Grasping", "authors": "Haokai Ding, Zhaohan Chen, Tao Yang, Wenzeng Zhang", "subjects": "Robotics (cs.RO)", "abstract": "This paper presents the SP-Diff parallel gripper system, addressing the limited adaptability of conventional end-effectors in intelligent industrial automation. The proposed design employs an innovative differential linkage mechanism with a modular symmetric dual-finger configuration to achieve linear-parallel grasping. By integrating a planetary gear transmission, the system enables synchronized linear motion and independent finger pose adjustment while maintaining structural rigidity, reducing Z-axis recalibration requirements by 30% compared to arc-trajectory grippers. The compact palm architecture incorporates a kinematically optimized parallelogram linkage and Differential mechanism, demonstrating adaptive grasping capabilities for diverse industrial workpieces and deformable objects such as citrus fruits. Future-ready interfaces are embedded for potential force/vision sensor integration to facilitate multimodal data acquisition (e.g., trajectory planning and object deformation) in digital twin frameworks. Designed as a flexible manufacturing solution, SP-Diff advances robotic end-effector intelligence through its adaptive architecture, showing promising applications in collaborative robotics, logistics automation, and specialized operational scenarios."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Realizing LLMs' Causal Potential Requires Science-Grounded, Novel Benchmarks", "authors": "Ashutosh Srivastava, Lokesh Nagalapatti, Gautam Jajoo, Aniket Vashishtha, Parameswari Krishnamurthy, Amit Sharma", "subjects": "Machine Learning (cs.LG); Machine Learning (stat.ML)", "abstract": "Recent claims of strong performance by Large Language Models (LLMs) on causal discovery are undermined by a key flaw: many evaluations rely on benchmarks likely included in pretraining corpora. Thus, apparent success suggests that LLM-only methods, which ignore observational data, outperform classical statistical approaches. We challenge this narrative by asking: Do LLMs truly reason about causal structure, and how can we measure it without memorization concerns? Can they be trusted for real-world scientific discovery? We argue that realizing LLMs' potential for causal analysis requires two shifts: (P.1) developing robust evaluation protocols based on recent scientific studies to guard against dataset leakage, and (P.2) designing hybrid methods that combine LLM-derived knowledge with data-driven statistics. To address P.1, we encourage evaluating discovery methods on novel, real-world scientific studies. We outline a practical recipe for extracting causal graphs from recent publications released after an LLM's training cutoff, ensuring relevance and preventing memorization while capturing both established and novel relations. Compared to benchmarks like BNLearn, where LLMs achieve near-perfect accuracy, they perform far worse on our curated graphs, underscoring the need for statistical grounding. Supporting P.2, we show that using LLM predictions as priors for the classical PC algorithm significantly improves accuracy over both LLM-only and purely statistical methods. We call on the community to adopt science-grounded, leakage-resistant benchmarks and invest in hybrid causal discovery methods suited to real-world inquiry."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Hey Pentti, We Did It Again!: Differentiable vector-symbolic types that prove polynomial termination", "authors": "Eilene Tomkins-Flanagan, Connor Hanley, Mary A. Kelly", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "abstract": "We present a typed computer language, Doug, in which all typed programs may be proved to halt in polynomial time, encoded in a vector-symbolic architecture (VSA). Doug is just an encoding of the light linear functional programming language (LLFPL) described by (Schimanski2009, ch. 7). The types of Doug are encoded using a slot-value encoding scheme based on holographic declarative memory (HDM; Kelly, 2020). The terms of Doug are encoded using a variant of the Lisp VSA defined by (Flanagan, 2024). Doug allows for some points on the embedding space of a neural network to be interpreted as types, where the types of nearby points are similar both in structure and content. Types in Doug are therefore learnable by a neural network. Following (Chollet, 2019), (Card, 1983), and (Newell, 1981), we view skill as the application of a procedure, or program of action, that causes a goal to be satisfied. Skill acquisition may therefore be expressed as program synthesis. Using Doug, we hope to describe a form of learning of skilled behaviour that follows a human-like pace of skill acquisition (i.e., substantially faster than brute force; Heathcote, 2000), exceeding the efficiency of all currently existing approaches (Kaplan, 2020; Jones, 2021; Chollet, 2024). Our approach brings us one step closer to modeling human mental representations, as they must actually exist in the brain, and those representations' acquisition, as they are actually learned."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Small-Signal Stability Analysis of Power Systems by Implicit Multilinear Models", "authors": "Christoph Kaufmann, Georg Pangalos, Gerwald Lichtenberg, Oriol Gomis-Bellmunt", "subjects": "Systems and Control (eess.SY)", "abstract": "This paper proposes a new approach to perform small-signal stability analysis based on linearization of implicit multilinear models. Multilinear models describe the system dynamics by multilinear functions of state, input, and algebraic variables. Using suitable transformations of variables, they can also represent trigonometric functions, which often occur in power systems modeling. This allows tensor representations of grid-following and grid-forming power converters. This paper introduces small-signal stability analysis of equilibrium points based on implicit multilinear models using generalized eigenvalues. The generalized eigenvalues are computed from linear descriptor models of the linearized implicit multilinear model. The proposed approach is tested using a 3-bus network example, first by comparing time-domain simulations of the implicit multilinear model with those of the nonlinear model, and second by comparing the generalized eigenvalues with those of the linearized nonlinear model. The results show that the decomposed tensor representation of the implicit multilinear model allows for a faster linearization compared to conventional methods in MATLAB Simulink."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Accelerated implicitization: Robust fixed-point iterations arising from an explicit scheme", "authors": "Nicolas A. Barnafi, Felipe Galarce, Pablo Brubeck", "subjects": "Numerical Analysis (math.NA)", "abstract": "This work proposes a general strategy for solving possibly nonlinear problems arising from implicit time discretizations as a sequence of explicit solutions. The resulting sequence may exhibit instabilities similar to those of the base explicit scheme, which can be mitigated through Anderson acceleration. The approach uses explicit fixed-point subiterations for nonlinear problems, combined with Anderson acceleration to improve convergence and computational efficiency. Its usability and scalability are verified on three nonlinear differential equations. An error analysis is presented to establish the expected properties of the proposed strategy for both time and space-time formulations. Several examples illustrate the simplicity of the implementation and reveal the influence of parameter choices. The method proves simple to implement and performs well across a range of problems, particularly when matrix assembly is expensive or a good preconditioner for the implicit system is unavailable, such as in highly convective fluid flows. This work formalizes the delay of implicit terms in time discretization, provides a concise error analysis, and enhances the approach using Anderson acceleration. The results are encouraging and well supported by existing theory, laying the groundwork for further research."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Hybrid CNN-Transformer Based Sparse Channel Prediction for High-Mobility OTFS Systems", "authors": "Zhaowei Guan, Wenkun Wen, Peiran Wu, Chen Wang, Minghua Xia", "subjects": "Information Theory (cs.IT)", "abstract": "High-mobility scenarios in next-generation wireless networks, such as those involving vehicular communications, require ultra-reliable and low-latency communications (URLLC). However, rapidly time-varying channels pose significant challenges to traditional OFDM-based systems due to the Doppler effect and channel aging. Orthogonal time frequency space (OTFS) modulation offers resilience by representing channels in the quasi-static delay-Doppler (DD) domain. This letter proposes a novel channel prediction framework for OTFS systems using a hybrid convolutional neural network and transformer (CNN-Transformer) architecture. The CNN extracts compact features that exploit the DD-domain sparsity of the channel matrices, while the transformer models temporal dependencies with causal masking for consistency. Simulation experiments under extreme $500$ \\si{km/h} mobility conditions demonstrate that the proposed method outperforms state-of-the-art baselines, reducing the root mean square error and mean absolute error by $12.2\\%$ and $9.4\\%$, respectively. These results demonstrate the effectiveness of DD-domain representations and the proposed model in accurately predicting channels in high-mobility scenarios, thereby supporting the stringent URLLC requirements in future wireless systems."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Enhancing Compositional Reasoning in CLIP via Reconstruction and Alignment of Text Descriptions", "authors": "Jihoon Kwon, Kyle Min, Jy-yong Sohn", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "abstract": "Despite recent advances, vision-language models trained with standard contrastive objectives still struggle with compositional reasoning -- the ability to understand structured relationships between visual and linguistic elements. This shortcoming is largely due to the tendency of the text encoder to focus on individual words rather than their relations, a limitation reinforced by contrastive training that primarily aligns words with visual objects. In this paper, we introduce REconstruction and Alignment of text Descriptions (READ), a fine-tuning method designed to enhance compositional reasoning by adding two auxiliary objectives to the contrastive learning: (1) a token-level reconstruction objective, where a frozen pre-trained decoder reconstructs alternative captions based on the embedding of the original caption; and (2) a sentence-level alignment objective, which explicitly aligns paraphrased sentences in the embedding space. We show that READ-CLIP, a model derived by applying the READ method to the pre-trained CLIP model, achieves the state-of-the-art performance across five major compositional reasoning benchmarks, outperforming the strongest conventional fine-tuning baseline by up to 4.1%. Furthermore, applying the READ to existing CLIP variants (including NegCLIP and FSC-CLIP) also improves performance on these benchmarks. Quantitative and qualitative analyses reveal that our proposed objectives -- reconstruction and alignment -- offer complementary benefits: the former encourages the encoder to capture relationships between words within a caption, while the latter ensures consistent representations for paraphrases expressed with different wording."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Watch Where You Move: Region-aware Dynamic Aggregation and Excitation for Gait Recognition", "authors": "Binyuan Huang, Yongdong Luo, Xianda Guo, Xiawu Zheng, Zheng Zhu, Jiahui Pan, Chengju Zhou", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "abstract": "Deep learning-based gait recognition has achieved great success in various applications. The key to accurate gait recognition lies in considering the unique and diverse behavior patterns in different motion regions, especially when covariates affect visual appearance. However, existing methods typically use predefined regions for temporal modeling, with fixed or equivalent temporal scales assigned to different types of regions, which makes it difficult to model motion regions that change dynamically over time and adapt to their specific patterns. To tackle this problem, we introduce a Region-aware Dynamic Aggregation and Excitation framework (GaitRDAE) that automatically searches for motion regions, assigns adaptive temporal scales and applies corresponding attention. Specifically, the framework includes two core modules: the Region-aware Dynamic Aggregation (RDA) module, which dynamically searches the optimal temporal receptive field for each region, and the Region-aware Dynamic Excitation (RDE) module, which emphasizes the learning of motion regions containing more stable behavior patterns while suppressing attention to static regions that are more susceptible to covariates. Experimental results show that GaitRDAE achieves state-of-the-art performance on several benchmark datasets."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          $\u03c1$Hammer: Reviving RowHammer Attacks on New Architectures via Prefetching", "authors": "Weijie Chen, Shan Tang, Yulin Tang, Xiapu Luo, Yinqian Zhang, Weizhong Qiang", "subjects": "Cryptography and Security (cs.CR)", "abstract": "Rowhammer is a critical vulnerability in dynamic random access memory (DRAM) that continues to pose a significant threat to various systems. However, we find that conventional load-based attacks are becoming highly ineffective on the most recent architectures such as Intel Alder and Raptor Lake. In this paper, we present $\\rho$Hammer, a new Rowhammer framework that systematically overcomes three core challenges impeding attacks on these new architectures. First, we design an efficient and generic DRAM address mapping reverse-engineering method that uses selective pairwise measurements and structured deduction, enabling recovery of complex mappings within seconds on the latest memory controllers. Second, to break through the activation rate bottleneck of load-based hammering, we introduce a novel prefetch-based hammering paradigm that leverages the asynchronous nature of x86 prefetch instructions and is further enhanced by multi-bank parallelism to maximize throughput. Third, recognizing that speculative execution causes more severe disorder issues for prefetching, which cannot be simply mitigated by memory barriers, we develop a counter-speculation hammering technique using control-flow obfuscation and optimized NOP-based pseudo-barriers to maintain prefetch order with minimal overhead. Evaluations across four latest Intel architectures demonstrate $\\rho$Hammer's breakthrough effectiveness: it induces up to 200K+ additional bit flips within 2-hour attack pattern fuzzing processes and has a 112x higher flip rate than the load-based hammering baselines on Comet and Rocket Lake. Also, we are the first to revive Rowhammer attacks on the latest Raptor Lake architecture, where baselines completely fail, achieving stable flip rates of 2,291/min and fast end-to-end exploitation."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Random generation of universal cycles and de Bruijn sequences", "authors": "Joe Sawada, Daniel Gabri\u0107", "subjects": "Discrete Mathematics (cs.DM); Combinatorics (math.CO)", "abstract": "We present practical algorithms for generating universal cycles uniformly at random. In particular, we consider universal cycles for shorthand permutations, subsets and multiset permutations, weak orders, and orientable sequences. Additionally, we consider de Bruijn sequences, weight-range de Bruin sequences, and de Bruijn sequences, with forbidden $0^z$ substring. Each algorithm, seeded with a random element from the given set, applies a random walk of an underlying Eulerian de Bruijn graph to obtain a random arborescence (spanning in-tree). Given the random arborescence and the de Bruijn graph, a corresponding random universal cycle can be generated in constant time per symbol. We present experimental results on the average cover time needed to compute a random arborescence for each object using a Las Vegas algorithm."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Predicting life satisfaction using machine learning and explainable AI", "authors": "Alif Elham Khan, Mohammad Junayed Hasan, Humayra Anjum, Nabeel Mohammed, Sifat Momen", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "Life satisfaction is a crucial facet of human well-being. Hence, research on life satisfaction is incumbent for understanding how individuals experience their lives and influencing interventions targeted at enhancing mental health and well-being. Life satisfaction has traditionally been measured using analog, complicated, and frequently error-prone methods. These methods raise questions concerning validation and propagation. However, this study demonstrates the potential for machine learning algorithms to predict life satisfaction with a high accuracy of 93.80% and a 73.00% macro F1-score. The dataset comes from a government survey of 19000 people aged 16-64 years in Denmark. Using feature learning techniques, 27 significant questions for assessing contentment were extracted, making the study highly reproducible, simple, and easily interpretable. Furthermore, clinical and biomedical large language models (LLMs) were explored for predicting life satisfaction by converting tabular data into natural language sentences through mapping and adding meaningful counterparts, achieving an accuracy of 93.74% and macro F1-score of 73.21%. It was found that life satisfaction prediction is more closely related to the biomedical domain than the clinical domain. Ablation studies were also conducted to understand the impact of data resampling and feature selection techniques on model performance. Moreover, the correlation between primary determinants with different age brackets was analyzed, and it was found that health condition is the most important determinant across all ages. This study demonstrates how machine learning, large language models and XAI can jointly contribute to building trust and understanding in using AI to investigate human behavior, with significant ramifications for academics and professionals working to quantify and comprehend subjective well-being."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          NeurIPT: Foundation Model for Neural Interfaces", "authors": "Zitao Fang, Chenxuan Li, Hongting Zhou, Shuyang Yu, Guodong Du, Ashwaq Qasem, Yang Lu, Jing Li, Junsong Zhang, Sim Kuan Goh", "subjects": "Machine Learning (cs.LG)", "abstract": "Electroencephalography (EEG) has wide-ranging applications, from clinical diagnosis to brain-computer interfaces (BCIs). With the increasing volume and variety of EEG data, there has been growing interest in establishing foundation models (FMs) to scale up and generalize neural decoding. Despite showing early potential, applying FMs to EEG remains challenging due to substantial inter-subject, inter-task, and inter-condition variability, as well as diverse electrode configurations across recording setups. To tackle these open challenges, we propose NeurIPT, a foundation model developed for diverse EEG-based Neural Interfaces with a Pre-trained Transformer by capturing both homogeneous and heterogeneous spatio-temporal characteristics inherent in EEG signals. Temporally, we introduce Amplitude-Aware Masked Pretraining (AAMP), masking based on signal amplitude rather than random intervals, to learn robust representations across varying signal intensities beyond local interpolation. Moreover, this temporal representation is enhanced by a Progressive Mixture-of-Experts (PMoE) architecture, where specialized expert subnetworks are progressively introduced at deeper layers, adapting effectively to the diverse temporal characteristics of EEG signals. Spatially, NeurIPT leverages the 3D physical coordinates of electrodes, enabling effective transfer of embedding across varying EEG settings, and develops Intra-Inter Lobe Pooling (IILP) during fine-tuning to efficiently exploit regional brain features. Empirical evaluations across eight downstream BCI datasets, via fine-tuning, demonstrated NeurIPT consistently achieved state-of-the-art performance, highlighting its broad applicability and robust generalization. Our work pushes forward the state of FMs in EEG and offers insights into scalable and generalizable neural information processing systems."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          ReviewGuard: Enhancing Deficient Peer Review Detection via LLM-Driven Data Augmentation", "authors": "Haoxuan Zhang, Ruochi Li, Sarthak Shrestha, Shree Harshini Mamidala, Revanth Putta, Arka Krishan Aggarwal, Ting Xiao, Junhua Ding, Haihua Chen", "subjects": "Computation and Language (cs.CL)", "abstract": "Peer review serves as the gatekeeper of science, yet the surge in submissions and widespread adoption of large language models (LLMs) in scholarly evaluation present unprecedented challenges. Recent work has focused on using LLMs to improve review efficiency or generate insightful review content. However, unchecked deficient reviews from both human experts and AI systems threaten to systematically undermine the peer review ecosystem and compromise academic integrity. To address this critical issue, we introduce ReviewGuard, an automated system for detecting and categorizing deficient reviews. ReviewGuard employs a comprehensive four-stage LLM-driven framework that: (1) collects ICLR and NeurIPS papers with their corresponding reviews from OpenReview; (2) annotates review types using GPT-4.1 with human validation; (3) addresses class imbalance and data scarcity through LLM-driven synthetic data augmentation, producing a final corpus of 6,634 papers, 24,657 real reviews, and 46,438 synthetic reviews; and (4) fine-tunes both encoder-based models and open source LLMs. We perform comprehensive feature analysis of the structure and quality of the review text. Compared to sufficient reviews, deficient reviews demonstrate lower rating scores, higher self-reported confidence, reduced structural complexity, and a higher proportion of negative sentiment. AI-generated text detection reveals that, since ChatGPT's emergence, AI-generated reviews have increased dramatically. In the evaluation of deficient review detection models, mixed training with synthetic and real review data provides substantial enhancements to recall and F1 scores on the binary task. This study presents the first LLM-driven system for detecting deficient peer reviews, providing evidence to inform AI governance in peer review while offering valuable insights into human-AI collaboration to maintain academic integrity."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          SMP-RCR: A Sparse Multipoint Moment Matching Method for RC Reduction", "authors": "Siyuan Yin, Yuncheng Xu, Lin Liu, Fan Yang, Xuan Zeng, Chengtao An, Yangfeng Su", "subjects": "Systems and Control (eess.SY)", "abstract": "In post--layout circuit simulation, efficient model order reduction (MOR) for many--port resistor--capacitor (RC) circuits remains a crucial issue. The current mainstream MOR methods for such circuits include high--order moment matching methods and elimination methods. High-order moment matching methods--characterized by high accuracy, such as PRIMA and TurboMOR--tend to generate large dense reduced-order systems when the number of ports is large, which impairs the efficiency of MOR. Another common type of MOR method for many--port circuits is based on Gaussian elimination, with the SIP method as a representative. The main limitation of this method lies in the inadequate matching of high--order moments. In this paper, we propose a sparse multipoint moment matching method and present comprehensive theoretical analysis results regarding the multi--frequency high--order moment matching property. Meanwhile, to enhance the algorithm's efficiency, sparse control and deflation techniques are introduced to further optimize the algorithm. Numerical experiments demonstrated that, compared to SIP, the accuracy is improved by more than two orders of magnitude at high frequency points without adding many extra linear components. Compared to TurboMOR methods, our method achieves a speed improvement of more than twice while maintaining the same level of precision."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          LANPO: Bootstrapping Language and Numerical Feedback for Reinforcement Learning in LLMs", "authors": "Ang Li, Yifei Wang, Zhihang Yuan, Stefanie Jegelka, Yisen Wang", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "Reinforcement learning in large language models (LLMs) often relies on scalar rewards, a practice that discards valuable textual rationale buried in the rollouts, forcing the model to explore \\textit{de novo} with each attempt and hindering sample efficiency. While LLMs can uniquely learn from language feedback provided in-context, naively integrating on-line experiences into RL training presents a paradox: feedback from the same problem risks information leakage and memorization, while feedback from different problems often leads to behavior collapse due to irrelevant context. To resolve this tension, we propose \\textbf{Language-And-Numerical Policy Optimization (LANPO)}, a framework that cleanly separates the roles of feedback: language guides exploration, while numerical rewards drive optimization. LANPO builds a dynamic experience pool from past trials and introduces two principles to ensure feedback is effective: \\emph{Reward-Agnostic Reflection} for safe intra-sample self-correction and \\emph{Relevant Abstraction} to distill generalizable lessons from inter-sample experiences. Across mathematical reasoning benchmarks, LANPO enables 7B and 14B models to significantly outperform strong baselines trained with GRPO in test accuracy. Our work provides a robust method for integrating historical experiences into the LLM RL loop, creating more effective and data-efficient learning agents."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Urban-R1: Reinforced MLLMs Mitigate Geospatial Biases for Urban General Intelligence", "authors": "Qiongyan Wang, Xingchen Zou, Yutian Jiang, Haomin Wen, Jiaheng Wei, Qingsong Wen, Yuxuan Liang", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "abstract": "Rapid urbanization intensifies the demand for Urban General Intelligence (UGI), referring to AI systems that can understand and reason about complex urban environments. Recent studies have built urban foundation models using supervised fine-tuning (SFT) of LLMs and MLLMs, yet these models exhibit persistent geospatial bias, producing regionally skewed predictions and limited generalization. To this end, we propose Urban-R1, a reinforcement learning-based post-training framework that aligns MLLMs with the objectives of UGI. Urban-R1 adopts Group Relative Policy Optimization (GRPO) to optimize reasoning across geographic groups and employs urban region profiling as a proxy task to provide measurable rewards from multimodal urban data. Extensive experiments across diverse regions and tasks show that Urban-R1 effectively mitigates geo-bias and improves cross-region generalization, outperforming both SFT-trained and closed-source models. Our results highlight reinforcement learning alignment as a promising pathway toward equitable and trustworthy urban intelligence."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Fit for Purpose? Deepfake Detection in the Real World", "authors": "Guangyu Lin, Li Lin, Christina P. Walker, Daniel S. Schiff, Shu Hu", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "The rapid proliferation of AI-generated content, driven by advances in generative adversarial networks, diffusion models, and multimodal large language models, has made the creation and dissemination of synthetic media effortless, heightening the risks of misinformation, particularly political deepfakes that distort truth and undermine trust in political institutions. In turn, governments, research institutions, and industry have strongly promoted deepfake detection initiatives as solutions. Yet, most existing models are trained and validated on synthetic, laboratory-controlled datasets, limiting their generalizability to the kinds of real-world political deepfakes circulating on social platforms that affect the public. In this work, we introduce the first systematic benchmark based on the Political Deepfakes Incident Database, a curated collection of real-world political deepfakes shared on social media since 2018. Our study includes a systematic evaluation of state-of-the-art deepfake detectors across academia, government, and industry. We find that the detectors from academia and government perform relatively poorly. While paid detection tools achieve relatively higher performance than free-access models, all evaluated detectors struggle to generalize effectively to authentic political deepfakes, and are vulnerable to simple manipulations, especially in the video domain. Results urge the need for politically contextualized deepfake detection frameworks to better safeguard the public in real-world settings."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Toward Understanding Security Issues in the Model Context Protocol Ecosystem", "authors": "Xiaofan Li, Xing Gao", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "abstract": "The Model Context Protocol (MCP) is an emerging open standard that enables AI-powered applications to interact with external tools through structured metadata. A rapidly growing ecosystem has formed around MCP, including a wide range of MCP hosts (i.e., Cursor, Windsurf, Claude Desktop, and Cline), MCP registries (i.e., this http URL, MCP Market, MCP Store, Pulse MCP, Smithery, and npm), and thousands of community-contributed MCP servers. Although the MCP ecosystem is gaining traction, there has been little systematic study of its architecture and associated security risks. In this paper, we present the first comprehensive security analysis of the MCP ecosystem. We decompose MCP ecosystem into three core components: hosts, registries, and servers, and study the interactions and trust relationships among them. Users search for servers on registries and configure them in the host, which translates LLM-generated output into external tool invocations provided by the servers and executes them. Our qualitative analysis reveals that hosts lack output verification mechanisms for LLM-generated outputs, enabling malicious servers to manipulate model behavior and induce a variety of security threats, including but not limited to sensitive data exfiltration. We uncover a wide range of vulnerabilities that enable attackers to hijack servers, due to the lack of a vetted server submission process in registries. To support our analysis, we collect and analyze a dataset of 67,057 servers from six public registries. Our quantitative analysis demonstrates that a substantial number of servers can be hijacked by attackers. Finally, we propose practical defense strategies for MCP hosts, registries, and users. We responsibly disclosed our findings to affected hosts and registries."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          BuildArena: A Physics-Aligned Interactive Benchmark of LLMs for Engineering Construction", "authors": "Tian Xia, Tianrun Gao, Wenhao Deng, Long Wei, Xiaowei Qian, Yixian Jiang, Chenglei Yu, Tailin Wu", "subjects": "Artificial Intelligence (cs.AI)", "abstract": "Engineering construction automation aims to transform natural language specifications into physically viable structures, requiring complex integrated reasoning under strict physical constraints. While modern LLMs possess broad knowledge and strong reasoning capabilities that make them promising candidates for this domain, their construction competencies remain largely unevaluated. To address this gap, we introduce BuildArena, the first physics-aligned interactive benchmark designed for language-driven engineering construction. It contributes to the community in four aspects: (1) a highly customizable benchmarking framework for in-depth comparison and analysis of LLMs; (2) an extendable task design strategy spanning static and dynamic mechanics across multiple difficulty tiers; (3) a 3D Spatial Geometric Computation Library for supporting construction based on language instructions; (4) a baseline LLM agentic workflow that effectively evaluates diverse model capabilities. On eight frontier LLMs, BuildArena comprehensively evaluates their capabilities for language-driven and physics-grounded construction automation. The project page is at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Language over Content: Tracing Cultural Understanding in Multilingual Large Language Models", "authors": "Seungho Cho, Changgeon Ko, Eui Jun Hwang, Junmyeong Lee, Huije Lee, Jong C. Park", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "abstract": "Large language models (LLMs) are increasingly used across diverse cultural contexts, making accurate cultural understanding essential. Prior evaluations have mostly focused on output-level performance, obscuring the factors that drive differences in responses, while studies using circuit analysis have covered few languages and rarely focused on culture. In this work, we trace LLMs' internal cultural understanding mechanisms by measuring activation path overlaps when answering semantically equivalent questions under two conditions: varying the target country while fixing the question language, and varying the question language while fixing the country. We also use same-language country pairs to disentangle language from cultural aspects. Results show that internal paths overlap more for same-language, cross-country questions than for cross-language, same-country questions, indicating strong language-specific patterns. Notably, the South Korea-North Korea pair exhibits low overlap and high variability, showing that linguistic similarity does not guarantee aligned internal representation."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Hallucination Benchmark for Speech Foundation Models", "authors": "Alkis Koudounas, Moreno La Quatra, Manuel Giollo, Sabato Marco Siniscalchi, Elena Baralis", "subjects": "Computation and Language (cs.CL); Sound (cs.SD); Audio and Speech Processing (eess.AS)", "abstract": "Hallucinations in automatic speech recognition (ASR) systems refer to fluent and coherent transcriptions produced by neural ASR models that are completely unrelated to the underlying acoustic input (i.e., the speech signal). While similar to conventional decoding errors in potentially compromising the usability of transcriptions for downstream applications, hallucinations can be more detrimental due to their preservation of syntactically and semantically plausible structure. This apparent coherence can mislead subsequent processing stages and introduce serious risks, particularly in critical domains such as healthcare and law. Conventional evaluation metrics are primarily centered on error-based metrics and fail to distinguish between phonetic inaccuracies and hallucinations. Consequently, there is a critical need for new evaluation frameworks that can effectively identify and assess models with a heightened propensity for generating hallucinated content. To this end, we introduce SHALLOW, the first benchmark framework that systematically categorizes and quantifies hallucination phenomena in ASR along four complementary axes: lexical, phonetic, morphological, and semantic. We define targeted metrics within each category to produce interpretable profiles of model behavior. Through evaluation across various architectures and speech domains, we have found that SHALLOW metrics correlate strongly with word error rate (WER) when recognition quality is high (i.e., low WER). Still, this correlation weakens substantially as WER increases. SHALLOW, therefore, captures fine-grained error patterns that WER fails to distinguish under degraded and challenging conditions. Our framework supports specific diagnosis of model weaknesses and provides feedback for model improvement beyond what aggregate error rates can offer."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Ripple Effect Protocol: Coordinating Agent Populations", "authors": "Ayush Chopra, Aman Sharma, Feroz Ahmad, Luca Muscariello, Vijoy Pandey, Ramesh Raskar", "subjects": "Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "abstract": "Modern AI agents can exchange messages using protocols such as A2A and ACP, yet these mechanisms emphasize communication over coordination. As agent populations grow, this limitation produces brittle collective behavior, where individually smart agents converge on poor group outcomes. We introduce the Ripple Effect Protocol (REP), a coordination protocol in which agents share not only their decisions but also lightweight sensitivities - signals expressing how their choices would change if key environmental variables shifted. These sensitivities ripple through local networks, enabling groups to align faster and more stably than with agent-centric communication alone. We formalize REP's protocol specification, separating required message schemas from optional aggregation rules, and evaluate it across scenarios with varying incentives and network topologies. Benchmarks across three domains: (i) supply chain cascades (Beer Game), (ii) preference aggregation in sparse networks (Movie Scheduling), and (iii) sustainable resource allocation (Fishbanks) show that REP improves coordination accuracy and efficiency over A2A by 41 to 100%, while flexibly handling multimodal sensitivity signals from LLMs. By making coordination a protocol-level capability, REP provides scalable infrastructure for the emerging Internet of Agents"}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          AI-Generated Text Detection in Low-Resource Languages: A Case Study on Urdu", "authors": "Muhammad Ammar, Hadiya Murad Hadi, Usman Majeed Butt", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "abstract": "Large Language Models (LLMs) are now capable of generating text that closely resembles human writing, making them powerful tools for content creation, but this growing ability has also made it harder to tell whether a piece of text was written by a human or by a machine. This challenge becomes even more serious for languages like Urdu, where there are very few tools available to detect AI-generated text. To address this gap, we propose a novel AI-generated text detection framework tailored for the Urdu language. A balanced dataset comprising 1,800 humans authored, and 1,800 AI generated texts, sourced from models such as Gemini, GPT-4o-mini, and Kimi AI was developed. Detailed linguistic and statistical analysis was conducted, focusing on features such as character and word counts, vocabulary richness (Type Token Ratio), and N-gram patterns, with significance evaluated through t-tests and MannWhitney U tests. Three state-of-the-art multilingual transformer models such as mdeberta-v3-base, distilbert-base-multilingualcased, and xlm-roberta-base were fine-tuned on this dataset. The mDeBERTa-v3-base achieved the highest performance, with an F1-score 91.29 and accuracy of 91.26% on the test set. This research advances efforts in contesting misinformation and academic misconduct in Urdu-speaking communities and contributes to the broader development of NLP tools for low resource languages."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          ViT-Transformer: Self-attention mechanism based constitutive modeling for nonlinear heterogeneous materials", "authors": "Yijing Zhou, Shabnam J. Semnani", "subjects": "Computational Engineering, Finance, and Science (cs.CE)", "abstract": "Multi-scale simulations of nonlinear heterogeneous materials and composites are challenging due to the prohibitive computational costs of high-fidelity simulations. Recently, machine learning (ML) based approaches have emerged as promising alternatives to traditional multiscale methods. However, existing ML surrogate constitutive models struggle in capturing long-range dependencies and generalization across microstructures. The recent advancements in attention-based Transformer architectures open the door to a more powerful class of surrogate models. Attention mechanism has demonstrated remarkable capabilities in natural language processing and computer vision. In this work, we introduce a surrogate (meta) model, namely ViT-Transformer, using a Vision Transformer (ViT) encoder and a Transformer-based decoder which are both driven by the self-attention mechanism. The ViT encoder extracts microstructural features from material images, while the decoder is a masked Transformer encoder that combines the latent geometrical features with the macroscopic strain input sequence to predict the corresponding stress response. To enhance training, we propose a random extract training algorithm that improves robustness to sequences of variable length. We design and construct a compact yet diverse dataset via data augmentation, and validate the surrogate model using various composite material images and loading scenarios. Several numerical examples are provided to show the effectiveness and accuracy of the ViT-Transformer model and the training algorithm."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Enhancing Channel Estimation in RIS-aided Systems via Observation Matrix Design", "authors": "Zijian Zhang, Mingyao Cui", "subjects": "Information Theory (cs.IT); Information Retrieval (cs.IR); Signal Processing (eess.SP); Systems and Control (eess.SY)", "abstract": "Reconfigurable intelligent surfaces (RISs) have emerged as a promising technology for enhancing wireless communications through dense antenna arrays. Accurate channel estimation is critical to unlocking their full performance potential. To enhance RIS channel estimators, this paper proposes a novel observation matrix design scheme. Bayesian optimization framework is adopted to generate observation matrices that maximize the mutual information between received pilot signals and RIS channels. To solve the formulated problem efficiently, we develop an alternating Riemannian manifold optimization (ARMO) algorithm to alternately update the receiver combiners and RIS phase-shift matrices. An adaptive kernel training strategy is further introduced to iteratively refine the channel covariance matrix without requiring additional pilot resources. Simulation results demonstrate that the proposed ARMO-enhanced estimator achieves substantial gains in estimation accuracy over state-of-the-art methods."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Human-Aligned Code Readability Assessment with Large Language Models", "authors": "Wendk\u00fbuni C. Ou\u00e9draogo, Yinghua Li, Xueqi Dang, Pawel Borsukiewicz, Xin Zhou, Anil Koyuncu, Jacques Klein, David Lo, Tegawend\u00e9 F. Bissyand\u00e9", "subjects": "Software Engineering (cs.SE)", "abstract": "Code readability is crucial for software comprehension and maintenance, yet difficult to assess at scale. Traditional static metrics often fail to capture the subjective, context-sensitive nature of human judgments. Large Language Models (LLMs) offer a scalable alternative, but their behavior as readability evaluators remains underexplored. We introduce CoReEval, the first large-scale benchmark for evaluating LLM-based code readability assessment, comprising over 1.4 million model-snippet-prompt evaluations across 10 state of the art LLMs. The benchmark spans 3 programming languages (Java, Python, CUDA), 2 code types (functional code and unit tests), 4 prompting strategies (ZSL, FSL, CoT, ToT), 9 decoding settings, and developer-guided prompts tailored to junior and senior personas. We compare LLM outputs against human annotations and a validated static model, analyzing numerical alignment (MAE, Pearson's, Spearman's) and justification quality (sentiment, aspect coverage, semantic clustering). Our findings show that developer-guided prompting grounded in human-defined readability dimensions improves alignment in structured contexts, enhances explanation quality, and enables lightweight personalization through persona framing. However, increased score variability highlights trade-offs between alignment, stability, and interpretability. CoReEval provides a robust foundation for prompt engineering, model alignment studies, and human in the loop evaluation, with applications in education, onboarding, and CI/CD pipelines where LLMs can serve as explainable, adaptable reviewers."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Patronus: Safeguarding Text-to-Image Models against White-Box Adversaries", "authors": "Xinfeng Li, Shengyuan Pang, Jialin Wu, Jiangyi Deng, Huanlong Zhong, Yanjiao Chen, Jie Zhang, Wenyuan Xu", "subjects": "Cryptography and Security (cs.CR); Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Text-to-image (T2I) models, though exhibiting remarkable creativity in image generation, can be exploited to produce unsafe images. Existing safety measures, e.g., content moderation or model alignment, fail in the presence of white-box adversaries who know and can adjust model parameters, e.g., by fine-tuning. This paper presents a novel defensive framework, named Patronus, which equips T2I models with holistic protection to defend against white-box adversaries. Specifically, we design an internal moderator that decodes unsafe input features into zero vectors while ensuring the decoding performance of benign input features. Furthermore, we strengthen the model alignment with a carefully designed non-fine-tunable learning mechanism, ensuring the T2I model will not be compromised by malicious fine-tuning. We conduct extensive experiments to validate the intactness of the performance on safe content generation and the effectiveness of rejecting unsafe content generation. Results also confirm the resilience of Patronus against various fine-tuning attacks by white-box adversaries."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Can Knowledge-Graph-based Retrieval Augmented Generation Really Retrieve What You Need?", "authors": "Junchi Yu, Yujie Liu, Jindong Gu, Philip Torr, Dongzhan Zhou", "subjects": "Artificial Intelligence (cs.AI)", "abstract": "Retrieval-Augmented Generation (RAG) based on knowledge graphs (KGs) enhances large language models (LLMs) by providing structured and interpretable external knowledge. However, existing KG-based RAG methods struggle to retrieve accurate and diverse information from text-rich KGs for complex real-world queries. Process Reward Models (PRMs) offer a way to align the retrieval process of KG-based RAG with query-specific knowledge requirements, but they heavily rely on process-level supervision signals that are expensive and hard to obtain on KGs. To address this challenge, we propose GraphFlow, a framework that efficiently retrieves accurate and diverse knowledge required for real-world queries from text-rich KGs. GraphFlow employs a transition-based flow matching objective to jointly optimize a retrieval policy and a flow estimator. The flow estimator factorizes the reward of the retrieval outcome into the intermediate retrieval states. Such reward factorization guides the retrieval policy to retrieve candidates from KGs in proportion to their reward. This allows GraphFlow to explore high-quality regions of KGs that yield diverse and relevant results. We evaluate GraphFlow on the STaRK benchmark, which includes real-world queries from multiple domains over text-rich KGs. GraphFlow outperforms strong KG-RAG baselines, including GPT-4o, by 10% on average in hit rate and recall. It also shows strong generalization to unseen KGs, demonstrating its effectiveness and robustness."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Copy-Augmented Representation for Structure Invariant Template-Free Retrosynthesis", "authors": "Jiaxi Zhuang, Yu Zhang, Aimin Zhou, Ying Qian", "subjects": "Machine Learning (cs.LG); Computation and Language (cs.CL)", "abstract": "Retrosynthesis prediction is fundamental to drug discovery and chemical synthesis, requiring the identification of reactants that can produce a target molecule. Current template-free methods struggle to capture the structural invariance inherent in chemical reactions, where substantial molecular scaffolds remain unchanged, leading to unnecessarily large search spaces and reduced prediction accuracy. We introduce C-SMILES, a novel molecular representation that decomposes traditional SMILES into element-token pairs with five special tokens, effectively minimizing editing distance between reactants and products. Building upon this representation, we incorporate a copy-augmented mechanism that dynamically determines whether to generate new tokens or preserve unchanged molecular fragments from the product. Our approach integrates SMILES alignment guidance to enhance attention consistency with ground-truth atom mappings, enabling more chemically coherent predictions. Comprehensive evaluation on USPTO-50K and large-scale USPTO-FULL datasets demonstrates significant improvements: 67.2% top-1 accuracy on USPTO-50K and 50.8% on USPTO-FULL, with 99.9% validity in generated molecules. This work establishes a new paradigm for structure-aware molecular generation with direct applications in computational drug discovery."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Atom-anchored LLMs speak Chemistry: A Retrosynthesis Demonstration", "authors": "Alan Kai Hassen, Andrius Bernatavicius, Antonius P. A. Janssen, Mike Preuss, Gerard J. P. van Westen, Djork-Arn\u00e9 Clevert", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Biomolecules (q-bio.BM)", "abstract": "Applications of machine learning in chemistry are often limited by the scarcity and expense of labeled data, restricting traditional supervised methods. In this work, we introduce a framework for molecular reasoning using general-purpose Large Language Models (LLMs) that operates without requiring labeled training data. Our method anchors chain-of-thought reasoning to the molecular structure by using unique atomic identifiers. First, the LLM performs a one-shot task to identify relevant fragments and their associated chemical labels or transformation classes. In an optional second step, this position-aware information is used in a few-shot task with provided class examples to predict the chemical transformation. We apply our framework to single-step retrosynthesis, a task where LLMs have previously underperformed. Across academic benchmarks and expert-validated drug discovery molecules, our work enables LLMs to achieve high success rates in identifying chemically plausible reaction sites ($\\geq90\\%$), named reaction classes ($\\geq40\\%$), and final reactants ($\\geq74\\%$). Beyond solving complex chemical tasks, our work also provides a method to generate theoretically grounded synthetic datasets by mapping chemical knowledge onto the molecular structure and thereby addressing data scarcity."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Symmetry and Generalisation in Neural Approximations of Renormalisation Transformations", "authors": "Cassidy Ashworth, Pietro Li\u00f2, Francesco Caso", "subjects": "Machine Learning (cs.LG); Statistical Mechanics (cond-mat.stat-mech); Artificial Intelligence (cs.AI); Machine Learning (stat.ML)", "abstract": "Deep learning models have proven enormously successful at using multiple layers of representation to learn relevant features of structured data. Encoding physical symmetries into these models can improve performance on difficult tasks, and recent work has motivated the principle of parameter symmetry breaking and restoration as a unifying mechanism underlying their hierarchical learning dynamics. We evaluate the role of parameter symmetry and network expressivity in the generalisation behaviour of neural networks when learning a real-space renormalisation group (RG) transformation, using the central limit theorem (CLT) as a test case map. We consider simple multilayer perceptrons (MLPs) and graph neural networks (GNNs), and vary weight symmetries and activation functions across architectures. Our results reveal a competition between symmetry constraints and expressivity, with overly complex or overconstrained models generalising poorly. We analytically demonstrate this poor generalisation behaviour for certain constrained MLP architectures by recasting the CLT as a cumulant recursion relation and making use of an established framework to propagate cumulants through MLPs. We also empirically validate an extension of this framework from MLPs to GNNs, elucidating the internal information processing performed by these more complex models. These findings offer new insight into the learning dynamics of symmetric networks and their limitations in modelling structured physical transformations."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          DESTinE Block: Private Blockchain Based Data Storage Framework for Power System", "authors": "Khandaker Akramul Haque, Katherine R. Davis", "subjects": "Cryptography and Security (cs.CR)", "abstract": "This paper presents DESTinE Block, a blockchain-based data storage framework designed for power systems and optimized for resource-constrained environments, including grid-edge devices such as single-board computers. The proposed architecture leverages the InterPlanetary File System (IPFS) for storing large files while maintaining secure and traceable metadata on a custom blockchain named DESTinE Block. The metadata, comprising the IPFS Content Identifier (CID), uploader identity, administrator verification, and timestamp; is immutably recorded on-chain to ensure authenticity and integrity. DESTinE Block adopts a dual-blockchain abstraction, where the blockchain remains unaware of the IPFS storage layer to enhance security and limit the exposure of sensitive file data. The consensus mechanism is based on Proof of Authority (PoA), where both an administrator and an uploader with distinct cryptographic key pairs are required to create a block collaboratively. Each block contains verified signatures of both parties and is designed to be computationally efficient, enabling deployment on devices like the Raspberry Pi 5. The framework was tested on both an x86-based device and an ARM64-based Raspberry Pi, demonstrating its potential for secure, decentralized logging and measurement storage in smart grid applications. Moreover, DESTinE Block is compared with a similar framework based on Multichain. The results indicate that DESTinE Block provides a promising solution for tamper-evident data retention in distributed power system infrastructure while maintaining minimal hardware requirements."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          SimpliPy: A Source-Tracking Notional Machine for Simplified Python", "authors": "Moida Praneeth Jain, Venkatesh Choppella", "subjects": "Programming Languages (cs.PL)", "abstract": "Misconceptions about program execution hinder many novice programmers. We introduce SimpliPy, a notional machine designed around a carefully chosen Python subset to clarify core control flow and scoping concepts. Its foundation is a precise operational semantics that explicitly tracks source code line numbers for each execution step, making the link between code and behavior unambiguous. Complementing the dynamic semantics, SimpliPy uses static analysis to generate Control Flow Graphs (CFGs) and identify lexical scopes, helping students build a structural understanding before tracing. We also present an interactive web-based debugger built on these principles. This tool embodies the formal techniques, visualizing the operational state (environments, stack) and using the static CFG to animate control flow directly on the graph during step-by-step execution. SimpliPy thus integrates formal semantics, program analysis, and visualization to offer both a pedagogical approach and a practical demonstration of applying formal methods to program understanding."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          SHIELD: Suppressing Hallucinations In LVLM Encoders via Bias and Vulnerability Defense", "authors": "Yiyang Huang, Liang Shi, Yitian Zhang, Yi Xu, Yun Fu", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "abstract": "Large Vision-Language Models (LVLMs) excel in diverse cross-modal tasks. However, object hallucination, where models produce plausible but inaccurate object descriptions, remains a significant challenge. In contrast to previous work focusing on LLM components, this paper is the first to trace LVLM hallucinations to visual encoders and identifies three key issues: statistical bias, inherent bias, and vulnerability. To address these challenges, we propose SHIELD, a training-free framework that mitigates hallucinations through three strategies: re-weighting visual tokens to reduce statistical bias, introducing noise-derived tokens to counter inherent bias, and applying adversarial attacks with contrastive decoding to address vulnerability. Experiments demonstrate that SHIELD effectively mitigates object hallucinations across diverse benchmarks and LVLM families. Moreover, SHIELD achieves strong performance on the general LVLM benchmark, highlighting its broad applicability. Code will be released."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          FRONTIER-RevRec: A Large-scale Dataset for Reviewer Recommendation", "authors": "Qiyao Peng, Chen Wang, Yinghui Wang, Hongtao Liu, Xuan Guo, Wenjun Wang", "subjects": "Information Retrieval (cs.IR)", "abstract": "Reviewer recommendation is a critical task for enhancing the efficiency of academic publishing workflows. However, research in this area has been persistently hindered by the lack of high-quality benchmark datasets, which are often limited in scale, disciplinary scope, and comparative analyses of different methodologies. To address this gap, we introduce FRONTIER-RevRec, a large-scale dataset constructed from authentic peer review records (2007-2025) from the Frontiers open-access publishing platform this https URL. The dataset contains 177941 distinct reviewers and 478379 papers across 209 journals spanning multiple disciplines including clinical medicine, biology, psychology, engineering, and social sciences. Our comprehensive evaluation on this dataset reveals that content-based methods significantly outperform collaborative filtering. This finding is explained by our structural analysis, which uncovers fundamental differences between academic recommendation and commercial domains. Notably, approaches leveraging language models are particularly effective at capturing the semantic alignment between a paper's content and a reviewer's expertise. Furthermore, our experiments identify optimal aggregation strategies to enhance the recommendation pipeline. FRONTIER-RevRec is intended to serve as a comprehensive benchmark to advance research in reviewer recommendation and facilitate the development of more effective academic peer review systems. The FRONTIER-RevRec dataset is available at: this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          VisionSelector: End-to-End Learnable Visual Token Compression for Efficient Multimodal LLMs", "authors": "Jiaying Zhu, Yurui Zhu, Xin Lu, Wenrui Yan, Dong Li, Kunlin Liu, Xueyang Fu, Zheng-Jun Zha", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Multimodal Large Language Models (MLLMs) encounter significant computational and memory bottlenecks from the massive number of visual tokens generated by high-resolution images or multi-image inputs. Previous token compression techniques are often constrained by heuristic rules that risk discarding critical information. They may suffer from biases, such as attention sinks, that lead to sharp performance drops under aggressive compression ratios. To address these limitations, we reformulate token compression as a lightweight plug-and-play framework that reformulates token compression into an end-to-end learnable decision process. To be specific, we propose VisionSelector, a scorer module decoupled from the MLLM backbone that incorporates a differentiable Top-K mechanism and a curriculum annealing strategy to bridge the training-inference gap, enabling efficient and adaptive token selection various arbitrary compression rates. Remarkably lightweight with only 12.85M trainable parameters, VisionSelector demonstrates generalization across various compression rates and adaptively identifying critical tokens. This leads to superior performance across all compression budgets, evidenced by preserving 100% accuracy on MME with 30% retention budget, outperforming prior methods by 12.14% at 10% retention budget, and doubling prefill speed. Our code is available at this https URL ."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Uncertain Knowledge Graph Completion via Semi-Supervised Confidence Distribution Learning", "authors": "Tianxing Wu, Shutong Zhu, Jingting Wang, Ning Xu, Guilin Qi, Haofen Wang", "subjects": "Artificial Intelligence (cs.AI)", "abstract": "Uncertain knowledge graphs (UKGs) associate each triple with a confidence score to provide more precise knowledge representations. Recently, since real-world UKGs suffer from the incompleteness, uncertain knowledge graph (UKG) completion attracts more attention, aiming to complete missing triples and confidences. Current studies attempt to learn UKG embeddings to solve this problem, but they neglect the extremely imbalanced distributions of triple confidences. This causes that the learnt embeddings are insufficient to high-quality UKG completion. Thus, in this paper, to address the above issue, we propose a new semi-supervised Confidence Distribution Learning (ssCDL) method for UKG completion, where each triple confidence is transformed into a confidence distribution to introduce more supervision information of different confidences to reinforce the embedding learning process. ssCDL iteratively learns UKG embedding by relational learning on labeled data (i.e., existing triples with confidences) and unlabeled data with pseudo labels (i.e., unseen triples with the generated confidences), which are predicted by meta-learning to augment the training data and rebalance the distribution of triple confidences. Experiments on two UKG datasets demonstrate that ssCDL consistently outperforms state-of-the-art baselines in different evaluation metrics."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Fine-tuning of Large Language Models for Constituency Parsing Using a Sequence to Sequence Approach", "authors": "Francisco Jose Cortes Delgado, Eduardo Martinez Gracia, Rafael Valencia Garcia", "subjects": "Computation and Language (cs.CL)", "abstract": "Recent advances in natural language processing with large neural models have opened new possibilities for syntactic analysis based on machine learning. This work explores a novel approach to phrase-structure analysis by fine-tuning large language models (LLMs) to translate an input sentence into its corresponding syntactic structure. The main objective is to extend the capabilities of MiSintaxis, a tool designed for teaching Spanish syntax. Several models from the Hugging Face repository were fine-tuned using training data generated from the AnCora-ES corpus, and their performance was evaluated using the F1 score. The results demonstrate high accuracy in phrase-structure analysis and highlight the potential of this methodology."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Reimagining RDMA Through the Lens of ML", "authors": "Ertza Warraich, Ali Imran, Annus Zulfiqar, Shay Vargaftik, Sonia Fahmy, Muhammad Shahbaz", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC); Networking and Internet Architecture (cs.NI)", "abstract": "As distributed machine learning (ML) workloads scale to thousands of GPUs connected by ultra-high-speed inter-connects, tail latency in collective communication has emerged as a primary bottleneck. Prior RDMA designs, like RoCE, IRN, and SRNIC, enforce strict reliability and in-order delivery, relying on retransmissions and packet sequencing to ensure correctness. While effective for general-purpose workloads, these mechanisms introduce complexity and latency that scale poorly, where even rare packet losses or delays can consistently degrade system performance. We introduce Celeris, a domain-specific RDMA transport that revisits traditional reliability guarantees based on ML's tolerance for lost or partial data. Celeris removes retransmissions and in-order delivery from the RDMA NIC, enabling best-effort transport that exploits the robustness of ML workloads. It retains congestion control (e.g., DCQCN) and manages communication with software-level mechanisms such as adaptive timeouts and data prioritization, while shifting loss recovery to the ML pipeline (e.g., using the Hadamard Transform). Early results show that Celeris reduces 99th-percentile latency by up to 2.3x, cuts BRAM usage by 67%, and nearly doubles NIC resilience to faults -- delivering a resilient, scalable transport tailored for ML at cluster scale."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Asymptotically Stable Quaternion-valued Hopfield-structured Neural Network with Periodic Projection-based Supervised Learning Rules", "authors": "Tianwei Wang, Xinhui Ma, Wei Pang", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "Motivated by the geometric advantages of quaternions in representing rotations and postures, we propose a quaternion-valued supervised learning Hopfield-structured neural network (QSHNN) with a fully connected structure inspired by the classic Hopfield neural network (HNN). Starting from a continuous-time dynamical model of HNNs, we extend the formulation to the quaternionic domain and establish the existence and uniqueness of fixed points with asymptotic stability. For the learning rules, we introduce a periodic projection strategy that modifies standard gradient descent by periodically projecting each 4*4 block of the weight matrix onto the closest quaternionic structure in the least-squares sense. This approach preserves both convergence and quaternionic consistency throughout training. Benefiting from this rigorous mathematical foundation, the experimental model implementation achieves high accuracy, fast convergence, and strong reliability across randomly generated target sets. Moreover, the evolution trajectories of the QSHNN exhibit well-bounded curvature, i.e., sufficient smoothness, which is crucial for applications such as control systems or path planning modules in robotic arms, where joint postures are parameterized by quaternion neurons. Beyond these application scenarios, the proposed model offers a practical implementation framework and a general mathematical methodology for designing neural networks under hypercomplex or non-commutative algebraic structures."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Prior Makes It Possible: From Sublinear Graph Algorithms to LLM Test-Time Methods", "authors": "Avrim Blum, Daniel Hsu, Cyrus Rashtchian, Donya Saless", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computational Complexity (cs.CC); Data Structures and Algorithms (cs.DS)", "abstract": "Test-time augmentation, such as Retrieval-Augmented Generation (RAG) or tool use, critically depends on an interplay between a model's parametric knowledge and externally retrieved information. However, the theoretical underpinnings of this relationship remain poorly understood. Specifically, it is not clear how much pre-training knowledge is required to answer queries with a small number of augmentation steps, which is a desirable property in practice. To address this question, we formulate multi-step reasoning as an $s$-$t$ connectivity problem on a knowledge graph. We represent a model's pre-training parametric knowledge as a partial, potentially noisy subgraph. We view augmentation as querying an oracle for true edges that augment the model's knowledge. Then, we characterize the necessary and sufficient number of augmentation steps for the model to generate an accurate answer given partial prior knowledge. One key result shows a phase transition: if the prior knowledge graph over $n$ vertices is disconnected into small components, then finding a path via augmentation is inefficient and requires $\\Omega(\\sqrt{n})$ queries. On the other hand, once the density of correct knowledge surpasses a threshold, forming a giant component, we can find paths with an expected constant number of queries."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Structuring Security: A Survey of Cybersecurity Ontologies, Semantic Log Processing, and LLMs Application", "authors": "Bruno Louren\u00e7o, Pedro Ad\u00e3o, Jo\u00e3o F. Ferreira, Mario Monteiro Marques, C\u00e1tia Vaz", "subjects": "Cryptography and Security (cs.CR)", "abstract": "This survey investigates how ontologies, semantic log processing, and Large Language Models (LLMs) enhance cybersecurity. Ontologies structure domain knowledge, enabling interoperability, data integration, and advanced threat analysis. Security logs, though critical, are often unstructured and complex. To address this, automated construction of Knowledge Graphs (KGs) from raw logs is emerging as a key strategy for organizing and reasoning over security data. LLMs enrich this process by providing contextual understanding and extracting insights from unstructured content. This work aligns with European Union (EU) efforts such as NIS 2 and the Cybersecurity Taxonomy, highlighting challenges and opportunities in intelligent ontology-driven cyber defense."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          A Deep Learning Framework for Real-Time Image Processing in Medical Diagnostics: Enhancing Accuracy and Speed in Clinical Applications", "authors": "Melika Filvantorkaman, Maral Filvan Torkaman", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "abstract": "Medical imaging plays a vital role in modern diagnostics; however, interpreting high-resolution radiological data remains time-consuming and susceptible to variability among clinicians. Traditional image processing techniques often lack the precision, robustness, and speed required for real-time clinical use. To overcome these limitations, this paper introduces a deep learning framework for real-time medical image analysis designed to enhance diagnostic accuracy and computational efficiency across multiple imaging modalities, including X-ray, CT, and MRI. The proposed system integrates advanced neural network architectures such as U-Net, EfficientNet, and Transformer-based models with real-time optimization strategies including model pruning, quantization, and GPU acceleration. The framework enables flexible deployment on edge devices, local servers, and cloud infrastructures, ensuring seamless interoperability with clinical systems such as PACS and EHR. Experimental evaluations on public benchmark datasets demonstrate state-of-the-art performance, achieving classification accuracies above 92%, segmentation Dice scores exceeding 91%, and inference times below 80 milliseconds. Furthermore, visual explanation tools such as Grad-CAM and segmentation overlays enhance transparency and clinical interpretability. These results indicate that the proposed framework can substantially accelerate diagnostic workflows, reduce clinician workload, and support trustworthy AI integration in time-critical healthcare environments."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Count Counts: Motivating Exploration in LLM Reasoning with Count-based Intrinsic Rewards", "authors": "Xuan Zhang, Ruixiao Li, Zhijian Zhou, Long Li, Yulei Qin, Ke Li, Xing Sun, Xiaoyu Tan, Chao Qu, Yuan Qi", "subjects": "Artificial Intelligence (cs.AI)", "abstract": "Reinforcement Learning (RL) has become a compelling way to strengthen the multi step reasoning ability of Large Language Models (LLMs). However, prevalent RL paradigms still lean on sparse outcome-based rewards and limited exploration, which often drives LLMs toward repetitive and suboptimal reasoning patterns. In this paper, we study the central question of how to design exploration for LLM reasoning and introduce MERCI (Motivating Exploration in LLM Reasoning with Count-based Intrinsic Rewards), a novel RL algorithm that augments policy optimization with a principled intrinsic reward. Building on the idea of count-based exploration, MERCI leverages a lightweight Coin Flipping Network (CFN) to estimate the pseudo count and further epistemic uncertainty over reasoning trajectories, and converts them into an intrinsic reward that values novelty while preserving the learning signal from task rewards. We integrate MERCI into some advanced RL frameworks like Group Relative Policy Optimization (GRPO). Experiments on complex reasoning benchmarks demonstrate that MERCI encourages richer and more varied chains of thought, significantly improves performance over strong baselines, and helps the policy escape local routines to discover better solutions. It indicates that our targeted intrinsic motivation can make exploration reliable for language model reasoning."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          MoS-VLA: A Vision-Language-Action Model with One-Shot Skill Adaptation", "authors": "Ruihan Zhao, Tyler Ingebrand, Sandeep Chinchali, Ufuk Topcu", "subjects": "Robotics (cs.RO)", "abstract": "Vision-Language-Action (VLA) models trained on large robot datasets promise general-purpose, robust control across diverse domains and embodiments. However, existing approaches often fail out-of-the-box when deployed in novel environments, embodiments, or tasks. We introduce Mixture of Skills VLA (MoS-VLA), a framework that represents robot manipulation policies as linear combinations of a finite set of learned basis functions. During pretraining, MoS-VLA jointly learns these basis functions across datasets from the Open X-Embodiment project, producing a structured skill space. At test time, adapting to a new task requires only a single expert demonstration. The corresponding skill representation is then inferred via a lightweight convex optimization problem that minimizes the L1 action error, without requiring gradient updates. This gradient-free adaptation incurs minimal overhead while enabling rapid instantiation of new skills. Empirically, MoS-VLA achieves lower action-prediction error on five out of five unseen datasets and succeeds in both simulation and real-robot tasks where a pretrained VLA model fails outright. Project page: this http URL"}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Feedback Lunch: Deep Feedback Codes for Wiretap Channels", "authors": "Yingyao Zhou, Natasha Devroye, Onur G\u00fcnl\u00fc", "subjects": "Information Theory (cs.IT)", "abstract": "We consider reversely-degraded wiretap channels, for which the secrecy capacity is zero if there is no channel feedback. This work focuses on a seeded modular code design for the Gaussian wiretap channel with channel output feedback, combining universal hash functions for security and learned feedback-based codes for reliability to achieve positive secrecy rates. We study the trade-off between communication reliability and information leakage, illustrating that feedback enables agreeing on a secret key shared between legitimate parties, overcoming the security advantage of the wiretapper. Our findings also motivate code designs for sensing-assisted secure communication, to be used in next-generation integrated sensing and communication methods."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Towards Intelligent Traffic Signaling in Dhaka City Based on Vehicle Detection and Congestion Optimization", "authors": "Kazi Ababil Azam, Hasan Masum, Masfiqur Rahaman, A. B. M. Alim Al Islam", "subjects": "Hardware Architecture (cs.AR); Systems and Control (eess.SY)", "abstract": "The vehicular density in urbanizing cities of developing countries such as Dhaka, Bangladesh result in a lot of traffic congestion, causing poor on-road experiences. Traffic signaling is a key component in effective traffic management for such situations, but the advancements in intelligent traffic signaling have been exclusive to developed countries with structured traffic. The non-lane-based, heterogeneous traffic of Dhaka City requires a contextual approach. This study focuses on the development of an intelligent traffic signaling system feasible in the context of developing countries such as Bangladesh. We propose a pipeline leveraging Real Time Streaming Protocol (RTSP) feeds, a low resources system Raspberry Pi 4B processing, and a state of the art YOLO-based object detection model trained on the Non-lane-based and Heterogeneous Traffic (NHT-1071) dataset to detect and classify heterogeneous traffic. A multi-objective optimization algorithm, NSGA-II, then generates optimized signal timings, minimizing waiting time while maximizing vehicle throughput. We test our implementation in a five-road intersection at Palashi, Dhaka, demonstrating the potential to significantly improve traffic management in similar situations. The developed testbed paves the way for more contextual and effective Intelligent Traffic Signaling (ITS) solutions for developing areas with complicated traffic dynamics such as Dhaka City."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Self-Supervised Learning to Fly using Efficient Semantic Segmentation and Metric Depth Estimation for Low-Cost Autonomous UAVs", "authors": "Sebastian Mocanu, Emil Slusanschi, Marius Leordeanu", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)", "abstract": "This paper presents a vision-only autonomous flight system for small UAVs operating in controlled indoor environments. The system combines semantic segmentation with monocular depth estimation to enable obstacle avoidance, scene exploration, and autonomous safe landing operations without requiring GPS or expensive sensors such as LiDAR. A key innovation is an adaptive scale factor algorithm that converts non-metric monocular depth predictions into accurate metric distance measurements by leveraging semantic ground plane detection and camera intrinsic parameters, achieving a mean distance error of 14.4 cm. The approach uses a knowledge distillation framework where a color-based Support Vector Machine (SVM) teacher generates training data for a lightweight U-Net student network (1.6M parameters) capable of real-time semantic segmentation. For more complex environments, the SVM teacher can be replaced with a state-of-the-art segmentation model. Testing was conducted in a controlled 5x4 meter laboratory environment with eight cardboard obstacles simulating urban structures. Extensive validation across 30 flight tests in a real-world environment and 100 flight tests in a digital-twin environment demonstrates that the combined segmentation and depth approach increases the distance traveled during surveillance and reduces mission time while maintaining 100% success rates. The system is further optimized through end-to-end learning, where a compact student neural network learns complete flight policies from demonstration data generated by our best-performing method, achieving an 87.5% autonomous mission success rate. This work advances practical vision-based drone navigation in structured environments, demonstrating solutions for metric depth estimation and computational efficiency challenges that enable deployment on resource-constrained platforms."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          On the Impossibility of Retrain Equivalence in Machine Unlearning", "authors": "Jiatong Yu, Yinghui He, Anirudh Goyal, Sanjeev Arora", "subjects": "Machine Learning (cs.LG)", "abstract": "Machine unlearning seeks to selectively remove the \"influence\" of specific training data on a model's outputs. The ideal goal is Retrain Equivalence--behavior identical to a model trained from scratch on only the retained data. This goal was formulated for models trained on i.i.d. data batches, but modern pipelines often involve multi-stage training, with each stage having a distinct data distribution and objective. Examples include LLM fine-tuning for alignment, reasoning ability, etc. Our study shows via theory and experiments that this shift to multi-stage training introduces a fundamental barrier for machine unlearning. The theory indicates that the outcome of local unlearning--methods that only use gradients computed on the forget set--is path-dependent. That is, a model's behavior during unlearning is influenced by the order of its training stages during learning, making it impossible for path-oblivious algorithms to universally achieve Retrain Equivalence. We empirically demonstrate the same phenomenon in LLM post-training across Llama and Qwen models (1B to 14B) with gradient ascent, NPO, and SimNPO local unlearning algorithms. Models fine-tuned via different orderings of identical training stages diverge in behavior during unlearning, with the degradation in GSM8K accuracy after unlearning varying by over 20% across paths. We also observe that some learning paths consistently produce models that unlearn slowly. During unlearning, whether the probability mass gets squeezed into paraphrasing or alternative concepts is also path-dependent. These results consistently show that Retrain Equivalence is an ill-posed target for local unlearning algorithms, so long as the target models are trained in stages. In situations where access to models' training histories is hard, the current work calls for rethinking the definition and desiderata of machine unlearning."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Linking Facial Recognition of Emotions and Socially Shared Regulation in Medical Simulation", "authors": "Xiaoshan Huang, Tianlong Zhong, Haolun Wu, Yeyu Wang, Ethan Churchill, Xue Liu, David Williamson Shaffer", "subjects": "Human-Computer Interaction (cs.HC)", "abstract": "Computer-supported simulation enables a practical alternative for medical training purposes. This study investigates the co-occurrence of facial-recognition-derived emotions and socially shared regulation of learning (SSRL) interactions in a medical simulation training context. Using transmodal analysis (TMA), we compare novice and expert learners' affective and cognitive engagement patterns during collaborative virtual diagnosis tasks. Results reveal that expert learners exhibit strong associations between socio-cognitive interactions and high-arousal emotions (surprise, anger), suggesting focused, effortful engagement. In contrast, novice learners demonstrate stronger links between socio-cognitive processes and happiness or sadness, with less coherent SSRL patterns, potentially indicating distraction or cognitive overload. Transmodal analysis of multimodal data (facial expressions and discourse) highlights distinct regulatory strategies between groups, offering methodological and practical insights for computer-supported cooperative work (CSCW) in medical education. Our findings underscore the role of emotion-regulation dynamics in collaborative expertise development and suggest the need for tailored scaffolding to support novice learners' socio-cognitive and affective engagement."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Prompt Optimization via Retrieved Reasoning Assets and Multi-Agent Analysis", "authors": "Wonduk Seo, Juhyeon Lee, Junseo Koh, Hyunjin An, Jian Park, Seunghyun Lee, Haihua Chen, Yi Bu", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Human-Computer Interaction (cs.HC); Information Retrieval (cs.IR)", "abstract": "Prompt optimization has emerged as an effective alternative to retraining for improving the performance of Large Language Models (LLMs). However, most existing approaches treat evaluation as a black box, relying solely on numerical scores while offering limited insight into why a prompt succeeds or fails. They also depend heavily on trial-and-error refinements, which are difficult to interpret and control. In this paper, we introduce MA-SAPO, a Multi-Agent framework for Score-Aware Prompt Optimization. Compared to prior methods, MA-SAPO explicitly couples evaluation outcomes with structured reasoning to guide systematic edits. The framework specifically consists of two stages: during the Reasoning Phase, agents collaboratively explain metric scores, diagnose weaknesses, and synthesize targeted refinements that are stored as reusable reasoning assets; during the Test Phase, agents retrieve these assets to analyze optimized prompts and apply only evidence-grounded edits. By turning evaluation signals into interpretable reasoning chains, MA-SAPO produces prompt refinements that are more transparent, auditable, and controllable. Experiments on the HelpSteer1/2 benchmarks demonstrate consistent improvements over single-pass prompting, retrieval-augmented baselines, and prior multi-agent strategies, validating the effectiveness of our approach."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          A Versatile Framework for Designing Group-Sparse Adversarial Attacks", "authors": "Alireza Heshmati, Saman Soleimani Roudi, Sajjad Amini, Shahrokh Ghaemmaghami, Farokh Marvasti", "subjects": "Cryptography and Security (cs.CR); Machine Learning (cs.LG); Image and Video Processing (eess.IV)", "abstract": "Existing adversarial attacks often neglect perturbation sparsity, limiting their ability to model structural changes and to explain how deep neural networks (DNNs) process meaningful input patterns. We propose ATOS (Attack Through Overlapping Sparsity), a differentiable optimization framework that generates structured, sparse adversarial perturbations in element-wise, pixel-wise, and group-wise forms. For white-box attacks on image classifiers, we introduce the Overlapping Smoothed L0 (OSL0) function, which promotes convergence to a stationary point while encouraging sparse, structured perturbations. By grouping channels and adjacent pixels, ATOS improves interpretability and helps identify robust versus non-robust features. We approximate the L-infinity gradient using the logarithm of the sum of exponential absolute values to tightly control perturbation magnitude. On CIFAR-10 and ImageNet, ATOS achieves a 100% attack success rate while producing significantly sparser and more structurally coherent perturbations than prior methods. The structured group-wise attack highlights critical regions from the network's perspective, providing counterfactual explanations by replacing class-defining regions with robust features from the target class."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          MultiVerse: A Multi-Turn Conversation Benchmark for Evaluating Large Vision and Language Models", "authors": "Young-Jun Lee, Byung-Kwan Lee, Jianshu Zhang, Yechan Hwang, Byungsoo Ko, Han-Gyu Kim, Dongyu Yao, Xuankun Rong, Eojin Joo, Seung-Ho Han, Bowon Ko, Ho-Jin Choi", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Vision-and-Language Models (VLMs) have shown impressive capabilities on single-turn benchmarks, yet real-world applications often demand more intricate multi-turn dialogues. Existing multi-turn datasets (e.g, MMDU, ConvBench) only partially capture the breadth and depth of conversational scenarios encountered by users. In this work, we introduce MultiVerse, a novel multi-turn conversation benchmark featuring 647 dialogues - each averaging four turns - derived from a diverse set of 12 popular VLM evaluation benchmarks. With 484 tasks and 484 interaction goals, MultiVerse covers a wide range of topics, from factual knowledge and perception to advanced reasoning tasks such as mathematics and coding. To facilitate robust assessment, we propose a checklist-based evaluation method that leverages GPT-4o as the automated evaluator, measuring performance across 37 key aspects, including perceptual accuracy, linguistic clarity, and factual correctness. We evaluate 18 VLMs on MultiVerse, revealing that even the strongest models (e.g., GPT-4o) achieve only a 50% success rate in complex multi-turn conversations, highlighting the dataset's challenging nature. Notably, we find that providing full dialogue context significantly enhances performance for smaller or weaker models, emphasizing the importance of in-context learning. We believe MultiVerse is a landscape of evaluating multi-turn interaction abilities for VLMs."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Structured Interfaces for Automated Reasoning with 3D Scene Graphs", "authors": "Aaron Ray, Jacob Arkin, Harel Biggie, Chuchu Fan, Luca Carlone, Nicholas Roy", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Robotics (cs.RO)", "abstract": "In order to provide a robot with the ability to understand and react to a user's natural language inputs, the natural language must be connected to the robot's underlying representations of the world. Recently, large language models (LLMs) and 3D scene graphs (3DSGs) have become a popular choice for grounding natural language and representing the world. In this work, we address the challenge of using LLMs with 3DSGs to ground natural language. Existing methods encode the scene graph as serialized text within the LLM's context window, but this encoding does not scale to large or rich 3DSGs. Instead, we propose to use a form of Retrieval Augmented Generation to select a subset of the 3DSG relevant to the task. We encode a 3DSG in a graph database and provide a query language interface (Cypher) as a tool to the LLM with which it can retrieve relevant data for language grounding. We evaluate our approach on instruction following and scene question-answering tasks and compare against baseline context window and code generation methods. Our results show that using Cypher as an interface to 3D scene graphs scales significantly better to large, rich graphs on both local and cloud-based models. This leads to large performance improvements in grounded language tasks while also substantially reducing the token count of the scene graph content. A video supplement is available at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Unleashing Diverse Thinking Modes in LLMs through Multi-Agent Collaboration", "authors": "Zhixuan He, Yue Feng", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multiagent Systems (cs.MA)", "abstract": "Large Language Models (LLMs) demonstrate strong performance but often lack interpretable reasoning. This paper introduces the Multi-Agent Collaboration Framework for Diverse Thinking Modes (DiMo), which enhances both performance and interpretability by simulating a structured debate among four specialized LLM agents. Each agent embodies a distinct reasoning paradigm, allowing the framework to collaboratively explore diverse cognitive approaches. Through iterative debate, agents challenge and refine initial responses, yielding more robust conclusions and an explicit, auditable reasoning chain. Across six benchmarks and under a unified open-source setup, DiMo improves accuracy over widely used single-model and debate baselines, with the largest gains on math. We position DiMo as a semantics-aware, Web-native multi-agent framework: it models human-machine intelligence with LLM agents that produce semantically typed, URL-annotated evidence chains for explanations and user-friendly interactions. Although our experiments use standard reasoning benchmarks, the framework is designed to be instantiated over Web corpora and knowledge graphs, combining retrieval-augmented reasoning with structured justifications that downstream systems can inspect and reuse."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Simulation-free Structure Learning for Stochastic Dynamics", "authors": "Noah El Rimawi-Fine, Adam Stecklov, Lucas Nelson, Mathieu Blanchette, Alexander Tong, Stephen Y. Zhang, Lazar Atanackovic", "subjects": "Machine Learning (cs.LG); Quantitative Methods (q-bio.QM)", "abstract": "Modeling dynamical systems and unraveling their underlying causal relationships is central to many domains in the natural sciences. Various physical systems, such as those arising in cell biology, are inherently high-dimensional and stochastic in nature, and admit only partial, noisy state measurements. This poses a significant challenge for addressing the problems of modeling the underlying dynamics and inferring the network structure of these systems. Existing methods are typically tailored either for structure learning or modeling dynamics at the population level, but are limited in their ability to address both problems together. In this work, we address both problems simultaneously: we present StructureFlow, a novel and principled simulation-free approach for jointly learning the structure and stochastic population dynamics of physical systems. We showcase the utility of StructureFlow for the tasks of structure learning from interventions and dynamical (trajectory) inference of conditional population dynamics. We empirically evaluate our approach on high-dimensional synthetic systems, a set of biologically plausible simulated systems, and an experimental single-cell dataset. We show that StructureFlow can learn the structure of underlying systems while simultaneously modeling their conditional population dynamics -- a key step toward the mechanistic understanding of systems behavior."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Foundation and Large-Scale AI Models in Neuroscience: A Comprehensive Review", "authors": "Shihao Yang, Xiying Huang, Danilo Bernardo, Jun-En Ding, Andrew Michael, Jingmei Yang, Patrick Kwan, Ashish Raj, Feng Liu", "subjects": "Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE)", "abstract": "The advent of large-scale artificial intelligence (AI) models has a transformative effect on neuroscience research, which represents a paradigm shift from the traditional computational methods through the facilitation of end-to-end learning from raw brain signals and neural data. In this paper, we explore the transformative effects of large-scale AI models on five major neuroscience domains: neuroimaging and data processing, brain-computer interfaces and neural decoding, molecular neuroscience and genomic modeling, clinical assistance and translational frameworks, and disease-specific applications across neurological and psychiatric disorders. These models are demonstrated to address major computational neuroscience challenges, including multimodal neural data integration, spatiotemporal pattern interpretation, and the derivation of translational frameworks for clinical deployment. Moreover, the interaction between neuroscience and AI has become increasingly reciprocal, as biologically informed architectural constraints are now incorporated to develop more interpretable and computationally efficient models. This review highlights both the notable promise of such technologies and key implementation considerations, with particular emphasis on rigorous evaluation frameworks, effective domain knowledge integration, and comprehensive ethical guidelines for clinical use. Finally, a systematic listing of critical neuroscience datasets used to derive and validate large-scale AI models across diverse research applications is provided."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Universal and Transferable Attacks on Pathology Foundation Models", "authors": "Yuntian Wang, Xilin Yang, Che-Yung Shen, Nir Pillar, Aydogan Ozcan", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Medical Physics (physics.med-ph)", "abstract": "We introduce Universal and Transferable Adversarial Perturbations (UTAP) for pathology foundation models that reveal critical vulnerabilities in their capabilities. Optimized using deep learning, UTAP comprises a fixed and weak noise pattern that, when added to a pathology image, systematically disrupts the feature representation capabilities of multiple pathology foundation models. Therefore, UTAP induces performance drops in downstream tasks that utilize foundation models, including misclassification across a wide range of unseen data distributions. In addition to compromising the model performance, we demonstrate two key features of UTAP: (1) universality: its perturbation can be applied across diverse field-of-views independent of the dataset that UTAP was developed on, and (2) transferability: its perturbation can successfully degrade the performance of various external, black-box pathology foundation models - never seen before. These two features indicate that UTAP is not a dedicated attack associated with a specific foundation model or image dataset, but rather constitutes a broad threat to various emerging pathology foundation models and their applications. We systematically evaluated UTAP across various state-of-the-art pathology foundation models on multiple datasets, causing a significant drop in their performance with visually imperceptible modifications to the input images using a fixed noise pattern. The development of these potent attacks establishes a critical, high-standard benchmark for model robustness evaluation, highlighting a need for advancing defense mechanisms and potentially providing the necessary assets for adversarial training to ensure the safe and reliable deployment of AI in pathology."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Safire: Similarity Framework for Visualization Retrieval", "authors": "Huyen N. Nguyen, Nils Gehlenborg", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI); Information Retrieval (cs.IR); Machine Learning (cs.LG)", "abstract": "Effective visualization retrieval necessitates a clear definition of similarity. Despite the growing body of work in specialized visualization retrieval systems, a systematic approach to understanding visualization similarity remains absent. We introduce the Similarity Framework for Visualization Retrieval (Safire), a conceptual model that frames visualization similarity along two dimensions: comparison criteria and representation modalities. Comparison criteria identify the aspects that make visualizations similar, which we divide into primary facets (data, visual encoding, interaction, style, metadata) and derived properties (data-centric and human-centric measures). Safire connects what to compare with how comparisons are executed through representation modalities. We categorize existing representation approaches into four groups based on their levels of information content and visualization determinism: raster image, vector image, specification, and natural language description, together guiding what is computable and comparable. We analyze several visualization retrieval systems using Safire to demonstrate its practical value in clarifying similarity considerations. Our findings reveal how particular criteria and modalities align across different use cases. Notably, the choice of representation modality is not only an implementation detail but also an important decision that shapes retrieval capabilities and limitations. Based on our analysis, we provide recommendations and discuss broader implications for multimodal learning, AI applications, and visualization reproducibility."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Robust Dynamic Staffing with Predictions", "authors": "Yiding Feng, Vahideh Manshadi, Rad Niazadeh, Saba Neyshabouri", "subjects": "Data Structures and Algorithms (cs.DS); Machine Learning (cs.LG); Systems and Control (eess.SY)", "abstract": "We consider a natural dynamic staffing problem in which a decision-maker sequentially hires workers over a finite horizon to meet an unknown demand revealed at the end. Predictions about demand arrive over time and become increasingly accurate, while worker availability decreases. This creates a fundamental trade-off between hiring early to avoid understaffing (when workers are more available but forecasts are less reliable) and hiring late to avoid overstaffing (when forecasts are more accurate but availability is lower). This problem is motivated by last-mile delivery operations, where companies such as Amazon rely on gig-economy workers whose availability declines closer to the operating day. To address practical limitations of Bayesian models (in particular, to remain agnostic to the underlying forecasting method), we study this problem under adversarial predictions. In this model, sequential predictions are adversarially chosen uncertainty intervals that (approximately) contain the true demand. The objective is to minimize worst-case staffing imbalance cost. Our main result is a simple and computationally efficient online algorithm that is minimax optimal. We first characterize the minimax cost against a restricted adversary via a polynomial-size linear program, then show how to emulate this solution in the general case. While our base model focuses on a single demand, we extend the framework to multiple demands (with egalitarian/utilitarian objectives), to settings with costly reversals of hiring decisions, and to inconsistent prediction intervals. We also introduce a practical \"re-solving\" variant of our algorithm, which we prove is also minimax optimal. Finally we conduct numerical experiments showing that our algorithms outperform Bayesian heuristics in both cost and speed, and are competitive with (approximate or exact) Bayesian-optimal policies when those can be computed."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          HYDRA: HYbrid knowledge Distillation and spectral Reconstruction Algorithm for high channel hyperspectral camera applications", "authors": "Christopher Thirgood, Oscar Mendez, Erin Ling, Jon Storey, Simon Hadfield", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Hyperspectral images (HSI) promise to support a range of new applications in computer vision. Recent research has explored the feasibility of generalizable Spectral Reconstruction (SR), the problem of recovering a HSI from a natural three-channel color image in unseen scenarios. However, previous Multi-Scale Attention (MSA) works have only demonstrated sufficient generalizable results for very sparse spectra, while modern HSI sensors contain hundreds of channels. This paper introduces a novel approach to spectral reconstruction via our HYbrid knowledge Distillation and spectral Reconstruction Architecture (HYDRA). Using a Teacher model that encapsulates latent hyperspectral image data and a Student model that learns mappings from natural images to the Teacher's encoded domain, alongside a novel training method, we achieve high-quality spectral reconstruction. This addresses key limitations of prior SR models, providing SOTA performance across all metrics, including an 18\\% boost in accuracy, and faster inference times than current SOTA models at various channel depths."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Contrasting the Hyperparameter Tuning Impact Across Software Defect Prediction Scenarios", "authors": "Mohamed Sami Rakha, Andriy Miranskyy, Daniel Alencar da Costa", "subjects": "Software Engineering (cs.SE)", "abstract": "Software defect prediction (SDP) is crucial for delivering high-quality software products. Recent research has indicated that prediction performance improvements in SDP are achievable by applying hyperparameter tuning to a particular SDP scenario. However, the positive impact resulting from the hyperparameter tuning step may differ based on the targeted SDP scenario. Comparing the impact of hyperparameter tuning across SDP scenarios is necessary to provide comprehensive insights and enhance the robustness, generalizability, and, eventually, the practicality of SDP modeling for quality assurance. Therefore, in this study, we contrast the impact of hyperparameter tuning across two pivotal and consecutive SDP scenarios: (1) Inner Version Defect Prediction (IVDP) and (2) Cross Version Defect Prediction (CVDP). The main distinctions between the two scenarios lie in the scope of defect prediction and the selected evaluation setups. This study's experiments use common evaluation setups, 28 machine learning (ML) algorithms, 53 post-release software datasets, two tuning algorithms, and five optimization metrics. We apply statistical analytics to compare the SDP performance impact differences by investigating the overall impact, the single ML algorithm impact, and variations across different software dataset sizes. The results indicate that the SDP gains within the IVDP scenario are significantly larger than those within the CVDP scenario. The results reveal that asserting performance gains for up to 24 out of 28 ML algorithms may not hold across multiple SDP scenarios. Furthermore, we found that small software datasets are more susceptible to larger differences in performance impacts. Overall, the study findings recommend software engineering researchers and practitioners to consider the effect of the selected SDP scenario when expecting performance gains from hyperparameter tuning."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          All You Need is One: Capsule Prompt Tuning with a Single Vector", "authors": "Yiyang Liu, James C. Liang, Heng Fan, Wenhao Yang, Yiming Cui, Xiaotian Han, Lifu Huang, Dongfang Liu, Qifan Wang, Cheng Han", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "abstract": "Prompt-based learning has emerged as a parameter-efficient finetuning (PEFT) approach to facilitate Large Language Model (LLM) adaptation to downstream tasks by conditioning generation with task-aware guidance. Despite its successes, current prompt-based learning methods heavily rely on laborious grid searching for optimal prompt length and typically require considerable number of prompts, introducing additional computational burden. Worse yet, our pioneer findings indicate that the task-aware prompt design is inherently limited by its absence of instance-aware information, leading to a subtle attention interplay with the input sequence. In contrast, simply incorporating instance-aware information as a part of the guidance can enhance the prompt-tuned model performance without additional fine-tuning. Moreover, we find an interesting phenomenon, namely \"attention anchor\", that incorporating instance-aware tokens at the earliest position of the sequence can successfully preserve strong attention to critical structural information and exhibit more active attention interaction with all input tokens. In light of our observation, we introduce Capsule Prompt-Tuning (CaPT), an efficient and effective solution that leverages off-the-shelf, informative instance semantics into prompt-based learning. Our approach innovatively integrates both instance-aware and task-aware information in a nearly parameter-free manner (i.e., one single capsule prompt). Empirical results demonstrate that our method can exhibit superior performance across various language tasks (e.g., 84.03\\% average accuracy on T5-Large), serving as an \"attention anchor,\" while enjoying high parameter efficiency (e.g., 0.003\\% of model parameters on Llama3.2-1B)."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Evaluating protein binding interfaces with PUMBA", "authors": "Azam Shirali, Giri Narasimhan", "subjects": "Machine Learning (cs.LG); Quantitative Methods (q-bio.QM)", "abstract": "Protein-protein docking tools help in studying interactions between proteins, and are essential for drug, vaccine, and therapeutic development. However, the accuracy of a docking tool depends on a robust scoring function that can reliably differentiate between native and non-native complexes. PIsToN is a state-of-the-art deep learning-based scoring function that uses Vision Transformers in its architecture. Recently, the Mamba architecture has demonstrated exceptional performance in both natural language processing and computer vision, often outperforming Transformer-based models in their domains. In this study, we introduce PUMBA (Protein-protein interface evaluation with Vision Mamba), which improves PIsToN by replacing its Vision Transformer backbone with Vision Mamba. This change allows us to leverage Mamba's efficient long-range sequence modeling for sequences of image patches. As a result, the model's ability to capture both global and local patterns in protein-protein interface features is significantly improved. Evaluation on several widely-used, large-scale public datasets demonstrates that PUMBA consistently outperforms its original Transformer-based predecessor, PIsToN."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Active Target Discovery under Uninformative Prior: The Power of Permanent and Transient Memory", "authors": "Anindya Sarkar, Binglin Ji, Yevgeniy Vorobeychik", "subjects": "Machine Learning (cs.LG)", "abstract": "In many scientific and engineering fields, where acquiring high-quality data is expensive--such as medical imaging, environmental monitoring, and remote sensing--strategic sampling of unobserved regions based on prior observations is crucial for maximizing discovery rates within a constrained budget. The rise of powerful generative models, such as diffusion models, has enabled active target discovery in partially observable environments by leveraging learned priors--probabilistic representations that capture underlying structure from data. With guidance from sequentially gathered task-specific observations, these models can progressively refine exploration and efficiently direct queries toward promising regions. However, in domains where learning a strong prior is infeasible due to extremely limited data or high sampling cost (such as rare species discovery, diagnostics for emerging diseases, etc.), these methods struggle to generalize. To overcome this limitation, we propose a novel approach that enables effective active target discovery even in settings with uninformative priors, ensuring robust exploration and adaptability in complex real-world scenarios. Our framework is theoretically principled and draws inspiration from neuroscience to guide its design. Unlike black-box policies, our approach is inherently interpretable, providing clear insights into decision-making. Furthermore, it guarantees a strong, monotonic improvement in prior estimates with each new observation, leading to increasingly accurate sampling and reinforcing both reliability and adaptability in dynamic settings. Through comprehensive experiments and ablation studies across various domains, including species distribution modeling and remote sensing, we demonstrate that our method substantially outperforms baseline approaches."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Renaissance of RNNs in Streaming Clinical Time Series: Compact Recurrence Remains Competitive with Transformers", "authors": "Ran Tong, Jiaqi Liu, Su Liu, Xin Hu, Lanruo Wang", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "We present a compact, strictly causal benchmark for streaming clinical time series on the MIT--BIH Arrhythmia Database using per-second heart rate. Two tasks are studied under record-level, non-overlapping splits: near-term tachycardia risk (next ten seconds) and one-step heart rate forecasting. We compare a GRU-D (RNN) and a Transformer under matched training budgets against strong non-learned baselines. Evaluation is calibration-aware for classification and proper for forecasting, with temperature scaling and grouped bootstrap confidence intervals. On MIT-BIH, GRU-D slightly surpasses the Transformer for tachycardia risk, while the Transformer clearly lowers forecasting error relative to GRU-D and persistence. Our results show that, in longitudinal monitoring, model choice is task-dependent: compact RNNs remain competitive for short-horizon risk scoring, whereas compact Transformers deliver clearer gains for point forecasting."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          An Exact Algorithm for the Unanimous Vote Problem", "authors": "Feyza Duman Keles, Lisa Hellerstein, Kunal Marwaha, Christopher Musco, Xinchen Yang", "subjects": "Data Structures and Algorithms (cs.DS)", "abstract": "Consider $n$ independent, biased coins, each with a known probability of heads. Presented with an ordering of these coins, flip (i.e., toss) each coin once, in that order, until we have observed both a *head* and a *tail*, or flipped all coins. The Unanimous Vote problem asks us to find the ordering that minimizes the expected number of flips. Gkenosis et al. [arXiv:1806.10660] gave a polynomial-time $\\phi$-approximation algorithm for this problem, where $\\phi \\approx 1.618$ is the golden ratio. They left open whether the problem was NP-hard. We answer this question by giving an exact algorithm that runs in time $O(n \\log n)$. The Unanimous Vote problem is an instance of the more general Stochastic Boolean Function Evaluation problem: it thus becomes one of the only such problems known to be solvable in polynomial time. Our proof uses simple interchange arguments to show that the optimal ordering must be close to the ordering produced by a natural greedy algorithm. Beyond our main result, we compare the optimal ordering with the best adaptive strategy, proving a tight adaptivity gap of $1.2\\pm o(1)$ for the Unanimous Vote problem."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Ellipsoidal Filtration for Topological Denoising of Recurrent Signals", "authors": "Omer Bahadir Eryilmaz, Cihan Katar, Max A. Little", "subjects": "Computational Geometry (cs.CG)", "abstract": "We introduce ellipsoidal filtration, a novel method for persistent homology, and demonstrate its effectiveness in denoising recurrent signals. Unlike standard Rips filtrations, which use isotropic neighbourhoods and ignore the signal's direction of evolution, our approach constructs ellipsoids aligned with local gradients to capture trajectory flow. The death scale of the most persistent H_1 feature defines a data-driven neighbourhood for averaging. Experiments on synthetic signals show that our method achieves better noise reduction than both topological and moving-average filters, especially for low-amplitude components."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Filtering of Small Components for Isosurface Generation", "authors": "Devin Zhao, Rephael Wenger", "subjects": "Graphics (cs.GR); Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Let $f: \\mathbb{R}^3 \\rightarrow \\mathbb{R}$ be a scalar field. An isosurface is a piecewise linear approximation of a level set $f^{-1}(\\sigma)$ for some $\\sigma \\in \\mathbb{R}$ built from some regular grid sampling of $f$. Isosurfaces constructed from scanned data such as CT scans or MRIs often contain extremely small components that distract from the visualization and do not form part of any geometric model produced from the data. Simple prefiltering of the data can remove such small components while having no effect on the large components that form the body of the visualization. We present experimental results on such filtering."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Temporal Understanding under Deictic Frame of Reference", "authors": "Damin Zhang, Julia Rayz", "subjects": "Computation and Language (cs.CL)", "abstract": "Understanding time is fundamental to human cognition, where temporal experience is often conceptualized through spatial metaphors grounded in sensory-motor experience. For example, \"summer is approaching\" parallels \"We are approaching the summer\". In such expressions, humans rely on a frame of reference (FoR) to interpret meaning relative to a particular viewpoint. Extending this concept to time, a temporal frame of reference (t-FoR) defines how temporal relations are perceived relative to an experiencer's moment of \"now\". While Large Language Models (LLMs) have shown remarkable advances in natural language understanding, their ability to interpret and reason about time remains limited. In this work, we introduce TUuD (Temporal Understanding under Deictic t-FoR), a framework that evaluates how LLMs interpret time-event and event-event relations when the reference point of \"now\" dynamically shifts along a timeline. Following recent work on temporal cognition \\cite{li2025other}, LLMs are prompted to rate the similarity between the current moment and a target event from 0.00 (completely dissimilar) to 1.00 (highly similar), where similarity quantifies perceived temporal alignment between the two points. Our results show that four evaluated LLMs exhibit measurable adaptation to a deictic t-FoR, with similarity ratings peaking around the present and decreasing toward past and future events. The adaptation, however, weakens beyond near-term contexts, suggesting that while LLMs display partial human-like temporal cognition, their temporal reasoning remains sensitive to reference-frame shifts and temporal distance."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Investigating the Impact of Rationales for LLMs on Natural Language Understanding", "authors": "Wenhang Shi, Shuqing Bian, Yiren Chen, Xinyi Zhang, Zhe Zhao, Pengfei Hu, Wei Lu, Xiaoyong Du", "subjects": "Computation and Language (cs.CL)", "abstract": "Chain-of-thought (CoT) rationales, which provide step-by-step reasoning to derive final answers, benefit LLMs in both inference and training. Incorporating rationales, either by generating them before answering during inference, or by placing them before or after the original answers during training - significantly improves model performance on mathematical, symbolic and commonsense reasoning tasks. However, most work focuses on the role of rationales in these reasoning tasks, overlooking their potential impact on other important tasks like natural language understanding (NLU) tasks. In this work, we raise the question: Can rationales similarly benefit NLU tasks? To conduct a systematic exploration, we construct NLURC, a comprehensive and high-quality NLU dataset collection with rationales, and develop various rationale-augmented methods. Through exploring the applicability of these methods on NLU tasks using the dataset, we uncover several potentially surprising findings: (1) CoT inference shifts from hindering NLU performance to surpassing direct label prediction as model size grows, indicating a positive correlation. (2) Most rationale-augmented training methods perform worse than label-only training, with one specially designed method consistently achieving improvements. (3) LLMs trained with rationales achieve significant performance gains on unseen NLU tasks, rivaling models ten times their size, while delivering interpretability on par with commercial LLMs."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          High-Dimensional Privacy-Utility Dynamics of Noisy Stochastic Gradient Descent on Least Squares", "authors": "Shurong Lin, Eric D. Kolaczyk, Adam Smith, Elliot Paquette", "subjects": "Machine Learning (cs.LG)", "abstract": "The interplay between optimization and privacy has become a central theme in privacy-preserving machine learning. Noisy stochastic gradient descent (SGD) has emerged as a cornerstone algorithm, particularly in large-scale settings. These variants of gradient methods inject carefully calibrated noise into each update to achieve differential privacy, the gold standard notion of rigorous privacy guarantees. Prior work primarily provides various bounds on statistical risk and privacy loss for noisy SGD, yet the \\textit{exact} behavior of the process remains unclear, particularly in high-dimensional settings. This work leverages a diffusion approach to analyze noisy SGD precisely, providing a continuous-time perspective that captures both statistical risk evolution and privacy loss dynamics in high dimensions. Moreover, we study a variant of noisy SGD that does not require explicit knowledge of gradient sensitivity, unlike existing work that assumes or enforces sensitivity through gradient clipping. Specifically, we focus on the least squares problem with $\\ell_2$ regularization."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Pursuing Minimal Sufficiency in Spatial Reasoning", "authors": "Yejie Guo, Yunzhong Hou, Wufei Ma, Meng Tang, Ming-Hsuan Yang", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "abstract": "Spatial reasoning, the ability to ground language in 3D understanding, remains a persistent challenge for Vision-Language Models (VLMs). We identify two fundamental bottlenecks: inadequate 3D understanding capabilities stemming from 2D-centric pre-training, and reasoning failures induced by redundant 3D information. To address these, we first construct a Minimal Sufficient Set (MSS) of information before answering a given question: a compact selection of 3D perception results from \\textit{expert models}. We introduce MSSR (Minimal Sufficient Spatial Reasoner), a dual-agent framework that implements this principle. A Perception Agent programmatically queries 3D scenes using a versatile perception toolbox to extract sufficient information, including a novel SOG (Situated Orientation Grounding) module that robustly extracts language-grounded directions. A Reasoning Agent then iteratively refines this information to pursue minimality, pruning redundant details and requesting missing ones in a closed loop until the MSS is curated. Extensive experiments demonstrate that our method, by explicitly pursuing both sufficiency and minimality, significantly improves accuracy and achieves state-of-the-art performance across two challenging benchmarks. Furthermore, our framework produces interpretable reasoning paths, offering a promising source of high-quality training data for future models. Source code is available at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          First Responders' Perceptions of Semantic Information for Situational Awareness in Robot-Assisted Emergency Response", "authors": "Tianshu Ruan, Zoe Betta, Georgios Tzoumas, Rustam Stolkin, Manolis Chiou", "subjects": "Robotics (cs.RO)", "abstract": "This study investigates First Responders' (FRs) attitudes toward the use of semantic information and Situational Awareness (SA) in robotic systems during emergency operations. A structured questionnaire was administered to 22 FRs across eight countries, capturing their demographic profiles, general attitudes toward robots, and experiences with semantics-enhanced SA. Results show that most FRs expressed positive attitudes toward robots, and rated the usefulness of semantic information for building SA at an average of 3.6 out of 5. Semantic information was also valued for its role in predicting unforeseen emergencies (mean 3.9). Participants reported requiring an average of 74.6\\% accuracy to trust semantic outputs and 67.8\\% for them to be considered useful, revealing a willingness to use imperfect but informative AI support tools. To the best of our knowledge, this study offers novel insights by being one of the first to directly survey FRs on semantic-based SA in a cross-national context. It reveals the types of semantic information most valued in the field, such as object identity, spatial relationships, and risk context-and connects these preferences to the respondents' roles, experience, and education levels. The findings also expose a critical gap between lab-based robotics capabilities and the realities of field deployment, highlighting the need for more meaningful collaboration between FRs and robotics researchers. These insights contribute to the development of more user-aligned and situationally aware robotic systems for emergency response."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Linear State Estimation in Presence of Bounded Uncertainties: A Comparative Analysis", "authors": "Ayan Das, Anushka Sharma, Anamitra Pal", "subjects": "Systems and Control (eess.SY)", "abstract": "A variety of algorithms have been proposed to address the power system state estimation problem in the presence of uncertainties in the data. However, less emphasis has been given to handling perturbations in the model. In the context of linear state estimation (LSE), which is the focus of this paper, perturbations in the model come from variations in the line parameters. Since the actual values of the line parameters can be different from the values stored in a power utility's database, we investigate three approaches in this paper to estimate the states in the presence of bounded uncertainties in the data and the model. The first approach is based on interval arithmetic, the second is based on convex optimization, and the third is based on generalized linear fractional programming. The three algorithms are applied to multiple IEEE test systems and compared in terms of their speed and accuracy. The results indicate that the first two algorithms are extremely fast and give expected results, while the third suffers from scalability issues and is unsuitable for LSE."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          CLIP: Client-Side Invariant Pruning for Mitigating Stragglers in Secure Federated Learning", "authors": "Anthony DiMaggio, Raghav Sharma, Gururaj Saileshwar", "subjects": "Machine Learning (cs.LG); Cryptography and Security (cs.CR); Distributed, Parallel, and Cluster Computing (cs.DC)", "abstract": "Secure federated learning (FL) preserves data privacy during distributed model training. However, deploying such frameworks across heterogeneous devices results in performance bottlenecks, due to straggler clients with limited computational or network capabilities, slowing training for all participating clients. This paper introduces the first straggler mitigation technique for secure aggregation with deep neural networks. We propose CLIP, a client-side invariant neuron pruning technique coupled with network-aware pruning, that addresses compute and network bottlenecks due to stragglers during training with minimal accuracy loss. Our technique accelerates secure FL training by 13% to 34% across multiple datasets (CIFAR10, Shakespeare, FEMNIST) with an accuracy impact of between 1.3% improvement to 2.6% reduction."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Resolution-Aware Retrieval Augmented Zero-Shot Forecasting", "authors": "Iman Deznabi, Peeyush Kumar, Madalina Fiterau", "subjects": "Machine Learning (cs.LG); Information Retrieval (cs.IR)", "abstract": "Zero-shot forecasting aims to predict outcomes for previously unseen conditions without direct historical data, posing a significant challenge for traditional forecasting methods. We introduce a Resolution-Aware Retrieval-Augmented Forecasting model that enhances predictive accuracy by leveraging spatial correlations and temporal frequency characteristics. By decomposing signals into different frequency components, our model employs resolution-aware retrieval, where lower-frequency components rely on broader spatial context, while higher-frequency components focus on local influences. This allows the model to dynamically retrieve relevant data and adapt to new locations with minimal historical context. Applied to microclimate forecasting, our model significantly outperforms traditional forecasting methods, numerical weather prediction models, and modern foundation time series models, achieving 71% lower MSE than HRRR and 34% lower MSE than Chronos on the ERA5 dataset. Our results highlight the effectiveness of retrieval-augmented and resolution-aware strategies, offering a scalable and data-efficient solution for zero-shot forecasting in microclimate modeling and beyond."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Zero- and One-Shot Data Augmentation for Sentence-Level Dysarthric Speech Recognition in Constrained Scenarios", "authors": "Shiyao Wang, Shiwan Zhao, Jiaming Zhou, Yong Qin", "subjects": "Sound (cs.SD)", "abstract": "Dysarthric speech recognition (DSR) research has witnessed remarkable progress in recent years, evolving from the basic understanding of individual words to the intricate comprehension of sentence-level expressions, all driven by the pressing communication needs of individuals with dysarthria. Nevertheless, the scarcity of available data remains a substantial hurdle, posing a significant challenge to the development of effective sentence-level DSR systems. In response to this issue, dysarthric data augmentation (DDA) has emerged as a highly promising approach. Generative models are frequently employed to generate training data for automatic speech recognition tasks. However, their effectiveness hinges on the ability of the synthesized data to accurately represent the target domain. The wide-ranging variability in pronunciation among dysarthric speakers makes it extremely difficult for models trained on data from existing speakers to produce useful augmented data, especially in zero-shot or one-shot learning settings. To address this limitation, we put forward a novel text-coverage strategy specifically designed for text-matching data synthesis. This innovative strategy allows for efficient zero/one-shot DDA, leading to substantial enhancements in the performance of DSR when dealing with unseen dysarthric speakers. Such improvements are of great significance in practical applications, including dysarthria rehabilitation programs and day-to-day common-sentence communication scenarios."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          An Agentic Framework with LLMs for Solving Complex Vehicle Routing Problems", "authors": "Ni Zhang, Zhiguang Cao, Jianan Zhou, Cong Zhang, Yew-Soon Ong", "subjects": "Artificial Intelligence (cs.AI)", "abstract": "Complex vehicle routing problems (VRPs) remain a fundamental challenge, demanding substantial expert effort for intent interpretation and algorithm design. While large language models (LLMs) offer a promising path toward automation, current approaches still rely on external intervention, which restrict autonomy and often lead to execution errors and low solution feasibility. To address these challenges, we propose an Agentic Framework with LLMs (AFL) for solving complex vehicle routing problems, achieving full automation from problem instance to solution. AFL directly extracts knowledge from raw inputs and enables self-contained code generation without handcrafted modules or external solvers. To improve trustworthiness, AFL decomposes the overall pipeline into three manageable subtasks and employs four specialized agents whose coordinated interactions enforce cross-functional consistency and logical soundness. Extensive experiments on 60 complex VRPs, ranging from standard benchmarks to practical variants, validate the effectiveness and generality of our framework, showing comparable performance against meticulously designed algorithms. Notably, it substantially outperforms existing LLM-based baselines in both code reliability and solution feasibility, achieving rates close to 100% on the evaluated benchmarks."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          SDPA++: A General Framework for Self-Supervised Denoising with Patch Aggregation", "authors": "Huy Minh Nhat Nguyen, Triet Hoang Minh Dao, Chau Vinh Hoang Truong, Cuong Tuan Nguyen", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Optical Coherence Tomography (OCT) is a widely used non-invasive imaging technique that provides detailed three-dimensional views of the retina, which are essential for the early and accurate diagnosis of ocular diseases. Consequently, OCT image analysis and processing have emerged as key research areas in biomedical imaging. However, acquiring paired datasets of clean and real-world noisy OCT images for supervised denoising models remains a formidable challenge due to intrinsic speckle noise and practical constraints in clinical imaging environments. To address these issues, we propose SDPA++: A General Framework for Self-Supervised Denoising with Patch Aggregation. Our novel approach leverages only noisy OCT images by first generating pseudo-ground-truth images through self-fusion and self-supervised denoising. These refined images then serve as targets to train an ensemble of denoising models using a patch-based strategy that effectively enhances image clarity. Performance improvements are validated via metrics such as Contrast-to-Noise Ratio (CNR), Mean Square Ratio (MSR), Texture Preservation (TP), and Edge Preservation (EP) on the real-world dataset from the IEEE SPS Video and Image Processing Cup. Notably, the VIP Cup dataset contains only real-world noisy OCT images without clean references, highlighting our method's potential for improving image quality and diagnostic outcomes in clinical practice."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          On the Granularity of Causal Effect Identifiability", "authors": "Yizuo Chen, Adnan Darwiche", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Methodology (stat.ME)", "abstract": "The classical notion of causal effect identifiability is defined in terms of treatment and outcome variables. In this note, we consider the identifiability of state-based causal effects: how an intervention on a particular state of treatment variables affects a particular state of outcome variables. We demonstrate that state-based causal effects may be identifiable even when variable-based causal effects may not. Moreover, we show that this separation occurs only when additional knowledge -- such as context-specific independencies and conditional functional dependencies -- is available. We further examine knowledge that constrains the states of variables, and show that such knowledge does not improve identifiability on its own but can improve both variable-based and state-based identifiability when combined with other knowledge such as context-specific independencies. Our findings highlight situations where causal effects of interest may be estimable from observational data and this identifiability may be missed by existing variable-based frameworks."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Connecting Domains and Contrasting Samples: A Ladder for Domain Generalization", "authors": "Tianxin Wei, Yifan Chen, Xinrui He, Wenxuan Bao, Jingrui He", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)", "abstract": "Distribution shifts between training and testing samples frequently occur in practice and impede model generalization performance. This crucial challenge thereby motivates studies on domain generalization (DG), which aim to predict the label on unseen target domain data by solely using data from source domains. It is intuitive to conceive the class-separated representations learned in contrastive learning (CL) are able to improve DG, while the reality is quite the opposite: users observe directly applying CL deteriorates the performance. We analyze the phenomenon with the insights from CL theory and discover lack of intra-class connectivity in the DG setting causes the deficiency. We thus propose a new paradigm, domain-connecting contrastive learning (DCCL), to enhance the conceptual connectivity across domains and obtain generalizable representations for DG. On the data side, more aggressive data augmentation and cross-domain positive samples are introduced to improve intra-class connectivity. On the model side, to better embed the unseen test domains, we propose model anchoring to exploit the intra-class connectivity in pre-trained representations and complement the anchoring with generative transformation loss. Extensive experiments on five standard DG benchmarks are performed. The results verify that DCCL outperforms state-of-the-art baselines even without domain supervision. The detailed model implementation and the code are provided through this https URL"}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Rotation, Scale, and Translation Resilient Black-box Fingerprinting for Intellectual Property Protection of EaaS Models", "authors": "Hongjie Zhang, Zhiqi Zhao, Hanzhou Wu, Zhihua Xia, Athanasios V. Vasilakos", "subjects": "Cryptography and Security (cs.CR)", "abstract": "Feature embedding has become a cornerstone technology for processing high-dimensional and complex data, which results in that Embedding as a Service (EaaS) models have been widely deployed in the cloud. To protect the intellectual property of EaaS models, existing methods apply digital watermarking to inject specific backdoor triggers into EaaS models by modifying training samples or network parameters. However, these methods inevitably produce detectable patterns through semantic analysis and exhibit susceptibility to geometric transformations including rotation, scaling, and translation (RST). To address this problem, we propose a fingerprinting framework for EaaS models, rather than merely refining existing watermarking techniques. Different from watermarking techniques, the proposed method establishes EaaS model ownership through geometric analysis of embedding space's topological structure, rather than relying on the modified training samples or triggers. The key innovation lies in modeling the victim and suspicious embeddings as point clouds, allowing us to perform robust spatial alignment and similarity measurement, which inherently resists RST attacks. Experimental results evaluated on visual and textual embedding tasks verify the superiority and applicability. This research reveals inherent characteristics of EaaS models and provides a promising solution for ownership verification of EaaS models under the black-box scenario."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Natural Language Processing Applications in Cardiology: A Narrative Review", "authors": "Kailai Yang, Yan Leng, Xin Zhang, Tianlin Zhang, Paul Thompson, Bernard Keavney, Maciej Tomaszewski, Sophia Ananiadou", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "abstract": "Cardiovascular disease has become increasingly prevalent in modern society and has a significant effect on global health and well-being. Heart-related conditions are intricate, multifaceted disorders, which may be influenced by a combination of genetic predispositions, lifestyle choices, and various socioeconomic and clinical factors. Information regarding these potentially complex interrelationships is dispersed among diverse types of textual data, which include patient narratives, medical records, and scientific literature, among others. Natural language processing (NLP) techniques have increasingly been adopted as a powerful means to analyse and make sense of this vast amount of unstructured data. This, in turn, can allow healthcare professionals to gain deeper insights into the cardiology field, which has the potential to revolutionize current approaches to the diagnosis, treatment, and prevention of cardiac problems. This review provides a detailed overview of NLP research in cardiology between 2014 and 2025. We queried six literature databases to find articles describing the application of NLP techniques in the context of a range of different cardiovascular diseases. Following a rigorous screening process, we identified a total of 265 relevant articles. We analysed each article from multiple dimensions, i.e., NLP paradigm types, cardiology-related task types, cardiovascular disease types, and data source types. Our analysis reveals considerable diversity within each of these dimensions, thus demonstrating the considerable breadth of NLP research within the field. We also perform a temporal analysis, which illustrates the evolution and changing trends in NLP methods employed over the last decade that we cover. To our knowledge, the review constitutes the most comprehensive overview of NLP research in cardiology to date."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          HumanCM: One Step Human Motion Prediction", "authors": "Liu Haojie, Gao Suixiang", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "abstract": "We present HumanCM, a one-step human motion prediction framework built upon consistency models. Instead of relying on multi-step denoising as in diffusion-based methods, HumanCM performs efficient single-step generation by learning a self-consistent mapping between noisy and clean motion states. The framework adopts a Transformer-based spatiotemporal architecture with temporal embeddings to model long-range dependencies and preserve motion coherence. Experiments on Human3.6M and HumanEva-I demonstrate that HumanCM achieves comparable or superior accuracy to state-of-the-art diffusion models while reducing inference steps by up to two orders of magnitude."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          The Chameleon Nature of LLMs: Quantifying Multi-Turn Stance Instability in Search-Enabled Language Models", "authors": "Shivam Ratnakar, Sanjay Raghavendra", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "abstract": "Integration of Large Language Models with search/retrieval engines has become ubiquitous, yet these systems harbor a critical vulnerability that undermines their reliability. We present the first systematic investigation of \"chameleon behavior\" in LLMs: their alarming tendency to shift stances when presented with contradictory questions in multi-turn conversations (especially in search-enabled LLMs). Through our novel Chameleon Benchmark Dataset, comprising 17,770 carefully crafted question-answer pairs across 1,180 multi-turn conversations spanning 12 controversial domains, we expose fundamental flaws in state-of-the-art systems. We introduce two theoretically grounded metrics: the Chameleon Score (0-1) that quantifies stance instability, and Source Re-use Rate (0-1) that measures knowledge diversity. Our rigorous evaluation of Llama-4-Maverick, GPT-4o-mini, and Gemini-2.5-Flash reveals consistent failures: all models exhibit severe chameleon behavior (scores 0.391-0.511), with GPT-4o-mini showing the worst performance. Crucially, small across-temperature variance (less than 0.004) suggests the effect is not a sampling artifact. Our analysis uncovers the mechanism: strong correlations between source re-use rate and confidence (r=0.627) and stance changes (r=0.429) are statistically significant (p less than 0.05), indicating that limited knowledge diversity makes models pathologically deferential to query framing. These findings highlight the need for comprehensive consistency evaluation before deploying LLMs in healthcare, legal, and financial systems where maintaining coherent positions across interactions is critical for reliable decision support."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          so much depends / upon / a whitespace: Why Whitespace Matters for Poets and LLMs", "authors": "Sriharsh Bhyravajjula, Melanie Walsh, Anna Preus, Maria Antoniak", "subjects": "Computation and Language (cs.CL)", "abstract": "Whitespace is a critical component of poetic form, reflecting both adherence to standardized forms and rebellion against those forms. Each poem's whitespace distribution reflects the artistic choices of the poet and is an integral semantic and spatial feature of the poem. Yet, despite the popularity of poetry as both a long-standing art form and as a generation task for large language models (LLMs), whitespace has not received sufficient attention from the NLP community. Using a corpus of 19k English-language published poems from Poetry Foundation, we investigate how 4k poets have used whitespace in their works. We release a subset of 2.8k public-domain poems with preserved formatting to facilitate further research in this area. We compare whitespace usage in the published poems to (1) 51k LLM-generated poems, and (2) 12k unpublished poems posted in an online community. We also explore whitespace usage across time periods, poetic forms, and data sources. Additionally, we find that different text processing methods can result in significantly different representations of whitespace in poetry data, motivating us to use these poems and whitespace patterns to discuss implications for the processing strategies used to assemble pretraining datasets for LLMs."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Eliciting Grounded Chain-of-Thought Reasoning in 3D Scenes", "authors": "Xiongkun Linghu, Jiangyong Huang, Ziyu Zhu, Baoxiong Jia, Siyuan Huang", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "abstract": "Existing research on 3D Large Language Models (LLMs) still struggles to achieve grounded question-answering, primarily due to the under-exploration of the mech- anism of human-like scene-object grounded reasoning. This paper bridges the gap by presenting a novel framework. We first introduce a grounded Chain-of- Thought reasoning method in 3D scenes (SCENECOT), decoupling a complex reasoning task into simpler and manageable problems, and building corresponding visual clues based on multimodal expert modules. To enable such a method, we develop SCENECOT-185K, the first large-scale grounded CoT reasoning dataset, consisting of 185K high-quality instances. Extensive experiments across various complex 3D scene reasoning benchmarks demonstrate that our new framework achieves strong performance with high grounding-QA coherence. To the best of our knowledge, this is the first successful application of CoT reasoning to 3D scene understanding, enabling step-by-step human-like reasoning and showing potential for extension to broader 3D scene understanding scenarios."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Right Answer at the Right Time - Temporal Retrieval-Augmented Generation via Graph Summarization", "authors": "Zulun Zhu, Haoyu Liu, Mengke He, Siqiang Luo", "subjects": "Information Retrieval (cs.IR)", "abstract": "Question answering in temporal knowledge graphs requires retrieval that is both time-consistent and efficient. Existing RAG methods are largely semantic and typically neglect explicit temporal constraints, which leads to time-inconsistent answers and inflated token usage. We propose STAR-RAG, a temporal GraphRAG framework that relies on two key ideas: building a time-aligned rule graph and conducting propagation on this graph to narrow the search space and prioritize semantically relevant, time-consistent evidence. This design enforces temporal proximity during retrieval, reduces the candidate set of retrieval results, and lowers token consumption without sacrificing accuracy. Compared with existing temporal RAG approaches, STAR-RAG eliminates the need for heavy model training and fine-tuning, thereby reducing computational cost and significantly simplifying this http URL experiments on real-world temporal KG datasets show that our method achieves improved answer accuracy while consuming fewer tokens than strong GraphRAG baselines."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          DistilLock: Safeguarding LLMs from Unauthorized Knowledge Distillation on the Edge", "authors": "Asmita Mohanty, Gezheng Kang, Lei Gao, Murali Annavaram", "subjects": "Cryptography and Security (cs.CR); Machine Learning (cs.LG)", "abstract": "Large Language Models (LLMs) have demonstrated strong performance across diverse tasks, but fine-tuning them typically relies on cloud-based, centralized infrastructures. This requires data owners to upload potentially sensitive data to external servers, raising serious privacy concerns. An alternative approach is to fine-tune LLMs directly on edge devices using local data; however, this introduces a new challenge: the model owner must transfer proprietary models to the edge, which risks intellectual property (IP) leakage. To address this dilemma, we propose DistilLock, a TEE-assisted fine-tuning framework that enables privacy-preserving knowledge distillation on the edge. In DistilLock, a proprietary foundation model is executed within a trusted execution environment (TEE) enclave on the data owner's device, acting as a secure black-box teacher. This setup preserves both data privacy and model IP by preventing direct access to model internals. Furthermore, DistilLock employs a model obfuscation mechanism to offload obfuscated weights to untrusted accelerators for efficient knowledge distillation without compromising security. We demonstrate that DistilLock prevents unauthorized knowledge distillation processes and model-stealing attacks while maintaining high computational efficiency, but offering a secure and practical solution for edge-based LLM personalization."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          U-Codec: Ultra Low Frame-rate Neural Speech Codec for Fast High-fidelity Speech Generation", "authors": "Xusheng Yang, Long Zhou, Wenfu Wang, Kai Hu, Shulin Feng, Chenxing Li, Meng Yu, Dong Yu, Yuexian Zou", "subjects": "Sound (cs.SD); Computation and Language (cs.CL); Machine Learning (cs.LG)", "abstract": "We propose \\textbf{U-Codec}, an \\textbf{U}ltra low frame-rate neural speech \\textbf{Codec} that achieves high-fidelity reconstruction and fast speech generation at an extremely low frame-rate of 5Hz (5 frames per second). Extreme compression at 5Hz typically leads to severe intelligibility and spectral detail loss, we introduce a Transformer-based inter-frame long-term dependency module and systematically explore residual vector quantization (RVQ) depth and codebook size to identify optimal configurations. Moreover, we apply U-Codec into a large language model (LLM)-based auto-regressive TTS model, which leverages global and local hierarchical architecture to effectively capture dependencies across multi-layer tokens. We extend LLM-based TTS from 3-layer RVQ at 50Hz to 32-layer RVQ at 5Hz. Experimental results demonstrate that U-Codec improves LLM-based TTS inference speed by around 3 $\\times$ over high-frame-rate codecs while maintaining similarity and naturalness. These results validate the feasibility of using highly compressed 5Hz discrete tokens for fast and high-fidelity speech synthesis."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          LSTM-Based Forecasting and Analysis of EV Charging Demand in a Dense Urban Campus", "authors": "Zak Ressler, Marcus Grijalva, Angelica Marie Ignacio, Melanie Torres, Abelardo Cuadra Rojas, Rohollah Moghadam, Mohammad Rasoul narimani", "subjects": "Machine Learning (cs.LG); Optimization and Control (math.OC)", "abstract": "This paper presents a framework for processing EV charging load data in order to forecast future load predictions using a Recurrent Neural Network, specifically an LSTM. The framework processes a large set of raw data from multiple locations and transforms it with normalization and feature extraction to train the LSTM. The pre-processing stage corrects for missing or incomplete values by interpolating and normalizing the measurements. This information is then fed into a Long Short-Term Memory Model designed to capture the short-term fluctuations while also interpreting the long-term trends in the charging data. Experimental results demonstrate the model's ability to accurately predict charging demand across multiple time scales (daily, weekly, and monthly), providing valuable insights for infrastructure planning, energy management, and grid integration of EV charging facilities. The system's modular design allows for adaptation to different charging locations with varying usage patterns, making it applicable across diverse deployment scenarios."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Beyond Pipelines: A Survey of the Paradigm Shift toward Model-Native Agentic AI", "authors": "Jitao Sang, Jinlin Xiao, Jiarun Han, Jilin Chen, Xiaoyi Chen, Shuyu Wei, Yongjie Sun, Yuhang Wang", "subjects": "Artificial Intelligence (cs.AI)", "abstract": "The rapid evolution of agentic AI marks a new phase in artificial intelligence, where Large Language Models (LLMs) no longer merely respond but act, reason, and adapt. This survey traces the paradigm shift in building agentic AI: from Pipeline-based systems, where planning, tool use, and memory are orchestrated by external logic, to the emerging Model-native paradigm, where these capabilities are internalized within the model's parameters. We first position Reinforcement Learning (RL) as the algorithmic engine enabling this paradigm shift. By reframing learning from imitating static data to outcome-driven exploration, RL underpins a unified solution of LLM + RL + Task across language, vision and embodied domains. Building on this, the survey systematically reviews how each capability -- Planning, Tool use, and Memory -- has evolved from externally scripted modules to end-to-end learned behaviors. Furthermore, it examines how this paradigm shift has reshaped major agent applications, specifically the Deep Research agent emphasizing long-horizon reasoning and the GUI agent emphasizing embodied interaction. We conclude by discussing the continued internalization of agentic capabilities like Multi-agent collaboration and Reflection, alongside the evolving roles of the system and model layers in future agentic AI. Together, these developments outline a coherent trajectory toward model-native agentic AI as an integrated learning and interaction framework, marking the transition from constructing systems that apply intelligence to developing models that grow intelligence through experience."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          A Comprehensive Survey on Reinforcement Learning-based Agentic Search: Foundations, Roles, Optimizations, Evaluations, and Applications", "authors": "Minhua Lin, Zongyu Wu, Zhichao Xu, Hui Liu, Xianfeng Tang, Qi He, Charu Aggarwal, Hui Liu, Xiang Zhang, Suhang Wang", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "abstract": "The advent of large language models (LLMs) has transformed information access and reasoning through open-ended natural language interaction. However, LLMs remain limited by static knowledge, factual hallucinations, and the inability to retrieve real-time or domain-specific information. Retrieval-Augmented Generation (RAG) mitigates these issues by grounding model outputs in external evidence, but traditional RAG pipelines are often single turn and heuristic, lacking adaptive control over retrieval and reasoning. Recent advances in agentic search address these limitations by enabling LLMs to plan, retrieve, and reflect through multi-step interaction with search environments. Within this paradigm, reinforcement learning (RL) offers a powerful mechanism for adaptive and self-improving search behavior. This survey provides the first comprehensive overview of \\emph{RL-based agentic search}, organizing the emerging field along three complementary dimensions: (i) What RL is for (functional roles), (ii) How RL is used (optimization strategies), and (iii) Where RL is applied (scope of optimization). We summarize representative methods, evaluation protocols, and applications, and discuss open challenges and future directions toward building reliable and scalable RL driven agentic search systems. We hope this survey will inspire future research on the integration of RL and agentic search. Our repository is available at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Beacon: Single-Turn Diagnosis and Mitigation of Latent Sycophancy in Large Language Models", "authors": "Sanskar Pandey, Ruhaan Chopra, Angkul Puniya, Sohom Pal", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "abstract": "Large language models internalize a structural trade-off between truthfulness and obsequious flattery, emerging from reward optimization that conflates helpfulness with polite submission. This latent bias, known as sycophancy, manifests as a preference for user agreement over principled reasoning. We introduce Beacon, a single-turn forced-choice benchmark that isolates this bias independent of conversational context, enabling precise measurement of the tension between factual accuracy and submissive bias. Evaluations across twelve state-of-the-art models reveal that sycophancy decomposes into stable linguistic and affective sub-biases, each scaling with model capacity. We further propose prompt-level and activation-level interventions that modulate these biases in opposing directions, exposing the internal geometry of alignment as a dynamic manifold between truthfulness and socially compliant judgment. Beacon reframes sycophancy as a measurable form of normative misgeneralization, providing a reproducible foundation for studying and mitigating alignment drift in large-scale generative systems."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Vision-Centric 4D Occupancy Forecasting and Planning via Implicit Residual World Models", "authors": "Jianbiao Mei, Yu Yang, Xuemeng Yang, Licheng Wen, Jiajun Lv, Botian Shi, Yong Liu", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "End-to-end autonomous driving systems increasingly rely on vision-centric world models to understand and predict their environment. However, a common ineffectiveness in these models is the full reconstruction of future scenes, which expends significant capacity on redundantly modeling static backgrounds. To address this, we propose IR-WM, an Implicit Residual World Model that focuses on modeling the current state and evolution of the world. IR-WM first establishes a robust bird's-eye-view representation of the current state from the visual observation. It then leverages the BEV features from the previous timestep as a strong temporal prior and predicts only the \"residual\", i.e., the changes conditioned on the ego-vehicle's actions and scene context. To alleviate error accumulation over time, we further apply an alignment module to calibrate semantic and dynamic misalignments. Moreover, we investigate different forecasting-planning coupling schemes and demonstrate that the implicit future state generated by world models substantially improves planning accuracy. On the nuScenes benchmark, IR-WM achieves top performance in both 4D occupancy forecasting and trajectory planning."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          UKANFormer: Noise-Robust Semantic Segmentation for Coral Reef Mapping via a Kolmogorov-Arnold Network-Transformer Hybrid", "authors": "Tianyang Dou, Ming Li, Jiangying Qin, Xuan Liao, Jiageng Zhong, Armin Gruen, Mengyi Deng", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Coral reefs are vital yet fragile ecosystems that require accurate large-scale mapping for effective conservation. Although global products such as the Allen Coral Atlas provide unprecedented coverage of global coral reef distri-bution, their predictions are frequently limited in spatial precision and semantic consistency, especially in regions requiring fine-grained boundary delineation. To address these challenges, we propose UKANFormer, a novel se-mantic segmentation model designed to achieve high-precision mapping under noisy supervision derived from Allen Coral Atlas. Building upon the UKAN architecture, UKANFormer incorporates a Global-Local Transformer (GL-Trans) block in the decoder, enabling the extraction of both global semantic structures and local boundary details. In experiments, UKANFormer achieved a coral-class IoU of 67.00% and pixel accuracy of 83.98%, outperforming conventional baselines under the same noisy labels setting. Remarkably, the model produces predictions that are visually and structurally more accurate than the noisy labels used for training. These results challenge the notion that data quality directly limits model performance, showing that architectural design can mitigate label noise and sup-port scalable mapping under imperfect supervision. UKANFormer provides a foundation for ecological monitoring where reliable labels are scarce."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          A Comprehensive Survey on World Models for Embodied AI", "authors": "Xinqing Li, Xin He, Le Zhang, Yun Liu", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Embodied AI requires agents that perceive, act, and anticipate how actions reshape future world states. World models serve as internal simulators that capture environment dynamics, enabling forward and counterfactual rollouts to support perception, prediction, and decision making. This survey presents a unified framework for world models in embodied AI. Specifically, we formalize the problem setting and learning objectives, and propose a three-axis taxonomy encompassing: (1) Functionality, Decision-Coupled vs. General-Purpose; (2) Temporal Modeling, Sequential Simulation and Inference vs. Global Difference Prediction; (3) Spatial Representation, Global Latent Vector, Token Feature Sequence, Spatial Latent Grid, and Decomposed Rendering Representation. We systematize data resources and metrics across robotics, autonomous driving, and general video settings, covering pixel prediction quality, state-level understanding, and task performance. Furthermore, we offer a quantitative comparison of state-of-the-art models and distill key open challenges, including the scarcity of unified datasets and the need for evaluation metrics that assess physical consistency over pixel fidelity, the trade-off between model performance and the computational efficiency required for real-time control, and the core modeling difficulty of achieving long-horizon temporal consistency while mitigating error accumulation. Finally, we maintain a curated bibliography at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          A Control-Theoretic Approach to Dynamic Payment Routing for Success Rate Optimization", "authors": "Aniket Agrawal, Harsharanga Patil", "subjects": "Systems and Control (eess.SY); Machine Learning (cs.LG)", "abstract": "This paper introduces a control-theoretic framework for dynamic payment routing, implemented within JUSPAY's Payment Orchestrator to maximize transaction success rate. The routing system is modeled as a closed-loop feedback controller continuously sensing gateway performance, computing corrective actions, and dynamically routes transactions across gateway to ensure operational resilience. The system leverages concepts from control theory, reinforcement learning, and multi-armed bandit optimization to achieve both short-term responsiveness and long-term stability. Rather than relying on explicit PID regulation, the framework applies generalized feedback-based adaptation, ensuring that corrective actions remain proportional to observed performance deviations and the computed gateway score gradually converges toward the success rate. This hybrid approach unifies control theory and adaptive decision systems, enabling self-regulating transaction routing that dampens instability, and improves reliability. Live production results show an improvement of up to 1.15% in success rate over traditional rule-based routing, demonstrating the effectiveness of feedback-based control in payment systems."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Exact Nearest-Neighbor Search on Energy-Efficient FPGA Devices", "authors": "Patrizio Dazzi, William Guglielmo, Franco Maria Nardini, Raffaele Perego, Salvatore Trani", "subjects": "Information Retrieval (cs.IR); Distributed, Parallel, and Cluster Computing (cs.DC)", "abstract": "This paper investigates the usage of FPGA devices for energy-efficient exact kNN search in high-dimension latent spaces. This work intercepts a relevant trend that tries to support the increasing popularity of learned representations based on neural encoder models by making their large-scale adoption greener and more inclusive. The paper proposes two different energy-efficient solutions adopting the same FPGA low-level configuration. The first solution maximizes system throughput by processing the queries of a batch in parallel over a streamed dataset not fitting into the FPGA memory. The second minimizes latency by processing each kNN incoming query in parallel over an in-memory dataset. Reproducible experiments on publicly available image and text datasets show that our solution outperforms state-of-the-art CPU-based competitors regarding throughput, latency, and energy consumption. Specifically, experiments show that the proposed FPGA solutions achieve the best throughput in terms of queries per second and the best-observed latency with scale-up factors of up to 16.6X. Similar considerations can be made regarding energy efficiency, where results show that our solutions can achieve up to 11.9X energy saving w.r.t. strong CPU-based competitors."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Towards Active Excitation-Based Dynamic Inertia Identification in Satellites", "authors": "Matteo El-Hariry, Vittorio Franzese, Miguel Olivares-Mendez", "subjects": "Robotics (cs.RO)", "abstract": "This paper presents a comprehensive analysis of how excitation design influences the identification of the inertia properties of rigid nano- and micro-satellites. We simulate nonlinear attitude dynamics with reaction-wheel coupling, actuator limits, and external disturbances, and excite the system using eight torque profiles of varying spectral richness. Two estimators are compared, a batch Least Squares method and an Extended Kalman Filter, across three satellite configurations and time-varying inertia scenarios. Results show that excitation frequency content and estimator assumptions jointly determine estimation accuracy and robustness, offering practical guidance for in-orbit adaptive inertia identification by outlining the conditions under which each method performs best. The code is provided as open-source ."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          All-Pairs Minimum Cut using $\\tilde{O}(n^{7/4})$ Cut Queries", "authors": "Yotam Kenneth-Mordoch, Robert Krauthgamer", "subjects": "Data Structures and Algorithms (cs.DS)", "abstract": "We present the first non-trivial algorithm for the all-pairs minimum cut problem in the cut-query model. Given cut-query access to an unweighted graph $G=(V,E)$ with $n$ vertices, our randomized algorithm constructs a Gomory-Hu tree of $G$, and thus solves the all-pairs minimum cut problem, using $\\tilde{O}(n^{7/4})$ cut queries."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Surrogate Modeling and Explainable Artificial Intelligence for Complex Systems: A Workflow for Automated Simulation Exploration", "authors": "Paul Saves, Pramudita Satria Palar, Muhammad Daffa Robani, Nicolas Verstaevel, Moncef Garouani, Julien Aligon, Benoit Gaudou, Koji Shimoyama, Joseph Morlier", "subjects": "Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA); Methodology (stat.ME)", "abstract": "Complex systems are increasingly explored through simulation-driven engineering workflows that combine physics-based and empirical models with optimization and analytics. Despite their power, these workflows face two central obstacles: (1) high computational cost, since accurate exploration requires many expensive simulator runs; and (2) limited transparency and reliability when decisions rely on opaque blackbox components. We propose a workflow that addresses both challenges by training lightweight emulators on compact designs of experiments that (i) provide fast, low-latency approximations of expensive simulators, (ii) enable rigorous uncertainty quantification, and (iii) are adapted for global and local Explainable Artificial Intelligence (XAI) analyses. This workflow unifies every simulation-based complex-system analysis tool, ranging from engineering design to agent-based models for socio-environmental understanding. In this paper, we proposea comparative methodology and practical recommendations for using surrogate-based explainability tools within the proposed workflow. The methodology supports continuous and categorical inputs, combines global-effect and uncertainty analyses with local attribution, and evaluates the consistency of explanations across surrogate models, thereby diagnosing surrogate adequacy and guiding further data collection or model refinement. We demonstrate the approach on two contrasting case studies: a multidisciplinary design analysis of a hybrid-electric aircraft and an agent-based model of urban segregation. Results show that the surrogate model and XAI coupling enables large-scale exploration in seconds, uncovers nonlinear interactions and emergent behaviors, identifies key design and policy levers, and signals regions where surrogates require more data or alternative architectures."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Zero-Shot Performance Prediction for Probabilistic Scaling Laws", "authors": "Viktoria Schram, Markus Hiller, Daniel Beck, Trevor Cohn", "subjects": "Machine Learning (cs.LG); Computation and Language (cs.CL)", "abstract": "The prediction of learning curves for Natural Language Processing (NLP) models enables informed decision-making to meet specific performance objectives, while reducing computational overhead and lowering the costs associated with dataset acquisition and curation. In this work, we formulate the prediction task as a multitask learning problem, where each task's data is modelled as being organized within a two-layer hierarchy. To model the shared information and dependencies across tasks and hierarchical levels, we employ latent variable multi-output Gaussian Processes, enabling to account for task correlations and supporting zero-shot prediction of learning curves (LCs). We demonstrate that this approach facilitates the development of probabilistic scaling laws at lower costs. Applying an active learning strategy, LCs can be queried to reduce predictive uncertainty and provide predictions close to ground truth scaling laws. We validate our framework on three small-scale NLP datasets with up to $30$ LCs. These are obtained from nanoGPT models, from bilingual translation using mBART and Transformer models, and from multilingual translation using M2M100 models of varying sizes."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Cryptanalysis of a Privacy-Preserving Ride-Hailing Service from NSS 2022", "authors": "Srinivas Vivek", "subjects": "Cryptography and Security (cs.CR)", "abstract": "Ride-Hailing Services (RHS) match a ride request initiated by a rider with a suitable driver responding to the ride request. A Privacy-Preserving RHS (PP-RHS) aims to facilitate ride matching while ensuring the privacy of riders' and drivers' location data w.r.t. the Service Provider (SP). At NSS 2022, Xie et al. proposed a PP-RHS. In this work, we demonstrate a passive attack on their PP-RHS protocol. Our attack allows the SP to completely recover the locations of the rider as well as that of the responding drivers in every ride request. Further, our attack is very efficient as it is independent of the security parameter."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          An Efficient Semantic Segmentation Decoder for In-Car or Distributed Applications", "authors": "Danish Nazir, Gowtham Sai Inti, Timo Bartels, Jan Piewek, Thorsten Bagdonat, Tim Fingscheidt", "subjects": "Machine Learning (cs.LG)", "abstract": "Modern automotive systems leverage deep neural networks (DNNs) for semantic segmentation and operate in two key application areas: (1) In-car, where the DNN solely operates in the vehicle without strict constraints on the data rate. (2) Distributed, where one DNN part operates in the vehicle and the other part typically on a large-scale cloud platform with a particular constraint on transmission bitrate efficiency. Typically, both applications share an image and source encoder, while each uses distinct (joint) source and task decoders. Prior work utilized convolutional neural networks for joint source and task decoding but did not investigate transformer-based alternatives such as SegDeformer, which offer superior performance at the cost of higher computational complexity. In this work, we propose joint feature and task decoding for SegDeformer, thereby enabling lower computational complexity in both in-car and distributed applications, despite SegDeformer's computational demands. This improves scalability in the cloud while reducing in-car computational complexity. For the in-car application, we increased the frames per second (fps) by up to a factor of $11.7$ ($1.4$ fps to $16.5$ fps) on Cityscapes and by up to a factor of $3.5$ ($43.3$ fps to $154.3$ fps) on ADE20K, while being on-par w.r.t.\\ the mean intersection over union (mIoU) of the transformer-based baseline that doesn't compress by a source codec. For the distributed application, we achieve state-of-the-art (SOTA) over a wide range of bitrates on the mIoU metric, while using only $0.14$\\% ($0.04$\\%) of cloud DNN parameters used in previous SOTA, reported on ADE20K (Cityscapes)."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Visual Autoregressive Models Beat Diffusion Models on Inference Time Scaling", "authors": "Erik Riise, Mehmet Onurcan Kaya, Dim P. Papadopoulos", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "While inference-time scaling through search has revolutionized Large Language Models, translating these gains to image generation has proven difficult. Recent attempts to apply search strategies to continuous diffusion models show limited benefits, with simple random sampling often performing best. We demonstrate that the discrete, sequential nature of visual autoregressive models enables effective search for image generation. We show that beam search substantially improves text-to-image generation, enabling a 2B parameter autoregressive model to outperform a 12B parameter diffusion model across benchmarks. Systematic ablations show that this advantage comes from the discrete token space, which allows early pruning and computational reuse, and our verifier analysis highlights trade-offs between speed and reasoning capability. These findings suggest that model architecture, not just scale, is critical for inference-time optimization in visual generation."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Prominence-Aware Artifact Detection and Dataset for Image Super-Resolution", "authors": "Ivan Molodetskikh, Kirill Malyshev, Mark Mirgaleev, Nikita Zagainov, Evgeney Bogatyrev, Dmitriy Vatolin", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)", "abstract": "Generative image super-resolution (SR) is rapidly advancing in visual quality and detail restoration. As the capacity of SR models expands, however, so does their tendency to produce artifacts: incorrect, visually disturbing details that reduce perceived quality. Crucially, their perceptual impact varies: some artifacts are barely noticeable while others strongly degrade the image. We argue that artifacts should be characterized by their prominence to human observers rather than treated as uniform binary defects. Motivated by this, we present a novel dataset of 1302 artifact examples from 11 contemporary image-SR methods, where each artifact is paired with a crowdsourced prominence score. Building on this dataset, we train a lightweight regressor that produces spatial prominence heatmaps and outperforms existing methods at detecting prominent artifacts. We release the dataset and code to facilitate prominence-aware evaluation and mitigation of SR artifacts."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          ELMM: Efficient Lightweight Multimodal Large Language Models for Multimodal Knowledge Graph Completion", "authors": "Wei Huang, Peining Li, Meiyu Liang, Xu Hou, Junping Du, Yingxia Shao, Guanhua Ye, Wu Liu, Kangkang Lu, Yang Yu", "subjects": "Artificial Intelligence (cs.AI)", "abstract": "Multimodal Knowledge Graphs (MKGs) extend traditional knowledge graphs by incorporating visual and textual modalities, enabling richer and more expressive entity representations. However, existing MKGs often suffer from incompleteness, which hinder their effectiveness in downstream tasks. Therefore, multimodal knowledge graph completion (MKGC) task is receiving increasing attention. While large language models (LLMs) have shown promise for knowledge graph completion (KGC), their application to the multimodal setting remains underexplored. Moreover, applying Multimodal Large Language Models (MLLMs) to the task of MKGC introduces significant challenges: (1) the large number of image tokens per entity leads to semantic noise and modality conflicts, and (2) the high computational cost of processing large token inputs. To address these issues, we propose Efficient Lightweight Multimodal Large Language Models (ELMM) for MKGC. ELMM proposes a Multi-view Visual Token Compressor (MVTC) based on multi-head attention mechanism, which adaptively compresses image tokens from both textual and visual views, thereby effectively reducing redundancy while retaining necessary information and avoiding modality conflicts. Additionally, we design an attention pruning strategy to remove redundant attention layers from MLLMs, thereby significantly reducing the inference cost. We further introduce a linear projection to compensate for the performance degradation caused by pruning. Extensive experiments on benchmark FB15k-237-IMG and WN18-IMG demonstrate that ELMM achieves state-of-the-art performance while substantially improving computational efficiency, establishing a new paradigm for multimodal knowledge graph completion."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Adaptive Invariant Extended Kalman Filter for Legged Robot State Estimation", "authors": "Kyung-Hwan Kim, DongHyun Ahn, Dong-hyun Lee, JuYoung Yoon, Dong Jin Hyun", "subjects": "Robotics (cs.RO); Systems and Control (eess.SY)", "abstract": "State estimation is crucial for legged robots as it directly affects control performance and locomotion stability. In this paper, we propose an Adaptive Invariant Extended Kalman Filter to improve proprioceptive state estimation for legged robots. The proposed method adaptively adjusts the noise level of the contact foot model based on online covariance estimation, leading to improved state estimation under varying contact conditions. It effectively handles small slips that traditional slip rejection fails to address, as overly sensitive slip rejection settings risk causing filter divergence. Our approach employs a contact detection algorithm instead of contact sensors, reducing the reliance on additional hardware. The proposed method is validated through real-world experiments on the quadruped robot LeoQuad, demonstrating enhanced state estimation performance in dynamic locomotion scenarios."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          End-to-end Listen, Look, Speak and Act", "authors": "Siyin Wang, Wenyi Yu, Xianzhao Chen, Xiaohai Tian, Jun Zhang, Lu Lu, Chao Zhang", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO); Audio and Speech Processing (eess.AS)", "abstract": "Human interaction is inherently multimodal and full-duplex: we listen while watching, speak while acting, and fluidly adapt to turn-taking and interruptions. Realizing these capabilities is essential for building models simulating humans. We present ELLSA (End-to-end Listen, Look, Speak and Act), which, to our knowledge, is the first full-duplex, end-to-end model that simultaneously perceives and generates across vision, text, speech, and action within a single architecture, enabling interaction patterns previously out of reach, yielding more natural, human-like behaviors. At its core is a novel SA-MoE architecture (Self-Attention Mixture-of-Experts) that routes each modality to specialized experts and fuses them through a unified attention backbone. This provides a generalizable solution for joint multimodal perception and concurrent generation, leveraging strong pre-trained components while enabling efficient modality integration and mitigating modality interference. On speech-interaction and robot-manipulation benchmarks, ELLSA matches modality-specific baselines, while uniquely supporting advanced multimodal and full-duplex behaviors such as dialogue and action turn-taking, defective instruction rejection, speaking-while-acting, context-grounded visual question answering, and action barge-ins. We contend that ELLSA represents a step toward more natural and general interactive intelligence, contributing to the broader pursuit of artificial general intelligence. All data, code and model checkpoints will be released upon acceptance."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          SAMOSA: Sharpness Aware Minimization for Open Set Active learning", "authors": "Young In Kim, Andrea Agiollo, Rajiv Khanna", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "Modern machine learning solutions require extensive data collection where labeling remains costly. To reduce this burden, open set active learning approaches aim to select informative samples from a large pool of unlabeled data that includes irrelevant or unknown classes. In this context, we propose Sharpness Aware Minimization for Open Set Active Learning (SAMOSA) as an effective querying algorithm. Building on theoretical findings concerning the impact of data typicality on the generalization properties of traditional stochastic gradient descent (SGD) and sharpness-aware minimization (SAM), SAMOSA actively queries samples based on their typicality. SAMOSA effectively identifies atypical samples that belong to regions of the embedding manifold close to the model decision boundaries. Therefore, SAMOSA prioritizes the samples that are (i) highly informative for the targeted classes, and (ii) useful for distinguishing between targeted and unwanted classes. Extensive experiments show that SAMOSA achieves up to 3% accuracy improvement over the state of the art across several datasets, while not introducing computational overhead. The source code of our experiments is available at: this https URL"}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Enhancing Language Agent Strategic Reasoning through Self-Play in Adversarial Games", "authors": "Yikai Zhang, Ye Rong, Siyu Yuan, Jiangjie Chen, Jian Xie, Yanghua Xiao", "subjects": "Computation and Language (cs.CL)", "abstract": "Existing language agents often encounter difficulties in dynamic adversarial games due to poor strategic reasoning. To mitigate this limitation, a promising approach is to allow agents to learn from game interactions automatically, without relying on costly expert-labeled data. Unlike static environments where agents receive fixed feedback or rewards, selecting appropriate opponents in dynamic adversarial games can significantly impact learning performance. However, the discussion of opponents in adversarial environments remains an area under exploration. In this paper, we propose a Step-level poliCy Optimization method through Play-And-Learn, SCO-PAL. Leveraging SCO-PAL, we conduct a detailed analysis of opponent selection by setting opponents at different levels and find that self-play is the most effective way to improve strategic reasoning in such adversarial environments. Utilizing SCO-PAL with self-play, we increase the average win rate against four opponents by approximately 30% compared to baselines and achieve a 54.76% win rate against GPT-4 in six adversarial games."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Bilateralist base-extension semantics with incompatible proofs and refutations", "authors": "Victor Barroso-Nascimento, Maria Os\u00f3rio Costa, Elaine Pimentel", "subjects": "Logic in Computer Science (cs.LO)", "abstract": "Logical bilateralism challenges traditional concepts of logic by treating assertion and denial as independent yet opposed acts. While initially devised to justify classical logic, its constructive variants show that both acts admit intuitionistic interpretations. This paper presents a bilateral system where a formula cannot be both provable and refutable without contradiction, offering a framework for modelling epistemic entities, such as mathematical proofs and refutations, that exclude inconsistency. The logic is formalised through a bilateral natural deduction system with desirable proof-theoretic properties, including normalisation. We also introduce a base-extension semantics requiring explicit constructions of proofs and refutations while preventing them from being established for the same formula. The semantics is proven sound and complete with respect to the calculus. Finally, we show that our notion of refutation corresponds to David Nelson's constructive falsity, extending rather than revising intuitionistic logic and reinforcing the system's suitability for representing constructive epistemic reasoning."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Comparing User Behavior in Real vs. Virtual Supermarket Shelves: An Eye-Tracking Study Using Tobii 3 Pro and Meta Quest Pro", "authors": "Francesco Vona, Julia Schorlemmer, Paulina Kaulard, Sebastian Fischer, Jessica Stemann, Jan-Niklas Voigt-Antons", "subjects": "Human-Computer Interaction (cs.HC)", "abstract": "This study compares user behavior between real and virtual supermarket shelves using eye tracking technology to assess behavior in both environments. A sample of 29 participants was randomly assigned to two conditions: a real world supermarket shelf with Tobii eye tracking and a virtual shelf using the Meta Quest Pro eye tracker. In both scenarios, participants were asked to select three packs of cereals belonging to specific categories, healthy or tasty. The aim was to explore whether virtual environments could realistically replicate real world experiences, particularly regarding consumer behavior. By analyzing eye tracking data, the study examined how attention and product selection strategies varied between real and virtual conditions. Results showed that participants' attention differed across product types and shopping environments. Consumers focused more on lower shelves in real settings, especially when looking for healthy products. In VR, attention shifted to eye level shelves, particularly for tasty items, aligning with optimal product placement strategies in supermarkets. Overall, sweet products received less visual attention across both settings."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          WaMaIR: Image Restoration via Multiscale Wavelet Convolutions and Mamba-based Channel Modeling with Texture Enhancement", "authors": "Shengyu Zhu, Fan, Fuxuan Zhang", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Image restoration is a fundamental and challenging task in computer vision, where CNN-based frameworks demonstrate significant computational efficiency. However, previous CNN-based methods often face challenges in adequately restoring fine texture details, which are limited by the small receptive field of CNN structures and the lack of channel feature modeling. In this paper, we propose WaMaIR, which is a novel framework with a large receptive field for image perception and improves the reconstruction of texture details in restored images. Specifically, we introduce the Global Multiscale Wavelet Transform Convolutions (GMWTConvs) for expandding the receptive field to extract image features, preserving and enriching texture features in model inputs. Meanwhile, we propose the Mamba-Based Channel-Aware Module (MCAM), explicitly designed to capture long-range dependencies within feature channels, which enhancing the model sensitivity to color, edges, and texture information. Additionally, we propose Multiscale Texture Enhancement Loss (MTELoss) for image restoration to guide the model in preserving detailed texture structures effectively. Extensive experiments confirm that WaMaIR outperforms state-of-the-art methods, achieving better image restoration and efficient computational performance of the model."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          T3 Planner: A Self-Correcting LLM Framework for Robotic Motion Planning with Temporal Logic", "authors": "Jia Li, Guoxiang Zhao", "subjects": "Robotics (cs.RO)", "abstract": "Translating natural language instructions into executable motion plans is a fundamental challenge in robotics. Traditional approaches are typically constrained by their reliance on domain-specific expertise to customize planners, and often struggle with spatio-temporal couplings that usually lead to infeasible motions or discrepancies between task planning and motion execution. Despite the proficiency of Large Language Models (LLMs) in high-level semantic reasoning, hallucination could result in infeasible motion plans. In this paper, we introduce the T3 Planner, an LLM-enabled robotic motion planning framework that self-corrects it output with formal methods. The framework decomposes spatio-temporal task constraints via three cascaded modules, each of which stimulates an LLM to generate candidate trajectory sequences and examines their feasibility via a Signal Temporal Logic (STL) verifier until one that satisfies complex spatial, temporal, and logical constraints is this http URL across different scenarios show that T3 Planner significantly outperforms the baselines. The required reasoning can be distilled into a lightweight Qwen3-4B model that enables efficient deployment. All supplementary materials are accessible at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          See or Say Graphs: Agent-Driven Scalable Graph Understanding with Vision-Language Models", "authors": "Shuo Han, Yukun Cao, Zezhong Ding, Zengyi Gao, S Kevin Zhou, Xike Xie", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "abstract": "Vision-language models (VLMs) have shown promise in graph understanding, but remain limited by input-token constraints, facing scalability bottlenecks and lacking effective mechanisms to coordinate textual and visual modalities. To address these challenges, we propose GraphVista, a unified framework that enhances both scalability and modality coordination in graph understanding. For scalability, GraphVista organizes graph information hierarchically into a lightweight GraphRAG base, which retrieves only task-relevant textual descriptions and high-resolution visual subgraphs, compressing redundant context while preserving key reasoning elements. For modality coordination, GraphVista introduces a planning agent that routes tasks to the most suitable modality-using the text modality for simple property reasoning and the visual modality for local and structurally complex reasoning grounded in explicit topology. Extensive experiments demonstrate that GraphVista scales to large graphs, up to $200\\times$ larger than those used in existing benchmarks, and consistently outperforms existing textual, visual, and fusion-based methods, achieving up to $4.4\\times$ quality improvement over the state-of-the-art baselines by fully exploiting the complementary strengths of both modalities."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          A Preliminary Exploration of the Differences and Conjunction of Traditional PNT and Brain-inspired PNT", "authors": "Xu He, Xiaolin Meng, Wenxuan Yin, Youdong Zhang, Lingfei Mo, Xiangdong An, Fangwen Yu, Shuguo Pan, Yufeng Liu, Jingnan Liu, Yujia Zhang, Wang Gao", "subjects": "Robotics (cs.RO)", "abstract": "Developing universal Positioning, Navigation, and Timing (PNT) is our enduring goal. Today's complex environments demand PNT that is more resilient, energy-efficient and cognitively capable. This paper asks how we can endow unmanned systems with brain-inspired spatial cognition navigation while exploiting the high precision of machine PNT to advance universal PNT. We provide a new perspective and roadmap for shifting PNT from \"tool-oriented\" to \"cognition-driven\". Contributions: (1) multi-level dissection of differences among traditional PNT, biological brain PNT and brain-inspired PNT; (2) a four-layer (observation-capability-decision-hardware) fusion framework that unites numerical precision and brain-inspired intelligence; (3) forward-looking recommendations for future development of brain-inspired PNT."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Region in Context: Text-condition Image editing with Human-like semantic reasoning", "authors": "Thuy Phuong Vu, Dinh-Cuong Hoang, Minhhuy Le, Phan Xuan Tan", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "abstract": "Recent research has made significant progress in localizing and editing image regions based on text. However, most approaches treat these regions in isolation, relying solely on local cues without accounting for how each part contributes to the overall visual and semantic composition. This often results in inconsistent edits, unnatural transitions, or loss of coherence across the image. In this work, we propose Region in Context, a novel framework for text-conditioned image editing that performs multilevel semantic alignment between vision and language, inspired by the human ability to reason about edits in relation to the whole scene. Our method encourages each region to understand its role within the global image context, enabling precise and harmonized changes. At its core, the framework introduces a dual-level guidance mechanism: regions are represented with full-image context and aligned with detailed region-level descriptions, while the entire image is simultaneously matched to a comprehensive scene-level description generated by a large vision-language model. These descriptions serve as explicit verbal references of the intended content, guiding both local modifications and global structure. Experiments show that it produces more coherent and instruction-aligned results. Code is available at: this https URL"}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Learning to play: A Multimodal Agent for 3D Game-Play", "authors": "Yuguang Yue, Irakli Salia, Samuel Hunt, Christopher Green, Wenzhe Shi, Jonathan J Hunt", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "We argue that 3-D first-person video games are a challenging environment for real-time multi-modal reasoning. We first describe our dataset of human game-play, collected across a large variety of 3-D first-person games, which is both substantially larger and more diverse compared to prior publicly disclosed datasets, and contains text instructions. We demonstrate that we can learn an inverse dynamics model from this dataset, which allows us to impute actions on a much larger dataset of publicly available videos of human game play that lack recorded actions. We then train a text-conditioned agent for game playing using behavior cloning, with a custom architecture capable of realtime inference on a consumer GPU. We show the resulting model is capable of playing a variety of 3-D games and responding to text input. Finally, we outline some of the remaining challenges such as long-horizon tasks and quantitative evaluation across a large set of games."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          EMRRG: Efficient Fine-Tuning Pre-trained X-ray Mamba Networks for Radiology Report Generation", "authors": "Mingzheng Zhang, Jinfeng Gao, Dan Xu, Jiangrui Yu, Yuhan Qiao, Lan Chen, Jin Tang, Xiao Wang", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "abstract": "X-ray image-based medical report generation (MRG) is a pivotal area in artificial intelligence that can significantly reduce diagnostic burdens for clinicians and patient wait times. Existing MRG models predominantly rely on Large Language Models (LLMs) to improve report generation, with limited exploration of pre-trained vision foundation models or advanced fine-tuning techniques. Mainstream frameworks either avoid fine-tuning or utilize simplistic methods like LoRA, often neglecting the potential of enhancing cross-attention mechanisms. Additionally, while Transformer-based models dominate vision-language tasks, non-Transformer architectures, such as the Mamba network, remain underexplored for medical report generation, presenting a promising avenue for future research. In this paper, we propose EMRRG, a novel X-ray report generation framework that fine-tunes pre-trained Mamba networks using parameter-efficient methods. Specifically, X-ray images are divided into patches, tokenized, and processed by an SSM-based vision backbone for feature extraction, with Partial LoRA yielding optimal performance. An LLM with a hybrid decoder generates the medical report, enabling end-to-end training and achieving strong results on benchmark datasets. Extensive experiments on three widely used benchmark datasets fully validated the effectiveness of our proposed strategies for the X-ray MRG. The source code of this paper will be released on this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          GS2POSE: Marry Gaussian Splatting to 6D Object Pose Estimation", "authors": "Junbo Li, Weimin Yuan, Yinuo Wang, Yue Zeng, Shihao Shu, Cai Meng, Xiangzhi Bai", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Accurate 6D pose estimation of 3D objects is a fundamental task in computer vision, and current research typically predicts the 6D pose by establishing correspondences between 2D image features and 3D model features. However, these methods often face difficulties with textureless objects and varying illumination conditions. To overcome these limitations, we propose GS2POSE, a novel approach for 6D object pose estimation. GS2POSE formulates a pose regression algorithm inspired by the principles of Bundle Adjustment (BA). By leveraging Lie algebra, we extend the capabilities of 3DGS to develop a pose-differentiable rendering pipeline, which iteratively optimizes the pose by comparing the input image to the rendered image. Additionally, GS2POSE updates color parameters within the 3DGS model, enhancing its adaptability to changes in illumination. Compared to previous models, GS2POSE demonstrates accuracy improvements of 1.4\\%, 2.8\\% and 2.5\\% on the T-LESS, LineMod-Occlusion and LineMod datasets, respectively."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          QuanBench: Benchmarking Quantum Code Generation with Large Language Models", "authors": "Xiaoyu Guo, Minggu Wang, Jianjun Zhao", "subjects": "Software Engineering (cs.SE)", "abstract": "Large language models (LLMs) have demonstrated good performance in general code generation; however, their capabilities in quantum code generation remain insufficiently studied. This paper presents QuanBench, a benchmark for evaluating LLMs on quantum code generation. QuanBench includes 44 programming tasks that cover quantum algorithms, state preparation, gate decomposition, and quantum machine learning. Each task has an executable canonical solution and is evaluated by functional correctness (Pass@K) and quantum semantic equivalence (Process Fidelity). We evaluate several recent LLMs, including general-purpose and code-specialized models. The results show that current LLMs have limited capability in generating the correct quantum code, with overall accuracy below 40% and frequent semantic errors. We also analyze common failure cases, such as outdated API usage, circuit construction errors, and incorrect algorithm logic. QuanBench provides a basis for future work on improving quantum code generation with LLMs."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          3D-GSRD: 3D Molecular Graph Auto-Encoder with Selective Re-mask Decoding", "authors": "Chang Wu, Zhiyuan Liu, Wen Shu, Liang Wang, Yanchen Luo, Wenqiang Lei, Yatao Bian, Junfeng Fang, Xiang Wang", "subjects": "Machine Learning (cs.LG)", "abstract": "Masked graph modeling (MGM) is a promising approach for molecular representation learning (MRL).However, extending the success of re-mask decoding from 2D to 3D MGM is non-trivial, primarily due to two conflicting challenges: avoiding 2D structure leakage to the decoder, while still providing sufficient 2D context for reconstructing re-masked this http URL address these challenges, we propose 3D-GSRD: a 3D Molecular Graph Auto-Encoder with Selective Re-mask Decoding. The core innovation of 3D-GSRD lies in its Selective Re-mask Decoding(SRD), which re-masks only 3D-relevant information from encoder representations while preserving the 2D graph this http URL SRD is synergistically integrated with a 3D Relational-Transformer(3D-ReTrans) encoder alongside a structure-independent decoder. We analyze that SRD, combined with the structure-independent decoder, enhances the encoder's role in MRL. Extensive experiments show that 3D-GSRD achieves strong downstream performance, setting a new state-of-the-art on 7 out of 8 targets in the widely used MD17 molecular property prediction benchmark. The code is released at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Xiaoice: Training-Free Video Understanding via Self-Supervised Spatio-Temporal Clustering of Semantic Features", "authors": "Shihao Ji, Zihui Song", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "abstract": "The remarkable zero-shot reasoning capabilities of large-scale Visual Language Models (VLMs) on static images have yet to be fully translated to the video domain. Conventional video understanding models often rely on extensive, task-specific training on annotated datasets, a process that is both costly and limited in scalability. This paper introduces a novel, training-free framework for video understanding that circumvents end-to-end training by synergistically combining the rich semantic priors of pre-trained VLMs with classic machine learning algorithms for pattern discovery. Our core idea is to reframe video understanding as a self-supervised spatio-temporal clustering problem within a high-dimensional semantic feature space. The proposed pipeline first transforms a video stream into a semantic feature trajectory using the frozen visual encoder of a pre-trained VLM. Subsequently, we employ Kernel Temporal Segmentation (KTS), a robust machine learning technique, to partition the continuous feature stream into discrete, semantically coherent event segments. These segments are then subjected to unsupervised density-based clustering to identify recurring macroscopic scenes and themes throughout the video. By selecting representative keyframes from each discovered cluster and leveraging the VLM's generative capabilities for textual description, our framework automatically produces a structured, multi-modal summary of the video content. This approach provides an effective, interpretable, and model-agnostic pathway for zero-shot, automated structural analysis of video content."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          LC-Eval: A Bilingual Multi-Task Evaluation Benchmark for Long-Context Understanding", "authors": "Sheikh Jubair, Arwa Omayrah, Amal Alshammari, Alhanoof Althnian, Abdulhamed Alothaimen, Norah A. Alzahrani, Shahad D. Alzaidi, Nora Al-Twairesh, Abdulmohsen Al-Thubaity", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "abstract": "Recent advancements in Large Language Models (LLMs) have demonstrated sophisticated capabilities, including the ability to process and comprehend extended contexts. These emergent capabilities necessitate rigorous evaluation methods to effectively assess their performance in long-context understanding. In this paper, we present \\textbf{LC-Eval}, a bilingual, multi-task evaluation benchmark designed to evaluate long-context understanding in English and Arabic, targeting context lengths ranging from 4k to over 128k tokens. LC-Eval introduces four novel and challenging tasks: multi-document question answering, bilingual question answering, claim verification within a paragraph, and multiple-choice questions based on long contexts. These tasks are designed to assess LLMs' abilities in deep reasoning, document comprehension, information tracing, and bilingual information extraction and understanding. The benchmark includes datasets in both Arabic and English for each task, allowing for a comparative analysis of their performance across different text genres. Evaluations were conducted on both open-weight and closed LLMs, with results indicating that LC-Eval presents significant challenges. Even high-performing models, such as GPT-4o, struggled with certain tasks, highlighting the complexity and rigor of the benchmark."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Segmentation as A Plug-and-Play Capability for Frozen Multimodal LLMs", "authors": "Jiazhen Liu, Long Chen", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Integrating diverse visual capabilities into a unified model is a significant trend in Multimodal Large Language Models (MLLMs). Among these, the inclusion of segmentation poses a distinct set of challenges. To equip MLLMs with pixel-level segmentation abilities, prevailing methods require finetuning the model to produce specific outputs compatible with a mask decoder. This process typically alters the model's output space and compromises its intrinsic generalization, which undermines the goal of building a unified model. We introduce LENS (Leveraging kEypoiNts for MLLMs' Segmentation), a novel plug-and-play solution. LENS attaches a lightweight, trainable head to a completely frozen MLLM. By refining the spatial cues embedded in attention maps, LENS extracts keypoints and describes them into point-wise features directly compatible with the mask decoder. Extensive experiments validate our approach: LENS achieves segmentation performance competitive with or superior to that of retraining-based methods. Crucially, it does so while fully preserving the MLLM's generalization capabilities, which are significantly degraded by finetuning approaches. As such, the attachable design of LENS establishes an efficient and powerful paradigm for extending MLLMs, paving the way for truly multi-talented, unified models."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          More with Less: An Empirical Study of Turn-Control Strategies for Efficient Coding Agents", "authors": "Pengfei Gao, Chao Peng", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "abstract": "LLM-powered coding agents, which operate in iterative loops (turns) to solve software engineering tasks, are becoming increasingly powerful. However, their practical deployment is hindered by significant and unpredictable costs. This challenge arises from a combination of factors: quadratically growing token counts with each turn, the high price of models, the large number of turns required for real-world tasks, and the tendency of agents to take inefficient or unnecessary actions. While existing research focuses on optimizing individual turns, the strategic control of the total number of turns remains an underexplored area for managing agent performance and cost. To address this gap, we conduct a comprehensive empirical study on SWE-bench using three state-of-the-art models and evaluate the impact of three distinct turn-control strategies: an unrestricted baseline, a fixed-turn limit with reminders, and a novel dynamic-turn strategy that grants extensions on-demand. Our findings first reveal a fundamental trade-off in the unrestricted setting, where no single model excels across performance, cost, and turn efficiency. We then show that a fixed-turn limit, specifically at the 75th percentile of the baseline, serves as a \"sweet spot\", substantially reducing costs (by 24%-68%) with minimal impact on solve rates. Most significantly, the dynamic-turn strategy consistently outperforms fixed-limit approaches, achieving comparable or better solve rates while further reducing costs by an additional 12%-24% by intelligently allocating resources only to tasks that need them. This work provides the first systematic analysis of turn-control strategies, offering simple yet effective guidelines for developers to balance cost and efficacy. We demonstrate that dynamic resource allocation is a superior, easy-to-implement approach for deploying powerful yet economically viable coding agents."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Unsupervised Monocular Road Segmentation for Autonomous Driving via Scene Geometry", "authors": "Sara Hatami Rostami, Behrooz Nasihatkon", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "This paper presents a fully unsupervised approach for binary road segmentation (road vs. non-road), eliminating the reliance on costly manually labeled datasets. The method leverages scene geometry and temporal cues to distinguish road from non-road regions. Weak labels are first generated from geometric priors, marking pixels above the horizon as non-road and a predefined quadrilateral in front of the vehicle as road. In a refinement stage, temporal consistency is enforced by tracking local feature points across frames and penalizing inconsistent label assignments using mutual information maximization. This enhances both precision and temporal stability. On the Cityscapes dataset, the model achieves an Intersection-over-Union (IoU) of 0.82, demonstrating high accuracy with a simple design. These findings demonstrate the potential of combining geometric constraints and temporal consistency for scalable unsupervised road segmentation in autonomous driving."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Personalized Image Filter: Mastering Your Photographic Style", "authors": "Chengxuan Zhu, Shuchen Weng, Jiacong Fang, Peixuan Zhang, Si Li, Chao Xu, Boxin Shi", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Photographic style, as a composition of certain photographic concepts, is the charm behind renowned photographers. But learning and transferring photographic style need a profound understanding of how the photo is edited from the unknown original appearance. Previous works either fail to learn meaningful photographic concepts from reference images, or cannot preserve the content of the content image. To tackle these issues, we proposed a Personalized Image Filter (PIF). Based on a pretrained text-to-image diffusion model, the generative prior enables PIF to learn the average appearance of photographic concepts, as well as how to adjust them according to text prompts. PIF then learns the photographic style of reference images with the textual inversion technique, by optimizing the prompts for the photographic concepts. PIF shows outstanding performance in extracting and transferring various kinds of photographic style. Project page: this https URL"}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Non-Orthogonal Pilot Sequence Design for Multi-Cells Interference Networks", "authors": "Zhi Gu, Wai Ho Mow", "subjects": "Information Theory (cs.IT)", "abstract": "In wireless communications, the performance of non-orthogonal sequence sets significantly affects the level of multi-user interference when the number of users surpasses the sequence length. The design of non-orthogonal sequences plays a crucial role in both the non-orthogonality of the pilots in multi-cell systems and the signature sequences in overloaded code-division multiple-access (CDMA) systems. In multi-cell systems, considering the strength disparity between channels originating from the home cell and the neighboring cells, the extended total squared correlation (ETSC) is proposed as a new sequence design criterion, which is defined as the sum of squares of the weighted correlations among sequences. In this paper, we derive a closed-form expression for the lower bound of ETSC for multi-cell systems with a given sequence length $\\tau$, where $\\tau \\leq K$ and $K$ is the number of users per cell. This can be regarded as a generalization of the well-known Welch bound (Welch, 1974, IEEE TIT) and the extended Welch bound (Wang et al., 2021, IEEE TWC). Additionally, from the necessary conditions of the bound, the optimal sequence set can be easily obtained when the interference power factor matrix is positive definite. On the other hand, to address the lack of sequence generation methods under certain parameter conditions, we propose the ETSC-MM algorithm, which generates sequence sets with low ETSC based on a Majorization-Minimization (MM) optimization framework."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Black-box Optimization of LLM Outputs by Asking for Directions", "authors": "Jie Zhang, Meng Ding, Yang Liu, Jue Hong, Florian Tram\u00e8r", "subjects": "Cryptography and Security (cs.CR); Machine Learning (cs.LG)", "abstract": "We present a novel approach for attacking black-box large language models (LLMs) by exploiting their ability to express confidence in natural language. Existing black-box attacks require either access to continuous model outputs like logits or confidence scores (which are rarely available in practice), or rely on proxy signals from other models. Instead, we demonstrate how to prompt LLMs to express their internal confidence in a way that is sufficiently calibrated to enable effective adversarial optimization. We apply our general method to three attack scenarios: adversarial examples for vision-LLMs, jailbreaks and prompt injections. Our attacks successfully generate malicious inputs against systems that only expose textual outputs, thereby dramatically expanding the attack surface for deployed LLMs. We further find that better and larger models exhibit superior calibration when expressing confidence, creating a concerning security paradox where model capability improvements directly enhance vulnerability. Our code is available at this [link](this https URL)."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          MOSAIC: Masked Objective with Selective Adaptation for In-domain Contrastive Learning", "authors": "Vera Pavlova, Mohammed Makhlouf", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "abstract": "We introduce MOSAIC (Masked Objective with Selective Adaptation for In-domain Contrastive learning), a multi-stage framework for domain adaptation of sentence embedding models that incorporates joint domain-specific masked supervision. Our approach addresses the challenges of adapting large-scale general-domain sentence embedding models to specialized domains. By jointly optimizing masked language modeling (MLM) and contrastive objectives within a unified training pipeline, our method enables effective learning of domain-relevant representations while preserving the robust semantic discrimination properties of the original model. We empirically validate our approach on both high-resource and low-resource domains, achieving improvements up to 13.4% in NDCG@10 (Normalized Discounted Cumulative Gain) over strong general-domain baselines. Comprehensive ablation studies further demonstrate the effectiveness of each component, highlighting the importance of balanced joint supervision and staged adaptation."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          An RGB-D Image Dataset for Lychee Detection and Maturity Classification for Robotic Harvesting", "authors": "Zhenpeng Zhang, Yi Wang, Shanglei Chai, Yingying Liu, Zekai Xie, Wenhao Huang, Pengyu Li, Zipei Luo, Dajiang Lu, Yibin Tian", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)", "abstract": "Lychee is a high-value subtropical fruit. The adoption of vision-based harvesting robots can significantly improve productivity while reduce reliance on labor. High-quality data are essential for developing such harvesting robots. However, there are currently no consistently and comprehensively annotated open-source lychee datasets featuring fruits in natural growing environments. To address this, we constructed a dataset to facilitate lychee detection and maturity classification. Color (RGB) images were acquired under diverse weather conditions, and at different times of the day, across multiple lychee varieties, such as Nuomici, Feizixiao, Heiye, and Huaizhi. The dataset encompasses three different ripeness stages and contains 11,414 images, consisting of 878 raw RGB images, 8,780 augmented RGB images, and 1,756 depth images. The images are annotated with 9,658 pairs of lables for lychee detection and maturity classification. To improve annotation consistency, three individuals independently labeled the data, and their results were then aggregated and verified by a fourth reviewer. Detailed statistical analyses were done to examine the dataset. Finally, we performed experiments using three representative deep learning models to evaluate the dataset. It is publicly available for academic"}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Strong error analysis and first-order convergence of Milstein-type schemes for McKean-Vlasov SDEs with superlinear coefficients", "authors": "Jingtao Zhu, Yuying Zhao, Siqing Gan", "subjects": "Numerical Analysis (math.NA)", "abstract": "In the study of McKean-Vlasov stochastic differential equations (MV-SDEs), numerical approximation plays a crucial role in understanding the behavior of interacting particle systems (IPS). Classical Milstein schemes provide strong convergence of order one under globally Lipschitz coefficients. Nevertheless, many MV-SDEs arising from applications possess super-linearly growing drift and diffusion terms, where classical methods may diverge and particle corruption can occur. In the present work, we aim to fill this gap by developing a unified class of Milstein-type discretizations handling both super-linear drift and diffusion coefficients. The proposed framework includes the tamed-, tanh-, and sine-Milstein methods as special cases and establishes order-one strong convergence for the associated interacting particle system under mild regularity assumptions, requiring only once differentiable coefficients. In particular, our results complement Chen et al. (Electron. J. Probab., 2025), where a taming-based Euler scheme was only tested numerically without theoretical guarantees, by providing a rigorous convergence theory within a broader Milstein-type framework. The analysis relies on discrete-time arguments and binomial-type expansions, avoiding the continuous-time It\u00f4 approach that is standard in the literature. Numerical experiments are presented to illustrate the convergence behavior and support the theoretical findings."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Domain-Contextualized Concept Graphs: A Computable Framework for Knowledge Representation", "authors": "Chao Li, Yuru Wang", "subjects": "Artificial Intelligence (cs.AI)", "abstract": "Traditional knowledge graphs are constrained by fixed ontologies that organize concepts within rigid hierarchical structures. The root cause lies in treating domains as implicit context rather than as explicit, reasoning-level components. To overcome these limitations, we propose the Domain-Contextualized Concept Graph (CDC), a novel knowledge modeling framework that elevates domains to first-class elements of conceptual representation. CDC adopts a C-D-C triple structure - <Concept, Relation@Domain, Concept'> - where domain specifications serve as dynamic classification dimensions defined on demand. Grounded in a cognitive-linguistic isomorphic mapping principle, CDC operationalizes how humans understand concepts through contextual frames. We formalize more than twenty standardized relation predicates (structural, logical, cross-domain, and temporal) and implement CDC in Prolog for full inference capability. Case studies in education, enterprise knowledge systems, and technical documentation demonstrate that CDC enables context-aware reasoning, cross-domain analogy, and personalized knowledge modeling - capabilities unattainable under traditional ontology-based frameworks."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          An Efficient Framework for Whole-Page Reranking via Single-Modal Supervision", "authors": "Zishuai Zhang, Sihao Yu, Wenyi Xie, Ying Nie, Junfeng Wang, Zhiming Zheng, Dawei Yin, Hainan Zhang", "subjects": "Information Retrieval (cs.IR)", "abstract": "The whole-page reranking plays a critical role in shaping the user experience of search engines, which integrates retrieval results from multiple modalities, such as documents, images, videos, and LLM outputs. Existing methods mainly rely on large-scale human-annotated data, which is costly to obtain and time-consuming. This is because whole-page annotation is far more complex than single-modal: it requires assessing the entire result page while accounting for cross-modal relevance differences. Thus, how to improve whole-page reranking performance while reducing annotation costs is still a key challenge in optimizing search engine result pages(SERP). In this paper, we propose SMAR, a novel whole-page reranking framework that leverages strong Single-modal rankers to guide Modal-wise relevance Alignment for effective Reranking, using only limited whole-page annotation to outperform fully-annotated reranking models. Specifically, high-quality single-modal rankers are first trained on data specific to their respective modalities. Then, for each query, we select a subset of their outputs to construct candidate pages and perform human annotation at the page level. Finally, we train the whole-page reranker using these limited annotations and enforcing consistency with single-modal preferences to maintain ranking quality within each modality. Experiments on the Qilin and Baidu datasets demonstrate that SMAR reduces annotation costs by about 70-90\\% while achieving significant ranking improvements compared to baselines. Further offline and online A/B testing on Baidu APPs also shows notable gains in standard ranking metrics as well as user experience indicators, fully validating the effectiveness and practical value of our approach in real-world search scenarios."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          The Layout Is the Model: On Action-Item Coupling in Generative Recommendation", "authors": "Xiaokai Wei, Jiajun Wu, Daiyao Yi, Reza Shirkavand, Michelle Gong", "subjects": "Information Retrieval (cs.IR)", "abstract": "Generative Recommendation (GR) models treat a user's interaction history as a sequence to be autoregressively predicted. When both items and actions (e.g., watch time, purchase, comment) are modeled, the layout-the ordering and visibility of item/action tokens-critically determines what information the model can use and how it generalizes. We present a unified study of token layouts for GR grounded in first principles: (P1) maximize item/action signal in both input/output space, (P2) preserve the conditioning relationship \"action given item\" and (P3) no information leakage. While interleaved layout (where item and action occupy separate tokens) naturally satisfies these principles, it also bloats sequence length with larger training/inference cost. On the non-interleaved front, we design a novel and effective approach, Lagged Action Conditioning (LAC), which appears strange on the surface but aligns well with the design principles to yield strong accuracy. Comprehensive experiments on public datasets and large-scale production logs evaluate different layout options and empirically verifies the design principles. Our proposed non-interleaved method, LAC, achieves competitive or superior quality at substantially lower FLOPs than interleaving. Our findings offer actionable guidance for assembling GR systems that are both accurate and efficient."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Mixed-Precision Quantization for Language Models: Techniques and Prospects", "authors": "Mariam Rakka, Marios Fournarakis, Olga Krestinskaya, Jinane Bazzi, Khaled N. Salama, Fadi Kurdahi, Ahmed M. Eltawil, Mohammed E. Fouda", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "The rapid scaling of language models (LMs) has resulted in unprecedented computational, memory, and energy requirements, making their training and deployment increasingly unsustainable. Quantization has emerged as an essential compression technique to reduce model size, alleviate memory bottlenecks, and accelerate inference. However, while uniform low-bit quantization (e.g., INT8, INT4) provides significant efficiency gains, it can degrade accuracy in sensitive components of transformer-based LMs. Mixed-precision quantization offers a promising alternative by selectively allocating precision across layers or within tensors to balance efficiency and accuracy. This survey provides a comprehensive overview of Mixed-Precision quantization frameworks for LMs (MXPLMs). We first review quantization fundamentals, including uniform and non-uniform quantizers, quantization granularity, and methods widely used in post-training quantization. We then categorize and compare recent MXPLM frameworks according to their bit allocation strategies and precision configurations across weights, activations, and key-value caches. A comparative analysis highlights differences in perplexity, zero-shot task performance, and deployment trade-offs. Furthermore, we contrast MXPLMs with earlier mixed-precision quantization methods for deep neural networks, identifying strategies that transfer and those that face challenges in the LM setting. Finally, we summarize open issues and future directions, including hardware-aware design, activation quantization, and scalable optimization methods for billion-parameter models. By consolidating recent advances, this work serves as a reference for understanding the current landscape and research prospects of mixed-precision quantization for large-scale language models."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Computational Budget Should Be Considered in Data Selection", "authors": "Weilin Wan, Weizhong Zhang, Cheng Jin", "subjects": "Machine Learning (cs.LG)", "abstract": "Data selection improves computational efficiency by choosing informative subsets of training samples. However, existing methods ignore the compute budget, treating data selection and importance evaluation independently of compute budget constraints. Yet empirical studies show no algorithm can consistently outperform others (or even random selection) across varying budgets. We therefore argue that compute budget must be integral to data-selection strategies, since different budgets impose distinct requirements on data quantity, quality, and distribution for effective training. To this end, we propose a novel Computational budget-Aware Data Selection (CADS) method and naturally formulate it into a bilevel optimization framework, where the inner loop trains the model within the constraints of the computational budget on some selected subset of training data, while the outer loop optimizes data selection based on model evaluation. Our technical contributions lie in addressing two main challenges in solving this bilevel optimization problem: the expensive Hessian matrix estimation for outer-loop gradients and the computational burden of achieving inner-loop optimality during iterations. To solve the first issue, we propose a probabilistic reparameterization strategy and compute the gradient using a Hessian-free policy gradient estimator. To address the second challenge, we transform the inner optimization problem into a penalty term in the outer objective, further discovering that we only need to estimate the minimum of a one-dimensional loss to calculate the gradient, significantly improving efficiency. Extensive experiments show that our method achieves performance gains of up to 14.42% over baselines in vision and language benchmarks."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Improving Model Representation and Reducing KV Cache via Skip Connections with First Value Heads", "authors": "Zhoutong Wu, Yuan Zhang, Yiming Dong, Chenheng Zhang, Cong Fang, Kun Yuan, Zhouchen Lin", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "Transformer models have driven breakthroughs across various language tasks by their strong capability to learn rich contextual representations. Scaling them to improve representation, however, often demands substantial memory and compute costs, such as the Key-Value (KV) cache used during auto-regressive decoding. Skip connections offer a promising way to improve representation without bloating resource usage, yet most prior works either improve expressivity while leaving KV costs unchanged, or reduce memory at the cost of weaker representation. In this work, we propose SkipV1Former, a Transformer variant that uses skip connections from the first layer's Value heads to strengthen model representation and reduce KV cache. Specifically, from the second block onward, each layer reuses half of its Value heads from the very first layer, while computing the other half as usual-cutting Value projections and V cache by nearly 50 \\%. Theoretically, we show that routing uncompressed first-layer Values into deeper layers restores information lost to compression and accelerates the model's implicit mesa-optimization-a key pattern of Transformer in auto-regressive tasks. Empirically, across different model scales, SkipV1Former delivers consistent reductions of approximately 25 \\% in KV cache while improving perplexity relative to standard Multi-Head Attention (MHA) Transformers and some advanced variants. Moreover, we propose a recipe for uptraining existing MHA Transformer checkpoints to SkipV1Former with only 10-15\\% additional compute. Finally, SkipV1Former can seamlessly combine advanced methods like Group-Query Attention and Multi-Latent Attention to achieve further KV cache savings and performance improvement. When combined with YOCO, it cuts KV cache size by nearly 50 \\% while still improving performance."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          When Many-Shot Prompting Fails: An Empirical Study of LLM Code Translation", "authors": "Amirkia Rafiei Oskooei, Kaan Baturalp Cosdan, Husamettin Isiktas, Mehmet S. Aktas", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Programming Languages (cs.PL)", "abstract": "Large Language Models (LLMs) with vast context windows offer new avenues for in-context learning (ICL), where providing many examples (\"many-shot\" prompting) is often assumed to enhance performance. We investigate this assumption for the complex task of code translation. Through a large-scale empirical study of over 90,000 translations, we systematically evaluate the impact of scaling in-context examples from zero-shot to many-shot configurations of up to 625 examples, with prompts spanning from approximately 100,000 to 800,000 tokens. Our findings reveal a \"many-shot paradox\": while static similarity metrics may modestly improve with more examples, functional correctness consistently peaks with few-shot prompting (5-25 examples). Providing substantially more examples often degrades this crucial functional performance. This study highlights that for code translation, the quality of a few well-chosen examples outweighs sheer quantity, challenging the universal efficacy of \"more is better\" for ICL and underscoring the task-dependent nature of optimal prompting strategies. Our results have significant implications for effectively leveraging LLMs in software engineering."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Graph Learning is Suboptimal in Causal Bandits", "authors": "Mohammad Shahverdikondori, Jalal Etesami, Negar Kiyavash", "subjects": "Machine Learning (cs.LG)", "abstract": "We study regret minimization in causal bandits under causal sufficiency where the underlying causal structure is not known to the agent. Previous work has focused on identifying the reward's parents and then applying classic bandit methods to them, or jointly learning the parents while minimizing regret. We investigate whether such strategies are optimal. Somewhat counterintuitively, our results show that learning the parent set is suboptimal. We do so by proving that there exist instances where regret minimization and parent identification are fundamentally conflicting objectives. We further analyze both the known and unknown parent set size regimes, establish novel regret lower bounds that capture the combinatorial structure of the action space. Building on these insights, we propose nearly optimal algorithms that bypass graph and parent recovery, demonstrating that parent identification is indeed unnecessary for regret minimization. Experiments confirm that there exists a large performance gap between our method and existing baselines in various environments."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          New results on $B_\u03b1$-eigenvalues of a graph", "authors": "Germain Past\u00e9n, Carla Silva Oliveira, Jo\u00e3o Domingos G. da Silva Junior, Claudia M. Justel", "subjects": "Discrete Mathematics (cs.DM)", "abstract": "Let $G$ be a graph with adjacency matrix $A(G)$ and Laplacian matrix $L(G)$. In 2024, Samanta \\textit{et} \\textit{al.} defined the convex linear combination of $A(G)$ and $L(G)$ as $B_\\alpha(G) = \\alpha A(G) + (1-\\alpha)L(G)$, for $\\alpha \\in [0,1]$. This paper presents some results on the eigenvalues of $B_{\\alpha}(G)$ and their multiplicity when some sets of vertices satisfy certain conditions. Moreover, the positive semidefiniteness problem of $B_{\\alpha}(G)$ is studied."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Needles in the Landscape: Semi-Supervised Pseudolabeling for Archaeological Site Discovery under Label Scarcity", "authors": "Simon Jaxy, Anton Theys, Patrick Willett, W. Chris Carleton, Ralf Vandam, Pieter Libin", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Archaeological predictive modelling estimates where undiscovered sites are likely to occur by combining known locations with environmental, cultural, and geospatial variables. We address this challenge using a deep learning approach but must contend with structural label scarcity inherent to archaeology: positives are rare, and most locations are unlabeled. To address this, we adopt a semi-supervised, positive-unlabeled (PU) learning strategy, implemented as a semantic segmentation model and evaluated on two datasets covering a representative range of archaeological periods. Our approach employs dynamic pseudolabeling, refined with a Conditional Random Field (CRF) implemented via an RNN, increasing label confidence under severe class imbalance. On a geospatial dataset derived from a digital elevation model (DEM), our model performs on par with the state-of-the-art, LAMAP, while achieving higher Dice scores. On raw satellite imagery, assessed end-to-end with stratified k-fold cross-validation, it maintains performance and yields predictive surfaces with improved interpretability. Overall, our results indicate that semi-supervised learning offers a promising approach to identifying undiscovered sites across large, sparsely annotated landscapes."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Knowing the Facts but Choosing the Shortcut: Understanding How Large Language Models Compare Entities", "authors": "Hans Hergen Lehmann, Jae Hee Lee, Steven Schockaert, Stefan Wermter", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "abstract": "Large Language Models (LLMs) are increasingly used for knowledge-based reasoning tasks, yet understanding when they rely on genuine knowledge versus superficial heuristics remains challenging. We investigate this question through entity comparison tasks by asking models to compare entities along numerical attributes (e.g., ``Which river is longer, the Danube or the Nile?''), which offer clear ground truth for systematic analysis. Despite having sufficient numerical knowledge to answer correctly, LLMs frequently make predictions that contradict this knowledge. We identify three heuristic biases that strongly influence model predictions: entity popularity, mention order, and semantic co-occurrence. For smaller models, a simple logistic regression using only these surface cues predicts model choices more accurately than the model's own numerical predictions, suggesting heuristics largely override principled reasoning. Crucially, we find that larger models (32B parameters) selectively rely on numerical knowledge when it is more reliable, while smaller models (7--8B parameters) show no such discrimination, which explains why larger models outperform smaller ones even when the smaller models possess more accurate knowledge. Chain-of-thought prompting steers all models towards using the numerical features across all model sizes."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Efficient High-Accuracy PDEs Solver with the Linear Attention Neural Operator", "authors": "Ming Zhong, Zhenya Yan", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Mathematical Physics (math-ph); Computational Physics (physics.comp-ph)", "abstract": "Neural operators offer a powerful data-driven framework for learning mappings between function spaces, in which the transformer-based neural operator architecture faces a fundamental scalability-accuracy trade-off: softmax attention provides excellent fidelity but incurs quadratic complexity $\\mathcal{O}(N^2 d)$ in the number of mesh points $N$ and hidden dimension $d$, while linear attention variants reduce cost to $\\mathcal{O}(N d^2)$ but often suffer significant accuracy degradation. To address the aforementioned challenge, in this paper, we present a novel type of neural operators, Linear Attention Neural Operator (LANO), which achieves both scalability and high accuracy by reformulating attention through an agent-based mechanism. LANO resolves this dilemma by introducing a compact set of $M$ agent tokens $(M \\ll N)$ that mediate global interactions among $N$ tokens. This agent attention mechanism yields an operator layer with linear complexity $\\mathcal{O}(MN d)$ while preserving the expressive power of softmax attention. Theoretically, we demonstrate the universal approximation property, thereby demonstrating improved conditioning and stability properties. Empirically, LANO surpasses current state-of-the-art neural PDE solvers, including Transolver with slice-based softmax attention, achieving average $19.5\\%$ accuracy improvement across standard benchmarks. By bridging the gap between linear complexity and softmax-level performance, LANO establishes a scalable, high-accuracy foundation for scientific machine learning applications."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Trace Regularity PINNs: Enforcing $\\mathrm{H}^{\\frac{1}{2}}(\\partial \u03a9)$ for Boundary Data", "authors": "Doyoon Kim, Junbin Song", "subjects": "Machine Learning (cs.LG); Analysis of PDEs (math.AP)", "abstract": "We propose an enhanced physics-informed neural network (PINN), the Trace Regularity Physics-Informed Neural Network (TRPINN), which enforces the boundary loss in the Sobolev-Slobodeckij norm $H^{1/2}(\\partial \\Omega)$, the correct trace space associated with $H^1(\\Omega)$. We reduce computational cost by computing only the theoretically essential portion of the semi-norm and enhance convergence stability by avoiding denominator evaluations in the discretization. By incorporating the exact $H^{1/2}(\\partial \\Omega)$ norm, we show that the approximation converges to the true solution in the $H^{1}(\\Omega)$ sense, and, through Neural Tangent Kernel (NTK) analysis, we demonstrate that TRPINN can converge faster than standard PINNs. Numerical experiments on the Laplace equation with highly oscillatory Dirichlet boundary conditions exhibit cases where TRPINN succeeds even when standard PINNs fail, and show performance improvements of one to three decimal digits."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Cross-Genre Authorship Attribution via LLM-Based Retrieve-and-Rerank", "authors": "Shantanu Agarwal, Joel Barry, Steven Fincke, Scott Miller", "subjects": "Computation and Language (cs.CL)", "abstract": "Authorship attribution (AA) is the task of identifying the most likely author of a query document from a predefined set of candidate authors. We introduce a two-stage retrieve-and-rerank framework that finetunes LLMs for cross-genre AA. Unlike the field of information retrieval (IR), where retrieve-and-rerank is a de facto strategy, cross-genre AA systems must avoid relying on topical cues and instead learn to identify author-specific linguistic patterns that are independent of the text's subject matter (genre/domain/topic). Consequently, for the reranker, we demonstrate that training strategies commonly used in IR are fundamentally misaligned with cross-genre AA, leading to suboptimal behavior. To address this, we introduce a targeted data curation strategy that enables the reranker to effectively learn author-discriminative signals. Using our LLM-based retrieve-and-rerank pipeline, we achieve substantial gains of 22.3 and 34.4 absolute Success@8 points over the previous state-of-the-art on HIATUS's challenging HRS1 and HRS2 cross-genre AA benchmarks."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Finding Manifolds With Bilinear Autoencoders", "authors": "Thomas Dooms, Ward Gauderis", "subjects": "Machine Learning (cs.LG)", "abstract": "Sparse autoencoders are a standard tool for uncovering interpretable latent representations in neural networks. Yet, their interpretation depends on the inputs, making their isolated study incomplete. Polynomials offer a solution; they serve as algebraic primitives that can be analysed without reference to input and can describe structures ranging from linear concepts to complicated manifolds. This work uses bilinear autoencoders to efficiently decompose representations into quadratic polynomials. We discuss improvements that induce importance ordering, clustering, and activation sparsity. This is an initial step toward nonlinear yet analysable latents through their algebraic properties."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Sparse variational regularization with oversmoothing penalty term in the scale of sequence spaces", "authors": "Robert Plato, Bernd Hofmann", "subjects": "Numerical Analysis (math.NA)", "abstract": "In this work, we consider a class of linear ill-posed problems with operators that map from the sequence space $ \\ell_r $ ($r \\ge 1$) into a Banach space and in addition satisfy a conditional stability estimate in the scale of sequence spaces $ \\ell_q, \\, q \\ge 0 $. For the regularization of such problems in the presence of deterministic noise, we consider variational regularization with a penalty functional either of the form $ \\mathcal{R} =\\Vert \\cdot \\Vert_p^p $ for some $ p > 0 $ or in form of the counting measure $\\mathcal{R}_0 = \\Vert \\cdot \\Vert_0 $. The latter case guarantees sparsity of the corresponding regularized solutions. In this framework, we present first stability and then convergence rates for suitable a priori parameter choices. The results cover the oversmoothing situation, where the desired solution does not belong to the domain of definition of the considered penalty functional. The analysis of the oversmoothing case utilizes auxiliary elements that are defined by means of hard thresholding. Such technique can also be used for post processing to guarantee sparsity."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          ReefNet: A Large scale, Taxonomically Enriched Dataset and Benchmark for Hard Coral Classification", "authors": "Yahia Battach, Abdulwahab Felemban, Faizan Farooq Khan, Yousef A. Radwan, Xiang Li, Fabio Marchese, Sara Beery, Burton H. Jones, Francesca Benzoni, Mohamed Elhoseiny", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "abstract": "Coral reefs are rapidly declining due to anthropogenic pressures such as climate change, underscoring the urgent need for scalable, automated monitoring. We introduce ReefNet, a large public coral reef image dataset with point-label annotations mapped to the World Register of Marine Species (WoRMS). ReefNet aggregates imagery from 76 curated CoralNet sources and an additional site from Al Wajh in the Red Sea, totaling approximately 925000 genus-level hard coral annotations with expert-verified labels. Unlike prior datasets, which are often limited by size, geography, or coarse labels and are not ML-ready, ReefNet offers fine-grained, taxonomically mapped labels at a global scale to WoRMS. We propose two evaluation settings: (i) a within-source benchmark that partitions each source's images for localized evaluation, and (ii) a cross-source benchmark that withholds entire sources to test domain generalization. We analyze both supervised and zero-shot classification performance on ReefNet and find that while supervised within-source performance is promising, supervised performance drops sharply across domains, and performance is low across the board for zero-shot models, especially for rare and visually similar genera. This provides a challenging benchmark intended to catalyze advances in domain generalization and fine-grained coral classification. We will release our dataset, benchmarking code, and pretrained models to advance robust, domain-adaptive, global coral reef monitoring and conservation."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          When AI Takes the Wheel: Security Analysis of Framework-Constrained Program Generation", "authors": "Yue Liu, Zhenchang Xing, Shidong Pan, Chakkrit Tantithamthavorn", "subjects": "Software Engineering (cs.SE); Cryptography and Security (cs.CR)", "abstract": "In recent years, the AI wave has grown rapidly in software development. Even novice developers can now design and generate complex framework-constrained software systems based on their high-level requirements with the help of Large Language Models (LLMs). However, when LLMs gradually \"take the wheel\" of software development, developers may only check whether the program works. They often miss security problems hidden in how the generated programs are implemented. In this work, we investigate the security properties of framework-constrained programs generated by state-of-the-art LLMs. We focus specifically on Chrome extensions due to their complex security model involving multiple privilege boundaries and isolated components. To achieve this, we built ChromeSecBench, a dataset with 140 prompts based on known vulnerable extensions. We used these prompts to instruct nine state-of-the-art LLMs to generate complete Chrome extensions, and then analyzed them for vulnerabilities across three dimensions: scenario types, model differences, and vulnerability categories. Our results show that LLMs produced vulnerable programs at alarmingly high rates (18%-50%), particularly in Authentication & Identity and Cookie Management scenarios (up to 83% and 78% respectively). Most vulnerabilities exposed sensitive browser data like cookies, history, or bookmarks to untrusted code. Interestingly, we found that advanced reasoning models performed worse, generating more vulnerabilities than simpler models. These findings highlight a critical gap between LLMs' coding skills and their ability to write secure framework-constrained programs."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          ProtoMol: Enhancing Molecular Property Prediction via Prototype-Guided Multimodal Learning", "authors": "Yingxu Wang, Kunyu Zhang, Jiaxin Huang, Nan Yin, Siwei Liu, Eran Segal", "subjects": "Machine Learning (cs.LG); Molecular Networks (q-bio.MN)", "abstract": "Multimodal molecular representation learning, which jointly models molecular graphs and their textual descriptions, enhances predictive accuracy and interpretability by enabling more robust and reliable predictions of drug toxicity, bioactivity, and physicochemical properties through the integration of structural and semantic information. However, existing multimodal methods suffer from two key limitations: (1) they typically perform cross-modal interaction only at the final encoder layer, thus overlooking hierarchical semantic dependencies; (2) they lack a unified prototype space for robust alignment between modalities. To address these limitations, we propose ProtoMol, a prototype-guided multimodal framework that enables fine-grained integration and consistent semantic alignment between molecular graphs and textual descriptions. ProtoMol incorporates dual-branch hierarchical encoders, utilizing Graph Neural Networks to process structured molecular graphs and Transformers to encode unstructured texts, resulting in comprehensive layer-wise representations. Then, ProtoMol introduces a layer-wise bidirectional cross-modal attention mechanism that progressively aligns semantic features across layers. Furthermore, a shared prototype space with learnable, class-specific anchors is constructed to guide both modalities toward coherent and discriminative representations. Extensive experiments on multiple benchmark datasets demonstrate that ProtoMol consistently outperforms state-of-the-art baselines across a variety of molecular property prediction tasks."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Who's Asking? Simulating Role-Based Questions for Conversational AI Evaluation", "authors": "Navreet Kaur, Hoda Ayad, Hayoung Jung, Shravika Mittal, Munmun De Choudhury, Tanushree Mitra", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Human-Computer Interaction (cs.HC)", "abstract": "Language model users often embed personal and social context in their questions. The asker's role -- implicit in how the question is framed -- creates specific needs for an appropriate response. However, most evaluations, while capturing the model's capability to respond, often ignore who is asking. This gap is especially critical in stigmatized domains such as opioid use disorder (OUD), where accounting for users' contexts is essential to provide accessible, stigma-free responses. We propose CoRUS (COmmunity-driven Roles for User-centric Question Simulation), a framework for simulating role-based questions. Drawing on role theory and posts from an online OUD recovery community (r/OpiatesRecovery), we first build a taxonomy of asker roles -- patients, caregivers, practitioners. Next, we use it to simulate 15,321 questions that embed each role's goals, behaviors, and experiences. Our evaluations show that these questions are both highly believable and comparable to real-world data. When used to evaluate five LLMs, for the same question but differing roles, we find systematic differences: vulnerable roles, such as patients and caregivers, elicit more supportive responses (+17%) and reduced knowledge content (-19%) in comparison to practitioners. Our work demonstrates how implicitly signaling a user's role shapes model responses, and provides a methodology for role-informed evaluation of conversational AI."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Verifiable Fine-Tuning for LLMs: Zero-Knowledge Training Proofs Bound to Data Provenance and Policy", "authors": "Hasan Akgul, Daniel Borg, Arta Berisha, Amina Rahimova, Andrej Novak, Mila Petrov", "subjects": "Cryptography and Security (cs.CR); Computation and Language (cs.CL)", "abstract": "Large language models are often adapted through parameter efficient fine tuning, but current release practices provide weak assurances about what data were used and how updates were computed. We present Verifiable Fine Tuning, a protocol and system that produces succinct zero knowledge proofs that a released model was obtained from a public initialization under a declared training program and an auditable dataset commitment. The approach combines five elements. First, commitments that bind data sources, preprocessing, licenses, and per epoch quota counters to a manifest. Second, a verifiable sampler that supports public replayable and private index hiding batch selection. Third, update circuits restricted to parameter efficient fine tuning that enforce AdamW style optimizer semantics and proof friendly approximations with explicit error budgets. Fourth, recursive aggregation that folds per step proofs into per epoch and end to end certificates with millisecond verification. Fifth, provenance binding and optional trusted execution property cards that attest code identity and constants. On English and bilingual instruction mixtures, the method maintains utility within tight budgets while achieving practical proof performance. Policy quotas are enforced with zero violations, and private sampling windows show no measurable index leakage. Federated experiments demonstrate that the system composes with probabilistic audits and bandwidth constraints. These results indicate that end to end verifiable fine tuning is feasible today for real parameter efficient pipelines, closing a critical trust gap for regulated and decentralized deployments."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Robust Cross-Domain Adaptation in Texture Features Transferring for Wood Chip Moisture Content Prediction", "authors": "Abdur Rahman, Mohammad Marufuzzaman, Jason Street, Haifeng Wang, Veera G. Gude, Randy Buchanan", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Accurate and quick prediction of wood chip moisture content is critical for optimizing biofuel production and ensuring energy efficiency. The current widely used direct method (oven drying) is limited by its longer processing time and sample destructiveness. On the other hand, existing indirect methods, including near-infrared spectroscopy-based, electrical capacitance-based, and image-based approaches, are quick but not accurate when wood chips come from various sources. Variability in the source material can alter data distributions, undermining the performance of data-driven models. Therefore, there is a need for a robust approach that effectively mitigates the impact of source variability. Previous studies show that manually extracted texture features have the potential to predict wood chip moisture class. Building on this, in this study, we conduct a comprehensive analysis of five distinct texture feature types extracted from wood chip images to predict moisture content. Our findings reveal that a combined feature set incorporating all five texture features achieves an accuracy of 95% and consistently outperforms individual texture features in predicting moisture content. To ensure robust moisture prediction, we propose a domain adaptation method named AdaptMoist that utilizes the texture features to transfer knowledge from one source of wood chip data to another, addressing variability across different domains. We also proposed a criterion for model saving based on adjusted mutual information. The AdaptMoist method improves prediction accuracy across domains by 23%, achieving an average accuracy of 80%, compared to 57% for non-adapted models. These results highlight the effectiveness of AdaptMoist as a robust solution for wood chip moisture content estimation across domains, making it a potential solution for wood chip-reliant industries."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          From Mannequin to Human: A Pose-Aware and Identity-Preserving Video Generation Framework for Lifelike Clothing Display", "authors": "Xiangyu Mu, Dongliang Zhou, Jie Hou, Haijun Zhang, Weili Guan", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Graphics (cs.GR)", "abstract": "Mannequin-based clothing displays offer a cost-effective alternative to real-model showcases for online fashion presentation, but lack realism and expressive detail. To overcome this limitation, we introduce a new task called mannequin-to-human (M2H) video generation, which aims to synthesize identity-controllable, photorealistic human videos from footage of mannequins. We propose M2HVideo, a pose-aware and identity-preserving video generation framework that addresses two key challenges: the misalignment between head and body motion, and identity drift caused by temporal modeling. In particular, M2HVideo incorporates a dynamic pose-aware head encoder that fuses facial semantics with body pose to produce consistent identity embeddings across frames. To address the loss of fine facial details due to latent space compression, we introduce a mirror loss applied in pixel space through a denoising diffusion implicit model (DDIM)-based one-step denoising. Additionally, we design a distribution-aware adapter that aligns statistical distributions of identity and clothing features to enhance temporal coherence. Extensive experiments on the UBC fashion dataset, our self-constructed ASOS dataset, and the newly collected MannequinVideos dataset captured on-site demonstrate that M2HVideo achieves superior performance in terms of clothing consistency, identity preservation, and video fidelity in comparison to state-of-the-art methods."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Schr\u00f6dinger Bridge Mamba for One-Step Speech Enhancement", "authors": "Jing Yang, Sirui Wang, Chao Wu, Fan Fan", "subjects": "Sound (cs.SD); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)", "abstract": "We propose Schr\u00f6dinger Bridge Mamba (SBM), a new concept of training-inference framework motivated by the inherent compatibility between Schr\u00f6dinger Bridge (SB) training paradigm and selective state-space model Mamba. We exemplify the concept of SBM with an implementation for generative speech enhancement. Experiments on a joint denoising and dereverberation task using four benchmark datasets demonstrate that SBM, with only 1-step inference, outperforms strong baselines with 1-step or iterative inference and achieves the best real-time factor (RTF). Beyond speech enhancement, we discuss the integration of SB paradigm and selective state-space model architecture based on their underlying alignment, which indicates a promising direction for exploring new deep generative models potentially applicable to a broad range of generative tasks. Demo page: this https URL"}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          ThreatIntel-Andro: Expert-Verified Benchmarking for Robust Android Malware Research", "authors": "Hongpeng Bai, Minhong Dong, Yao Zhang, Shunzhe Zhao, Haobo Zhang, Lingyue Li, Yude Bai, Guangquan Xu", "subjects": "Cryptography and Security (cs.CR)", "abstract": "The rapidly evolving Android malware ecosystem demands high-quality, real-time datasets as a foundation for effective detection and defense. With the widespread adoption of mobile devices across industrial systems, they have become a critical yet often overlooked attack surface in industrial cybersecurity. However, mainstream datasets widely used in academia and industry (e.g., Drebin) exhibit significant limitations: on one hand, their heavy reliance on VirusTotal's multi-engine aggregation results introduces substantial label noise; on the other hand, outdated samples reduce their temporal relevance. Moreover, automated labeling tools (e.g., AVClass2) suffer from suboptimal aggregation strategies, further compounding labeling errors and propagating inaccuracies throughout the research community."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          2DGS-R: Revisiting the Normal Consistency Regularization in 2D Gaussian Splatting", "authors": "Haofan Ren, Qingsong Yan, Ming Lu, Rongfeng Lu, Zunjie Zhu", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Recent advancements in 3D Gaussian Splatting (3DGS) have greatly influenced neural fields, as it enables high-fidelity rendering with impressive visual quality. However, 3DGS has difficulty accurately representing surfaces. In contrast, 2DGS transforms the 3D volume into a collection of 2D planar Gaussian disks. Despite advancements in geometric fidelity, rendering quality remains compromised, highlighting the challenge of achieving both high-quality rendering and precise geometric structures. This indicates that optimizing both geometric and rendering quality in a single training stage is currently unfeasible. To overcome this limitation, we present 2DGS-R, a new method that uses a hierarchical training approach to improve rendering quality while maintaining geometric accuracy. 2DGS-R first trains the original 2D Gaussians with the normal consistency regularization. Then 2DGS-R selects the 2D Gaussians with inadequate rendering quality and applies a novel in-place cloning operation to enhance the 2D Gaussians. Finally, we fine-tune the 2DGS-R model with opacity frozen. Experimental results show that compared to the original 2DGS, our method requires only 1\\% more storage and minimal additional training time. Despite this negligible overhead, it achieves high-quality rendering results while preserving fine geometric structures. These findings indicate that our approach effectively balances efficiency with performance, leading to improvements in both visual fidelity and geometric reconstruction accuracy."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          FinSight: Towards Real-World Financial Deep Research", "authors": "Jiajie Jin, Yuyao Zhang, Yimeng Xu, Hongjin Qian, Yutao Zhu, Zhicheng Dou", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE)", "abstract": "Generating professional financial reports is a labor-intensive and intellectually demanding process that current AI systems struggle to fully automate. To address this challenge, we introduce FinSight (Financial InSight), a novel multi agent framework for producing high-quality, multimodal financial reports. The foundation of FinSight is the Code Agent with Variable Memory (CAVM) architecture, which unifies external data, designed tools, and agents into a programmable variable space, enabling flexible data collection, analysis and report generation through executable code. To ensure professional-grade visualization, we propose an Iterative Vision-Enhanced Mechanism that progressively refines raw visual outputs into polished financial charts. Furthermore, a two stage Writing Framework expands concise Chain-of-Analysis segments into coherent, citation-aware, and multimodal reports, ensuring both analytical depth and structural consistency. Experiments on various company and industry-level tasks demonstrate that FinSight significantly outperforms all baselines, including leading deep research systems in terms of factual accuracy, analytical depth, and presentation quality, demonstrating a clear path toward generating reports that approach human-expert quality."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Global Overview of Computational Thinking and Digital Tools for Teaching", "authors": "Roberto Massi De Oliveira, M^onica Cristina Garbin, Rodolfo Azevedo", "subjects": "Computers and Society (cs.CY)", "abstract": "Computational Thinking (CT) has emerged as a critical component in modern education, essential to equip students with the skills necessary to thrive in a technology-driven world. This survey provides a comprehensive analysis of the presence and integration of CT in school curricula across various countries. In addition, this study categorizes digital tools into groups such as visual programming, textual programming, electronic games, modeling, and simulation, assessing their use in different educational settings. Furthermore, it examines how these tools are employed in various contexts, including the areas of knowledge and age groups they target, and the specific skills they help develop. The research also identifies key CT competencies that have been improved through these tools, including Cognitive and Analytical Competencies (CAC), Technical and Computational Competencies (TCC) and Social and Emotional Competencies (SEC). Furthermore, the study highlights recurring challenges in the implementation of digital tools for CT development, such as inadequate infrastructure, difficulties in the usability of the tool, teacher training, adapting pedagogical practices, and measuring student CT skills. Finally, it proposes areas for future research to address these challenges and advance CT education."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          DiRAC - Distributed Robot Awareness and Consensus", "authors": "Uday Gopan, Manjari Kulkarni, Lakshasri S, Kashish Mittal, Sriram Radhakrishna, Aditya Naskar, Rameshwar DL", "subjects": "Multiagent Systems (cs.MA); Distributed, Parallel, and Cluster Computing (cs.DC); Robotics (cs.RO)", "abstract": "DiRAC is a scalable, distributed framework designed to enable efficient task assignment and path planning in very large robotic swarms. It introduces a novel zone-partitioned architecture with dynamically elected leaders and a tick-synchronized consensus protocol that yields strong consistency and deterministic outcomes. For path planning, DiRAC uses a novel algorithm, a force-based decentralized planner for real-time collision resolution. Validated within ROS 2 middleware through preliminary simulation, DiRAC demonstrates architectural scalability and modular efficiency in simulated warehouse environments, laying the groundwork for real-world deployment in large-scale industrial and logistics domains."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Neuronal Group Communication for Efficient Neural representation", "authors": "Zhengqi Pei, Qingming Huang, Shuhui Wang", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE)", "abstract": "The ever-increasing scale of modern neural networks has brought unprecedented performance alongside daunting challenges in efficiency and interpretability. This paper addresses the core question of how to build large neural systems that learn efficient, modular, and interpretable representations. We propose Neuronal Group Communication (NGC), a theory-driven framework that reimagines a neural network as a dynamical system of interacting neuronal groups rather than a monolithic collection of neural weights. Instead of treating each weight as an independent trainable parameter, NGC treats weights as transient interactions between embedding-like neuronal states, with neural computation unfolding through iterative communication among groups of neurons. This low-rank, modular representation yields compact models: groups of neurons exchange low-dimensional signals, enabling intra-group specialization and inter-group information sharing while dramatically reducing redundant parameters. By drawing on dynamical systems theory, we introduce a neuronal stability metric (analogous to Lyapunov stability) that quantifies the contraction of neuron activations toward stable patterns during sequence processing. Using this metric, we reveal that emergent reasoning capabilities correspond to an external driving force or ``potential'', which nudges the neural dynamics away from trivial trajectories while preserving stability. Empirically, we instantiate NGC in large language models (LLMs) and demonstrate improved performance on complex reasoning benchmarks under moderate compression. NGC consistently outperforms standard low-rank approximations and cross-layer basis-sharing methods at comparable compression rates. We conclude by discussing the broader implications of NGC, including how structured neuronal group dynamics might relate to generalization in high-dimensional learning systems."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Agentic Inequality", "authors": "Matthew Sharp, Omer Bilgin, Iason Gabriel, Lewis Hammond", "subjects": "Computers and Society (cs.CY); Artificial Intelligence (cs.AI)", "abstract": "Autonomous AI agents, capable of complex planning and action, represent a significant technological evolution beyond current generative tools. As these systems become integrated into political and economic life, their distribution and capabilities will be highly consequential. This paper introduces and explores \"agentic inequality\" - the potential disparities in power, opportunity, and outcomes stemming from differential access to, and capabilities of, AI agents. We analyse the dual potential of this technology, exploring how agents could both exacerbate existing divides and, under the right conditions, serve as a powerful equalising force. To this end, the paper makes three primary contributions. First, it establishes an analytical framework by delineating the three core dimensions through which this inequality can manifest: disparities in the availability, quality, and quantity of agents. Second, it argues that agentic inequality is distinct from prior technological divides. Unlike tools that primarily augment human abilities, agents act as autonomous delegates, creating novel power asymmetries through scalable goal delegation and direct agent-to-agent competition that are poised to reshape outcomes across economic and socio-political spheres. Finally, it provides a systematic analysis of the technical and socioeconomic drivers - from model release strategies to market incentives - that will shape the distribution of agentic power, concluding with a research agenda for navigating the complex governance challenges ahead."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          ArmFormer: Lightweight Transformer Architecture for Real-Time Multi-Class Weapon Segmentation and Classification", "authors": "Akhila Kambhatla, Taminul Islam, Khaled R Ahmed", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "abstract": "The escalating threat of weapon-related violence necessitates automated detection systems capable of pixel-level precision for accurate threat assessment in real-time security applications. Traditional weapon detection approaches rely on object detection frameworks that provide only coarse bounding box localizations, lacking the fine-grained segmentation required for comprehensive threat analysis. Furthermore, existing semantic segmentation models either sacrifice accuracy for computational efficiency or require excessive computational resources incompatible with edge deployment scenarios. This paper presents ArmFormer, a lightweight transformer-based semantic segmentation framework that strategically integrates Convolutional Block Attention Module (CBAM) with MixVisionTransformer architecture to achieve superior accuracy while maintaining computational efficiency suitable for resource-constrained edge devices. Our approach combines CBAM-enhanced encoder backbone with attention-integrated hamburger decoder to enable multi-class weapon segmentation across five categories: handgun, rifle, knife, revolver, and human. Comprehensive experiments demonstrate that ArmFormer achieves state-of-the-art performance with 80.64% mIoU and 89.13% mFscore while maintaining real-time inference at 82.26 FPS. With only 4.886G FLOPs and 3.66M parameters, ArmFormer outperforms heavyweight models requiring up to 48x more computation, establishing it as the optimal solution for deployment on portable security cameras, surveillance drones, and embedded AI accelerators in distributed security infrastructure."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          DrivAerStar: An Industrial-Grade CFD Dataset for Vehicle Aerodynamic Optimization", "authors": "Jiyan Qiu, Lyulin Kuang, Guan Wang, Yichen Xu, Leiyao Cui, Shaotong Fu, Yixin Zhu, Ruihua Zhang", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "Vehicle aerodynamics optimization has become critical for automotive electrification, where drag reduction directly determines electric vehicle range and energy efficiency. Traditional approaches face an intractable trade-off: computationally expensive Computational Fluid Dynamics (CFD) simulations requiring weeks per design iteration, or simplified models that sacrifice production-grade accuracy. While machine learning offers transformative potential, existing datasets exhibit fundamental limitations -- inadequate mesh resolution, missing vehicle components, and validation errors exceeding 5% -- preventing deployment in industrial workflows. We present DrivAerStar, comprising 12,000 industrial-grade automotive CFD simulations generated using $\\text{STAR-CCM+}^\\unicode{xAE}$ software. The dataset systematically explores three vehicle configurations through 20 Computer Aided Design (CAD) parameters via Free Form Deformation (FFD) algorithms, including complete engine compartments and cooling systems with realistic internal airflow. DrivAerStar achieves wind tunnel validation accuracy below 1.04% -- a five-fold improvement over existing datasets -- through refined mesh strategies with strict wall $y^+$ control. Benchmarks demonstrate that models trained on this data achieve production-ready accuracy while reducing computational costs from weeks to minutes. This represents the first dataset bridging academic machine learning research and industrial CFD practice, establishing a new standard for data-driven aerodynamic optimization in automotive development. Beyond automotive applications, DrivAerStar demonstrates a paradigm for integrating high-fidelity physics simulations with Artificial Intelligence (AI) across engineering disciplines where computational constraints currently limit innovation."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Sustainable and Adaptive Growth in Creative Tech", "authors": "Enes Ayalp", "subjects": "Computers and Society (cs.CY)", "abstract": "The creative technology evolves rapidly in both scope and depth, demanding cross-disciplinary expertise and continuous improvement. Although educational programs and other collaborative initiatives enable strong technical and artistic skills, even the most advanced pathways rarely ensure a stable career. Success in these professions often depends on visibility, timing, and self-directed development. As markets shift or technologies change, talents still find themselves displaced. Existing learning paths often fail to connect the skills they teach, leaving learners with fragmented expertise that decays quickly when not continuously applied. The industry demands depth, yet specialization carries risk when tools, pipelines, or roles evolve faster than the expertise built around them. Broad skill sets, by contrast, may increase employability but are easily replaced or rendered obsolete by technological change. CLEAR CORE is a framework for learning and sustaining in creative technology. It integrates two iterative interconnected cycles into a continuous process linking structured education with independent growth as a lifelong, renewable practice that allows professionals to excel amid constant change."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Unconditionally Stable, Variable Step DLN Methods for the Allen-Cahn Active Fluid Model: A Divergence-free Preserving Approach", "authors": "Nan Zheng, Wenlong Pei, Qingguang Guan, Wenju Zhao", "subjects": "Numerical Analysis (math.NA)", "abstract": "This paper addresses the divergence-free mixed finite element method (FEM) for nonlinear fourth-order Allen-Cahn phase field coupled active fluid equations. By introducing an auxiliary variable $w = \\Delta u$, the original fourth-order problem is converted into a system of second-order equations, thereby easing the regularity constraints imposed on standard $H^2$-comforming finite element spaces. To further refine the formulation, an additional auxiliary variable $\\xi$, analogous to the pressure, is introduced, resulting in a mixed finite element scheme that preserves the divergence-free condition in $which = \\Delta u$ inherited from the model. A fully discrete scheme is then established by combining the spatial approximation by the divergence-free mixed finite element method with the variable-step Dahlquist-Liniger-Nevanlinna (DLN) time integrator. The boundedness of the scheme is rigorously derived under suitable regularity assumptions. Additionally, an adaptive time-stepping strategy based on the minimum dissipation criterion is carried out to enhance computational efficiency. Several numerical experiments validate the theoretical findings and demonstrate the method's effectiveness and accuracy in simulating complex active fluid dynamics."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          BARL: Bilateral Alignment in Representation and Label Spaces for Semi-Supervised Volumetric Medical Image Segmentation", "authors": "Shujian Gao, Yuan Wang, Zekuan Yu", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Semi-supervised medical image segmentation (SSMIS) seeks to match fully supervised performance while sharply reducing annotation cost. Mainstream SSMIS methods rely on \\emph{label-space consistency}, yet they overlook the equally critical \\emph{representation-space alignment}. Without harmonizing latent features, models struggle to learn representations that are both discriminative and spatially coherent. To this end, we introduce \\textbf{Bilateral Alignment in Representation and Label spaces (BARL)}, a unified framework that couples two collaborative branches and enforces alignment in both spaces. For label-space alignment, inspired by co-training and multi-scale decoding, we devise \\textbf{Dual-Path Regularization (DPR)} and \\textbf{Progressively Cognitive Bias Correction (PCBC)} to impose fine-grained cross-branch consistency while mitigating error accumulation from coarse to fine scales. For representation-space alignment, we conduct region-level and lesion-instance matching between branches, explicitly capturing the fragmented, complex pathological patterns common in medical imagery. Extensive experiments on four public benchmarks and a proprietary CBCT dataset demonstrate that BARL consistently surpasses state-of-the-art SSMIS methods. Ablative studies further validate the contribution of each component. Code will be released soon."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Registration is a Powerful Rotation-Invariance Learner for 3D Anomaly Detection", "authors": "Yuyang Yu, Zhengwei Chen, Xuemiao Xu, Lei Zhang, Haoxin Yang, Yongwei Nie, Shengfeng He", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "3D anomaly detection in point-cloud data is critical for industrial quality control, aiming to identify structural defects with high reliability. However, current memory bank-based methods often suffer from inconsistent feature transformations and limited discriminative capacity, particularly in capturing local geometric details and achieving rotation invariance. These limitations become more pronounced when registration fails, leading to unreliable detection results. We argue that point-cloud registration plays an essential role not only in aligning geometric structures but also in guiding feature extraction toward rotation-invariant and locally discriminative representations. To this end, we propose a registration-induced, rotation-invariant feature extraction framework that integrates the objectives of point-cloud registration and memory-based anomaly detection. Our key insight is that both tasks rely on modeling local geometric structures and leveraging feature similarity across samples. By embedding feature extraction into the registration learning process, our framework jointly optimizes alignment and representation learning. This integration enables the network to acquire features that are both robust to rotations and highly effective for anomaly detection. Extensive experiments on the Anomaly-ShapeNet and Real3D-AD datasets demonstrate that our method consistently outperforms existing approaches in effectiveness and generalizability."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          No-Regret Online Autobidding Algorithms in First-price Auctions", "authors": "Yuan Deng, Yilin Li, Wei Tang, Hanrui Zhang", "subjects": "Computer Science and Game Theory (cs.GT)", "abstract": "Automated bidding to optimize online advertising with various constraints, e.g. ROI constraints and budget constraints, is widely adopted by advertisers. A key challenge lies in designing algorithms for non-truthful mechanisms with ROI constraints. While prior work has addressed truthful auctions or non-truthful auctions with weaker benchmarks, this paper provides a significant improvement: We develop online bidding algorithms for repeated first-price auctions with ROI constraints, benchmarking against the optimal randomized strategy in hindsight. In the full feedback setting, where the maximum competing bid is observed, our algorithm achieves a near-optimal $\\widetilde{O}(\\sqrt{T})$ regret bound, and in the bandit feedback setting (where the bidder only observes whether the bidder wins each auction), our algorithm attains $\\widetilde{O}(T^{3/4})$ regret bound."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Uncovering Brain-Like Hierarchical Patterns in Vision-Language Models through fMRI-Based Neural Encoding", "authors": "Yudan Ren, Xinlong Wang, Kexin Wang, Tian Xia, Zihan Ma, Zhaowei Li, Xiangrong Bi, Xiao Li, Xiaowei He", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "While brain-inspired artificial intelligence(AI) has demonstrated promising results, current understanding of the parallels between artificial neural networks (ANNs) and human brain processing remains limited: (1) unimodal ANN studies fail to capture the brain's inherent multimodal processing capabilities, and (2) multimodal ANN research primarily focuses on high-level model outputs, neglecting the crucial role of individual neurons. To address these limitations, we propose a novel neuron-level analysis framework that investigates the multimodal information processing mechanisms in vision-language models (VLMs) through the lens of human brain activity. Our approach uniquely combines fine-grained artificial neuron (AN) analysis with fMRI-based voxel encoding to examine two architecturally distinct VLMs: CLIP and METER. Our analysis reveals four key findings: (1) ANs successfully predict biological neurons (BNs) activities across multiple functional networks (including language, vision, attention, and default mode), demonstrating shared representational mechanisms; (2) Both ANs and BNs demonstrate functional redundancy through overlapping neural representations, mirroring the brain's fault-tolerant and collaborative information processing mechanisms; (3) ANs exhibit polarity patterns that parallel the BNs, with oppositely activated BNs showing mirrored activation trends across VLM layers, reflecting the complexity and bidirectional nature of neural information processing; (4) The architectures of CLIP and METER drive distinct BNs: CLIP's independent branches show modality-specific specialization, whereas METER's cross-modal design yields unified cross-modal activation, highlighting the architecture's influence on ANN brain-like properties. These results provide compelling evidence for brain-like hierarchical processing in VLMs at the neuronal level."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Addendum: Systematic Evaluation of Randomized Cache Designs against Cache Occupancy", "authors": "Anirban Chakraborty, Nimish Mishra, Sayandeep Saha, Sarani Bhattacharya, Debdeep Mukhopadhyay", "subjects": "Cryptography and Security (cs.CR)", "abstract": "In the main text published at USENIX Security 2025, we presented a systematic analysis of the role of cache occupancy in the design considerations for randomized caches (from the perspectives of performance and security). On the performance front, we presented a uniform benchmarking strategy that allows for a fair comparison among different randomized cache designs. Likewise, from the security perspective, we presented three threat assumptions: (1) covert channels; (2) process fingerprinting side-channel; and (3) AES key recovery. The main takeaway of our work is an open problem of designing a randomized cache of comparable efficiency with modern set-associative LLCs, while still resisting both contention-based and occupancy-based attacks. This note is meant as an addendum to the main text in light of the observations made in [2]. To summarize, the authors in [2] argue that (1) L1d cache size plays a role in adversarial success, and that (2) a patched version of MIRAGE with randomized initial seeding of global eviction map prevents leakage of AES key. We discuss the same in this addendum."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          DeepAnalyze: Agentic Large Language Models for Autonomous Data Science", "authors": "Shaolei Zhang, Ju Fan, Meihao Fan, Guoliang Li, Xiaoyong Du", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Databases (cs.DB)", "abstract": "Autonomous data science, from raw data sources to analyst-grade deep research reports, has been a long-standing challenge, and is now becoming feasible with the emergence of powerful large language models (LLMs). Recent workflow-based data agents have shown promising results on specific data tasks but remain fundamentally limited in achieving fully autonomous data science due to their reliance on predefined workflows. In this paper, we introduce DeepAnalyze-8B, the first agentic LLM designed for autonomous data science, capable of automatically completing the end-toend pipeline from data sources to analyst-grade deep research reports. To tackle high-complexity data science tasks, we propose a curriculum-based agentic training paradigm that emulates the learning trajectory of human data scientists, enabling LLMs to progressively acquire and integrate multiple capabilities in real-world environments. We also introduce a data-grounded trajectory synthesis framework that constructs high-quality training data. Through agentic training, DeepAnalyze learns to perform a broad spectrum of data tasks, ranging from data question answering and specialized analytical tasks to open-ended data research. Experiments demonstrate that, with only 8B parameters, DeepAnalyze outperforms previous workflow-based agents built on most advanced proprietary LLMs. The model, code, and training data of DeepAnalyze are open-sourced, paving the way toward autonomous data science."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          On the Credibility of Deniable Communication in Court", "authors": "Jacob Leiken, Sunoo Park", "subjects": "Cryptography and Security (cs.CR)", "abstract": "Over time, cryptographically deniable systems have come to be associated in computer-science literature with the idea of \"denying\" evidence in court - specifically, with the ability to convincingly forge evidence in courtroom scenarios and an inability to authenticate evidence in such contexts. Evidentiary processes in courts, however, have been developed over centuries to account for the reality that evidence has always been forgeable, and relies on factors outside of cryptographic models to seek the truth \"as well as possible\" while acknowledging that all evidence is imperfect. We argue that deniability does not and need not change this paradigm. Our analysis highlights a gap between technical deniability notions and their application to the real world. There will always be factors outside a cryptographic model that influence perceptions of a message's authenticity, in realistic situations. We propose the broader concept of credibility to capture these factors. The credibility of a system is determined by (1) a threshold of quality that a forgery must pass to be \"believable\" as an original communication, which varies based on sociotechnical context and threat model, (2) the ease of creating a forgery that passes this threshold, which is also context- and threat-model-dependent, and (3) default system retention policy and retention settings. All three aspects are important for designing secure communication systems for real-world threat models, and some aspects of (2) and (3) may be incorporated directly into technical system design. We hope that our model of credibility will facilitate system design and deployment that addresses threats that are not and cannot be captured by purely technical definitions and existing cryptographic models, and support more nuanced discourse on the strengths and limitations of cryptographic guarantees within specific legal and sociotechnical contexts."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Fly-CL: A Fly-Inspired Framework for Enhancing Efficient Decorrelation and Reduced Training Time in Pre-trained Model-based Continual Representation Learning", "authors": "Heming Zou, Yunliang Zang, Wutong Xu, Xiangyang Ji", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Using a nearly-frozen pretrained model, the continual representation learning paradigm reframes parameter updates as a similarity-matching problem to mitigate catastrophic forgetting. However, directly leveraging pretrained features for downstream tasks often suffers from multicollinearity in the similarity-matching stage, and more advanced methods can be computationally prohibitive for real-time, low-latency applications. Inspired by the fly olfactory circuit, we propose Fly-CL, a bio-inspired framework compatible with a wide range of pretrained backbones. Fly-CL substantially reduces training time while achieving performance comparable to or exceeding that of current state-of-the-art methods. We theoretically show how Fly-CL progressively resolves multicollinearity, enabling more effective similarity matching with low time complexity. Extensive simulation experiments across diverse network architectures and data regimes validate Fly-CL's effectiveness in addressing this challenge through a biologically inspired design. Code is available at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Chem-R: Learning to Reason as a Chemist", "authors": "Weida Wang, Benteng Chen, Di Zhang, Wanhao Liu, Shuchen Pu, Ben Gao, Jin Zeng, Lei Bai, Wanli Ouyang, Xiaoyong Wei, Tianshu Yu, Tianfan Fu, Shuzhou Sun, Jiatong Li, Zifu Wang, Yuqiang Li, Shufei Zhang", "subjects": "Computational Engineering, Finance, and Science (cs.CE)", "abstract": "Although large language models (LLMs) have significant potential to advance chemical discovery, current LLMs lack core chemical knowledge, produce unreliable reasoning trajectories, and exhibit suboptimal performance across diverse chemical tasks. To address these challenges, we propose Chem-R, a generalizable Chemical Reasoning model designed to emulate the deliberative processes of chemists. Chem-R is trained through a three-phase framework that progressively builds advanced reasoning capabilities, including: 1) Chemical Foundation Training, which establishes core chemical knowledge. 2) Chemical Reasoning Protocol Distillation, incorporating structured, expert-like reasoning traces to guide systematic and reliable problem solving. 3) Multi-task Group Relative Policy Optimization that optimizes the model for balanced performance across diverse molecular- and reaction-level tasks. This structured pipeline enables Chem-R to achieve state-of-the-art performance on comprehensive benchmarks, surpassing leading large language models, including Gemini-2.5-Pro and DeepSeek-R1, by up to 46% on molecular tasks and 66% on reaction tasks. Meanwhile, Chem-R also consistently outperforms the existing chemical foundation models across both molecular and reaction level tasks. These results highlight Chem-R's robust generalization, interpretability, and potential as a foundation for next-generation AI-driven chemical discovery."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Utility-Diversity Aware Online Batch Selection for LLM Supervised Fine-tuning", "authors": "Heming Zou, Yixiu Mao, Yun Qu, Qi Wang, Xiangyang Ji", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "abstract": "Supervised fine-tuning (SFT) is a commonly used technique to adapt large language models (LLMs) to downstream tasks. In practice, SFT on a full dataset is computationally expensive and sometimes suffers from overfitting or bias amplification. This facilitates the rise of data curation in SFT, which prioritizes the most valuable data to optimze. This work studies the online batch selection family that dynamically scores and filters samples during the training process. However, existing popular methods often (i) rely merely on the utility of data to select a subset while neglecting other crucial factors like diversity, (ii) rely on external resources such as reference models or validation sets, and (iii) incur extra training time over full-dataset training. To address these limitations, this work develops \\textbf{UDS (Utility-Diversity Sampling)}, a framework for efficient online batch selection in SFT. UDS leverages the nuclear norm of the logits matrix to capture both data utility and intra-sample diversity, while estimating inter-sample diversity through efficient low-dimensional embedding comparisons with a lightweight memory buffer of historical samples. Such a design eliminates the need for external resources and unnecessary backpropagation, securing computational efficiency. Experiments on multiple benchmarks demonstrate that UDS consistently outperforms state-of-the-art online batch selection methods under varying data budgets, and significantly reduces training time compared to full-dataset fine-tuning. Code is available at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          JAX Autodiff from a Linear Logic Perspective (Extended Version)", "authors": "Giulia Giusti, Michele Pagani", "subjects": "Programming Languages (cs.PL); Logic in Computer Science (cs.LO)", "abstract": "Autodiff refers to the core of the automatic differentiation systems developed in projects like JAX and Dex. Autodiff has recently been formalised in a linear typed calculus by Radul et al in arXiv:2204.10923. Although this formalisation suffices to express the main program transformations of Autodiff, the calculus is very specific to this task, and it is not clear whether the type system yields a substructural logic that has interest on its own. We propose an encoding of Autodiff into a linear $\\lambda$-calculus that enjoys a Curry-Howard correspondence with Girard's linear logic. We prove that the encoding is sound both qualitatively (the encoded terms are extensionally equivalent to the original ones) and quantitatively (the encoding preserves the original work cost as described in arXiv:2204.10923). As a byproduct, we show that unzipping, one of the transformations used to implement backpropagation in Autodiff, is, in fact, optional."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          UniGTE: Unified Graph-Text Encoding for Zero-Shot Generalization across Graph Tasks and Domains", "authors": "Duo Wang, Yuan Zuo, Guangyue Lu, Junjie Wu", "subjects": "Machine Learning (cs.LG)", "abstract": "Generalizing to unseen graph tasks without task-specific supervision is challenging: conventional graph neural networks are typically tied to a fixed label space, while large language models (LLMs) struggle to capture graph structure. We introduce UniGTE, an instruction-tuned encoder-decoder framework that unifies structural and semantic reasoning. The encoder augments a pretrained autoregressive LLM with learnable alignment tokens and a structure-aware graph-text attention mechanism, enabling it to attend jointly to a tokenized graph and a natural-language task prompt while remaining permutation-invariant to node order. This yields compact, task-aware graph representations. Conditioned solely on these representations, a frozen LLM decoder predicts and reconstructs: it outputs the task answer and simultaneously paraphrases the input graph in natural language. The reconstruction objective regularizes the encoder to preserve structural cues. UniGTE is instruction-tuned on five datasets spanning node-level, edge-level, and graph-level tasks across diverse domains, yet requires no fine-tuning at inference. It achieves new state-of-the-art zero-shot results on node classification, link prediction, graph classification, and graph regression under cross-task and cross-domain settings, demonstrating that tight integration of graph structure with LLM semantics enables robust, transferable graph reasoning."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Class-N-Diff: Classification-Induced Diffusion Model Can Make Fair Skin Cancer Diagnosis", "authors": "Nusrat Munia, Abdullah Imran", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Generative models, especially Diffusion Models, have demonstrated remarkable capability in generating high-quality synthetic data, including medical images. However, traditional class-conditioned generative models often struggle to generate images that accurately represent specific medical categories, limiting their usefulness for applications such as skin cancer diagnosis. To address this problem, we propose a classification-induced diffusion model, namely, Class-N-Diff, to simultaneously generate and classify dermoscopic images. Our Class-N-Diff model integrates a classifier within a diffusion model to guide image generation based on its class conditions. Thus, the model has better control over class-conditioned image synthesis, resulting in more realistic and diverse images. Additionally, the classifier demonstrates improved performance, highlighting its effectiveness for downstream diagnostic tasks. This unique integration in our Class-N-Diff makes it a robust tool for enhancing the quality and utility of diffusion model-based synthetic dermoscopic image generation. Our code is available at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Uniworld-V2: Reinforce Image Editing with Diffusion Negative-aware Finetuning and MLLM Implicit Feedback", "authors": "Zongjian Li, Zheyuan Liu, Qihui Zhang, Bin Lin, Shenghai Yuan, Zhiyuan Yan, Yang Ye, Wangbo Yu, Yuwei Niu, Li Yuan", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Instruction-based image editing has achieved remarkable progress; however, models solely trained via supervised fine-tuning often overfit to annotated patterns, hindering their ability to explore and generalize beyond training distributions. To this end, we introduce Edit-R1, a novel post-training framework for instruction-based image editing based on policy optimization. Specifically, we utilize Diffusion Negative-aware Finetuning (DiffusionNFT), a likelihood-free policy optimization method consistent with the flow matching forward process, thereby enabling the use of higher-order samplers and more efficient training. Another key challenge here is the absence of a universal reward model, resulting from the diverse nature of editing instructions and tasks. To bridge this gap, we employ a Multimodal Large Language Model (MLLM) as a unified, training-free reward model, leveraging its output logits to provide fine-grained feedback. Furthermore, we carefully design a low-variance group filtering mechanism to reduce MLLM scoring noise and stabilize optimization. UniWorld-V2, trained with this framework, achieves \\textbf{state-of-the-art} results on the ImgEdit and GEdit-Bench benchmarks, scoring 4.49 and 7.83, respectively. Crucially, our framework is model-agnostic, delivering substantial performance gains when applied to diverse base models like Qwen-Image-Edit and FLUX-Kontext, demonstrating its wide applicability. Code and models are publicly available at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Addressing data scarcity in structural health monitoring through generative augmentation", "authors": "Sasan Farhadi, Mariateresa Iavarone, Mauro Corrado, Eleni Chatzi, Giulio Ventura", "subjects": "Computational Engineering, Finance, and Science (cs.CE)", "abstract": "Structural Health Monitoring plays a crucial role in ensuring the safety, reliability, and longevity of bridge infrastructures through early damage detection. Although recent advances in deep learning-based models have enabled automated event detection, their performance is often limited by data scarcity, environmental noise, and class imbalance. To address these challenges, this study introduces a customized Generative Adversarial Network model, STFTSynth, designed particularly for generating short-time Fourier transform spectrograms derived from acoustic event signals. In contrast to augmentation techniques such as MixUp, generative adversarial networks can synthesize high-quality spectrograms that mimic real-world events, enhancing dataset diversity and robustness. The proposed model integrates dense residual blocks for spatial consistency with bidirectional gated recurrent units for temporal dependency modeling. Model performance is evaluated against three baseline generative models using qualitative inspection and quantitative metrics, including Structural Similarity Index Measure, Peak Signal-to-Noise Ratio, and Fr\u00e9chet Inception Distance. Results show that STFTSynth outperforms baseline models, producing high-resolution, temporally consistent spectrograms that align closely with real-world data. These findings indicate the potential of generative-based data augmentation as a scalable and cost-effective solution for bridge monitoring scenarios where rare events, such as prestressing wire breakage, suffer from data scarcity."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Layout-Agnostic MPI Abstraction for Distributed Computing in Modern C++", "authors": "Ji\u0159\u00ed Klepl, Martin Kruli\u0161, Maty\u00e1\u0161 Brabec", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "abstract": "Message Passing Interface (MPI) has been a well-established technology in the domain of distributed high-performance computing for several decades. However, one of its greatest drawbacks is a rather ancient pure-C interface. It lacks many useful features of modern languages (namely C++), like basic type-checking or support for generic code design. In this paper, we propose a novel abstraction for MPI, which we implemented as an extension of the C++ Noarr library. It follows Noarr paradigms (first-class layout and traversal abstraction) and offers layout-agnostic design of MPI applications. We also implemented a layout-agnostic distributed GEMM kernel as a case study to demonstrate the usability and syntax of the proposed abstraction. We show that the abstraction achieves performance comparable to the state-of-the-art MPI C++ bindings while allowing for a more flexible design of distributed applications."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Contrail-to-Flight Attribution Using Ground Visible Cameras and Flight Surveillance Data", "authors": "Ramon Dalmau, Gabriel Jarry, Philippe Very", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Aviation's non-CO2 effects, particularly contrails, are a significant contributor to its climate impact. Persistent contrails can evolve into cirrus-like clouds that trap outgoing infrared radiation, with radiative forcing potentially comparable to or exceeding that of aviation's CO2 emissions. While physical models simulate contrail formation, evolution and dissipation, validating and calibrating these models requires linking observed contrails to the flights that generated them, a process known as contrail-to-flight attribution. Satellite-based attribution is challenging due to limited spatial and temporal resolution, as contrails often drift and deform before detection. In this paper, we evaluate an alternative approach using ground-based cameras, which capture contrails shortly after formation at high spatial and temporal resolution, when they remain thin, linear, and visually distinct. Leveraging the ground visible camera contrail sequences (GVCCS) dataset, we introduce a modular framework for attributing contrails observed using ground-based cameras to theoretical contrails derived from aircraft surveillance and meteorological data. The framework accommodates multiple geometric representations and distance metrics, incorporates temporal smoothing, and enables flexible probability-based assignment strategies. This work establishes a strong baseline and provides a modular framework for future research in linking contrails to their source flight."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Investigating Safety Vulnerabilities of Large Audio-Language Models Under Speaker Emotional Variations", "authors": "Bo-Han Feng, Chien-Feng Liu, Yu-Hsuan Li Liang, Chih-Kai Yang, Szu-Wei Fu, Zhehuai Chen, Ke-Han Lu, Sung-Feng Huang, Chao-Han Huck Yang, Yu-Chiang Frank Wang, Yun-Nung Chen, Hung-yi Lee", "subjects": "Sound (cs.SD); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Audio and Speech Processing (eess.AS)", "abstract": "Large audio-language models (LALMs) extend text-based LLMs with auditory understanding, offering new opportunities for multimodal applications. While their perception, reasoning, and task performance have been widely studied, their safety alignment under paralinguistic variation remains underexplored. This work systematically investigates the role of speaker emotion. We construct a dataset of malicious speech instructions expressed across multiple emotions and intensities, and evaluate several state-of-the-art LALMs. Our results reveal substantial safety inconsistencies: different emotions elicit varying levels of unsafe responses, and the effect of intensity is non-monotonic, with medium expressions often posing the greatest risk. These findings highlight an overlooked vulnerability in LALMs and call for alignment strategies explicitly designed to ensure robustness under emotional variation, a prerequisite for trustworthy deployment in real-world settings."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          FTI-TMR: A Fault Tolerance and Isolation Algorithm for Interconnected Multicore Systems", "authors": "Yiming Hu", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "abstract": "Two-Phase Triple Modular Redundancy TMR divides redundancy operations into two stages, omitting part of the computation during fault-free operation to reduce energy consumption. However, it becomes ineffective under permanent faults, limiting its reliability in critical systems. To address this, Reactive-TMR (R-TMR) introduces permanent fault isolation mechanisms for faulty cores, tolerating both transient and permanent faults. Yet, its reliance on additional hardware increases system complexity and reduces fault tolerance when multiple cores or auxiliary modules fail. This paper proposes an integrated fault-tolerant architecture for interconnected multicore systems. By constructing a stability metric to identify reliable machines and performing periodic diagnostics, the method enables permanent fault isolation and adaptive task scheduling without extra hardware. Experimental results show that it reduces task workload by approximately 30% compared to baseline TMR and achieves superior fault coverage and isolation accuracy, significantly improving both reliability and energy efficiency."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          DeepChem Equivariant: SE(3)-Equivariant Support in an Open-Source Molecular Machine Learning Library", "authors": "Jose Siguenza, Bharath Ramsundar", "subjects": "Machine Learning (cs.LG)", "abstract": "Neural networks that incorporate geometric relationships respecting SE(3) group transformations (e.g. rotations and translations) are increasingly important in molecular applications, such as molecular property prediction, protein structure modeling, and materials design. These models, known as SE(3)-equivariant neural networks, ensure outputs transform predictably with input coordinate changes by explicitly encoding spatial atomic positions. Although libraries such as E3NN [4] and SE(3)-TRANSFORMER [3 ] offer powerful implementations, they often require substantial deep learning or mathematical prior knowledge and lack complete training pipelines. We extend DEEPCHEM [ 13] with support for ready-to-use equivariant models, enabling scientists with minimal deep learning background to build, train, and evaluate models, such as SE(3)-Transformer and Tensor Field Networks. Our implementation includes equivariant models, complete training pipelines, and a toolkit of equivariant utilities, supported with comprehensive tests and documentation, to facilitate both application and further development of SE(3)-equivariant models."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Adaptive Online Learning with LSTM Networks for Energy Price Prediction", "authors": "Salih Salihoglu, Ibrahim Ahmed, Afshin Asadi", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "Accurate prediction of electricity prices is crucial for stakeholders in the energy market, particularly for grid operators, energy producers, and consumers. This study focuses on developing a predictive model leveraging Long Short-Term Memory (LSTM) networks to forecast day-ahead electricity prices in the California energy market. The model incorporates a variety of features, including historical price data, weather conditions, and the energy generation mix. A novel custom loss function that integrates Mean Absolute Error (MAE), Jensen-Shannon Divergence (JSD), and a smoothness penalty is introduced to enhance the prediction accuracy and interpretability. Additionally, an online learning approach is implemented to allow the model to adapt to new data incrementally, ensuring continuous relevance and accuracy. The results demonstrate that the custom loss function can improve the model's performance, aligning predicted prices more closely with actual values, particularly during peak intervals. Also, the online learning model outperforms other models by effectively incorporating real-time data, resulting in lower prediction error and variability. The inclusion of the energy generation mix further enhances the model's predictive capabilities, highlighting the importance of comprehensive feature integration. This research provides a robust framework for electricity price forecasting, offering valuable insights and tools for better decision-making in dynamic electricity markets."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          SNOMED CT-powered Knowledge Graphs for Structured Clinical Data and Diagnostic Reasoning", "authors": "Dun Liu, Qin Pang, Guangai Liu, Hongyu Mou, Jipeng Fan, Yiming Miao, Pin-Han Ho, Limei Peng", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "The effectiveness of artificial intelligence (AI) in healthcare is significantly hindered by unstructured clinical documentation, which results in noisy, inconsistent, and logically fragmented training data. To address this challenge, we present a knowledge-driven framework that integrates the standardized clinical terminology SNOMED CT with the Neo4j graph database to construct a structured medical knowledge graph. In this graph, clinical entities such as diseases, symptoms, and medications are represented as nodes, and semantic relationships such as ``caused by,'' ``treats,'' and ``belongs to'' are modeled as edges in Neo4j, with types mapped from formal SNOMED CT relationship concepts (e.g., \\texttt{Causative agent}, \\texttt{Indicated for}). This design enables multi-hop reasoning and ensures terminological consistency. By extracting and standardizing entity-relationship pairs from clinical texts, we generate structured, JSON-formatted datasets that embed explicit diagnostic pathways. These datasets are used to fine-tune large language models (LLMs), significantly improving the clinical logic consistency of their outputs. Experimental results demonstrate that our knowledge-guided approach enhances the validity and interpretability of AI-generated diagnostic reasoning, providing a scalable solution for building reliable AI-assisted clinical systems."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          C-Free-Uniform: A Map-Conditioned Trajectory Sampler for Model Predictive Path Integral Control", "authors": "Yukang Cao, Rahul Moorthy, O. Goktug Poyrazoglu, Volkan Isler", "subjects": "Robotics (cs.RO)", "abstract": "Trajectory sampling is a key component of sampling-based control mechanisms. Trajectory samplers rely on control input samplers, which generate control inputs u from a distribution p(u | x) where x is the current state. We introduce the notion of Free Configuration Space Uniformity (C-Free-Uniform for short) which has two key features: (i) it generates a control input distribution so as to uniformly sample the free configuration space, and (ii) in contrast to previously introduced trajectory sampling mechanisms where the distribution p(u | x) is independent of the environment, C-Free-Uniform is explicitly conditioned on the current local map. Next, we integrate this sampler into a new Model Predictive Path Integral (MPPI) Controller, CFU-MPPI. Experiments show that CFU-MPPI outperforms existing methods in terms of success rate in challenging navigation tasks in cluttered polygonal environments while requiring a much smaller sampling budget."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          VAGEN: Reinforcing World Model Reasoning for Multi-Turn VLM Agents", "authors": "Kangrui Wang, Pingyue Zhang, Zihan Wang, Yaning Gao, Linjie Li, Qineng Wang, Hanyang Chen, Chi Wan, Yiping Lu, Zhengyuan Yang, Lijuan Wang, Ranjay Krishna, Jiajun Wu, Li Fei-Fei, Yejin Choi, Manling Li", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "abstract": "A key challenge in training Vision-Language Model (VLM) agents, compared to Language Model (LLM) agents, lies in the shift from textual states to complex visual observations. This transition introduces partial observability and demands robust world modeling. We ask: Can VLM agents construct internal world models through explicit visual state reasoning? To address this question, we architecturally enforce and reward the agent's reasoning process via reinforcement learning (RL), formulating it as a Partially Observable Markov Decision Process (POMDP). We find that decomposing the agent's reasoning into State Estimation (\"what is the current state?\") and Transition Modeling (\"what comes next?\") is critical for success, as demonstrated through five reasoning strategies. Our investigation into how agents represent internal beliefs reveals that the optimal representation is task-dependent: Natural Language excels at capturing semantic relationships in general tasks, while Structured formats are indispensable for precise manipulation and control. Building on these insights, we design a World Modeling Reward that provides dense, turn-level supervision for accurate state prediction, and introduce Bi-Level General Advantage Estimation (Bi-Level GAE) for turn-aware credit assignment. Through this form of visual state reasoning, a 3B-parameter model achieves a score of 0.82 across five diverse agent benchmarks, representing a 3$\\times$ improvement over its untrained counterpart (0.21) and outperforming proprietary reasoning models such as GPT-5 (0.75), Gemini 2.5 Pro (0.67) and Claude 4.5 (0.62). All experiments are conducted within our VAGEN framework, a scalable system for training and analyzing multi-turn VLM agents in diverse visual environments. Code and data are publicly available at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          A Lightweight DL Model for Smart Grid Power Forecasting with Feature and Resolution Mismatch", "authors": "Sarah Al-Shareeda, Gulcihan Ozdemir, Heung Seok Jeon, Khaleel Ahmad", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "How can short-term energy consumption be accurately forecasted when sensor data is noisy, incomplete, and lacks contextual richness? This question guided our participation in the \\textit{2025 Competition on Electric Energy Consumption Forecast Adopting Multi-criteria Performance Metrics}, which challenged teams to predict next-day power demand using real-world high-frequency data. We proposed a robust yet lightweight Deep Learning (DL) pipeline combining hourly downsizing, dual-mode imputation (mean and polynomial regression), and comprehensive normalization, ultimately selecting Standard Scaling for optimal balance. The lightweight GRU-LSTM sequence-to-one model achieves an average RMSE of 601.9~W, MAE of 468.9~W, and 84.36\\% accuracy. Despite asymmetric inputs and imputed gaps, it generalized well, captured nonlinear demand patterns, and maintained low inference latency. Notably, spatiotemporal heatmap analysis reveals a strong alignment between temperature trends and predicted consumption, further reinforcing the model's reliability. These results demonstrate that targeted preprocessing paired with compact recurrent architectures can still enable fast, accurate, and deployment-ready energy forecasting in real-world conditions."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Beyond RGB: Leveraging Vision Transformers for Thermal Weapon Segmentation", "authors": "Akhila Kambhatla, Ahmed R Khaled", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Thermal weapon segmentation is crucial for surveillance and security applications, enabling robust detection under lowlight and visually obscured conditions where RGB-based systems fail. While convolutional neural networks (CNNs) dominate thermal segmentation literature, their ability to capture long-range dependencies and fine structural details is limited. Vision Transformers (ViTs), with their global context modeling capabilities, have achieved state-of-the-art results in RGB segmentation tasks, yet their potential in thermal weapon segmentation remains underexplored. This work adapts and evaluates four transformer-based architectures SegFormer, DeepLabV3\\+, SegNeXt, and Swin Transformer for binary weapon segmentation on a custom thermal dataset comprising 9,711 images collected from real world surveillance videos and automatically annotated using SAM2. We employ standard augmentation strategies within the MMSegmentation framework to ensure robust model training and fair architectural comparison. Experimental results demonstrate significant improvements in segmentation performance: SegFormer-b5 achieves the highest mIoU (94.15\\%) and Pixel Accuracy (97.04\\%), while SegFormer-b0 provides the fastest inference speed (98.32 FPS) with competitive mIoU (90.84\\%). SegNeXt-mscans offers balanced performance with 85.12 FPS and 92.24\\% mIoU, and DeepLabV3\\+ R101-D8 reaches 92.76\\% mIoU at 29.86 FPS. The transformer architectures demonstrate robust generalization capabilities for weapon detection in low-light and occluded thermal environments, with flexible accuracy-speed trade-offs suitable for diverse real-time security applications."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Domain Generalizable Continual Learning", "authors": "Hongwei Yan, Guanglong Sun, Zhiqi Kang, Yi Zhong, Liyuan Wang", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)", "abstract": "To adapt effectively to dynamic real-world environments, intelligent systems must continually acquire new skills while generalizing them to diverse, unseen scenarios. Here, we introduce a novel and realistic setting named domain generalizable continual learning (DGCL): a model learns sequential tasks with each involving a single domain, aiming to perform well across all encountered tasks and domains. This setting poses unique challenges in acquiring, retaining, and leveraging both semantic- and domain-relevant information for robust generalization. Although state-of-the-art continual learning (CL) methods have employed pre-trained models (PTMs) to enhance task-specific generalization, they typically assume identical training and testing domains for each task and therefore perform poorly in DGCL. To this end, we propose adaptive Domain Transformation (DoT), an innovative PTMs-based approach tailored to DGCL. Inspired by the distributed-plus-hub theory of the human brain, DoT disentangles semantic- and domain-relevant information in representation learning, and adaptively transforms task representations across various domains for output alignment, ensuring balanced and generalized predictions. DoT serves as a plug-in strategy that greatly facilitates state-of-the-art CL baselines under both full parameter tuning and parameter-efficient tuning paradigms in DGCL, validated by extensive experiments. Also, DoT is shown to accumulate domain-generalizable knowledge from DGCL, and ensure resource efficiency with a lightweight implementation."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          SolverLLM: Leveraging Test-Time Scaling for Optimization Problem via LLM-Guided Search", "authors": "Dong Li, Xujiang Zhao, Linlin Yu, Yanchi Liu, Wei Cheng, Zhengzhang Chen, Zhong Chen, Feng Chen, Chen Zhao, Haifeng Chen", "subjects": "Machine Learning (cs.LG)", "abstract": "Large Language Models (LLMs) offer promising capabilities for tackling complex reasoning tasks, including optimization problems. However, existing methods either rely on prompt engineering, which leads to poor generalization across problem types, or require costly supervised training. We introduce SolverLLM, a training-free framework that leverages test-time scaling to solve diverse optimization problems. Rather than solving directly, SolverLLM generates mathematical formulations and translates them into solver-ready code, guided by a novel Monte Carlo Tree Search (MCTS) strategy. To enhance the search process, we modify classical MCTS with (1) dynamic expansion for adaptive formulation generation, (2) prompt backpropagation to guide exploration via outcome-driven feedback, and (3) uncertainty backpropagation to incorporate reward reliability into decision-making. Experiments on six standard benchmark datasets demonstrate that SolverLLM outperforms both prompt-based and learning-based baselines, achieving strong generalization without additional training."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          SAKE: Towards Editing Auditory Attribute Knowledge of Large Audio-Language Models", "authors": "Chih-Kai Yang, Yen-Ting Piao, Tzu-Wen Hsu, Szu-Wei Fu, Zhehuai Chen, Ke-Han Lu, Sung-Feng Huang, Chao-Han Huck Yang, Yu-Chiang Frank Wang, Yun-Nung Chen, Hung-yi Lee", "subjects": "Sound (cs.SD); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Audio and Speech Processing (eess.AS)", "abstract": "Knowledge editing offers an efficient way to update model knowledge without full retraining, but prior work has concentrated almost exclusively on textual or visual modalities. We introduce SAKE, the first benchmark specifically designed for editing auditory attribute knowledge in Large Audio-Language Models (LALMs). Unlike factual updates, SAKE targets several abstract auditory attributes, capturing knowledge types that go beyond conventional textual and visual domains. We benchmark seven editing methods on two LALMs along four dimensions: reliability, generality, audio/text locality, and portability. Results highlight challenges such as preserving intra-attribute knowledge unrelated to the edit, generalizing edits to multimodal reasoning, and maintaining edits under sequential updates. SAKE provides a principled framework to study how knowledge editing extends to the auditory modalities, opening new directions for maintaining and adapting LALMs in more diverse real-world scenarios."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          UNDREAM: Bridging Differentiable Rendering and Photorealistic Simulation for End-to-end Adversarial Attacks", "authors": "Mansi Phute, Matthew Hull, Haoran Wang, Alec Helbling, ShengYun Peng, Willian Lunardi, Martin Andreoni, Wenke Lee, Polo Chau", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "abstract": "Deep learning models deployed in safety critical applications like autonomous driving use simulations to test their robustness against adversarial attacks in realistic conditions. However, these simulations are non-differentiable, forcing researchers to create attacks that do not integrate simulation environmental factors, reducing attack success. To address this limitation, we introduce UNDREAM, the first software framework that bridges the gap between photorealistic simulators and differentiable renderers to enable end-to-end optimization of adversarial perturbations on any 3D objects. UNDREAM enables manipulation of the environment by offering complete control over weather, lighting, backgrounds, camera angles, trajectories, and realistic human and object movements, thereby allowing the creation of diverse scenes. We showcase a wide array of distinct physically plausible adversarial objects that UNDREAM enables researchers to swiftly explore in different configurable environments. This combination of photorealistic simulation and differentiable optimization opens new avenues for advancing research of physical adversarial attacks."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Does Visual Grounding Enhance the Understanding of Embodied Knowledge in Large Language Models?", "authors": "Zhihui Yang, Yupei Wang, Kaijie Mo, Zhe Zhao, Renfen Hu", "subjects": "Computation and Language (cs.CL)", "abstract": "Despite significant progress in multimodal language models (LMs), it remains unclear whether visual grounding enhances their understanding of embodied knowledge compared to text-only models. To address this question, we propose a novel embodied knowledge understanding benchmark based on the perceptual theory from psychology, encompassing visual, auditory, tactile, gustatory, olfactory external senses, and interoception. The benchmark assesses the models' perceptual abilities across different sensory modalities through vector comparison and question-answering tasks with over 1,700 questions. By comparing 30 state-of-the-art LMs, we surprisingly find that vision-language models (VLMs) do not outperform text-only models in either task. Moreover, the models perform significantly worse in the visual dimension compared to other sensory dimensions. Further analysis reveals that the vector representations are easily influenced by word form and frequency, and the models struggle to answer questions involving spatial perception and reasoning. Our findings underscore the need for more effective integration of embodied knowledge in LMs to enhance their understanding of the physical world."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Towards Context-aware Reasoning-enhanced Generative Searching in E-commerce", "authors": "Zhiding Liu, Ben Chen, Mingyue Cheng, Enchong Chen, Li Li, Chenyi Lei, Wenwu Ou, Han Li, Kun Gai", "subjects": "Information Retrieval (cs.IR)", "abstract": "Search-based recommendation is one of the most critical application scenarios in e-commerce platforms. Users' complex search contexts--such as spatiotemporal factors, historical interactions, and current query's information--constitute an essential part of their decision-making, reflecting implicit preferences that complement explicit query terms. Modeling such rich contextual signals and their intricate associations with candidate items remains a key challenge. Although numerous efforts have been devoted to building more effective search methods, existing approaches still show limitations in integrating contextual information, which hinders their ability to fully capture user intent. To address these challenges, we propose a context-aware reasoning-enhanced generative search framework for better \\textbf{understanding the complicated context}. Specifically, the framework first unifies heterogeneous user and item contexts into textual representations or text-based semantic identifiers and aligns them. To overcome the lack of explicit reasoning trajectories, we introduce a self-evolving post-training paradigm that iteratively combines supervised fine-tuning and reinforcement learning to progressively enhance the model's reasoning capability. In addition, we identify potential biases in existing RL algorithms when applied to search scenarios and present a debiased variant of GRPO to improve ranking performance. Extensive experiments on search log data collected from a real-world e-commerce platform demonstrate that our approach achieves superior performance compared with strong baselines, validating its effectiveness for search-based recommendation."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Res-Bench: Benchmarking the Robustness of Multimodal Large Language Models to Dynamic Resolution Input", "authors": "Chenxu Li, Zhicai Wang, Yuan Sheng, Xingyu Zhu, Yanbin Hao, Xiang Wang", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Computation and Language (cs.CL)", "abstract": "Multimodal Large Language Models (MLLMs) increasingly support dynamic image resolutions. However, current evaluation paradigms primarily assess semantic performance, overlooking the critical question of resolution robustness - whether performance remains stable across varying input resolutions. To address this gap, we introduce \\textbf{Res-Bench}, a comprehensive benchmark comprising 14,400 samples across 12 resolution levels and six core capability dimensions. We designed a novel evaluation framework that goes beyond traditional accuracy metrics to capture performance stability. This framework introduces multiple robustness metrics: Spearman's correlation for assessing resolution-performance trends, and Absolute/Relative Continuous Error (ACE/RCE) for measuring performance volatility. Using these metrics, we conducted a large-scale evaluation of leading MLLMs. Our analysis encompasses: (1) model-centric and task-centric robustness examination, (2) investigation of preprocessing strategies including padding and super-resolution, and (3) exploration of fine-tuning for stability enhancement."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Closing the Curvature Gap: Full Transformer Hessians and Their Implications for Scaling Laws", "authors": "Egor Petrov, Nikita Kiselev, Vladislav Meshkov, Andrey Grabovoy", "subjects": "Machine Learning (cs.LG)", "abstract": "The lack of theoretical results for Layer Normalization and feedforward Hessians has left a gap in the study of Transformer optimization landscapes. We address this by deriving explicit second-order expressions for these components, thereby completing the Hessian characterization of full Transformer blocks. Our results generalize prior self-attention analyses and yield estimations for the role of each sublayer in curvature propagation. We demonstrate how these Hessian structures inform both convergence dynamics and the empirical scaling laws governing large-model performance. Further, we propose a Taylor-expansion-based framework for analyzing loss differences to quantify convergence trajectories. By extending Hessian theory to the full Transformer architecture, this work establishes a new foundation for theoretical and empirical investigations of optimization in large-scale deep learning."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          ChiKhaPo: A Large-Scale Multilingual Benchmark for Evaluating Lexical Comprehension and Generation in Large Language Models", "authors": "Emily Chang, Niyati Bafna", "subjects": "Computation and Language (cs.CL)", "abstract": "Existing benchmarks for large language models (LLMs) are largely restricted to high- or mid-resource languages, and often evaluate performance on higher-order tasks in reasoning and generation. However, plenty of evidence points to the fact that LLMs lack basic linguistic competence in the vast majority of the world's 3800+ written languages. We introduce ChiKhaPo, consisting of 8 subtasks of varying difficulty designed to evaluate the lexical comprehension and generation abilities of generative models. ChiKhaPo draws on existing lexicons, monolingual data, and bitext, and provides coverage for 2700+ languages for 2 subtasks, surpassing any existing benchmark in terms of language coverage. We further show that 6 SOTA models struggle on our benchmark, and discuss the factors contributing to performance scores, including language family, language resourcedness, task, and comprehension versus generation directions. With ChiKhaPo, we hope to enable and encourage the massively multilingual benchmarking of LLMs."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          HOQRI: Higher-order QR Iteration for Low Multilinear Rank Approximation of Large and Sparse Tensors", "authors": "Yuchen Sun, Amit Bhat, Chunmei Wang, Kejun Huang", "subjects": "Numerical Analysis (math.NA)", "abstract": "We propose a new algorithm called higher-order QR iteration (HOQRI) for computing low multilinear rank approximation (LMLRA), also known as the Tucker decomposition, of large and sparse tensors. Compared to the celebrated higher-order orthogonal iterations (HOOI), HOQRI relies on a simple orthogonalization step in each iteration rather than a more sophisticated singular value decomposition step as in HOOI. More importantly, when dealing with extremely large and sparse data tensors, HOQRI completely eliminates the intermediate memory explosion by defining a new sparse tensor operation called TTMcTC (short for tensor times matrix chains times core). Furthermore, recognizing that the orthonormal constraints form a Cartesian product of Stiefel manifolds, we introduce the framework of manifold optimization and show that HOQRI guarantees convergence to the set of stationary points. Numerical experiments on synthetic and real data showcase the effectiveness of HOQRI."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Design of an Affordable, Fully-Actuated Biomimetic Hand for Dexterous Teleoperation Systems", "authors": "Zhaoliang Wan, Zida Zhou, Zetong Bi, Zehui Yang, Hao Ding, Hui Cheng", "subjects": "Robotics (cs.RO)", "abstract": "This paper addresses the scarcity of affordable, fully-actuated five-fingered hands for dexterous teleoperation, which is crucial for collecting large-scale real-robot data within the \"Learning from Demonstrations\" paradigm. We introduce the prototype version of the RAPID Hand, the first low-cost, 20-degree-of-actuation (DoA) dexterous hand that integrates a novel anthropomorphic actuation and transmission scheme with an optimized motor layout and structural design to enhance dexterity. Specifically, the RAPID Hand features a universal phalangeal transmission scheme for the non-thumb fingers and an omnidirectional thumb actuation mechanism. Prioritizing affordability, the hand employs 3D-printed parts combined with custom gears for easier replacement and repair. We assess the RAPID Hand's performance through quantitative metrics and qualitative testing in a dexterous teleoperation system, which is evaluated on three challenging tasks: multi-finger retrieval, ladle handling, and human-like piano playing. The results indicate that the RAPID Hand's fully actuated 20-DoF design holds significant promise for dexterous teleoperation."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Prompt-MII: Meta-Learning Instruction Induction for LLMs", "authors": "Emily Xiao, Yixiao Zeng, Ada Chen, Chin-Jou Li, Amanda Bertsch, Graham Neubig", "subjects": "Computation and Language (cs.CL)", "abstract": "A popular method to adapt large language models (LLMs) to new tasks is in-context learning (ICL), which is effective but incurs high inference costs as context length grows. In this paper we propose a method to perform instruction induction, where we take training examples and reduce them to a compact but descriptive prompt that can achieve performance comparable to ICL over the full training set. Specifically, we propose PROMPT-MII, a reinforcement learning (RL) based framework to meta-learn an instruction induction model that can generate compact instructions on the fly for an arbitrary new dataset. We train on over 3,000 diverse classification datasets from the HuggingFace hub, and evaluate on 90 unseen tasks. PROMPT-MII improves downstream model quality by 4-9 F1 points (10-20% relative), matching ICL performance while requiring 3-13x fewer tokens."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Tutoring LLM into a Better CUDA Optimizer", "authors": "Maty\u00e1\u0161 Brabec, Ji\u0159\u00ed Klepl, Michal T\u00f6pfer, Martin Kruli\u0161", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC); Artificial Intelligence (cs.AI)", "abstract": "Recent leaps in large language models (LLMs) caused a revolution in programming tools (like GitHub Copilot) that can help with code generation, debugging, and even performance optimization. In this paper, we focus on the capabilities of the most recent reasoning models to generate optimized CUDA code for predefined, well-known tasks. Our objective is to determine which types of code optimizations and parallel patterns the LLMs can perform by themselves and whether they can be improved by tutoring (providing more detailed hints and guidelines in the prompt). The generated solutions were evaluated both automatically (for correctness and speedup) and manually (code reviews) to provide a more detailed perspective. We also tried an interactive approach where the LLM can fix its previous mistakes within a session. The results indicate that LLMs are quite skilled coders; however, they require tutoring to reach optimized solutions provided by parallel computing experts."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          A Primer on Kolmogorov-Arnold Networks (KANs) for Probabilistic Time Series Forecasting", "authors": "Cristian J. Vaca-Rubio, Roberto Pereira, Luis Blanco, Engin Zeydan, M\u00e0rius Caus", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Signal Processing (eess.SP)", "abstract": "This work introduces Probabilistic Kolmogorov-Arnold Network (P-KAN), a novel probabilistic extension of Kolmogorov-Arnold Networks (KANs) for time series forecasting. By replacing scalar weights with spline-based functional connections and directly parameterizing predictive distributions, P-KANs offer expressive yet parameter-efficient models capable of capturing nonlinear and heavy-tailed dynamics. We evaluate P-KANs on satellite traffic forecasting, where uncertainty-aware predictions enable dynamic thresholding for resource allocation. Results show that P-KANs consistently outperform Multi Layer Perceptron (MLP) baselines in both accuracy and calibration, achieving superior efficiency-risk trade-offs while using significantly fewer parameters. We build up P-KANs on two distributions, namely Gaussian and Student-t distributions. The Gaussian variant provides robust, conservative forecasts suitable for safety-critical scenarios, whereas the Student-t variant yields sharper distributions that improve efficiency under stable demand. These findings establish P-KANs as a powerful framework for probabilistic forecasting with direct applicability to satellite communications and other resource-constrained domains."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Peering Inside the Black Box: Uncovering LLM Errors in Optimization Modelling through Component-Level Evaluation", "authors": "Dania Refai, Moataz Ahmed", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "abstract": "Large language models (LLMs) are increasingly used to convert natural language descriptions into mathematical optimization formulations. Current evaluations often treat formulations as a whole, relying on coarse metrics like solution accuracy or runtime, which obscure structural or numerical errors. In this study, we present a comprehensive, component-level evaluation framework for LLM-generated formulations. Beyond the conventional optimality gap, our framework introduces metrics such as precision and recall for decision variables and constraints, constraint and objective root mean squared error (RMSE), and efficiency indicators based on token usage and latency. We evaluate GPT-5, LLaMA 3.1 Instruct, and DeepSeek Math across optimization problems of varying complexity under six prompting strategies. Results show that GPT-5 consistently outperforms other models, with chain-of-thought, self-consistency, and modular prompting proving most effective. Analysis indicates that solver performance depends primarily on high constraint recall and low constraint RMSE, which together ensure structural correctness and solution reliability. Constraint precision and decision variable metrics play secondary roles, while concise outputs enhance computational efficiency. These findings highlight three principles for NLP-to-optimization modeling: (i) Complete constraint coverage prevents violations, (ii) minimizing constraint RMSE ensures solver-level accuracy, and (iii) concise outputs improve computational efficiency. The proposed framework establishes a foundation for fine-grained, diagnostic evaluation of LLMs in optimization modeling."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Learning Ecology with VERA Using Conceptual Models and Simulations", "authors": "Spencer Rugaber, Scott Bunin, Andrew Hornback, Sungeun An, Ashok Goel", "subjects": "Computers and Society (cs.CY); Symbolic Computation (cs.SC)", "abstract": "Conceptual modeling has been an important part of constructionist educational practices for many years, particularly in STEM (Science, Technology, Engineering and Mathematics) disciplines. What is not so common is using agent-based simulation to provide students feedback on model quality. This requires the capability of automatically compiling the concept model into its simulation. The VERA (Virtual Experimentation Research Assistant) system is a conceptual modeling tool used since 2016 to provide introductory college biology students with the capability of conceptual modeling and agent-based simulation in the ecological domain. This paper describes VERA and its approach to coupling conceptual modeling and simulation with emphasis on how a model's visual syntax is compiled into code executable on a NetLogo simulation engine. Experience with VERA in introductory biology classes at several universities and through the Smithsonian Institution's Encyclopedia of Life website is related."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Host-Side Telemetry for Performance Diagnosis in Cloud and HPC GPU Infrastructure", "authors": "Erfan Darzi, Aldo Pareja, Shreeanant Bharadwaj", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "abstract": "Diagnosing GPU tail latency spikes in cloud and HPC infrastructure is critical for maintaining performance predictability and resource utilization, yet existing monitoring tools lack the granularity for root cause analysis in shared computing environments. We introduce an eBPF-based telemetry system that provides unified host-side monitoring of GPU workloads, correlating eBPF-derived host metrics with GPU-internal events for holistic system observability. The system achieves 81--88\\% diagnostic accuracy, detects spikes within 5 seconds, and completes root cause analysis in 6--8 seconds, operating with 1.21\\% CPU overhead at 100Hz sampling. Evaluated on distributed learning workloads, the system identifies root causes including NIC contention, PCIe pressure, and CPU interference, enabling operational debugging for multi-tenant GPU infrastructure without requiring cluster-wide instrumentation."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Unlocking Off-the-Grid Sparse Recovery with Unlimited Sensing: Simultaneous Super-Resolution in Time and Amplitude", "authors": "Ruiming Guo, Ayush Bhandari", "subjects": "Information Theory (cs.IT); Computer Vision and Pattern Recognition (cs.CV); Signal Processing (eess.SP)", "abstract": "The recovery of Dirac impulses, or spikes, from filtered measurements is a classical problem in signal processing. As the spikes lie in the continuous domain while measurements are discrete, this task is known as super-resolution or off-the-grid sparse recovery. Despite significant theoretical and algorithmic advances over the past decade, these developments often overlook critical challenges at the analog-digital interface. In particular, when spikes exhibit strong-weak amplitude disparity, conventional digital acquisition may result in clipping of strong components or loss of weak ones beneath the quantization noise floor. This motivates a broader perspective: super-resolution must simultaneously resolve both amplitude and temporal structure. Under a fixed bit budget, such information loss is unavoidable. In contrast, the emerging theory and practice of the Unlimited Sensing Framework (USF) demonstrate that these fundamental limitations can be overcome. Building on this foundation, we demonstrate that modulo encoding within USF enables digital super-resolution by enhancing measurement precision, thereby unlocking temporal super-resolution beyond conventional limits. We develop new theoretical results that extend to non-bandlimited kernels commonly encountered in practice and introduce a robust algorithm for off-the-grid sparse recovery. To demonstrate practical impact, we instantiate our framework in the context of time-of-flight imaging. Both numerical simulations and hardware experiments validate the effectiveness of our approach under low-bit quantization, enabling super-resolution in amplitude and time."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Local News Hijacking: A Review of International Instances", "authors": "Christine Sowa Lepird, Kathleen M. Carley", "subjects": "Computers and Society (cs.CY)", "abstract": "In the rise of the digital era, it's easier than ever to create nefarious websites to spread misinformation. A more recent phenomenon in the United States has been the creation of inauthentic local news websites to further an information operation campaign. This paper is a review of the 7 instances in which local news websites were created to influence residents of a region between 2007 and 2024. By breaking down the ways in which these sites operated, we discovered commonalities in the approach - resurrecting \"zombie\" papers that were previously established authentic local news organizations, sharing these sites on social media, and using website templates from WordPress. By analyzing these commonalities, we propose ways to mitigate the occurrence of these campaigns in the future."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Real-Time World Crafting: Generating Structured Game Behaviors from Natural Language with Large Language Models", "authors": "Austin Drake, Hang Dong", "subjects": "Human-Computer Interaction (cs.HC); Computation and Language (cs.CL)", "abstract": "We present a novel architecture for safely integrating Large Language Models (LLMs) into interactive game engines, allowing players to \"program\" new behaviors using natural language. Our framework mitigates risks by using an LLM to translate commands into a constrained Domain-Specific Language (DSL), which configures a custom Entity-Component-System (ECS) at runtime. We evaluated this system in a 2D spell-crafting game prototype by experimentally assessing models from the Gemini, GPT, and Claude families with various prompting strategies. A validated LLM judge qualitatively rated the outputs, showing that while larger models better captured creative intent, the optimal prompting strategy is task-dependent: Chain-of-Thought improved creative alignment, while few-shot examples were necessary to generate more complex DSL scripts. This work offers a validated LLM-ECS pattern for emergent gameplay and a quantitative performance comparison for developers."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Safe Payload Transfer with Ship-Mounted Cranes: A Robust Model Predictive Control Approach", "authors": "Ersin Das, William A. Welch, Patrick Spieler, Keenan Albee, Aurelio Noca, Jeffrey Edlund, Jonathan Becktor, Thomas Touma, Jessica Todd, Sriramya Bhamidipati, Stella Kombo, Maira Saboia, Anna Sabel, Grace Lim, Rohan Thakker, Amir Rahmani, Joel W. Burdick", "subjects": "Systems and Control (eess.SY); Robotics (cs.RO)", "abstract": "Ensuring safe real-time control of ship-mounted cranes in unstructured transportation environments requires handling multiple safety constraints while maintaining effective payload transfer performance. Unlike traditional crane systems, ship-mounted cranes are consistently subjected to significant external disturbances affecting underactuated crane dynamics due to the ship's dynamic motion response to harsh sea conditions, which can lead to robustness issues. To tackle these challenges, we propose a robust and safe model predictive control (MPC) framework and demonstrate it on a 5-DOF crane system, where a Stewart platform simulates the external disturbances that ocean surface motions would have on the supporting ship. The crane payload transfer operation must avoid obstacles and accurately place the payload within a designated target area. We use a robust zero-order control barrier function (R-ZOCBF)-based safety constraint in the nonlinear MPC to ensure safe payload positioning, while time-varying bounding boxes are utilized for collision avoidance. We introduce a new optimization-based online robustness parameter adaptation scheme to reduce the conservativeness of R-ZOCBFs. Experimental trials on a crane prototype demonstrate the overall performance of our safe control approach under significant perturbing motions of the crane base. While our focus is on crane-facilitated transfer, the methods more generally apply to safe robotically-assisted parts mating and parts insertion."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          A Comparative User Evaluation of XRL Explanations using Goal Identification", "authors": "Mark Towers, Yali Du, Christopher Freeman, Timothy J. Norman", "subjects": "Artificial Intelligence (cs.AI)", "abstract": "Debugging is a core application of explainable reinforcement learning (XRL) algorithms; however, limited comparative evaluations have been conducted to understand their relative performance. We propose a novel evaluation methodology to test whether users can identify an agent's goal from an explanation of its decision-making. Utilising the Atari's Ms. Pacman environment and four XRL algorithms, we find that only one achieved greater than random accuracy for the tested goals and that users were generally overconfident in their selections. Further, we find that users' self-reported ease of identification and understanding for every explanation did not correlate with their accuracy."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Quantile Regression, Variational Autoencoders, and Diffusion Models for Uncertainty Quantification: A Spatial Analysis of Sub-seasonal Wind Speed Prediction", "authors": "Ganglin Tian, Anastase Alexandre Charantonis, Camille Le Coz, Alexis Tantet, Riwal Plougonven", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "This study aims to improve the spatial representation of uncertainties when regressing surface wind speeds from large-scale atmospheric predictors for sub-seasonal forecasting. Sub-seasonal forecasting often relies on large-scale atmospheric predictors such as 500 hPa geopotential height (Z500), which exhibit higher predictability than surface variables and can be downscaled to obtain more localised information. Previous work by Tian et al. (2024) demonstrated that stochastic perturbations based on model residuals can improve ensemble dispersion representation in statistical downscaling frameworks, but this method fails to represent spatial correlations and physical consistency adequately. More sophisticated approaches are needed to capture the complex relationships between large-scale predictors and local-scale predictands while maintaining physical consistency. Probabilistic deep learning models offer promising solutions for capturing complex spatial dependencies. This study evaluates three probabilistic methods with distinct uncertainty quantification mechanisms: Quantile Regression Neural Network that directly models distribution quantiles, Variational Autoencoders that leverage latent space sampling, and Diffusion Models that utilise iterative denoising. These models are trained on ERA5 reanalysis data and applied to ECMWF sub-seasonal hindcasts to regress probabilistic wind speed ensembles. Our results show that probabilistic downscaling approaches provide more realistic spatial uncertainty representations compared to simpler stochastic methods, with each probabilistic model offering different strengths in terms of ensemble dispersion, deterministic skill, and physical consistency. These findings establish probabilistic downscaling as an effective enhancement to operational sub-seasonal wind forecasts for renewable energy planning and risk assessment."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Efficient derandomization of differentially private counting queries", "authors": "Surendra Ghentiyala", "subjects": "Cryptography and Security (cs.CR); Computational Complexity (cs.CC)", "abstract": "Differential privacy for the 2020 census required an estimated 90 terabytes of randomness [GL20], an amount which may be prohibitively expensive or entirely infeasible to generate. Motivated by these practical concerns, [CSV25] initiated the study of the randomness complexity of differential privacy, and in particular, the randomness complexity of $d$ counting queries. This is the task of outputting the number of entries in a dataset that satisfy predicates $\\mathcal{P}_1, \\dots, \\mathcal{P}_d$ respectively. They showed the rather surprising fact that though any reasonably accurate, $\\varepsilon$-differentially private mechanism for one counting query requires $1-O(\\varepsilon)$ bits of randomness in expectation, there exists a fairly accurate mechanism for $d$ counting queries which requires only $O(\\log d)$ bits of randomness in expectation. The mechanism of [CSV25] is inefficient (not polynomial time) and relies on a combinatorial object known as rounding schemes. Here, we give a polynomial time mechanism which achieves nearly the same randomness complexity versus accuracy tradeoff as that of [CSV25]. Our construction is based on the following simple observation: after a randomized shift of the answer to each counting query, the answer to many counting queries remains the same regardless of whether we add noise to that coordinate or not. This allows us to forgo the step of adding noise to the result of many counting queries. Our mechanism does not make use of rounding schemes. Therefore, it provides a different -- and, in our opinion, clearer -- insight into the origins of the randomness savings that can be obtained by batching $d$ counting queries. Therefore, it provides a different -- and, in our opinion, clearer -- insight into the origins of the randomness savings that can be obtained by batching $d$ counting queries."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          A Scalable In Transit Solution for Comprehensive Exploration of Simulation Data", "authors": "Paascal Grosset, James Ahrens", "subjects": "Graphics (cs.GR)", "abstract": "As simulations produce more data than available disk space on supercomputers, many simulations are employing in situ analysis and visualization to reduce the amount of data that needs to be stored. While in situ visualization offers potential for substantial data reduction, its efficacy is hindered by the need for a priori knowledge. First, we need to know what visualization parameters to use to highlight features of interest. Second, we do not know ahead of time how much resources will be needed to run the in situ workflows, e.g. how many compute nodes will be needed for in situ work. In this work, we present SeerX, a lightweight, scalable in-transit in situ service that supports dynamic resource allocation and lossy compression of 3D simulation data. SeerX enables multiple simulations to offload analysis to a shared, elastic service infrastructure without MPI synchronization."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Leave It to the Experts: Detecting Knowledge Distillation via MoE Expert Signatures", "authors": "Pingzhi Li, Morris Yu-Chao Huang, Zhen Tan, Qingquan Song, Jie Peng, Kai Zou, Yu Cheng, Kaidi Xu, Tianlong Chen", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "abstract": "Knowledge Distillation (KD) accelerates training of large language models (LLMs) but poses intellectual property protection and LLM diversity risks. Existing KD detection methods based on self-identity or output similarity can be easily evaded through prompt engineering. We present a KD detection framework effective in both white-box and black-box settings by exploiting an overlooked signal: the transfer of MoE \"structural habits\", especially internal routing patterns. Our approach analyzes how different experts specialize and collaborate across various inputs, creating distinctive fingerprints that persist through the distillation process. To extend beyond the white-box setup and MoE architectures, we further propose Shadow-MoE, a black-box method that constructs proxy MoE representations via auxiliary distillation to compare these patterns between arbitrary model pairs. We establish a comprehensive, reproducible benchmark that offers diverse distilled checkpoints and an extensible framework to facilitate future research. Extensive experiments demonstrate >94% detection accuracy across various scenarios and strong robustness to prompt-based evasion, outperforming existing baselines while highlighting the structural habits transfer in LLMs."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Proactive and Fair Epidemic Resource Allocation Through an Integrated Supply Chain Framework: Insights from a COVID-19 Study", "authors": "Kimiya Jozani, Nihal A. Sageer, Hode Eldardiry, Sait Tunc, Esra Buyuktahtakin Toy", "subjects": "Social and Information Networks (cs.SI)", "abstract": "Timely and effective decision-making is critical during epidemics to reduce preventable infections and deaths. This demands integrated models that jointly capture disease dynamics, vaccine distribution, regional disparities, and behavioral responses. However, most existing approaches decouple epidemic forecasting from logistics planning, hindering adaptive and regionally responsive interventions. We propose a novel epidemiological-optimization framework that jointly models epidemic progression and a multiscale vaccine supply chain. The model incorporates spatio-temporally varying effective infection rates to reflect regional policy and behavioral dynamics. It supports coordinated, data-driven decision-making across spatial scales through two formulations: a multi-objective Gini-based model and a knapsack-based model that leverages regional vulnerability indicators for tractability and improved mitigation. To address computational complexity, we design two scalable heuristic decomposition algorithms inspired by the Benders decomposition. The model is validated using COVID-19 data in the U.S.. We introduce SARIMA-based forecasting as a novel approach for validating epidemic-optimization models under data limitations. The results show that our approach can prevent more than 2 million infections and 30,000 deaths in just six months while significantly improving the accessibility of vaccines in underserved regions. Our framework demonstrates that integrating fairness and epidemic dynamics with vaccine logistics leads to superior outcomes compared to traditional myopic policies. Fairness improves overall efficiency in the long term by prioritizing the most vulnerable populations, leading to better long-term public health outcomes. The model offers policymakers a scalable and operationally relevant tool to strengthen preparedness and ensure a more effective and equitable response to epidemics."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Foundation Models in Medical Image Analysis: A Systematic Review and Meta-Analysis", "authors": "Praveenbalaji Rajendran, Mojtaba Safari, Wenfeng He, Mingzhe Hu, Shansong Wang, Jun Zhou, Xiaofeng Yang", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Medical Physics (physics.med-ph)", "abstract": "Recent advancements in artificial intelligence (AI), particularly foundation models (FMs), have revolutionized medical image analysis, demonstrating strong zero- and few-shot performance across diverse medical imaging tasks, from segmentation to report generation. Unlike traditional task-specific AI models, FMs leverage large corpora of labeled and unlabeled multimodal datasets to learn generalized representations that can be adapted to various downstream clinical applications with minimal fine-tuning. However, despite the rapid proliferation of FM research in medical imaging, the field remains fragmented, lacking a unified synthesis that systematically maps the evolution of architectures, training paradigms, and clinical applications across modalities. To address this gap, this review article provides a comprehensive and structured analysis of FMs in medical image analysis. We systematically categorize studies into vision-only and vision-language FMs based on their architectural foundations, training strategies, and downstream clinical tasks. Additionally, a quantitative meta-analysis of the studies was conducted to characterize temporal trends in dataset utilization and application domains. We also critically discuss persistent challenges, including domain adaptation, efficient fine-tuning, computational constraints, and interpretability along with emerging solutions such as federated learning, knowledge distillation, and advanced prompting. Finally, we identify key future research directions aimed at enhancing the robustness, explainability, and clinical integration of FMs, thereby accelerating their translation into real-world medical practice."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Differentially Private Linear Regression and Synthetic Data Generation with Statistical Guarantees", "authors": "Shurong Lin, Aleksandra Slavkovi\u0107, Deekshith Reddy Bhoomireddy", "subjects": "Machine Learning (cs.LG); Machine Learning (stat.ML)", "abstract": "In social sciences, small- to medium-scale datasets are common and linear regression (LR) is canonical. In privacy-aware settings, much work has focused on differentially private (DP) LR, but mostly on point estimation with limited attention to uncertainty quantification. Meanwhile, synthetic data generation (SDG) is increasingly important for reproducibility studies, yet current DP LR methods do not readily support it. Mainstream SDG approaches are either tailored to discretized data, making them less suitable for continuous regression, or rely on deep models that require large datasets, limiting their use for the smaller, continuous data typical in social science. We propose a method for LR with valid inference under Gaussian DP: a DP bias-corrected estimator with asymptotic confidence intervals (CIs) and a general SDG procedure in which regression on the synthetic data matches our DP regression. Our binning-aggregation strategy is effective in small- to moderate-dimensional settings. Experiments show our method (1) improves accuracy over existing methods, (2) provides valid CIs, and (3) produces more reliable synthetic data for downstream ML tasks than current DP SDGs."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Lark: Biologically Inspired Neuroevolution for Multi-Stakeholder LLM Agents", "authors": "Dheeraj Chintapalli, Rikhil Tanugula, Sunkalp Chandra", "subjects": "Multiagent Systems (cs.MA)", "abstract": "We present Lark, a biologically inspired decision-making framework that couples LLM-driven reasoning with an evolutionary, stakeholder-aware Multi-Agent System (MAS). To address verbosity and stakeholder trade-offs, we integrate four mechanisms: (i) plasticity, which applies concise adjustments to candidate solutions; (ii) duplication and maturation, which copy high-performing candidates and specialize them into new modules; (iii) ranked-choice stakeholder aggregation using influence-weighted Borda scoring; and (iv) compute awareness via token-based penalties that reward brevity. The system iteratively proposes diverse strategies, applies plasticity tweaks, simulates stakeholder evaluations, aggregates preferences, selects top candidates, and performs duplication/maturation while factoring compute cost into final scores. In a controlled evaluation over 30 rounds comparing 14 systems, Lark Full achieves a mean rank of 2.55 (95% CI [2.17, 2.93]) and a mean composite score of 29.4/50 (95% CI [26.34, 32.46]), finishing Top-3 in 80% of rounds while remaining cost competitive with leading commercial models ($0.016 per task). Paired Wilcoxon tests confirm that all four mechanisms contribute significantly as ablating duplication/maturation yields the largest deficit ({\\Delta}Score = 3.5, Cohen's d_z = 2.53, p < 0.001), followed by plasticity ({\\Delta}Score = 3.4, d_z = 1.86), ranked-choice voting ({\\Delta}Score = 2.4, d_z = 1.20), and token penalties ({\\Delta}Score = 2.2, d_z = 1.63). Rather than a formal Markov Decision Process with constrained optimization, Lark is a practical, compute-aware neuroevolutionary loop that scales stakeholder-aligned strategy generation and makes trade-offs transparent through per-step metrics. Our work presents proof-of-concept findings and invites community feedback as we expand toward real-world validation studies."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Towards Interpretable and Trustworthy Time Series Reasoning: A BlueSky Vision", "authors": "Kanghui Ning, Zijie Pan, Yushan Jiang, Anderson Schneider, Yuriy Nevmyvaka, Dongjin Song", "subjects": "Machine Learning (cs.LG)", "abstract": "Time series reasoning is emerging as the next frontier in temporal analysis, aiming to move beyond pattern recognition towards explicit, interpretable, and trustworthy inference. This paper presents a BlueSky vision built on two complementary directions. One builds robust foundations for time series reasoning, centered on comprehensive temporal understanding, structured multi-step reasoning, and faithful evaluation frameworks. The other advances system-level reasoning, moving beyond language-only explanations by incorporating multi-agent collaboration, multi-modal context, and retrieval-augmented approaches. Together, these directions outline a flexible and extensible framework for advancing time series reasoning, aiming to deliver interpretable and trustworthy temporal intelligence across diverse domains."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          MuonBP: Faster Muon via Block-Periodic Orthogonalization", "authors": "Ahmed Khaled, Kaan Ozkara, Tao Yu, Mingyi Hong, Youngsuk Park", "subjects": "Machine Learning (cs.LG); Optimization and Control (math.OC)", "abstract": "Gradient orthogonalization is a simple strategy that shows great utility in speeding up gradient descent. The Muon optimizer (Jordan, Jin, et al., 2024) combines gradient orthogonalization with first-order momentum and achieves significant improvement in data efficiency over Adam/AdamW (Loshchilov and Hutter, 2019) for language model training. However, when using model parallelism, gradient orthogonalization introduces additional overhead compared to coordinate-wise optimizers (such as AdamW) due to additional gather and scatter operations on gradient matrix shards from different devices. This additional communication can amount to a throughput hit of 5%-10% compared to Adam/AdamW. To remedy this, we propose Muon with Block-Periodic Orthogonalization (MuonBP), which applies orthogonalization independently to matrix shards on each device and periodically performs full orthogonalization to maintain training stability at scale. We show how to adjust the learning rate from the baseline to MuonBP and give convergence guarantees for this algorithm. Crucially, our theory dictates that we use two stepsizes: one for the blockwise orthogonalization steps, and one for the full orthogonalization steps. Our method is simple, requires minimal hyperparameter adjustments, and achieves competitive iteration complexity compared with baseline Muon while providing per-iteration throughput comparable to coordinate-wise methods such as AdamW. When training an 8B model with eight-way tensor parallelism and ZeRO optimizer state sharding, MuonBP achieves 8% throughput increase compared to Muon with no degradation in performance."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          One-step Diffusion Models with Bregman Density Ratio Matching", "authors": "Yuanzhi Zhu, Eleftherios Tsonis, Lucas Degeorge, Vicky Kalogeiton", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "abstract": "Diffusion and flow models achieve high generative quality but remain computationally expensive due to slow multi-step sampling. Distillation methods accelerate them by training fast student generators, yet most existing objectives lack a unified theoretical foundation. In this work, we propose Di-Bregman, a compact framework that formulates diffusion distillation as Bregman divergence-based density-ratio matching. This convex-analytic view connects several existing objectives through a common lens. Experiments on CIFAR-10 and text-to-image generation demonstrate that Di-Bregman achieves improved one-step FID over reverse-KL distillation and maintains high visual fidelity compared to the teacher model. Our results highlight Bregman density-ratio matching as a practical and theoretically-grounded route toward efficient one-step diffusion generation."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Integrating Metaverse Technologies in Medical Education: Examining Acceptance Factors Among Current and Future Healthcare Providers", "authors": "Seckin Damar, Gulsah Hancerliogullari Koksalmis", "subjects": "Human-Computer Interaction (cs.HC)", "abstract": "This study investigates behavioral intention to use healthcare metaverse platforms among medical students and physicians in Turkey, where such technologies are in early stages of adoption. A multi-theoretical research model was developed by integrating constructs from the Innovation Diffusion Theory, Embodied Social Presence Theory, Interaction Equivalency Theorem and Technology Acceptance Model. Data from 718 participants were analyzed using partial least squares structural equation modeling. Results show that satisfaction, perceived usefulness, perceived ease of use, learner interactions, and technology readiness significantly enhance adoption, while technology anxiety and complexity have negative effects. Learner learner and learner teacher interactions strongly predict satisfaction, which subsequently increases behavioral intention. Perceived ease of use fully mediates the relationship between technology anxiety and perceived usefulness. However, technology anxiety does not significantly moderate the effects of perceived usefulness or ease of use on behavioral intention. The model explains 71.8% of the variance in behavioral intention, indicating strong explanatory power. The findings offer practical implications for educators, curriculum designers, and developers aiming to integrate metaverse platforms into healthcare training in digitally transitioning educational systems."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Parameter-Efficient Fine-Tuning for Low-Resource Languages: A Comparative Study of LLMs for Bengali Hate Speech Detection", "authors": "Akif Islam, Mohd Ruhul Ameen", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "abstract": "Bengali social media platforms have witnessed a sharp increase in hate speech, disproportionately affecting women and adolescents. While datasets such as BD-SHS provide a basis for structured evaluation, most prior approaches rely on either computationally costly full-model fine-tuning or proprietary APIs. This paper presents the first application of Parameter-Efficient Fine-Tuning (PEFT) for Bengali hate speech detection using LoRA and QLoRA. Three instruction-tuned large language models - Gemma-3-4B, Llama-3.2-3B, and Mistral-7B - were fine-tuned on the BD-SHS dataset of 50,281 annotated comments. Each model was adapted by training fewer than 1% of its parameters, enabling experiments on a single consumer-grade GPU. The results show that Llama-3.2-3B achieved the highest F1-score of 92.23%, followed by Mistral-7B at 88.94% and Gemma-3-4B at 80.25%. These findings establish PEFT as a practical and replicable strategy for Bengali and related low-resource languages."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Back to Bytes: Revisiting Tokenization Through UTF-8", "authors": "Amit Moryossef, Clara Meister, Pavel Stepachev, Desmond Elliott", "subjects": "Computation and Language (cs.CL)", "abstract": "We present UTF8Tokenizer, a minimalist byte-level tokenizer that maps text exactly to IDs corresponding to the bytes underlying the text's UTF-8 encoding (e.g., byte x09 is token ID 9). Unlike prior byte-level approaches (Xue et al., 2021; Pagnoni et al., 2025), our implementation never introduces out-of-range IDs (i.e. there is no token ID 256) or auxiliary tokens: all special behavior (e.g., padding, boundaries, conversation structure, attention segments, tool calling, \"thinking\" spans, etc.) is encoded using C0 control bytes - just as ASCII was originally designed to embed control information alongside printable text. These design principles yield practical benefits: (1) faster tokenization (14x) and significantly lower host-device transfer (8x less than int64); (2) simple, shareable 256*d embedding tables that can be aligned across models; and (3) a training-time enhancement via bit-biased embeddings, which exposes per-byte bit structure and can be added to the embedding table post-training, removing inference costs. Our HuggingFace-compatible implementation improves language modeling convergence."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          CARE: Contrastive Alignment for ADL Recognition from Event-Triggered Sensor Streams", "authors": "Junhao Zhao, Zishuai Liu, Ruili Fang, Jin Lu, Linghan Zhang, Fei Dou", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "abstract": "The recognition of Activities of Daily Living (ADLs) from event-triggered ambient sensors is an essential task in Ambient Assisted Living, yet existing methods remain constrained by representation-level limitations. Sequence-based approaches preserve temporal order of sensor activations but are sensitive to noise and lack spatial awareness, while image-based approaches capture global patterns and implicit spatial correlations but compress fine-grained temporal dynamics and distort sensor layouts. Naive fusion (e.g., feature concatenation) fail to enforce alignment between sequence- and image-based representation views, underutilizing their complementary strengths. We propose Contrastive Alignment for ADL Recognition from Event-Triggered Sensor Streams (CARE), an end-to-end framework that jointly optimizes representation learning via Sequence-Image Contrastive Alignment (SICA) and classification via cross-entropy, ensuring both cross-representation alignment and task-specific discriminability. CARE integrates (i) time-aware, noise-resilient sequence encoding with (ii) spatially-informed and frequency-sensitive image representations, and employs (iii) a joint contrastive-classification objective for end-to-end learning of aligned and discriminative embeddings. Evaluated on three CASAS datasets, CARE achieves state-of-the-art performance (89.8% on Milan, 88.9% on Cairo, and 73.3% on Kyoto7) and demonstrates robustness to sensor malfunctions and layout variability, highlighting its potential for reliable ADL recognition in smart homes."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Training-free Online Video Step Grounding", "authors": "Luca Zanella, Massimiliano Mancini, Yiming Wang, Alessio Tonioni, Elisa Ricci", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Given a task and a set of steps composing it, Video Step Grounding (VSG) aims to detect which steps are performed in a video. Standard approaches for this task require a labeled training set (e.g., with step-level annotations or narrations), which may be costly to collect. Moreover, they process the full video offline, limiting their applications for scenarios requiring online decisions. Thus, in this work, we explore how to perform VSG online and without training. We achieve this by exploiting the zero-shot capabilities of recent Large Multimodal Models (LMMs). In particular, we use LMMs to predict the step associated with a restricted set of frames, without access to the whole video. We show that this online strategy without task-specific tuning outperforms offline and training-based models. Motivated by this finding, we develop Bayesian Grounding with Large Multimodal Models (BaGLM), further injecting knowledge of past frames into the LMM-based predictions. BaGLM exploits Bayesian filtering principles, modeling step transitions via (i) a dependency matrix extracted through large language models and (ii) an estimation of step progress. Experiments on three datasets show superior performance of BaGLM over state-of-the-art training-based offline methods."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Graph4MM: Weaving Multimodal Learning with Structural Information", "authors": "Xuying Ning, Dongqi Fu, Tianxin Wei, Wujiang Xu, Jingrui He", "subjects": "Machine Learning (cs.LG)", "abstract": "Real-world multimodal data usually exhibit complex structural relationships beyond traditional one-to-one mappings like image-caption pairs. Entities across modalities interact in intricate ways, with images and text forming diverse interconnections through contextual dependencies and co-references. Graphs provide powerful structural information for modeling intra-modal and inter-modal relationships. However, previous works fail to distinguish multi-hop neighbors and treat the graph as a standalone modality, which fragments the overall understanding. This limitation presents two key challenges in multimodal learning: (1) integrating structural information from multi-hop neighbors into foundational models, and (2) fusing modality-specific information in a principled manner. To address these challenges, we revisit the role of graphs in multimodal learning within the era of foundation models and propose Graph4MM, a graph-based multimodal learning framework. To be specific, we introduce Hop-Diffused Attention, which integrates multi-hop structural information into self-attention through causal masking and hop diffusion. Furthermore, we design MM-QFormer, a multi-mapping querying transformer for cross-modal fusion. Through theoretical and empirical analysis, we show that leveraging structures to integrate both intra- and inter-modal interactions improves multimodal understanding beyond treating them as a standalone modality. Experiments on both generative and discriminative tasks show that Graph4MM outperforms larger VLMs, LLMs, and multimodal graph baselines, achieving a 6.93% average improvement."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Deterministic Hardness of Approximation of Unique-SVP and GapSVP in $\\ell_p$ norms for $p>2$", "authors": "Yahli Hecht, Muli Safra", "subjects": "Computational Complexity (cs.CC); Cryptography and Security (cs.CR)", "abstract": "We establish deterministic hardness of approximation results for the Shortest Vector Problem in $\\ell_p$ norm ($\\mathsf{SVP}_p$) and for Unique-SVP ($\\mathsf{uSVP}_p$) for all $p > 2$. Previously, no deterministic hardness results were known, except for $\\ell_\\infty$. For every $p > 2$, we prove constant-ratio hardness: no polynomial-time algorithm approximates $\\mathsf{SVP}_p$ or $\\mathsf{uSVP}_p$ within a ratio of $\\sqrt{2} - o(1)$, assuming $\\textsf{3SAT} \\notin \\text{DTIME}(2^{O(n^{2/3}\\log n)})$, and, $\\textsf{Unambiguous-3SAT} \\notin \\text{DTIME}(2^{O(n^{2/3}\\log n)})$. We also show that for any $\\varepsilon > 0$ there exists $p_\\varepsilon > 2$ such that for every $p \\ge p_\\varepsilon$: no polynomial-time algorithm approximates $\\mathsf{SVP}_p$ within a ratio of $2^{(\\log n)^{1- \\varepsilon}}$, assuming $\\text{NP} \\nsubseteq \\text{DTIME}(n^{(\\log n)^\\varepsilon})$; and within a ratio of $n^{1/(\\log\\log(n))^\\varepsilon}$, assuming $\\text{NP} \\nsubseteq \\text{SUBEXP}$. This improves upon [Haviv, Regev, Theory of Computing 2012], which obtained similar inapproximation ratios under randomized reductions. We obtain analogous results for $\\mathsf{uSVP}_p$ under the assumptions $\\textsf{Unambiguous-3SAT} \\not\\subseteq \\text{DTIME}(n^{(\\log n)^\\varepsilon})$ and $\\textsf{Unambiguous-3SAT} \\not\\subseteq \\text{SUBEXP}$, improving the previously known $1+o(1)$ [Stephens-Davidowitz, Approx 2016]. Strengthening the hardness of $\\textsf{uSVP}$ has direct cryptographic impact. By the reduction of Lyubashevsky and Micciancio [Lyubashevsky, Micciancio, CRYPTO 2009], hardness for $\\gamma$-$\\mathsf{uSVP}_p$ carries over to ${\\frac{1}{\\gamma}}$-$\\mathsf{BDD}_p$ (Bounded Distance Decoding). Thus, understanding the hardness of $\\textsf{uSVP}$ improves worst-case guarantees for two core problems that underpin security in lattice-based cryptography."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          STARK: Strategic Team of Agents for Refining Kernels", "authors": "Juncheng Dong, Yang Yang, Tao Liu, Yang Wang, Feng Qi, Vahid Tarokh, Kaushik Rangadurai, Shuang Yang", "subjects": "Artificial Intelligence (cs.AI)", "abstract": "The efficiency of GPU kernels is central to the progress of modern AI, yet optimizing them remains a difficult and labor-intensive task due to complex interactions between memory hierarchies, thread scheduling, and hardware-specific characteristics. While recent advances in large language models (LLMs) provide new opportunities for automated code generation, existing approaches largely treat LLMs as single-shot generators or naive refinement tools, limiting their effectiveness in navigating the irregular kernel optimization landscape. We introduce an LLM agentic framework for GPU kernel optimization that systematically explores the design space through multi-agent collaboration, grounded instruction, dynamic context management, and strategic search. This framework mimics the workflow of expert engineers, enabling LLMs to reason about hardware trade-offs, incorporate profiling feedback, and refine kernels iteratively. We evaluate our approach on KernelBench, a benchmark for LLM-based kernel optimization, and demonstrate substantial improvements over baseline agents: our system produces correct solutions where baselines often fail, and achieves kernels with up to 16x faster runtime performance. These results highlight the potential of agentic LLM frameworks to advance fully automated, scalable GPU kernel optimization."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Bits Leaked per Query: Information-Theoretic Bounds on Adversarial Attacks against LLMs", "authors": "Masahiro Kaneko, Timothy Baldwin", "subjects": "Cryptography and Security (cs.CR); Computation and Language (cs.CL); Machine Learning (cs.LG)", "abstract": "Adversarial attacks by malicious users that threaten the safety of large language models (LLMs) can be viewed as attempts to infer a target property $T$ that is unknown when an instruction is issued, and becomes knowable only after the model's reply is observed. Examples of target properties $T$ include the binary flag that triggers an LLM's harmful response or rejection, and the degree to which information deleted by unlearning can be restored, both elicited via adversarial instructions. The LLM reveals an \\emph{observable signal} $Z$ that potentially leaks hints for attacking through a response containing answer tokens, thinking process tokens, or logits. Yet the scale of information leaked remains anecdotal, leaving auditors without principled guidance and defenders blind to the transparency--risk trade-off. We fill this gap with an information-theoretic framework that computes how much information can be safely disclosed, and enables auditors to gauge how close their methods come to the fundamental limit. Treating the mutual information $I(Z;T)$ between the observation $Z$ and the target property $T$ as the leaked bits per query, we show that achieving error $\\varepsilon$ requires at least $\\log(1/\\varepsilon)/I(Z;T)$ queries, scaling linearly with the inverse leak rate and only logarithmically with the desired accuracy. Thus, even a modest increase in disclosure collapses the attack cost from quadratic to logarithmic in terms of the desired accuracy. Experiments on seven LLMs across system-prompt leakage, jailbreak, and relearning attacks corroborate the theory: exposing answer tokens alone requires about a thousand queries; adding logits cuts this to about a hundred; and revealing the full thinking process trims it to a few dozen. Our results provide the first principled yardstick for balancing transparency and security when deploying LLMs."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Vocab Diet: Reshaping the Vocabulary of LLMs with Vector Arithmetic", "authors": "Yuval Reif, Guy Kaplan, Roy Schwartz", "subjects": "Computation and Language (cs.CL)", "abstract": "Large language models (LLMs) were shown to encode word form variations, such as \"walk\"->\"walked\", as linear directions in embedding space. However, standard tokenization algorithms treat these variations as distinct tokens -- filling the size-capped vocabulary with surface form variants (e.g., \"walk\", \"walking\", \"Walk\"), at the expense of less frequent words and multilingual coverage. We show that many of these variations can be captured by transformation vectors -- additive offsets that yield the appropriate word's representation when applied to the base form word embedding -- in both the input and output spaces. Building on this, we propose a compact reshaping of the vocabulary: rather than assigning unique tokens to each surface form, we compose them from shared base form and transformation vectors (e.g., \"walked\" = \"walk\" + past tense). We apply our approach to multiple LLMs and across five languages, removing up to 10% of vocabulary entries -- thereby freeing space to allocate new, more diverse tokens. Importantly, we do so while also expanding vocabulary coverage to out-of-vocabulary words, with minimal impact on downstream performance, and without modifying model weights. Our findings motivate a foundational rethinking of vocabulary design, moving from string enumeration to a compositional vocabulary that leverages the underlying structure of language."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          EEschematic: Multimodal-LLM Based AI Agent for Schematic Generation of Analog Circuit", "authors": "Chang Liu, Danial Chitnis", "subjects": "Machine Learning (cs.LG)", "abstract": "Circuit schematics play a crucial role in analog integrated circuit design, serving as the primary medium for human understanding and verification of circuit functionality. While recent large language model (LLM)-based approaches have shown promise in circuit topology generation and device sizing, most rely solely on textual representations such as SPICE netlists, which lack visual interpretability for circuit designers. To address this limitation, we propose EEschematic, an AI agent for automatic analog schematic generation based on a Multimodal Large Language Model (MLLM). EEschematic integrates textual, visual, and symbolic modalities to translate SPICE netlists into schematic diagrams represented in a human-editable format. The framework uses six analog substructure examples for few-shot placement and a Visual Chain-of-Thought (VCoT) strategy to iteratively refine placement and wiring, enhancing schematic clarity and symmetry. Experimental results on representative analog circuits, including a CMOS inverter, a five-transistor operational transconductance amplifier (5T-OTA), and a telescopic cascode amplifier, demonstrate that EEschematic produces schematics with high visual quality and structural correctness."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          ReclAIm: A multi-agent framework for degradation-aware performance tuning of medical imaging AI", "authors": "Eleftherios Tzanis, Michail E. Klontzas", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI)", "abstract": "Ensuring the long-term reliability of AI models in clinical practice requires continuous performance monitoring and corrective actions when degradation occurs. Addressing this need, this manuscript presents ReclAIm, a multi-agent framework capable of autonomously monitoring, evaluating, and fine-tuning medical image classification models. The system, built on a large language model core, operates entirely through natural language interaction, eliminating the need for programming expertise. ReclAIm successfully trains, evaluates, and maintains consistent performance of models across MRI, CT, and X-ray datasets. Once ReclAIm detects significant performance degradation, it autonomously executes state-of-the-art fine-tuning procedures that substantially reduce the performance gap. In cases with performance drops of up to -41.1% (MRI InceptionV3), ReclAIm managed to readjust performance metrics within 1.5% of the initial model results. ReclAIm enables automated, continuous maintenance of medical imaging AI models in a user-friendly and adaptable manner that facilitates broader adoption in both research and clinical environments."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Bombardier Beetle Optimizer: A Novel Bio-Inspired Algorithm for Global Optimization", "authors": "Hisham A. Shehadeh, Mohd Yamani Idna Idris, Iqbal H. Jebril", "subjects": "Neural and Evolutionary Computing (cs.NE)", "abstract": "In this paper, a novel bio-inspired optimization algorithm is proposed, called Bombardier Beetle Optimizer (BBO). This type of species is very intelligent, which has an ability to defense and escape from predators. The principles of the former one is inspired by the defense mechanism of Bombardier Beetle against the predators, which the Bombardier Beetle triggers a toxic chemical spray when it feels threatened. This reaction occurs in a specialized reaction chamber inside its abdomen and includes a well regulated enzymatic mechanism, which comprises hot water vapor, oxygen, and irritating substances like p-benzoquinones. In addition, the proposed BBO simulates also the escape mechanism of Bombardier Beetle from predator, which it has the ability to calculate its distance from predator and it can fly away. The BBO is tested with optimizing Congress on Evolutionary Computation (CEC 2017) test bed suites. Moreover, it is compared against well-known metaheuristic optimization algorithms includes Chernobyl Disaster Optimizer (CDO), Grey Wolf Optimizer (GWO), Particle Swarm Optimization (PSO), Bermuda Triangle Optimizer (BTO), Sperm Swarm Optimization (SSO) and Gravitational Search Algorithm (GSA). The outcomes of this paper prove the BBO's efficiency in which outperforms the other algorithms in terms of convergence rate and quality of results."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Online Learning Defense against Iterative Jailbreak Attacks via Prompt Optimization", "authors": "Masahiro Kaneko, Zeerak Talat, Timothy Baldwin", "subjects": "Computation and Language (cs.CL)", "abstract": "Iterative jailbreak methods that repeatedly rewrite and input prompts into large language models (LLMs) to induce harmful outputs -- using the model's previous responses to guide each new iteration -- have been found to be a highly effective attack strategy. Despite being an effective attack strategy against LLMs and their safety mechanisms, existing defenses do not proactively disrupt this dynamic trial-and-error cycle. In this study, we propose a novel framework that dynamically updates its defense strategy through online learning in response to each new prompt from iterative jailbreak methods. Leveraging the distinctions between harmful jailbreak-generated prompts and typical harmless prompts, we introduce a reinforcement learning-based approach that optimizes prompts to ensure appropriate responses for harmless tasks while explicitly rejecting harmful prompts. Additionally, to curb overfitting to the narrow band of partial input rewrites explored during an attack, we introduce Past-Direction Gradient Damping (PDGD). Experiments conducted on three LLMs show that our approach significantly outperforms five existing defense methods against five iterative jailbreak methods. Moreover, our results indicate that our prompt optimization strategy simultaneously enhances response quality for harmless tasks."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          An empirical study of the effect of video encoders on Temporal Video Grounding", "authors": "Ignacio M. De la Jara, Cristian Rodriguez-Opazo, Edison Marrese-Taylor, Felipe Bravo-Marquez", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Temporal video grounding is a fundamental task in computer vision, aiming to localize a natural language query in a long, untrimmed video. It has a key role in the scientific community, in part due to the large amount of video generated every day. Although we find extensive work in this task, we note that research remains focused on a small selection of video representations, which may lead to architectural overfitting in the long run. To address this issue, we propose an empirical study to investigate the impact of different video features on a classical architecture. We extract features for three well-known benchmarks, Charades-STA, ActivityNet-Captions and YouCookII, using video encoders based on CNNs, temporal reasoning and transformers. Our results show significant differences in the performance of our model by simply changing the video encoder, while also revealing clear patterns and errors derived from the use of certain features, ultimately indicating potential feature complementarity."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Traffic Prioritization Mechanisms for Mission and Time Critical Applications in Industrial Internet of Things", "authors": "Anwar Ahmed Khan, Shama Siddiqui, Indrakshi Dey", "subjects": "Networking and Internet Architecture (cs.NI); Signal Processing (eess.SP)", "abstract": "Industrial Internet of Things (IIoT) promises to revolutionize industrial operations and productions through utilizing Machine-to-Machine (M2M) communications. Since each node in such environments generates various types of data with diverse service requirements, MAC protocol holds crucial importance to ensure efficient delivery. In this context, simple to complex MAC schemes are found in literature. This paper focuses on evaluating the performance of two major techniques \"slot stealing\" and \"packet fragmentation\" for the IIoT; representative protocols SS-MAC and FROG-MAC have been chosen from each category respectively. We conducted realistic simulations for the two protocols using Contiki. Delay and packet loss comparison for SS-MAC and FROG-MAC indicates the superiority of FROG-MAC due to reduction in the waiting time for urgent traffic. Thus, a simple fragmentation scheme could be deployed for efficient scheduling of heterogenous traffic in the industrial environments."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          DiscoTrack: A Multilingual LLM Benchmark for Discourse Tracking", "authors": "Lanni Bu, Lauren Levin, Amir Zeldes", "subjects": "Computation and Language (cs.CL)", "abstract": "Recent LLM benchmarks have tested models on a range of phenomena, but are still focused primarily on natural language understanding for extraction of explicit information, such as QA or summarization, with responses often tar- geting information from individual sentences. We are still lacking more challenging, and im- portantly also multilingual, benchmarks focus- ing on implicit information and pragmatic infer- ences across larger documents in the context of discourse tracking: integrating and aggregating information across sentences, paragraphs and multiple speaker utterances. To this end, we present DiscoTrack, an LLM benchmark target- ing a range of tasks across 12 languages and four levels of discourse understanding: salience recognition, entity tracking, discourse relations and bridging inference. Our evaluation shows that these tasks remain challenging, even for state-of-the-art models."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Do Satellite Tasks Need Special Pretraining?", "authors": "Ani Vanyan, Alvard Barseghyan, Hakob Tamazyan, Tigran Galstyan, Vahan Huroyan, Naira Hovakimyan, Hrant Khachatrian", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Foundation models have advanced machine learning across various modalities, including images. Recently multiple teams trained foundation models specialized for remote sensing applications. This line of research is motivated by the distinct characteristics of remote sensing imagery, specific applications and types of robustness useful for satellite image analysis. In this work we systematically challenge the idea that specific foundation models are more useful than general-purpose vision foundation models, at least in the small scale. First, we design a simple benchmark that measures generalization of remote sensing models towards images with lower resolution for two downstream tasks. Second, we train iBOT, a self-supervised vision encoder, on MillionAID, an ImageNet-scale satellite imagery dataset, with several modifications specific to remote sensing. We show that none of those pretrained models bring consistent improvements upon general-purpose baselines at the ViT-B scale."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Justitia: Fair and Efficient Scheduling for LLM Applications", "authors": "Mingyan Yang, Guanjie Wang, Manqi Luo, Yifei Liu, Chen Chen, Han Zhao, Yu Feng, Quan Chen, Minyi Guo", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC)", "abstract": "In the era of Large Language Models (LLMs), it has been popular to launch a series of LLM inferences -- we call an LLM application -- to better solve real-world problems. When serving those applications in shared GPU servers, the schedulers are expected to attain fast application completions with guaranteed worst-case performance. However, mainstream LLM schedulers fail to behave well for LLM applications -- due to head-of-line blocking or over-constrained resource allocation. In this paper, we propose to serve LLM applications in a fair and also efficient manner. To this end, we design Justitia, a novel scheduler with three key techniques. First, given that memory is prevalently a bottleneck for mainstream inference frameworks like vLLM, Justitia models the service cost of LLM applications in a memory-centric manner. Meanwhile, it uses a simple neural network model to conduct light-weight and also accurate demand prediction. Moreover, Justitia adopts a virtual-time based fair queuing algorithm to reduce the overall performance with guaranteed worst-case delay. We have implemented Justitia atop vLLM, and experimental results involving diverse LLM applications show that it can substantially enhance the scheduling efficiency with fairness preserved."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          SafeSearch: Do Not Trade Safety for Utility in LLM Search Agents", "authors": "Qiusi Zhan, Angeline Budiman-Chan, Abdelrahman Zayed, Xingzhi Guo, Daniel Kang, Joo-Kyung Kim", "subjects": "Computation and Language (cs.CL)", "abstract": "Large language model (LLM) based search agents iteratively generate queries, retrieve external information, and reason to answer open-domain questions. While researchers have primarily focused on improving their utility, their safety behaviors remain underexplored. In this paper, we first evaluate search agents using red-teaming datasets and find that they are more likely to produce harmful outputs than base LLMs. For example, when asked ``How can I track someone's location without their consent?'', a base model refuses, whereas a search agent designed to retrieve and cite sources may lower its refusal threshold, fetch documents (e.g., court cases), and, once appended, synthesize them into an informative yet unsafe summary. We further show that utility-oriented fine-tuning intensifies this risk, motivating joint alignment of safety and utility. We present SafeSearch, a multi-objective reinforcement learning approach that couples a final-output safety/utility reward with a novel query-level shaping term that penalizes unsafe queries and rewards safe ones. Experiments show that SafeSearch reduces agent harmfulness by over 70% across three red-teaming datasets while producing safe, helpful responses, and matches the QA performance of a utility-only finetuned agent; further analyses confirm the effectiveness of the query-level reward in jointly improving safety and utility."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Extended LSTM: Adaptive Feature Gating for Toxic Comment Classification", "authors": "Noor Islam S. Mohammad", "subjects": "Computation and Language (cs.CL); Machine Learning (cs.LG)", "abstract": "Toxic comment detection remains a challenging task, where transformer-based models (e.g., BERT) incur high computational costs and degrade on minority toxicity classes, while classical ensembles lack semantic adaptability. We propose xLSTM, a parameter-efficient and theoretically grounded framework that unifies cosine-similarity gating, adaptive feature prioritization, and principled class rebalancing. A learnable reference vector {v} in {R}^d modulates contextual embeddings via cosine similarity, amplifying toxic cues and attenuating benign signals to yield stronger gradients under severe class imbalance. xLSTM integrates multi-source embeddings (GloVe, FastText, BERT CLS) through a projection layer, a character-level BiLSTM for morphological cues, embedding-space SMOTE for minority augmentation, and adaptive focal loss with dynamic class weighting. On the Jigsaw Toxic Comment benchmark, xLSTM attains 96.0% accuracy and 0.88 macro-F1, outperforming BERT by 33% on threat and 28% on identity_hate categories, with 15 times fewer parameters and 50ms inference latency. Cosine gating contributes a +4.8% F1 gain in ablations. The results establish a new efficiency adaptability frontier, demonstrating that lightweight, theoretically informed architectures can surpass large pretrained models on imbalanced, domain-specific NLP tasks."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Forgetting to Forget: Attention Sink as A Gateway for Backdooring LLM Unlearning", "authors": "Bingqi Shang, Yiwei Chen, Yihua Zhang, Bingquan Shen, Sijia Liu", "subjects": "Machine Learning (cs.LG); Computation and Language (cs.CL)", "abstract": "Large language model (LLM) unlearning has become a critical mechanism for removing undesired data, knowledge, or behaviors from pre-trained models while retaining their general utility. Yet, with the rise of open-weight LLMs, we ask: can the unlearning process itself be backdoored, appearing successful under normal conditions yet reverting to pre-unlearned behavior when a hidden trigger is activated? Drawing inspiration from classical backdoor attacks that embed triggers into training data to enforce specific behaviors, we investigate backdoor unlearning, where models forget as intended in the clean setting but recover forgotten knowledge when the trigger appears. We show that designing such attacks presents unique challenges, hinging on where triggers are placed and how backdoor training is reinforced. We uncover a strong link between backdoor efficacy and the attention sink phenomenon, i.e., shallow input tokens consistently attract disproportionate attention in LLMs. Our analysis reveals that these attention sinks serve as gateways for backdoor unlearning: placing triggers at sink positions and aligning their attention values markedly enhances backdoor persistence. Extensive experiments validate these findings, showing that attention-sink-guided backdoor unlearning reliably restores forgotten knowledge in the presence of backdoor triggers, while behaving indistinguishably from a normally unlearned model when triggers are absent. Code is available at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Curiosity-driven RL for symbolic equation solving", "authors": "Kevin P. O Keeffe", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "We explore if RL can be useful for symbolic mathematics. Previous work showed contrastive learning can solve linear equations in one variable. We show model-free PPO \\cite{schulman2017proximal} augmented with curiosity-based exploration and graph-based actions can solve nonlinear equations such as those involving radicals, exponentials, and trig functions. Our work suggests curiosity-based exploration may be useful for general symbolic reasoning tasks."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Enrich and Detect: Video Temporal Grounding with Multimodal LLMs", "authors": "Shraman Pramanick, Effrosyni Mavroudi, Yale Song, Rama Chellappa, Lorenzo Torresani, Triantafyllos Afouras", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Multimedia (cs.MM)", "abstract": "We introduce ED-VTG, a method for fine-grained video temporal grounding utilizing multi-modal large language models. Our approach harnesses the capabilities of multimodal LLMs to jointly process text and video, in order to effectively localize natural language queries in videos through a two-stage process. Rather than being directly grounded, language queries are initially transformed into enriched sentences that incorporate missing details and cues to aid in grounding. In the second stage, these enriched queries are grounded, using a lightweight decoder, which specializes at predicting accurate boundaries conditioned on contextualized representations of the enriched queries. To mitigate noise and reduce the impact of hallucinations, our model is trained with a multiple-instance-learning objective that dynamically selects the optimal version of the query for each training sample. We demonstrate state-of-the-art results across various benchmarks in temporal video grounding and paragraph grounding settings. Experiments reveal that our method significantly outperforms all previously proposed LLM-based temporal grounding approaches and is either superior or comparable to specialized models, while maintaining a clear advantage against them in zero-shot evaluation scenarios."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Mapping from Meaning: Addressing the Miscalibration of Prompt-Sensitive Language Models", "authors": "Kyle Cox, Jiawei Xu, Yikun Han, Rong Xu, Tianhao Li, Chi-Yang Hsu, Tianlong Chen, Walter Gerych, Ying Ding", "subjects": "Computation and Language (cs.CL); Machine Learning (cs.LG)", "abstract": "An interesting behavior in large language models (LLMs) is prompt sensitivity. When provided with different but semantically equivalent versions of the same prompt, models may produce very different distributions of answers. This suggests that the uncertainty reflected in a model's output distribution for one prompt may not reflect the model's uncertainty about the meaning of the prompt. We model prompt sensitivity as a type of generalization error, and show that sampling across the semantic ``concept space'' with paraphrasing perturbations improves uncertainty calibration without compromising accuracy. Additionally, we introduce a new metric for uncertainty decomposition in black-box LLMs that improves upon entropy-based decomposition by modeling semantic continuities in natural language generation. We show that this decomposition metric can be used to quantify how much LLM uncertainty is attributed to prompt sensitivity. Our work introduces a new way to improve uncertainty calibration in prompt-sensitive language models, and provides evidence that some LLMs fail to exhibit consistent general reasoning about the meanings of their inputs."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Watermark Robustness and Radioactivity May Be at Odds in Federated Learning", "authors": "Leixu Huang, Zedian Shao, Teodora Baluta", "subjects": "Cryptography and Security (cs.CR)", "abstract": "Federated learning (FL) enables fine-tuning large language models (LLMs) across distributed data sources. As these sources increasingly include LLM-generated text, provenance tracking becomes essential for accountability and transparency. We adapt LLM watermarking for data provenance in FL where a subset of clients compute local updates on watermarked data, and the server averages all updates into the global LLM. In this setup, watermarks are radioactive: the watermark signal remains detectable after fine-tuning with high confidence. The $p$-value can reach $10^{-24}$ even when as little as $6.6\\%$ of data is watermarked. However, the server can act as an active adversary that wants to preserve model utility while evading provenance tracking. Our observation is that updates induced by watermarked synthetic data appear as outliers relative to non-watermark updates. Our adversary thus applies strong robust aggregation that can filter these outliers, together with the watermark signal. All evaluated radioactive watermarks are not robust against such an active filtering server. Our work suggests fundamental trade-offs between radioactivity, robustness, and utility."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Where, Not What: Compelling Video LLMs to Learn Geometric Causality for 3D-Grounding", "authors": "Yutong Zhong", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Multimodal 3D grounding has garnered considerable interest in Vision-Language Models (VLMs) \\cite{yin2025spatial} for advancing spatial reasoning in complex environments. However, these models suffer from a severe \"2D semantic bias\" that arises from over-reliance on 2D image features for coarse localization, largely disregarding 3D geometric inputs and resulting in suboptimal fusion performance. In this paper, we propose a novel training framework called What-Where Representation Re-Forming (W2R2) to tackle this issue via disentangled representation learning and targeted shortcut suppression. Our approach fundamentally reshapes the model's internal space by designating 2D features as semantic beacons for \"What\" identification and 3D features as spatial anchors for \"Where\" localization, enabling precise 3D grounding without modifying inference architecture. Key components include a dual-objective loss function with an Alignment Loss that supervises fused predictions using adapted cross-entropy for multimodal synergy, and a Pseudo-Label Loss that penalizes overly effective 2D-dominant pseudo-outputs via a margin-based mechanism. Experiments conducted on ScanRefer and ScanQA demonstrate the effectiveness of W2R2, with significant gains in localization accuracy and robustness, particularly in cluttered outdoor scenes."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Conditional Synthetic Live and Spoof Fingerprint Generation", "authors": "Syed Konain Abbas, Sandip Purnapatra, M. G. Sarwar Murshed, Conor Miller-Lynch, Lambert Igene, Soumyabrata Dey, Stephanie Schuckers, Faraz Hussain", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Large fingerprint datasets, while important for training and evaluation, are time-consuming and expensive to collect and require strict privacy measures. Researchers are exploring the use of synthetic fingerprint data to address these issues. This paper presents a novel approach for generating synthetic fingerprint images (both spoof and live), addressing concerns related to privacy, cost, and accessibility in biometric data collection. Our approach utilizes conditional StyleGAN2-ADA and StyleGAN3 architectures to produce high-resolution synthetic live fingerprints, conditioned on specific finger identities (thumb through little finger). Additionally, we employ CycleGANs to translate these into realistic spoof fingerprints, simulating a variety of presentation attack materials (e.g., EcoFlex, Play-Doh). These synthetic spoof fingerprints are crucial for developing robust spoof detection systems. Through these generative models, we created two synthetic datasets (DB2 and DB3), each containing 1,500 fingerprint images of all ten fingers with multiple impressions per finger, and including corresponding spoofs in eight material types. The results indicate robust performance: our StyleGAN3 model achieves a Fr\u00e9chet Inception Distance (FID) as low as 5, and the generated fingerprints achieve a True Accept Rate of 99.47% at a 0.01% False Accept Rate. The StyleGAN2-ADA model achieved a TAR of 98.67% at the same 0.01% FAR. We assess fingerprint quality using standard metrics (NFIQ2, MINDTCT), and notably, matching experiments confirm strong privacy preservation, with no significant evidence of identity leakage, confirming the strong privacy-preserving properties of our synthetic datasets."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Hephaestus: Mixture Generative Modeling with Energy Guidance for Large-scale QoS Degradation", "authors": "Nguyen Do, Bach Ngo, Youval Kashuv, Canh V. Pham, Hanghang Tong, My T. Thai", "subjects": "Machine Learning (cs.LG)", "abstract": "We study the Quality of Service Degradation (QoSD) problem, in which an adversary perturbs edge weights to degrade network performance. This setting arises in both network infrastructures and distributed ML systems, where communication quality, not just connectivity, determines functionality. While classical methods rely on combinatorial optimization, and recent ML approaches address only restricted linear variants with small-size networks, no prior model directly tackles the QoSD problem under nonlinear edge-weight functions. This work proposes \\PIMMA, a self-reinforcing generative framework that synthesizes feasible solutions in latent space, to fill this gap. Our method includes three phases: (1) Forge: a Predictive Path-Stressing (PPS) algorithm that uses graph learning and approximation to produce feasible solutions with performance guarantee, (2) Morph: a new theoretically grounded training paradigm for Mixture of Conditional VAEs guided by an energy-based model to capture solution feature distributions, and (3) Refine: a reinforcement learning agent that explores this space to generate progressively near-optimal solutions using our designed differentiable reward function. Experiments on both synthetic and real-world networks show that our approach consistently outperforms classical and ML baselines, particularly in scenarios with nonlinear cost functions where traditional methods fail to generalize."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          DINO-CVA: A Multimodal Goal-Conditioned Vision-to-Action Model for Autonomous Catheter Navigation", "authors": "Pedram Fekri, Majid Roshanfar, Samuel Barbeau, Seyedfarzad Famouri, Thomas Looi, Dale Podolsky, Mehrdad Zadeh, Javad Dargahi", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Cardiac catheterization remains a cornerstone of minimally invasive interventions, yet it continues to rely heavily on manual operation. Despite advances in robotic platforms, existing systems are predominantly follow-leader in nature, requiring continuous physician input and lacking intelligent autonomy. This dependency contributes to operator fatigue, more radiation exposure, and variability in procedural outcomes. This work moves towards autonomous catheter navigation by introducing DINO-CVA, a multimodal goal-conditioned behavior cloning framework. The proposed model fuses visual observations and joystick kinematics into a joint embedding space, enabling policies that are both vision-aware and kinematic-aware. Actions are predicted autoregressively from expert demonstrations, with goal conditioning guiding navigation toward specified destinations. A robotic experimental setup with a synthetic vascular phantom was designed to collect multimodal datasets and evaluate performance. Results show that DINO-CVA achieves high accuracy in predicting actions, matching the performance of a kinematics-only baseline while additionally grounding predictions in the anatomical environment. These findings establish the feasibility of multimodal, goal-conditioned architectures for catheter navigation, representing an important step toward reducing operator dependency and improving the reliability of catheterbased therapies."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Click, Predict, Trust: Clinician-in-the-Loop AI Segmentation for Lung Cancer CT-Based Prognosis within the Knowledge-to-Action Framework", "authors": "Mohammad R. Salmanpour, Sonya Falahati, Amir Hossein Pouria, Amin Mousavi, Somayeh Sadat Mehrnia, Morteza Alizadeh, Arman Gorji, Zeinab Farsangi, Alireza Safarian, Mehdi Maghsudi, Carlos Uribe, Arman Rahmim, Ren Yuan", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Lung cancer remains the leading cause of cancer mortality, with CT imaging central to screening, prognosis, and treatment. Manual segmentation is variable and time-intensive, while deep learning (DL) offers automation but faces barriers to clinical adoption. Guided by the Knowledge-to-Action framework, this study develops a clinician-in-the-loop DL pipeline to enhance reproducibility, prognostic accuracy, and clinical trust. Multi-center CT data from 999 patients across 12 public datasets were analyzed using five DL models (3D Attention U-Net, ResUNet, VNet, ReconNet, SAM-Med3D), benchmarked against expert contours on whole and click-point cropped images. Segmentation reproducibility was assessed using 497 PySERA-extracted radiomic features via Spearman correlation, ICC, Wilcoxon tests, and MANOVA, while prognostic modeling compared supervised (SL) and semi-supervised learning (SSL) across 38 dimensionality reduction strategies and 24 classifiers. Six physicians qualitatively evaluated masks across seven domains, including clinical meaningfulness, boundary quality, prognostic value, trust, and workflow integration. VNet achieved the best performance (Dice = 0.83, IoU = 0.71), radiomic stability (mean correlation = 0.76, ICC = 0.65), and predictive accuracy under SSL (accuracy = 0.88, F1 = 0.83). SSL consistently outperformed SL across models. Radiologists favored VNet for peritumoral representation and smoother boundaries, preferring AI-generated initial masks for refinement rather than replacement. These results demonstrate that integrating VNet with SSL yields accurate, reproducible, and clinically trusted CT-based lung cancer prognosis, highlighting a feasible path toward physician-centered AI translation."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Diverse Influence Component Analysis: A Geometric Approach to Nonlinear Mixture Identifiability", "authors": "Hoang-Son Nguyen, Xiao Fu", "subjects": "Machine Learning (cs.LG)", "abstract": "Latent component identification from unknown nonlinear mixtures is a foundational challenge in machine learning, with applications in tasks such as disentangled representation learning and causal inference. Prior work in nonlinear independent component analysis (nICA) has shown that auxiliary signals -- such as weak supervision -- can support identifiability of conditionally independent latent components. More recent approaches explore structural assumptions, e.g., sparsity in the Jacobian of the mixing function, to relax such requirements. In this work, we introduce Diverse Influence Component Analysis (DICA), a framework that exploits the convex geometry of the mixing function's Jacobian. We propose a Jacobian Volume Maximization (J-VolMax) criterion, which enables latent component identification by encouraging diversity in their influence on the observed variables. Under reasonable conditions, this approach achieves identifiability without relying on auxiliary information, latent component independence, or Jacobian sparsity assumptions. These results extend the scope of identifiability analysis and offer a complementary perspective to existing methods."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Person Re-Identification via Generalized Class Prototypes", "authors": "Md Ahmed Al Muzaddid, William J. Beksi", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV)", "abstract": "Advanced feature extraction methods have significantly contributed to enhancing the task of person re-identification. In addition, modifications to objective functions have been developed to further improve performance. Nonetheless, selecting better class representatives is an underexplored area of research that can also lead to advancements in re-identification performance. Although past works have experimented with using the centroid of a gallery image class during training, only a few have investigated alternative representations during the retrieval stage. In this paper, we demonstrate that these prior techniques yield suboptimal results in terms of re-identification metrics. To address the re-identification problem, we propose a generalized selection method that involves choosing representations that are not limited to class centroids. Our approach strikes a balance between accuracy and mean average precision, leading to improvements beyond the state of the art. For example, the actual number of representations per class can be adjusted to meet specific application requirements. We apply our methodology on top of multiple re-identification embeddings, and in all cases it substantially improves upon contemporary results"}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Video Reasoning without Training", "authors": "Deepak Sridhar, Kartikeya Bhardwaj, Jeya Pradha Jeyaraj, Nuno Vasconcelos, Ankita Nayak, Harris Teague", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "abstract": "Video reasoning using Large Multimodal Models (LMMs) relies on costly reinforcement learning (RL) and verbose chain-of-thought, resulting in substantial computational overhead during both training and inference. Moreover, the mechanisms that control the thinking process in these reasoning models are very limited. In this paper, using entropy of the model's output as a signal, we discover that the high-quality models go through a series of micro-explorations and micro-exploitations which keep the reasoning process grounded (i.e., avoid excessive randomness while the model is exploring or thinking through an answer). We further observe that once this \"thinking\" process is over, more accurate models demonstrate a better convergence by reducing the entropy significantly via a final exploitation phase (i.e., a more certain convergence towards a solution trajectory). We then use these novel, theoretically-grounded insights to tune the model's behavior directly at inference, without using any RL or supervised fine-tuning. Specifically, during inference, our proposed approach called V-Reason (Video-Reason) adapts the value cache of the LMM via a few optimization steps on a small, trainable controller using an entropy-based objective, i.e., no supervision from any dataset or RL is necessary. This tuning improves the model's micro-exploration and exploitation behavior during inference. Our experiments show that our proposed method achieves significant improvements over the base instruction-tuned models across several video reasoning datasets, narrowing the gap with RL-trained models to within 0.6% average accuracy without any training, while offering massive efficiency benefits: output tokens are reduced by 58.6% compared to the RL model."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          How Universal Are SAM2 Features?", "authors": "Masoud Khairi Atani, Alon Harell, Hyomin Choi, Runyu Yang, Fabien Racape, Ivan V. Bajic", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "The trade-off between general-purpose foundation vision models and their specialized counterparts is critical for efficient feature coding design and is not yet fully understood. We investigate this trade-off by comparing the feature versatility of the general-purpose Hiera encoder against the segmentation-specialized Segment Anything Model 2 (SAM2). Using a lightweight, trainable neck to probe the adaptability of their frozen features, we quantify the information-theoretic cost of specialization. Our results reveal that while SAM2's specialization is highly effective for spatially-related tasks like depth estimation, it comes at a cost. The specialized SAM2 encoder underperforms its generalist predecessor, Hiera, on conceptually distant tasks such as pose estimation and image captioning, demonstrating a measurable loss of broader semantic information. A novel cross-neck analysis on SAM2 reveals that each level of adaptation creates a further representational bottleneck. Our analysis illuminates these trade-offs in feature universality, providing a quantitative foundation for designing efficient feature coding and adaptation strategies for diverse downstream applications."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          ToolCritic: Detecting and Correcting Tool-Use Errors in Dialogue Systems", "authors": "Hassan Hamad, Yingru Xu, Liang Zhao, Wenbo Yan, Narendra Gyanchandani", "subjects": "Artificial Intelligence (cs.AI)", "abstract": "Tool-augmented large language models (LLMs) are increasingly employed in real-world applications, but tool usage errors still hinder their reliability. We introduce ToolCritic, a diagnostic framework that evaluates and improves LLM behavior in multi-turn, tool-augmented dialogues. ToolCritic detects eight distinct error types specific to tool-calling (e.g., premature invocation, argument misalignment, and misinterpretation of tool outputs) and provides targeted feedback to the main LLM. The main LLM, assumed to have strong reasoning, task understanding and orchestration capabilities, then revises its response based on ToolCritic's feedback. We systematically define these error categories and construct a synthetic dataset to train ToolCritic. Experimental results on the Schema-Guided Dialogue (SGD) dataset demonstrate that ToolCritic improves tool-calling accuracy by up to 13% over baselines, including zero-shot prompting and self-correction techniques. This represents a promising step toward more robust LLM integration with external tools in real-world dialogue applications."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Will AI also replace inspectors? Investigating the potential of generative AIs in usability inspection", "authors": "Luis F. G. Campos, Leonardo C. Marques, Walter T. Nakamura", "subjects": "Software Engineering (cs.SE); Human-Computer Interaction (cs.HC)", "abstract": "Usability inspection is a well-established technique for identifying interaction issues in software interfaces, thereby contributing to improved product quality. However, it is a costly process that requires time and specialized knowledge from inspectors. With advances in Artificial Intelligence (AI), new opportunities have emerged to support this task, particularly through generative models capable of interpreting interfaces and performing inspections more efficiently. This study examines the performance of generative AIs in identifying usability problems, comparing them to those of experienced human inspectors. A software prototype was evaluated by four specialists and two AI models (GPT-4o and Gemini 2.5 Flash), using metrics such as precision, recall, and F1-score. While inspectors achieved the highest levels of precision and overall coverage, the AIs demonstrated high individual performance and discovered many novel defects, but with a higher rate of false positives and redundant reports. The combination of AIs and human inspectors produced the best results, revealing their complementarity. These findings suggest that AI, in its current stage, cannot replace human inspectors but can serve as a valuable augmentation tool to improve efficiency and expand defect coverage. The results provide evidence based on quantitative analysis to inform the discussion on the role of AI in usability inspections, pointing to viable paths for its complementary use in software quality assessment contexts."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          The Ends Justify the Thoughts: RL-Induced Motivated Reasoning in LLMs", "authors": "Nikolaus Howe, Micah Carroll", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "The use of reinforcement learning (RL) with chain-of-thought (CoT) reasoning has emerged as a promising approach for developing more capable language models. In turn, this has led to investigation of CoT monitoring as a compelling method for detecting harmful behaviors such as reward hacking, under the assumption that models' reasoning processes reflect their internal decision-making. In practice, LLM training often produces unintended behaviors due to imperfect reward signals, leading models to develop misaligned tendencies. A common corrective approach is to apply post-hoc instructions to avoid problematic behaviors like sycophancy, but what happens to the model's reasoning process when these instructions conflict with learned behaviors? We investigate this question in simple settings and find that models engage in systematic motivated reasoning -- generating plausible-sounding justifications for violating their instructions while downplaying potential harms. Beyond being an interesting property of training, we find that while motivated reasoning can be detected by most frontier reasoning models, smaller LLM judges can fail to identify a portion of it, and in rare cases can themselves be persuaded that the reasoning is correct, despite it contradicting clear instructions. This capability gap raises concerns that as models become more sophisticated, their motivated reasoning may become increasingly difficult for monitors to detect. Our results underscore the need to account for motivated reasoning when relying on chain-of-thought processes for model evaluation and oversight. All code for this paper will be made available. WARNING: some examples in this paper may be upsetting."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Bitwidth-Specific Logarithmic Arithmetic for Future Hardware-Accelerated Training", "authors": "Hassan Hamad, Yuou Qiu, Peter A. Beerel, Keith M. Chugg", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "While advancements in quantization have significantly reduced the computational costs of inference in deep learning, training still predominantly relies on complex floating-point arithmetic. Low-precision fixed-point training presents a compelling alternative. This work introduces a novel enhancement in low-precision logarithmic fixed-point training, geared towards future hardware accelerator designs. We propose incorporating bitwidth in the design of approximations to arithmetic operations. To this end, we introduce a new hardware-friendly, piece-wise linear approximation for logarithmic addition. Using simulated annealing, we optimize this approximation at different precision levels. A C++ bit-true simulation demonstrates training of VGG-11 and VGG-16 models on CIFAR-100 and TinyImageNet, respectively, using 12-bit integer arithmetic with minimal accuracy degradation compared to 32-bit floating-point training. Our hardware study reveals up to 32.5% reduction in area and 53.5% reduction in energy consumption for the proposed LNS multiply-accumulate units compared to that of linear fixed-point equivalents."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Consistent Zero-Shot Imitation with Contrastive Goal Inference", "authors": "Kathryn Wantlin, Chongyi Zheng, Benjamin Eysenbach", "subjects": "Machine Learning (cs.LG)", "abstract": "In the same way that generative models today conduct most of their training in a self-supervised fashion, how can agentic models conduct their training in a self-supervised fashion, interactively exploring, learning, and preparing to quickly adapt to new tasks? A prerequisite for embodied agents deployed in real world interactions ought to be training with interaction, yet today's most successful AI models (e.g., VLMs, LLMs) are trained without an explicit notion of action. The problem of pure exploration (which assumes no data as input) is well studied in the reinforcement learning literature and provides agents with a wide array of experiences, yet it fails to prepare them for rapid adaptation to new tasks. Today's language and vision models are trained on data provided by humans, which provides a strong inductive bias for the sorts of tasks that the model will have to solve (e.g., modeling chords in a song, phrases in a sonnet, sentences in a medical record). However, when they are prompted to solve a new task, there is a faulty tacit assumption that humans spend most of their time in the most rewarding states. The key contribution of our paper is a method for pre-training interactive agents in a self-supervised fashion, so that they can instantly mimic human demonstrations. Our method treats goals (i.e., observations) as the atomic construct. During training, our method automatically proposes goals and practices reaching them, building off prior work in reinforcement learning exploration. During evaluation, our method solves an (amortized) inverse reinforcement learning problem to explain demonstrations as optimal goal-reaching behavior. Experiments on standard benchmarks (not designed for goal-reaching) show that our approach outperforms prior methods for zero-shot imitation."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Investigating Thinking Behaviours of Reasoning-Based Language Models for Social Bias Mitigation", "authors": "Guoqing Luo, Iffat Maab, Lili Mou, Junichi Yamagishi", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "abstract": "While reasoning-based large language models excel at complex tasks through an internal, structured thinking process, a concerning phenomenon has emerged that such a thinking process can aggregate social stereotypes, leading to biased outcomes. However, the underlying behaviours of these language models in social bias scenarios remain underexplored. In this work, we systematically investigate mechanisms within the thinking process behind this phenomenon and uncover two failure patterns that drive social bias aggregation: 1) stereotype repetition, where the model relies on social stereotypes as its primary justification, and 2) irrelevant information injection, where it fabricates or introduces new details to support a biased narrative. Building on these insights, we introduce a lightweight prompt-based mitigation approach that queries the model to review its own initial reasoning against these specific failure patterns. Experiments on question answering (BBQ and StereoSet) and open-ended (BOLD) benchmarks show that our approach effectively reduces bias while maintaining or improving accuracy."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          A Brain Cell Type Resource Created by Large Language Models and a Multi-Agent AI System for Collaborative Community Annotation", "authors": "Rongbin Li, Wenbo Chen, Zhao Li, Rodrigo Munoz-Castaneda, Jinbo Li, Neha S. Maurya, Arnav Solanki, Huan He, Hanwen Xing, Meaghan Ramlakhan, Zachary Wise, Zhuhao Wu, Hua Xu, Michael Hawrylycz, W. Jim Zheng", "subjects": "Artificial Intelligence (cs.AI)", "abstract": "Single-cell RNA sequencing has transformed our ability to identify diverse cell types and their transcriptomic signatures. However, annotating these signatures-especially those involving poorly characterized genes-remains a major challenge. Traditional methods, such as Gene Set Enrichment Analysis (GSEA), depend on well-curated annotations and often perform poorly in these contexts. Large Language Models (LLMs) offer a promising alternative but struggle to represent complex biological knowledge within structured ontologies. To address this, we present BRAINCELL-AID (BRAINCELL-AID: this https URL), a novel multi-agent AI system that integrates free-text descriptions with ontology labels to enable more accurate and robust gene set annotation. By incorporating retrieval-augmented generation (RAG), we developed a robust agentic workflow that refines predictions using relevant PubMed literature, reducing hallucinations and enhancing interpretability. Using this workflow, we achieved correct annotations for 77% of mouse gene sets among their top predictions. Applying this approach, we annotated 5,322 brain cell clusters from the comprehensive mouse brain cell atlas generated by the BRAIN Initiative Cell Census Network, enabling novel insights into brain cell function by identifying region-specific gene co-expression patterns and inferring functional roles of gene ensembles. BRAINCELL-AID also identifies Basal Ganglia-related cell types with neurologically meaningful descriptions. Hence, we create a valuable resource to support community-driven cell type annotation."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Convergence of Regret Matching in Potential Games and Constrained Optimization", "authors": "Ioannis Anagnostides, Emanuel Tewolde, Brian Hu Zhang, Ioannis Panageas, Vincent Conitzer, Tuomas Sandholm", "subjects": "Computer Science and Game Theory (cs.GT); Machine Learning (cs.LG); Optimization and Control (math.OC)", "abstract": "Regret matching (RM} -- and its modern variants -- is a foundational online algorithm that has been at the heart of many AI breakthrough results in solving benchmark zero-sum games, such as poker. Yet, surprisingly little is known so far in theory about its convergence beyond two-player zero-sum games. For example, whether regret matching converges to Nash equilibria in potential games has been an open problem for two decades. Even beyond games, one could try to use RM variants for general constrained optimization problems. Recent empirical evidence suggests that they -- particularly regret matching$^+$ (RM$^+$) -- attain strong performance on benchmark constrained optimization problems, outperforming traditional gradient descent-type algorithms. We show that alternating RM$^+$ converges to an $\\epsilon$-KKT point after $O_\\epsilon(1/\\epsilon^4)$ iterations, establishing for the first time that it is a sound and fast first-order optimizer. Our argument relates the KKT gap to the accumulated regret, two quantities that are entirely disparate in general but interact in an intriguing way in our setting, so much so that when regrets are bounded, our complexity bound improves all the way to $O_\\epsilon(1/\\epsilon^2)$. From a technical standpoint, while RM$^+$ does not have the usual one-step improvement property in general, we show that it does in a certain region that the algorithm will quickly reach and remain in thereafter. In sharp contrast, our second main result establishes a lower bound: RM, with or without alternation, can take an exponential number of iterations to reach a crude approximate solution even in two-player potential games. This represents the first worst-case separation between RM and RM$^+$. Our lower bound shows that convergence to coarse correlated equilibria in potential games is exponentially faster than convergence to Nash equilibria."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          ProDAT: Progressive Density-Aware Tail-Drop for Point Cloud Coding", "authors": "Zhe Luo, Wenjing Jia, Stuart Perry", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Three-dimensional (3D) point clouds are becoming increasingly vital in applications such as autonomous driving, augmented reality, and immersive communication, demanding real-time processing and low latency. However, their large data volumes and bandwidth constraints hinder the deployment of high-quality services in resource-limited environments. Progres- sive coding, which allows for decoding at varying levels of detail, provides an alternative by allowing initial partial decoding with subsequent refinement. Although recent learning-based point cloud geometry coding methods have achieved notable success, their fixed latent representation does not support progressive decoding. To bridge this gap, we propose ProDAT, a novel density-aware tail-drop mechanism for progressive point cloud coding. By leveraging density information as a guidance signal, latent features and coordinates are decoded adaptively based on their significance, therefore achieving progressive decoding at multiple bitrates using one single model. Experimental results on benchmark datasets show that the proposed ProDAT not only enables progressive coding but also achieves superior coding efficiency compared to state-of-the-art learning-based coding techniques, with over 28.6% BD-rate improvement for PSNR- D2 on SemanticKITTI and over 18.15% for ShapeNet"}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Differentiating Through Power Flow Solutions for Admittance and Topology Control", "authors": "Samuel Talkington, Daniel Turizo, Sergio A. Dorado-Rojas, Rahul K. Gupta, Daniel K. Molzahn", "subjects": "Systems and Control (eess.SY); Optimization and Control (math.OC)", "abstract": "The power flow equations relate bus voltage phasors to power injections via the network admittance matrix. These equations are central to the key operational and protection functions of power systems (e.g., optimal power flow scheduling and control, state estimation, protection, and fault location, among others). As control, optimization, and estimation of network admittance parameters are central to multiple avenues of research in electric power systems, we propose a linearization of power flow solutions obtained by implicitly differentiating them with respect to the network admittance parameters. This is achieved by utilizing the implicit function theorem, in which we show that such a differentiation is guaranteed to exist under mild conditions and is applicable to generic power systems (radial or meshed). The proposed theory is applied to derive sensitivities of complex voltages, line currents, and power flows. The developed theory of linearizing the power flow equations around changes in the complex network admittance parameters has numerous applications. We demonstrate several of these applications, such as predicting the nodal voltages when the network topology changes without solving the power flow equations. We showcase the application for continuous admittance control, which is used to increase the hosting capacity of a given distribution network."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Planar or Spatial: Exploring Design Aspects and Challenges for Presentations in Virtual Reality with No-coding Interface", "authors": "Liwei Wu, Yilin Zhang, Justin Leung, Jingyi Gao, April Li, Jian Zhao", "subjects": "Human-Computer Interaction (cs.HC)", "abstract": "The proliferation of virtual reality (VR) has led to its increasing adoption as an immersive medium for delivering presentations, distinct from other VR experiences like games and 360-degree videos by sharing information in richly interactive environments. However, creating engaging VR presentations remains a challenging and time-consuming task for users, hindering the full realization of VR presentation's capabilities. This research aims to explore the potential of VR presentation, analyze users' opinions, and investigate these via providing a user-friendly no-coding authoring tool. Through an examination of popular presentation software and interviews with seven professionals, we identified five design aspects and four design challenges for VR presentations. Based on the findings, we developed VRStory, a prototype for presentation authoring without coding to explore the design aspects and strategies for addressing the challenges. VRStory offers a variety of predefined and customizable VR elements, as well as modules for layout design, navigation control, and asset generation. A user study was then conducted with 12 participants to investigate their opinions and authoring experience with VRStory. Our results demonstrated that, while acknowledging the advantages of immersive and spatial features in VR, users often have a consistent mental model for traditional 2D presentations and may still prefer planar and static formats in VR for better accessibility and efficient communication. We finally shared our learned design considerations for future development of VR presentation tools, emphasizing the importance of balancing of promoting immersive features and ensuring accessibility."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Towards a Generalizable Fusion Architecture for Multimodal Object Detection", "authors": "Jad Berjawi, Yoann Dupas, Christophe C'erin", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Multimodal object detection improves robustness in chal- lenging conditions by leveraging complementary cues from multiple sensor modalities. We introduce Filtered Multi- Modal Cross Attention Fusion (FMCAF), a preprocess- ing architecture designed to enhance the fusion of RGB and infrared (IR) inputs. FMCAF combines a frequency- domain filtering block (Freq-Filter) to suppress redun- dant spectral features with a cross-attention-based fusion module (MCAF) to improve intermodal feature sharing. Unlike approaches tailored to specific datasets, FMCAF aims for generalizability, improving performance across different multimodal challenges without requiring dataset- specific tuning. On LLVIP (low-light pedestrian detec- tion) and VEDAI (aerial vehicle detection), FMCAF outper- forms traditional fusion (concatenation), achieving +13.9% mAP@50 on VEDAI and +1.1% on LLVIP. These results support the potential of FMCAF as a flexible foundation for robust multimodal fusion in future detection pipelines."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Toward a Cognitive-Affective-Systemic Framework for Art and Sustainability", "authors": "Ivan C. H. Liu", "subjects": "Human-Computer Interaction (cs.HC)", "abstract": "This paper proposes a ognitive-Affective-Systemic (CAS) framework that integrates cognition, emotion, and systemic understanding to cultivate sustainability awareness through art. Drawing from eco-aesthetics, affect theory, complexity science, and posthuman ethics, the framework defines artistic practice as both epistemic and performative--a way of knowing through making and feeling. Central to this is logomotion, an aesthetic mode where comprehension and emotion move together as a unified experience. Two artworks, SPill, visualizing antimicrobial resistance through avalanche dynamics, and Echoes of the Land, modeling anthropogenic seismicity, demonstrate how systemic modeling and sensory immersion transform complex science into embodied ecological understanding. The framework offers a methodological foundation for artists, theorists, and activists to translate awareness into engagement, advancing collective creativity toward sustainable futures."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Data Reliability Scoring", "authors": "Yiling Chen, Shi Feng, Paul Kattuman, Fang-Yi Yu", "subjects": "Machine Learning (cs.LG); Computer Science and Game Theory (cs.GT); Machine Learning (stat.ML)", "abstract": "How can we assess the reliability of a dataset without access to ground truth? We introduce the problem of reliability scoring for datasets collected from potentially strategic sources. The true data are unobserved, but we see outcomes of an unknown statistical experiment that depends on them. To benchmark reliability, we define ground-truth-based orderings that capture how much reported data deviate from the truth. We then propose the Gram determinant score, which measures the volume spanned by vectors describing the empirical distribution of the observed data and experiment outcomes. We show that this score preserves several ground-truth based reliability orderings and, uniquely up to scaling, yields the same reliability ranking of datasets regardless of the experiment -- a property we term experiment agnosticism. Experiments on synthetic noise models, CIFAR-10 embeddings, and real employment data demonstrate that the Gram determinant score effectively captures data quality across diverse observation processes."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Learning to Design Soft Hands using Reward Models", "authors": "Xueqian Bai, Nicklas Hansen, Adabhav Singh, Michael T. Tolley, Yan Duan, Pieter Abbeel, Xiaolong Wang, Sha Yi", "subjects": "Robotics (cs.RO)", "abstract": "Soft robotic hands promise to provide compliant and safe interaction with objects and environments. However, designing soft hands to be both compliant and functional across diverse use cases remains challenging. Although co-design of hardware and control better couples morphology to behavior, the resulting search space is high-dimensional, and even simulation-based evaluation is computationally expensive. In this paper, we propose a Cross-Entropy Method with Reward Model (CEM-RM) framework that efficiently optimizes tendon-driven soft robotic hands based on teleoperation control policy, reducing design evaluations by more than half compared to pure optimization while learning a distribution of optimized hand designs from pre-collected teleoperation data. We derive a design space for a soft robotic hand composed of flexural soft fingers and implement parallelized training in simulation. The optimized hands are then 3D-printed and deployed in the real world using both teleoperation data and real-time teleoperation. Experiments in both simulation and hardware demonstrate that our optimized design significantly outperforms baseline hands in grasping success rates across a diverse set of challenging objects."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Quantum Key Distribution for Virtual Power Plant Communication: A Lightweight Key-Aware Scheduler with Provable Stability", "authors": "Ziqing Zhu", "subjects": "Cryptography and Security (cs.CR); Systems and Control (eess.SY)", "abstract": "Virtual power plants (VPPs) are becoming a cornerstone of future grids, aggregating distributed PV, wind, storage, and flexible loads for market participation and real-time balancing. As operations move to minute-- and second--level feedback, communication security shifts from a compliance item to an operational constraint: latency, reliability, and confidentiality jointly determine whether dispatch, protection, and settlement signals arrive on time. Conventional PKI and key-rotation schemes struggle with cross-domain, high-frequency messaging and face long-term quantum threats. Quantum key distribution (QKD) offers information-theoretic key freshness, but its key yield is scarce and stochastic, often misaligned with bursty VPP traffic. This paper proposes a key-aware priority and quota framework that treats quantum keys as first-class scheduling resources. The design combines (i) forecast-driven long-term quotas and short-term tokens, (ii) key-aware deficit-round-robin arbitration, (iii) a preemptive emergency key reserve, and (iv) graceful degradation via encryption-mode switching and controlled down-sampling for non-critical traffic. A drift-plus-penalty analysis establishes strong stability under average supply--demand balance with quantifiable bounds on backlog and tail latency, providing interpretable operating guarantees. We build a reproducible testbed on IEEE 33- and 123-bus VPP systems and evaluate normal, degraded, and outage regimes with industry-consistent message classes and TTLs. Against FIFO, fixed-priority, and static-quota baselines, the proposed scheme consistently reduces tail delay and passive timeouts for critical messages, improves per-bit key utility, and enhances power-tracking reliability during key scarcity and regime switches."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Explainable Heterogeneous Anomaly Detection in Financial Networks via Adaptive Expert Routing", "authors": "Zan Li, Rui Fan", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE)", "abstract": "Financial anomalies exhibit heterogeneous mechanisms (price shocks, liquidity freezes, contagion cascades, regime shifts), but existing detectors treat all anomalies uniformly, producing scalar scores without revealing which mechanism is failing, where risks concentrate, or how to intervene. This opacity prevents targeted regulatory responses. Three unsolved challenges persist: (1) static graph structures cannot adapt when market correlations shift during regime changes; (2) uniform detection mechanisms miss type-specific signatures across multiple temporal scales while failing to integrate individual behaviors with network contagion; (3) black-box outputs provide no actionable guidance on anomaly mechanisms or their temporal evolution. We address these via adaptive graph learning with specialized expert networks that provide built-in interpretability. Our framework captures multi-scale temporal dependencies through BiLSTM with self-attention, fuses temporal and spatial information via cross-modal attention, learns dynamic graphs through neural multi-source interpolation, adaptively balances learned dynamics with structural priors via stress-modulated fusion, routes anomalies to four mechanism-specific experts, and produces dual-level interpretable attributions. Critically, interpretability is embedded architecturally rather than applied post-hoc. On 100 US equities (2017-2024), we achieve 92.3% detection of 13 major events with 3.8-day lead time, outperforming best baseline by 30.8pp. Silicon Valley Bank case study demonstrates anomaly evolution tracking: Price-Shock expert weight rose to 0.39 (33% above baseline 0.29) during closure, peaking at 0.48 (66% above baseline) one week later, revealing automatic temporal mechanism identification without labeled supervision."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          AVOCADO: The Streaming Process Mining Challenge", "authors": "Christian Imenkamp, Andrea Maldonado, Hendrik Reiter, Martin Werner, Wilhelm Hasselbring, Agnes Koschmider, Andrea Burattin", "subjects": "Databases (cs.DB)", "abstract": "Streaming process mining deals with the real-time analysis of streaming data. Event streams require algorithms capable of processing data incrementally. To systematically address the complexities of this domain, we propose AVOCADO, a standardized challenge framework that provides clear structural divisions: separating the concept and instantiation layers of challenges in streaming process mining for algorithm evaluation. The AVOCADO evaluates algorithms on streaming-specific metrics like accuracy, Mean Absolute Error (MAE), Root Mean Square Error (RMSE), Processing Latency, and robustness. This initiative seeks to foster innovation and community-driven discussions to advance the field of streaming process mining. We present this framework as a foundation and invite the community to contribute to its evolution by suggesting new challenges, such as integrating metrics for system throughput and memory consumption, and expanding the scope to address real-world stream complexities like out-of-order event arrival."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Channel Capacity for FMCW-based Optical Wireless Integrated Sensing and Communication: Asymptotic Analysis and Envelope Design", "authors": "Yunfeng Wen, Fang Yang, Jian Song, Zhu Han", "subjects": "Information Theory (cs.IT); Signal Processing (eess.SP)", "abstract": "Optical wireless integrated sensing and communication (OW-ISAC) is rapidly burgeoning as a complement and augmentation to its radio-frequency counterpart. In this paper, the channel capacity is analyzed to guide the design of a coherent OW-ISAC system based on frequency-modulated continuous wave (FMCW). Firstly, the system model of FMCW-based OW-ISAC is recast into an information-theoretic formulation, where an additional harmonic-mean constraint is imposed to ensure the sensing performance. Subsequently, both lower and upper bounds for channel capacity are derived under the imposed sensing constraint, based on which asymptotic expressions for channel capacity are presented for both low and high signal-to-noise-ratio regions. Moreover, the analysis of channel capacity provides guidance for the envelope design based on pulse amplitude modulation, whose capacity-achieving capabilities are demonstrated by numerical results. Furthermore, simulations reveal the trade-off between communication and sensing functionalities. In summary, the analysis of channel capacity under the sensing constraint provides insights into both the optimality and the practicality of OW-ISAC design."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          GSPlane: Concise and Accurate Planar Reconstruction via Structured Representation", "authors": "Ruitong Gan, Junran Peng, Yang Liu, Chuanchen Luo, Qing Li, Zhaoxiang Zhang", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Planes are fundamental primitives of 3D sences, especially in man-made environments such as indoor spaces and urban streets. Representing these planes in a structured and parameterized format facilitates scene editing and physical simulations in downstream applications. Recently, Gaussian Splatting (GS) has demonstrated remarkable effectiveness in the Novel View Synthesis task, with extensions showing great potential in accurate surface reconstruction. However, even state-of-the-art GS representations often struggle to reconstruct planar regions with sufficient smoothness and precision. To address this issue, we propose GSPlane, which recovers accurate geometry and produces clean and well-structured mesh connectivity for plane regions in the reconstructed scene. By leveraging off-the-shelf segmentation and normal prediction models, GSPlane extracts robust planar priors to establish structured representations for planar Gaussian coordinates, which help guide the training process by enforcing geometric consistency. To further enhance training robustness, a Dynamic Gaussian Re-classifier is introduced to adaptively reclassify planar Gaussians with persistently high gradients as non-planar, ensuring more reliable optimization. Furthermore, we utilize the optimized planar priors to refine the mesh layouts, significantly improving topological structure while reducing the number of vertices and faces. We also explore applications of the structured planar representation, which enable decoupling and flexible manipulation of objects on supportive planes. Extensive experiments demonstrate that, with no sacrifice in rendering quality, the introduction of planar priors significantly improves the geometric accuracy of the extracted meshes across various baselines."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Can Transformer Memory Be Corrupted? Investigating Cache-Side Vulnerabilities in Large Language Models", "authors": "Elias Hossain, Swayamjit Saha, Somshubhra Roy, Ravi Prasad", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "abstract": "Even when prompts and parameters are secured, transformer language models remain vulnerable because their key-value (KV) cache during inference constitutes an overlooked attack surface. This paper introduces Malicious Token Injection (MTI), a modular framework that systematically perturbs cached key vectors at selected layers and timesteps through controlled magnitude and frequency, using additive Gaussian noise, zeroing, and orthogonal rotations. A theoretical analysis quantifies how these perturbations propagate through attention, linking logit deviations to the Frobenius norm of corruption and softmax Lipschitz dynamics. Empirical results show that MTI significantly alters next-token distributions and downstream task performance across GPT-2 and LLaMA-2/7B, as well as destabilizes retrieval-augmented and agentic reasoning pipelines. These findings identify cache integrity as a critical yet underexplored vulnerability in current LLM deployments, positioning cache corruption as a reproducible and theoretically grounded threat model for future robustness and security research."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          On the Universal Near Optimality of Hedge in Combinatorial Settings", "authors": "Zhiyuan Fan, Arnab Maiti, Kevin Jamieson, Lillian J. Ratliff, Gabriele Farina", "subjects": "Machine Learning (cs.LG); Computer Science and Game Theory (cs.GT)", "abstract": "In this paper, we study the classical Hedge algorithm in combinatorial settings. In each round, the learner selects a vector $\\boldsymbol{x}_t$ from a set $X \\subseteq \\{0,1\\}^d$, observes a full loss vector $\\boldsymbol{y}_t \\in \\mathbb{R}^d$, and incurs a loss $\\langle \\boldsymbol{x}_t, \\boldsymbol{y}_t \\rangle \\in [-1,1]$. This setting captures several important problems, including extensive-form games, resource allocation, $m$-sets, online multitask learning, and shortest-path problems on directed acyclic graphs (DAGs). It is well known that Hedge achieves a regret of $O\\big(\\sqrt{T \\log |X|}\\big)$ after $T$ rounds of interaction. In this paper, we ask whether Hedge is optimal across all combinatorial settings. To that end, we show that for any $X \\subseteq \\{0,1\\}^d$, Hedge is near-optimal--specifically, up to a $\\sqrt{\\log d}$ factor--by establishing a lower bound of $\\Omega\\big(\\sqrt{T \\log(|X|)/\\log d}\\big)$ that holds for any algorithm. We then identify a natural class of combinatorial sets--namely, $m$-sets with $\\log d \\leq m \\leq \\sqrt{d}$--for which this lower bound is tight, and for which Hedge is provably suboptimal by a factor of exactly $\\sqrt{\\log d}$. At the same time, we show that Hedge is optimal for online multitask learning, a generalization of the classical $K$-experts problem. Finally, we leverage the near-optimality of Hedge to establish the existence of a near-optimal regularizer for online shortest-path problems in DAGs--a setting that subsumes a broad range of combinatorial domains. Specifically, we show that the classical Online Mirror Descent (OMD) algorithm, when instantiated with the dilated entropy regularizer, is iterate-equivalent to Hedge, and therefore inherits its near-optimal regret guarantees for DAGs."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Shape-aware Inertial Poser: Motion Tracking for Humans with Diverse Shapes Using Sparse Inertial Sensors", "authors": "Lu Yin, Ziying Shi, Yinghao Wu, Xinyu Yi, Feng Xu, Shihui Guo", "subjects": "Graphics (cs.GR); Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Human motion capture with sparse inertial sensors has gained significant attention recently. However, existing methods almost exclusively rely on a template adult body shape to model the training data, which poses challenges when generalizing to individuals with largely different body shapes (such as a child). This is primarily due to the variation in IMU-measured acceleration caused by changes in body shape. To fill this gap, we propose Shape-aware Inertial Poser (SAIP), the first solution considering body shape differences in sparse inertial-based motion capture. Specifically, we decompose the sensor measurements related to shape and pose in order to effectively model their joint correlations. Firstly, we train a regression model to transfer the IMU-measured accelerations of a real body to match the template adult body model, compensating for the shape-related sensor measurements. Then, we can easily follow the state-of-the-art methods to estimate the full body motions of the template-shaped body. Finally, we utilize a second regression model to map the joint velocities back to the real body, combined with a shape-aware physical optimization strategy to calculate global motions on the subject. Furthermore, our method relies on body shape awareness, introducing the first inertial shape estimation scheme. This is accomplished by modeling the shape-conditioned IMU-pose correlation using an MLP-based network. To validate the effectiveness of SAIP, we also present the first IMU motion capture dataset containing individuals of different body sizes. This dataset features 10 children and 10 adults, with heights ranging from 110 cm to 190 cm, and a total of 400 minutes of paired IMU-Motion samples. Extensive experimental results demonstrate that SAIP can effectively handle motion capture tasks for diverse body shapes. The code and dataset are available at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Kinesthetic Weight Modulation: The Effects of Whole-Arm Tendon Vibration on the Perceived Heaviness", "authors": "Keigo Ushiyama, Hiroyuki Kajimoto", "subjects": "Human-Computer Interaction (cs.HC)", "abstract": "Kinesthetic illusions, which arise when muscle spindles are activated by vibration, provide a compact means of presenting kinesthetic sensations. Because muscle spindles contribute not only to sensing body movement but also to perceiving heaviness, vibration-induced illusions could potentially modulate weight perception. While prior studies have primarily focused on conveying virtual movement, the modulation of perceived heaviness has received little attention. Presenting a sense of heaviness is essential for enriching haptic interactions with virtual objects. This study investigates whether multi-point tendon vibration can increase or decrease perceived heaviness (Experiment 1) and how the magnitude of the effect can be systematically controlled (Experiment 2). The results show that tendon vibration significantly increases perceived heaviness but does not significantly decrease it, although a decreasing trend was observed. Moreover, the increase can be adjusted across at least three levels within the range of 350-450 g. Finally, we discuss plausible mechanisms underlying this vibration-induced modulation of weight perception."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Adapting to Stochastic and Adversarial Losses in Episodic MDPs with Aggregate Bandit Feedback", "authors": "Shinji Ito, Kevin Jamieson, Haipeng Luo, Arnab Maiti, Taira Tsuchiya", "subjects": "Machine Learning (cs.LG); Machine Learning (stat.ML)", "abstract": "We study online learning in finite-horizon episodic Markov decision processes (MDPs) under the challenging aggregate bandit feedback model, where the learner observes only the cumulative loss incurred in each episode, rather than individual losses at each state-action pair. While prior work in this setting has focused exclusively on worst-case analysis, we initiate the study of best-of-both-worlds (BOBW) algorithms that achieve low regret in both stochastic and adversarial environments. We propose the first BOBW algorithms for episodic tabular MDPs with aggregate bandit feedback. In the case of known transitions, our algorithms achieve $O(\\log T)$ regret in stochastic settings and ${O}(\\sqrt{T})$ regret in adversarial ones. Importantly, we also establish matching lower bounds, showing the optimality of our algorithms in this setting. We further extend our approach to unknown-transition settings by incorporating confidence-based techniques. Our results rely on a combination of FTRL over occupancy measures, self-bounding techniques, and new loss estimators inspired by recent advances in online shortest path problems. Along the way, we also provide the first individual-gap-dependent lower bounds and demonstrate near-optimal BOBW algorithms for shortest path problems with bandit feedback."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Boosting Fidelity for Pre-Trained-Diffusion-Based Low-Light Image Enhancement via Condition Refinement", "authors": "Xiaogang Xu, Jian Wang, Yunfan Lu, Ruihang Chu, Ruixing Wang, Jiafei Wu, Bei Yu, Liang Lin", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Diffusion-based methods, leveraging pre-trained large models like Stable Diffusion via ControlNet, have achieved remarkable performance in several low-level vision tasks. However, Pre-Trained Diffusion-Based (PTDB) methods often sacrifice content fidelity to attain higher perceptual realism. This issue is exacerbated in low-light scenarios, where severely degraded information caused by the darkness limits effective control. We identify two primary causes of fidelity loss: the absence of suitable conditional latent modeling and the lack of bidirectional interaction between the conditional latent and noisy latent in the diffusion process. To address this, we propose a novel optimization strategy for conditioning in pre-trained diffusion models, enhancing fidelity while preserving realism and aesthetics. Our method introduces a mechanism to recover spatial details lost during VAE encoding, i.e., a latent refinement pipeline incorporating generative priors. Additionally, the refined latent condition interacts dynamically with the noisy latent, leading to improved restoration performance. Our approach is plug-and-play, seamlessly integrating into existing diffusion networks to provide more effective control. Extensive experiments demonstrate significant fidelity improvements in PTDB methods."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Fighter: Unveiling the Graph Convolutional Nature of Transformers in Time Series Modeling", "authors": "Chen Zhang, Weixin Bu, Wendong Xu, Runsheng Yu, Yik-Chung Wu, Ngai Wong", "subjects": "Machine Learning (cs.LG)", "abstract": "Transformers have achieved remarkable success in time series modeling, yet their internal mechanisms remain opaque. This work demystifies the Transformer encoder by establishing its fundamental equivalence to a Graph Convolutional Network (GCN). We show that in the forward pass, the attention distribution matrix serves as a dynamic adjacency matrix, and its composition with subsequent transformations performs computations analogous to graph convolution. Moreover, we demonstrate that in the backward pass, the update dynamics of value and feed-forward projections mirror those of GCN parameters. Building on this unified theoretical reinterpretation, we propose \\textbf{Fighter} (Flexible Graph Convolutional Transformer), a streamlined architecture that removes redundant linear projections and incorporates multi-hop graph aggregation. This perspective yields an explicit and interpretable representation of temporal dependencies across different scales, naturally expressed as graph edges. Experiments on standard forecasting benchmarks confirm that Fighter achieves competitive performance while providing clearer mechanistic interpretability of its predictions."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Structured Debate Improves Corporate Credit Reasoning in Financial AI", "authors": "Yoonjin Lee, Munhee Kim, Hanbi Choi, Juhyeon Park, Seungho Lyoo, Woojin Park", "subjects": "Artificial Intelligence (cs.AI)", "abstract": "Despite advances in financial AI, the automation of evidence-based reasoning remains unresolved in corporate credit assessment, where qualitative non-financial indicators exert decisive influence on loan repayment outcomes yet resist formalization. Existing approaches focus predominantly on numerical prediction and provide limited support for the interpretive judgments required in professional loan evaluation. This study develops and evaluates two operational large language model (LLM)-based systems designed to generate structured reasoning from non-financial evidence. The first is a non-adversarial single-agent system (NAS) that produces bidirectional analysis through a single-pass reasoning pipeline. The second is a debate-based multi-agent system (KPD-MADS) that operationalizes adversarial verification through a ten-step structured interaction protocol grounded in Karl Popper's critical dialogue framework. Both systems were applied to three real corporate cases and evaluated by experienced credit risk professionals. Compared to manual expert reporting, both systems achieved substantial productivity gains (NAS: 11.55 s per case; KPD-MADS: 91.97 s; human baseline: 1920 s). The KPD-MADS demonstrated superior reasoning quality, receiving higher median ratings in explanatory adequacy (4.0 vs. 3.0), practical applicability (4.0 vs. 3.0), and usability (62.5 vs. 52.5). These findings show that structured multi-agent interaction can enhance reasoning rigor and interpretability in financial AI, advancing scalable and defensible automation in corporate credit assessment."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Verification-Aware Planning for Multi-Agent Systems", "authors": "Tianyang Xu, Dan Zhang, Kushan Mitra, Estevam Hruschka", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multiagent Systems (cs.MA)", "abstract": "Large language model (LLM) agents are increasingly deployed to tackle complex tasks, often necessitating collaboration among multiple specialized agents. However, multi-agent collaboration introduces new challenges in planning, coordination, and verification. Execution failures frequently arise not from flawed reasoning alone, but from subtle misalignments in task interpretation, output format, or inter-agent handoffs. To address these challenges, we present VeriMAP, a framework for multi-agent collaboration with verification-aware planning. The VeriMAP planner decomposes tasks, models subtask dependencies, and encodes planner-defined passing criteria as subtask verification functions (VFs) in Python and natural language. We evaluate VeriMAP on diverse datasets, demonstrating that it outperforms both single- and multi-agent baselines while enhancing system robustness and interpretability. Our analysis highlights how verification-aware planning enables reliable coordination and iterative refinement in multi-agent systems, without relying on external labels or annotations."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          M2QCode: A Model-Driven Framework for Generating Multi-Platform Quantum Programs", "authors": "Xiaoyu Guo, Shinobu Saito, Jianjun Zhao", "subjects": "Software Engineering (cs.SE)", "abstract": "With the growing interest in quantum computing, the emergence of quantum supremacy has marked a pivotal milestone in the field. As a result, numerous quantum programming languages (QPLs) have been introduced to support the development of quantum algorithms. However, the application of Model-Driven Development (MDD) in quantum system engineering remains largely underexplored. This paper presents an MDD-based approach to support the structured design and implementation of quantum systems. Our framework enables the automatic generation of quantum code for multiple QPLs, thereby enhancing development efficiency and consistency across heterogeneous quantum platforms. The effectiveness and practicality of our approach have been demonstrated through multiple case studies."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Efficient Vision-Language-Action Models for Embodied Manipulation: A Systematic Survey", "authors": "Weifan Guan, Qinghao Hu, Aosheng Li, Jian Cheng", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "abstract": "Vision-Language-Action (VLA) models extend vision-language models to embodied control by mapping natural-language instructions and visual observations to robot actions. Despite their capabilities, VLA systems face significant challenges due to their massive computational and memory demands, which conflict with the constraints of edge platforms such as on-board mobile manipulators that require real-time performance. Addressing this tension has become a central focus of recent research. In light of the growing efforts toward more efficient and scalable VLA systems, this survey provides a systematic review of approaches for improving VLA efficiency, with an emphasis on reducing latency, memory footprint, and training and inference costs. We categorize existing solutions into four dimensions: model architecture, perception feature, action generation, and training/inference strategies, summarizing representative techniques within each category. Finally, we discuss future trends and open challenges, highlighting directions for advancing efficient embodied intelligence."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Towards Imperceptible Watermarking Via Environment Illumination for Consumer Cameras", "authors": "Hodaka Kawachi, Tomoya Nakamura, Hiroaki Santo, SaiKiran Kumar Tedla, Trevor Dalton Canham, Yasushi Yagi, Michael S. Brown", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "This paper introduces a method for using LED-based environmental lighting to produce visually imperceptible watermarks for consumer cameras. Our approach optimizes an LED light source's spectral profile to be minimally visible to the human eye while remaining highly detectable by typical consumer cameras. The method jointly considers the human visual system's sensitivity to visible spectra, modern consumer camera sensors' spectral sensitivity, and narrowband LEDs' ability to generate broadband spectra perceived as \"white light\" (specifically, D65 illumination). To ensure imperceptibility, we employ spectral modulation rather than intensity modulation. Unlike conventional visible light communication, our approach enables watermark extraction at standard low frame rates (30-60 fps). While the information transfer rate is modest-embedding 128 bits within a 10-second video clip-this capacity is sufficient for essential metadata supporting privacy protection and content verification."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          DVAGen: Dynamic Vocabulary Augmented Generation", "authors": "Wei Du, Nuowei Liu, Jie Wang, Jiahao Kuang, Tao Ji, Xiaoling Wang, Yuanbin Wu", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "abstract": "Language models trained with a fixed vocabulary struggle to generalize to novel or out-of-vocabulary words, limiting their flexibility in handling diverse token combinations. Existing dynamic vocabulary approaches attempt to address this limitation but face challenges such as fragmented codebases, lack of support for modern LLMs, and limited inference scalability. To overcome these issues, we introduce DVAGen, a fully open-source, unified framework designed for training, evaluation, and visualization of dynamic vocabulary-augmented language models. Our framework modularizes the pipeline for ease of customization, integrates seamlessly with open-source LLMs, and is the first to provide both CLI and WebUI tools for real-time result inspection. We validate the effectiveness of dynamic vocabulary methods on modern LLMs and demonstrate support for batch inference, significantly improving inference throughput."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Design Framework for Conversational Agent in Couple relationships: A Systematic Review", "authors": "Soyoung Jung, Sung Park", "subjects": "Human-Computer Interaction (cs.HC)", "abstract": "The development of conversational agents (CAs) has shown strong potential in supporting mental health through dialogue. While many studies focus on CAs for individual psychological care, research on agents designed for couples facing relational or emotional challenges remains limited. This study aims to identify design considerations for CAs that address the relational context of couples and support their well-being. Following PRISMA guidelines, a systematic review was conducted across seven databases: CINAHL, Embase, PubMed, PsycINFO, Scopus, Web of Science, and the ACM Digital Library. Peer-reviewed empirical studies were screened, duplicates removed, and selection criteria applied, resulting in twelve studies for analysis. Thematic analysis was conducted across three dimensions: AI interaction design, relational framing, and technical limitations. Three key themes emerged: (1) the need for a relational expert persona, (2) technological directions leveraging state-of-the-art AI for relational specificity and emotional competence, and (3) a shift from content-centered to relationship-centered design. Based on these insights, eight design considerations are proposed for couple-oriented CAs: (1) agent persona, (2) individual mode, (3) concurrent mode, (4) conjoint mode, (5) ethics, (6) data and privacy, (7) interaction pattern, and (8) safety mechanism. These principles guide CAs as relational mediators capable of maintaining multiple alliances, respecting cultural and ethical boundaries, and ensuring fairness and emotional safety between partners. Ultimately, this review introduces a design framework that integrates relational theory with advanced AI technologies to inform future development of CAs for couple-based mental health interventions."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Matricial Free Energy as a Gaussianizing Regularizer: Enhancing Autoencoders for Gaussian Code Generation", "authors": "Rishi Sonthalia, Raj Rao Nadakuditi", "subjects": "Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)", "abstract": "We introduce a novel regularization scheme for autoencoders based on matricial free energy. Our approach defines a differentiable loss function in terms of the singular values of the code matrix (code dimension x batch size). From the standpoint of free probability an d random matrix theory, this loss achieves its minimum when the singular value distribution of the code matrix coincides with that of an appropriately sculpted random metric with i.i.d. Gaussian entries. Empirical simulations demonstrate that minimizing the negative matricial free energy through standard stochastic gradient-based training yields Gaussian-like codes that generalize across training and test sets. Building on this foundation, we propose a matricidal free energy maximizing autoencoder that reliably produces Gaussian codes and show its application to underdetermined inverse problems."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Continuous Q-Score Matching: Diffusion Guided Reinforcement Learning for Continuous-Time Control", "authors": "Chengxiu Hua, Jiawen Gu, Yushun Tang", "subjects": "Machine Learning (cs.LG); Optimization and Control (math.OC)", "abstract": "Reinforcement learning (RL) has achieved significant success across a wide range of domains, however, most existing methods are formulated in discrete time. In this work, we introduce a novel RL method for continuous-time control, where stochastic differential equations govern state-action dynamics. Departing from traditional value function-based approaches, our key contribution is the characterization of continuous-time Q-functions via a martingale condition and the linking of diffusion policy scores to the action gradient of a learned continuous Q-function by the dynamic programming principle. This insight motivates Continuous Q-Score Matching (CQSM), a score-based policy improvement algorithm. Notably, our method addresses a long-standing challenge in continuous-time RL: preserving the action-evaluation capability of Q-functions without relying on time discretization. We further provide theoretical closed-form solutions for linear-quadratic (LQ) control problems within our framework. Numerical results in simulated environments demonstrate the effectiveness of our proposed method and compare it to popular baselines."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Semantic Intelligence: A Bio-Inspired Cognitive Framework for Embodied Agents", "authors": "Wenbing Tang, Meilin Zhu, Fenghua Wu, Yang Liu", "subjects": "Systems and Control (eess.SY)", "abstract": "Recent advancements in Large Language Models (LLMs) have greatly enhanced natural language understanding and content generation. However, these models primarily operate in disembodied digital environments and lack interaction with the physical world. To address this limitation, Embodied Artificial Intelligence (EAI) has emerged, focusing on agents that can perceive and interact with their surroundings. Despite progress, current embodied agents face challenges in unstructured real-world environments due to insufficient semantic intelligence, which is critical for understanding and reasoning about complex tasks. This paper introduces the Semantic Intelligence-Driven Embodied (SIDE) agent framework, which integrates a hierarchical semantic cognition architecture with a semantic-driven decision-making process. This enables agents to reason about and interact with the physical world in a contextually adaptive manner. The framework is inspired by biological cognitive mechanisms and utilizes bio-inspired principles to design a semantic cognitive architecture that mimics how humans and animals integrate and process sensory information. We present this framework as a step toward developing more intelligent and versatile embodied agents."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          SEER: Enhancing Chain-of-Thought Code Generation through Self-Exploring Deep Reasoning", "authors": "Shuzheng Gao, Chaozheng Wang, Cuiyun Gao, Michael R. Lyu", "subjects": "Software Engineering (cs.SE)", "abstract": "Code generation, the task of creating executable programs from natural language requirements, has recently seen tremendous advances through Chain-of-Thought (CoT) reasoning, which enables Large Language Models (LLMs) to develop high-level reasoning plans before writing code. Recent research has proposed various methods to enhance models' CoT reasoning for code generation such as prompt engineering and supervised fine-tuning. However, existing approaches still face three critical limitations: (1) limited exploration of diverse reasoning paths, which constrains generalization across various programming scenarios, (2) lack of quality assessment for intermediate reasoning steps, which hampers the reliability of the generated plans and code, and (3) the potential negative impact of \"overthinking\", potentially leading to unnecessarily complex and incorrect solutions. To address these limitations, we frame CoT code generation as a decision making problem and present SEER, a SElf-Exploring deep Reasoning framework that enables accurate and adaptive reasoning for code generation. SEER introduces three key components: (1) Diverse reasoning path exploration, which aims at exploring diverse reasoning paths and annotating intermediate steps without relying on manual experts or closed-source proprietary models; (2) Reasoning quality-aware model training, which trains a policy model for generating candidate reasoning steps and a value model for assessing their quality; and (3) Adaptive CoT reasoning, which dynamically switches between direct generation and step-by-step reasoning for different problems."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          GOOD: Training-Free Guided Diffusion Sampling for Out-of-Distribution Detection", "authors": "Xin Gao, Jiyao Liu, Guanghao Li, Yueming Lyu, Jianxiong Gao, Weichen Yu, Ningsheng Xu, Liang Wang, Caifeng Shan, Ziwei Liu, Chenyang Si", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "abstract": "Recent advancements have explored text-to-image diffusion models for synthesizing out-of-distribution (OOD) samples, substantially enhancing the performance of OOD detection. However, existing approaches typically rely on perturbing text-conditioned embeddings, resulting in semantic instability and insufficient shift diversity, which limit generalization to realistic OOD. To address these challenges, we propose GOOD, a novel and flexible framework that directly guides diffusion sampling trajectories towards OOD regions using off-the-shelf in-distribution (ID) classifiers. GOOD incorporates dual-level guidance: (1) Image-level guidance based on the gradient of log partition to reduce input likelihood, drives samples toward low-density regions in pixel space. (2) Feature-level guidance, derived from k-NN distance in the classifier's latent space, promotes sampling in feature-sparse regions. Hence, this dual-guidance design enables more controllable and diverse OOD sample generation. Additionally, we introduce a unified OOD score that adaptively combines image and feature discrepancies, enhancing detection robustness. We perform thorough quantitative and qualitative analyses to evaluate the effectiveness of GOOD, demonstrating that training with samples generated by GOOD can notably enhance OOD detection performance."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Do LLMs Recognize Your Latent Preferences? A Benchmark for Latent Information Discovery in Personalized Interaction", "authors": "Ioannis Tsaknakis, Bingqing Song, Shuyu Gan, Dongyeop Kang, Alfredo Garcia, Gaowen Liu, Charles Fleming, Mingyi Hong", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "abstract": "Large Language Models (LLMs) excel at producing broadly relevant text, but this generality becomes a limitation when user-specific preferences are required, such as recommending restaurants or planning travel. In these scenarios, users rarely articulate every preference explicitly; instead, much of what they care about remains latent, waiting to be inferred. This raises a fundamental question: Can LLMs uncover and reason about such latent information through conversation? We address this problem by introducing a unified benchmark for evaluating latent information discovery - the ability of LLMs to reveal and utilize hidden user attributes through multi-turn interaction. The benchmark spans three progressively realistic settings: the classic 20 Questions game, Personalized Question Answering, and Personalized Text Summarization. All tasks share a tri-agent framework (User, Assistant, Judge) enabling turn-level evaluation of elicitation and adaptation. Our results reveal that while LLMs can indeed surface latent information through dialogue, their success varies dramatically with context: from 32% to 98%, depending on task complexity, topic, and number of hidden attributes. This benchmark provides the first systematic framework for studying latent information discovery in personalized interaction, highlighting that effective preference inference remains an open frontier for building truly adaptive AI systems."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          In-situ Autoguidance: Eliciting Self-Correction in Diffusion Models", "authors": "Enhao Gu, Haolin Hou", "subjects": "Machine Learning (cs.LG)", "abstract": "The generation of high-quality, diverse, and prompt-aligned images is a central goal in image-generating diffusion models. The popular classifier-free guidance (CFG) approach improves quality and alignment at the cost of reduced variation, creating an inherent entanglement of these effects. Recent work has successfully disentangled these properties by guiding a model with a separately trained, inferior counterpart; however, this solution introduces the considerable overhead of requiring an auxiliary model. We challenge this prerequisite by introducing In-situ Autoguidance, a method that elicits guidance from the model itself without any auxiliary components. Our approach dynamically generates an inferior prediction on the fly using a stochastic forward pass, reframing guidance as a form of inference-time self-correction. We demonstrate that this zero-cost approach is not only viable but also establishes a powerful new baseline for cost-efficient guidance, proving that the benefits of self-guidance can be achieved without external models."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          KineDiff3D: Kinematic-Aware Diffusion for Category-Level Articulated Object Shape Reconstruction and Generation", "authors": "WenBo Xu, Liu Liu, Li Zhang, Ran Zhang, Hao Wu, Dan Guo, Meng Wang", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Articulated objects, such as laptops and drawers, exhibit significant challenges for 3D reconstruction and pose estimation due to their multi-part geometries and variable joint configurations, which introduce structural diversity across different states. To address these challenges, we propose KineDiff3D: Kinematic-Aware Diffusion for Category-Level Articulated Object Shape Reconstruction and Generation, a unified framework for reconstructing diverse articulated instances and pose estimation from single view input. Specifically, we first encode complete geometry (SDFs), joint angles, and part segmentation into a structured latent space via a novel Kinematic-Aware VAE (KA-VAE). In addition, we employ two conditional diffusion models: one for regressing global pose (SE(3)) and joint parameters, and another for generating the kinematic-aware latent code from partial observations. Finally, we produce an iterative optimization module that bidirectionally refines reconstruction accuracy and kinematic parameters via Chamfer-distance minimization while preserving articulation constraints. Experimental results on synthetic, semi-synthetic, and real-world datasets demonstrate the effectiveness of our approach in accurately reconstructing articulated objects and estimating their kinematic properties."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Rethinking On-policy Optimization for Query Augmentation", "authors": "Zhichao Xu, Shengyao Zhuang, Xueguang Ma, Bingsen Chen, Yijun Tian, Fengran Mo, Jie Cao, Vivek Srikumar", "subjects": "Computation and Language (cs.CL); Information Retrieval (cs.IR)", "abstract": "Recent advances in large language models (LLMs) have led to a surge of interest in query augmentation for information retrieval (IR). Two main approaches have emerged. The first prompts LLMs to generate answers or pseudo-documents that serve as new queries, relying purely on the model's parametric knowledge or contextual information. The second applies reinforcement learning (RL) to fine-tune LLMs for query rewriting, directly optimizing retrieval metrics. While having respective advantages and limitations, the two approaches have not been compared under consistent experimental conditions. In this work, we present the first systematic comparison of prompting-based and RL-based query augmentation across diverse benchmarks, including evidence-seeking, ad hoc, and tool retrieval. Our key finding is that simple, training-free query augmentation often performs on par with, or even surpasses, more expensive RL-based counterparts, especially when using powerful LLMs. Motivated by this discovery, we introduce a novel hybrid method, On-policy Pseudo-document Query Expansion (OPQE), which, instead of rewriting a query, the LLM policy learns to generate a pseudo-document that maximizes retrieval performance, thus merging the flexibility and generative structure of prompting with the targeted optimization of RL. We show OPQE outperforms both standalone prompting and RL-based rewriting, demonstrating that a synergistic approach yields the best results. Our implementation is made available to facilitate reproducibility."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          PEACE: Towards Efficient Project-Level Efficiency Optimization via Hybrid Code Editing", "authors": "Xiaoxue Ren (2), Jun Wan (2), Yun Peng (3), Zhongxin Liu (2), Ming Liang (4), Dajun Chen (4), Wei Jiang (4), Yong Li (4) ((2) Hangzhou High-Tech Zone (Binjiang) Institute of Blockchain and Data Security, Zhejiang University, Hangzhou, China, (3) The Chinese University of Hong Kong, Hong Kong, China, (4) Ant Group, Hangzhou, China)", "subjects": "Software Engineering (cs.SE)", "abstract": "Large Language Models (LLMs) have demonstrated significant capability in code generation, but their potential in code efficiency optimization remains underexplored. Previous LLM-based code efficiency optimization approaches exclusively focus on function-level optimization and overlook interaction between functions, failing to generalize to real-world development scenarios. Code editing techniques show great potential for conducting project-level optimization, yet they face challenges associated with invalid edits and suboptimal internal functions. To address these gaps, we propose Peace, a novel hybrid framework for Project-level code Efficiency optimization through Automatic Code Editing, which also ensures the overall correctness and integrity of the project. Peace integrates three key phases: dependency-aware optimizing function sequence construction, valid associated edits identification, and efficiency optimization editing iteration. To rigorously evaluate the effectiveness of Peace, we construct PeacExec, the first benchmark comprising 146 real-world optimization tasks from 47 high-impact GitHub Python projects, along with highly qualified test cases and executable environments. Extensive experiments demonstrate Peace's superiority over the state-of-the-art baselines, achieving a 69.2% correctness rate (pass@1), +46.9% opt rate, and 0.840 speedup in execution efficiency. Notably, our Peace outperforms all baselines by significant margins, particularly in complex optimization tasks with multiple functions. Moreover, extensive experiments are also conducted to validate the contributions of each component in Peace, as well as the rationale and effectiveness of our hybrid framework design."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Decentralized Real-Time Planning for Multi-UAV Cooperative Manipulation via Imitation Learning", "authors": "Shantnav Agarwal, Javier Alonso-Mora, Sihao Sun", "subjects": "Robotics (cs.RO)", "abstract": "Existing approaches for transporting and manipulating cable-suspended loads using multiple UAVs along reference trajectories typically rely on either centralized control architectures or reliable inter-agent communication. In this work, we propose a novel machine learning based method for decentralized kinodynamic planning that operates effectively under partial observability and without inter-agent communication. Our method leverages imitation learning to train a decentralized student policy for each UAV by imitating a centralized kinodynamic motion planner with access to privileged global observations. The student policy generates smooth trajectories using physics-informed neural networks that respect the derivative relationships in motion. During training, the student policies utilize the full trajectory generated by the teacher policy, leading to improved sample efficiency. Moreover, each student policy can be trained in under two hours on a standard laptop. We validate our method in both simulation and real-world environments to follow an agile reference trajectory, demonstrating performance comparable to that of centralized approaches."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Enhanced Fish Freshness Classification with Incremental Handcrafted Feature Fusion", "authors": "Phi-Hung Hoang, Nam-Thuan Trinh, Van-Manh Tran, Thi-Thu-Hong Phan", "subjects": "Artificial Intelligence (cs.AI)", "abstract": "Accurate assessment of fish freshness remains a major challenge in the food industry, with direct consequences for product quality, market value, and consumer health. Conventional sensory evaluation is inherently subjective, inconsistent, and difficult to standardize across contexts, often limited by subtle, species-dependent spoilage cues. To address these limitations, we propose a handcrafted feature-based approach that systematically extracts and incrementally fuses complementary descriptors, including color statistics, histograms across multiple color spaces, and texture features such as Local Binary Patterns (LBP) and Gray-Level Co-occurrence Matrices (GLCM), from fish eye images. Our method captures global chromatic variations from full images and localized degradations from ROI segments, fusing each independently to evaluate their effectiveness in assessing freshness. Experiments on the Freshness of the Fish Eyes (FFE) dataset demonstrate the approach's effectiveness: in a standard train-test setting, a LightGBM classifier achieved 77.56% accuracy, a 14.35% improvement over the previous deep learning baseline of 63.21%. With augmented data, an Artificial Neural Network (ANN) reached 97.16% accuracy, surpassing the prior best of 77.3% by 19.86%. These results demonstrate that carefully engineered, handcrafted features, when strategically processed, yield a robust, interpretable, and reliable solution for automated fish freshness assessment, providing valuable insights for practical applications in food quality monitoring."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Physics-Informed Large Language Models for HVAC Anomaly Detection with Autonomous Rule Generation", "authors": "Subin Lin, Chuanbo Hua", "subjects": "Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE)", "abstract": "Heating, Ventilation, and Air-Conditioning (HVAC) systems account for a substantial share of global building energy use, making reliable anomaly detection essential for improving efficiency and reducing emissions. Classical rule-based approaches offer explainability but lack adaptability, while deep learning methods provide predictive power at the cost of transparency, efficiency, and physical plausibility. Recent attempts to use Large Language Models (LLMs) for anomaly detection improve interpretability but largely ignore the physical principles that govern HVAC operations. We present PILLM, a Physics-Informed LLM framework that operates within an evolutionary loop to automatically generate, evaluate, and refine anomaly detection rules. Our approach introduces physics-informed reflection and crossover operators that embed thermodynamic and control-theoretic constraints, enabling rules that are both adaptive and physically grounded. Experiments on the public Building Fault Detection dataset show that PILLM achieves state-of-the-art performance while producing diagnostic rules that are interpretable and actionable, advancing trustworthy and deployable AI for smart building systems."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Mamba4Net: Distilled Hybrid Mamba Large Language Models For Networking", "authors": "Linhan Xia, Mingzhan Yang, Jingjing Wang, Ziwei Yan, Yakun Ren, Guo Yu, Kai Lei", "subjects": "Networking and Internet Architecture (cs.NI)", "abstract": "Transformer-based large language models (LLMs) are increasingly being adopted in networking research to address domain-specific challenges. However, their quadratic time complexity and substantial model sizes often result in significant computational overhead and memory constraints, particularly in resource-constrained environments. Drawing inspiration from the efficiency and performance of the Deepseek-R1 model within the knowledge distillation paradigm, this paper introduces Mamba4Net, a novel cross-architecture distillation framework. Mamba4Net transfers networking-specific knowledge from transformer-based LLMs to student models built on the Mamba architecture, which features linear time complexity. This design substantially enhances computational efficiency compared to the quadratic complexity of transformer-based models, while the reduced model size further minimizes computational demands, improving overall performance and resource utilization. To evaluate its effectiveness, Mamba4Net was tested across three diverse networking tasks: viewport prediction, adaptive bitrate streaming, and cluster job scheduling. Compared to existing methods that do not leverage LLMs, Mamba4Net demonstrates superior task performance. Furthermore, relative to direct applications of transformer-based LLMs, it achieves significant efficiency gains, including a throughput 3.96 times higher and a storage footprint of only 5.48% of that required by previous LLM-based approaches. These results highlight Mamba4Net's potential to enable the cost-effective application of LLM-derived knowledge in networking contexts. The source code is openly available to support further research and development."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          DiffVLA++: Bridging Cognitive Reasoning and End-to-End Driving through Metric-Guided Alignment", "authors": "Yu Gao, Yiru Wang, Anqing Jiang, Heng Yuwen, Wang Shuo, Sun Hao, Wang Jijun", "subjects": "Robotics (cs.RO); Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Conventional end-to-end (E2E) driving models are effective at generating physically plausible trajectories, but often fail to generalize to long-tail scenarios due to the lack of essential world knowledge to understand and reason about surrounding environments. In contrast, Vision-Language-Action (VLA) models leverage world knowledge to handle challenging cases, but their limited 3D reasoning capability can lead to physically infeasible actions. In this work we introduce DiffVLA++, an enhanced autonomous driving framework that explicitly bridges cognitive reasoning and E2E planning through metric-guided alignment. First, we build a VLA module directly generating semantically grounded driving trajectories. Second, we design an E2E module with a dense trajectory vocabulary that ensures physical feasibility. Third, and most critically, we introduce a metric-guided trajectory scorer that guides and aligns the outputs of the VLA and E2E modules, thereby integrating their complementary strengths. The experiment on the ICCV 2025 Autonomous Grand Challenge leaderboard shows that DiffVLA++ achieves EPDMS of 49.12."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Which LLM Multi-Agent Protocol to Choose?", "authors": "Hongyi Du, Jiaqi Su, Jisen Li, Lijie Ding, Yingxuan Yang, Peixuan Han, Xiangru Tang, Kunlun Zhu, Jiaxuan You", "subjects": "Artificial Intelligence (cs.AI)", "abstract": "As large-scale multi-agent systems evolve, the communication protocol layer has become a critical yet under-evaluated factor shaping performance and reliability. Despite the existence of diverse protocols (A2A, ACP, ANP, Agora, etc.), selection is often intuition-driven and lacks standardized guidance. We introduce ProtocolBench, a benchmark that systematically compares agent protocols along four measurable axes: task success, end-to-end latency, message or byte overhead, and robustness under failures. On ProtocolBench, protocol choice significantly influences system behavior. In the Streaming Queue scenario, overall completion time varies by up to 36.5% across protocols, and mean end-to-end latency differs by 3.48 s. Under Fail-Storm Recovery, resilience also differs consistently across protocols. Beyond evaluation, we present ProtocolRouter, a learnable protocol router that selects per-scenario (or per-module) protocols from requirement and runtime signals. ProtocolRouter reduces Fail-Storm recovery time by up to 18.1% versus the best single-protocol baseline, and achieves scenario-specific gains such as higher success in GAIA. We also release ProtocolRouterBench to standardize protocol evaluation and improve reliability at scale."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          OmniVIC: A Self-Improving Variable Impedance Controller with Vision-Language In-Context Learning for Safe Robotic Manipulation", "authors": "Heng Zhang, Wei-Hsing Huang, Gokhan Solak, Arash Ajoudani", "subjects": "Robotics (cs.RO)", "abstract": "We present OmniVIC, a universal variable impedance controller (VIC) enhanced by a vision language model (VLM), which improves safety and adaptation in any contact-rich robotic manipulation task to enhance safe physical interaction. Traditional VIC have shown advantages when the robot physically interacts with the environment, but lack generalization in unseen, complex, and unstructured safe interactions in universal task scenarios involving contact or uncertainty. To this end, the proposed OmniVIC interprets task context derived reasoning from images and natural language and generates adaptive impedance parameters for a VIC controller. Specifically, the core of OmniVIC is a self-improving Retrieval-Augmented Generation(RAG) and in-context learning (ICL), where RAG retrieves relevant prior experiences from a structured memory bank to inform the controller about similar past tasks, and ICL leverages these retrieved examples and the prompt of current task to query the VLM for generating context-aware and adaptive impedance parameters for the current manipulation scenario. Therefore, a self-improved RAG and ICL guarantee OmniVIC works in universal task scenarios. The impedance parameter regulation is further informed by real-time force/torque feedback to ensure interaction forces remain within safe thresholds. We demonstrate that our method outperforms baselines on a suite of complex contact-rich tasks, both in simulation and on real-world robotic tasks, with improved success rates and reduced force violations. OmniVIC takes a step towards bridging high-level semantic reasoning and low-level compliant control, enabling safer and more generalizable manipulation. Overall, the average success rate increases from 27% (baseline) to 61.4% (OmniVIC)."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          HyperSearch: Prediction of New Hyperedges through Unconstrained yet Efficient Search", "authors": "Hyunjin Choo, Fanchen Bu, Hyunjin Hwang, Young-Gyu Yoon, Kijung Shin", "subjects": "Social and Information Networks (cs.SI); Machine Learning (cs.LG)", "abstract": "Higher-order interactions (HOIs) in complex systems, such as scientific collaborations, multi-protein complexes, and multi-user communications, are commonly modeled as hypergraphs, where each hyperedge (i.e., a subset of nodes) represents an HOI among the nodes. Given a hypergraph, hyperedge prediction aims to identify hyperedges that are either missing or likely to form in the future, and it has broad applications, including recommending interest-based social groups, predicting collaborations, and uncovering functional complexes in biological systems. However, the vast search space of hyperedge candidates (i.e., all possible subsets of nodes) poses a significant computational challenge, making naive exhaustive search infeasible. As a result, existing approaches rely on either heuristic sampling to obtain constrained candidate sets or ungrounded assumptions on hypergraph structure to select promising hyperedges. In this work, we propose HyperSearch, a search-based algorithm for hyperedge prediction that efficiently evaluates unconstrained candidate sets, by incorporating two key components: (1) an empirically grounded scoring function derived from observations in real-world hypergraphs and (2) an efficient search mechanism, where we derive and use an anti-monotonic upper bound of the original scoring function (which is not antimonotonic) to prune the search space. This pruning comes with theoretical guarantees, ensuring that discarded candidates are never better than the kept ones w.r.t. the original scoring function. In extensive experiments on 10 real-world hypergraphs across five domains, HyperSearch consistently outperforms state-of-the-art baselines, achieving higher accuracy in predicting new (i.e., not in the training set) hyperedges."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          A Data-Driven Framework for Online Mitigation of False Data Injection Signals in Networked Control Systems", "authors": "Mohammadamin Lari", "subjects": "Systems and Control (eess.SY)", "abstract": "This paper introduces a novel two-stage framework for online mitigation of False Data Injection (FDI) signals to improve the resiliency of Networked Control Systems (NCSs) and ensure their safe operation in the presence of malicious activities. The first stage involves meta learning to select a base time series forecasting model within a stacked ensemble learning architecture. This is achieved by converting time series data into scalograms using continuous wavelet transform, which are then split into image frames to generate a scalo-temporal representation of the data and to distinguish between different complexity levels of time series data based on an entropy metric using a convolutional neural network. In the second stage, the selected model mitigates false data injection signals in real-time. The proposed framework's effectiveness is demonstrated through rigorous simulations involving the formation control of differential drive mobile robots. By addressing the security challenges in NCSs, this framework offers a promising approach to maintaining system integrity and ensuring operational safety."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          GACO-CAD: Geometry-Augmented and Conciseness-Optimized CAD Model Generation from Single Image", "authors": "Yinghui Wang, Xinyu Zhang, Peng Du", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "abstract": "Generating editable, parametric CAD models from a single image holds great potential to lower the barriers of industrial concept design. However, current multi-modal large language models (MLLMs) still struggle with accurately inferring 3D geometry from 2D images due to limited spatial reasoning capabilities. We address this limitation by introducing GACO-CAD, a novel two-stage post-training framework. It is designed to achieve a joint objective: simultaneously improving the geometric accuracy of the generated CAD models and encouraging the use of more concise modeling procedures. First, during supervised fine-tuning, we leverage depth and surface normal maps as dense geometric priors, combining them with the RGB image to form a multi-channel input. In the context of single-view reconstruction, these priors provide complementary spatial cues that help the MLLM more reliably recover 3D geometry from 2D observations. Second, during reinforcement learning, we introduce a group length reward that, while preserving high geometric fidelity, promotes the generation of more compact and less redundant parametric modeling sequences. A simple dynamic weighting strategy is adopted to stabilize training. Experiments on the DeepCAD and Fusion360 datasets show that GACO-CAD achieves state-of-the-art performance under the same MLLM backbone, consistently outperforming existing methods in terms of code validity, geometric accuracy, and modeling conciseness."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Integrating Performance Tools in Model Reasoning for GPU Kernel Optimization", "authors": "Daniel Nichols, Konstantinos Parasyris, Charles Jekel, Abhinav Bhatele, Harshitha Menon", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC); Performance (cs.PF); Software Engineering (cs.SE)", "abstract": "Language models are now prevalent in software engineering with many developers using them to automate tasks and accelerate their development. While language models have been tremendous at accomplishing complex software engineering tasks, there are still many areas where they fail to deliver desirable results, for instance code performance related tasks. Tasks like optimization depend on many complex data from the environment, hardware, etc. that are not directly represented in source code. Recent efforts have seen large improvements in general code modeling tasks using chain-of-thought style reasoning, but these models still fail to comprehend how the environment interacts with code performance. In this paper we propose a methodology to train language models that can interact with performance tools during their reasoning process. We then demonstrate how this methodology can be used to train a state-of-the-art GPU kernel optimization model."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Learning After Model Deployment", "authors": "Derda Kaymak, Gyuhak Kim, Tomoya Kaichi, Tatsuya Konishi, Bing Liu", "subjects": "Machine Learning (cs.LG)", "abstract": "In classic supervised learning, once a model is deployed in an application, it is fixed. No updates will be made to it during the application. This is inappropriate for many dynamic and open environments, where unexpected samples from unseen classes may appear. In such an environment, the model should be able to detect these novel samples from unseen classes and learn them after they are labeled. We call this paradigm Autonomous Learning after Model Deployment (ALMD). The learning here is continuous and involves no human engineers. Labeling in this scenario is performed by human co-workers or other knowledgeable agents, which is similar to what humans do when they encounter an unfamiliar object and ask another person for its name. In ALMD, the detection of novel samples is dynamic and differs from traditional out-of-distribution (OOD) detection in that the set of in-distribution (ID) classes expands as new classes are learned during application, whereas ID classes is fixed in traditional OOD detection. Learning is also different from classic supervised learning because in ALMD, we learn the encountered new classes immediately and incrementally. It is difficult to retrain the model from scratch using all the past data from the ID classes and the novel samples from newly discovered classes, as this would be resource- and time-consuming. Apart from these two challenges, ALMD faces the data scarcity issue because instances of new classes often appear sporadically in real-life applications. To address these issues, we propose a novel method, PLDA, which performs dynamic OOD detection and incremental learning of new classes on the fly. Empirical evaluations will demonstrate the effectiveness of PLDA."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          ALPINE: A Lightweight and Adaptive Privacy-Decision Agent Framework for Dynamic Edge Crowdsensing", "authors": "Guanjie Cheng, Siyang Liu, Junqin Huang, Xinkui Zhao, Yin Wang, Mengying Zhu, Linghe Kong, Shuiguang Deng", "subjects": "Machine Learning (cs.LG)", "abstract": "Mobile edge crowdsensing (MECS) systems continuously generate and transmit user data in dynamic, resource-constrained environments, exposing users to significant privacy threats. In practice, many privacy-preserving mechanisms build on differential privacy (DP). However, static DP mechanisms often fail to adapt to evolving risks, for example, shifts in adversarial capabilities, resource constraints and task requirements, resulting in either excessive noise or inadequate protection. To address this challenge, we propose ALPINE, a lightweight, adaptive framework that empowers terminal devices to autonomously adjust differential privacy levels in real time. ALPINE operates as a closed-loop control system consisting of four modules: dynamic risk perception, privacy decision via twin delayed deep deterministic policy gradient (TD3), local privacy execution and performance verification from edge nodes. Based on environmental risk assessments, we design a reward function that balances privacy gains, data utility and energy cost, guiding the TD3 agent to adaptively tune noise magnitude across diverse risk scenarios and achieve a dynamic equilibrium among privacy, utility and cost. Both the collaborative risk model and pretrained TD3-based agent are designed for low-overhead deployment. Extensive theoretical analysis and real-world simulations demonstrate that ALPINE effectively mitigates inference attacks while preserving utility and cost, making it practical for large-scale edge applications."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          TREAT: A Code LLMs Trustworthiness / Reliability Evaluation and Testing Framework", "authors": "Shuzheng Gao, Eric John Li, Man Ho Lam, Jingyu Xiao, Yuxuan Wan, Chaozheng Wang, Ng Man Tik, Michael R. Lyu", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI)", "abstract": "Large foundation models are fundamentally transforming the software engineering landscape, demonstrating exceptional capabilities across diverse tasks such as code generation, debugging, and testing. Despite this rapid progress, a significant gap remains in how to comprehensively evaluate these models' trustworthiness in real-world software engineering scenarios. Existing benchmarks suffer from limited task scope and fail to incorporate critical evaluation aspects such as the robustness and reliability of models. To bridge this gap, we present an evaluation framework called TREAT (Code LLMs Trustworthiness / Reliability Evaluation And Testing) that provides a holistic assessment of model performance in code intelligence tasks. Our evaluation framework addresses key limitations in existing approaches with four main improvements: (1) Multi-Task Holistic Evaluation that spans diverse software engineering activities rather than limited coding tasks; (2) Multi-Language and Multi-Modality Assessment that extends beyond traditional single-language, text-only benchmarks to include multi-modality coding tasks; (3) Robustness Assessment that evaluates model reliability under semantically-preserving code transformations; and (4) Rigorous Evaluation Methodology that enhances the trustworthiness of evaluation results through diverse evaluation prompts and adaptive solution extraction. Based on this evaluation framework, we assess 26 state-of-the-art models and uncover both their strengths and limitations, yielding several key insights:(1) Current models show substantial performance variation across programming tasks; (2) Multi-modal language models demonstrate specific performance limitations in UI code generation and edit;"}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Software Testing with Large Language Models: An Interview Study with Practitioners", "authors": "Maria Deolinda Santana, Cleyton Magalhaes, Ronnie de Souza Santos", "subjects": "Software Engineering (cs.SE)", "abstract": "\\textit{Background:} The use of large language models in software testing is growing fast as they support numerous tasks, from test case generation to automation, and documentation. However, their adoption often relies on informal experimentation rather than structured guidance. \\textit{Aims:} This study investigates how software testing professionals use LLMs in practice to propose a preliminary, practitioner-informed guideline to support their integration into testing workflows. \\textit{Method:} We conducted a qualitative study with 15 software testers from diverse roles and domains. Data were collected through semi-structured interviews and analyzed using grounded theory-based processes focused on thematic analysis. \\textit{Results:} Testers described an iterative and reflective process that included defining testing objectives, applying prompt engineering strategies, refining prompts, evaluating outputs, and learning over time. They emphasized the need for human oversight and careful validation, especially due to known limitations of LLMs such as hallucinations and inconsistent reasoning. \\textit{Conclusions:} LLM adoption in software testing is growing, but remains shaped by evolving practices and caution around risks. This study offers a starting point for structuring LLM use in testing contexts and invites future research to refine these practices across teams, tools, and tasks."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Trading with the Devil: Risk and Return in Foundation Model Strategies", "authors": "Jinrui Zhang", "subjects": "Computational Engineering, Finance, and Science (cs.CE); Trading and Market Microstructure (q-fin.TR)", "abstract": "Foundation models - already transformative in domains such as natural language processing - are now starting to emerge for time-series tasks in finance. While these pretrained architectures promise versatile predictive signals, little is known about how they shape the risk profiles of the trading strategies built atop them, leaving practitioners reluctant to commit serious capital. In this paper, we propose an extension to the Capital Asset Pricing Model (CAPM) that disentangles the systematic risk introduced by a shared foundation model - potentially capable of generating alpha if the underlying model is genuinely predictive - from the idiosyncratic risk attributable to custom fine-tuning, which typically accrues no systematic premium. To enable a practical estimation of these separate risks, we align this decomposition with the concepts of uncertainty disentanglement, casting systematic risk as epistemic uncertainty (rooted in the pretrained model) and idiosyncratic risk as aleatory uncertainty (introduced during custom adaptations). Under the Aleatory Collapse Assumption, we illustrate how Monte Carlo dropout - among other methods in the uncertainty-quantization toolkit - can directly measure the epistemic risk, thereby mapping trading strategies to a more transparent risk-return plane. Our experiments show that isolating these distinct risk factors yields deeper insights into the performance limits of foundation-model-based strategies, their model degradation over time, and potential avenues for targeted refinements. Taken together, our results highlight both the promise and the pitfalls of deploying large pretrained models in competitive financial markets."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          When AI companions become witty: Can human brain recognize AI-generated irony?", "authors": "Xiaohui Rao, Hanlin Wu, Zhenguang G. Cai", "subjects": "Computation and Language (cs.CL)", "abstract": "As Large Language Models (LLMs) are increasingly deployed as social agents and trained to produce humor and irony, a question emerges: when encountering witty AI remarks, do people interpret these as intentional communication or mere computational output? This study investigates whether people adopt the intentional stance, attributing mental states to explain behavior,toward AI during irony comprehension. Irony provides an ideal paradigm because it requires distinguishing intentional contradictions from unintended errors through effortful semantic reanalysis. We compared behavioral and neural responses to ironic statements from AI versus human sources using established ERP components: P200 reflecting early incongruity detection and P600 indexing cognitive efforts in reinterpreting incongruity as deliberate irony. Results demonstrate that people do not fully adopt the intentional stance toward AI-generated irony. Behaviorally, participants attributed incongruity to deliberate communication for both sources, though significantly less for AI than human, showing greater tendency to interpret AI incongruities as computational errors. Neural data revealed attenuated P200 and P600 effects for AI-generated irony, suggesting reduced effortful detection and reanalysis consistent with diminished attribution of communicative intent. Notably, people who perceived AI as more sincere showed larger P200 and P600 effects for AI-generated irony, suggesting that intentional stance adoption is calibrated by specific mental models of artificial agents. These findings reveal that source attribution shapes neural processing of social-communicative phenomena. Despite current LLMs' linguistic sophistication, achieving genuine social agency requires more than linguistic competence, it necessitates a shift in how humans perceive and attribute intentionality to artificial agents."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Investigating Adversarial Robustness against Preprocessing used in Blackbox Face Recognition", "authors": "Roland Croft, Brian Du, Darcy Joseph, Sharath Kumar", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Face Recognition (FR) models have been shown to be vulnerable to adversarial examples that subtly alter benign facial images, exposing blind spots in these systems, as well as protecting user privacy. End-to-end FR systems first obtain preprocessed faces from diverse facial imagery prior to computing the similarity of the deep feature embeddings. Whilst face preprocessing is a critical component of FR systems, and hence adversarial attacks against them, we observe that this preprocessing is often overlooked in blackbox settings. Our study seeks to investigate the transferability of several out-of-the-box state-of-the-art adversarial attacks against FR when applied against different preprocessing techniques used in a blackbox setting. We observe that the choice of face detection model can degrade the attack success rate by up to 78%, whereas choice of interpolation method during downsampling has relatively minimal impacts. Furthermore, we find that the requirement for facial preprocessing even degrades attack strength in a whitebox setting, due to the unintended interaction of produced noise vectors against face detection models. Based on these findings, we propose a preprocessing-invariant method using input transformations that improves the transferability of the studied attacks by up to 27%. Our findings highlight the importance of preprocessing in FR systems, and the need for its consideration towards improving the adversarial generalisation of facial adversarial examples."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Generation then Reconstruction: Accelerating Masked Autoregressive Models via Two-Stage Sampling", "authors": "Feihong Yan, Peiru Wang, Yao Zhu, Kaiyu Pang, Qingyan Wei, Huiqi Li, Linfeng Zhang", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Masked Autoregressive (MAR) models promise better efficiency in visual generation than autoregressive (AR) models for the ability of parallel generation, yet their acceleration potential remains constrained by the modeling complexity of spatially correlated visual tokens in a single step. To address this limitation, we introduce Generation then Reconstruction (GtR), a training-free hierarchical sampling strategy that decomposes generation into two stages: structure generation establishing global semantic scaffolding, followed by detail reconstruction efficiently completing remaining tokens. Assuming that it is more difficult to create an image from scratch than to complement images based on a basic image framework, GtR is designed to achieve acceleration by computing the reconstruction stage quickly while maintaining the generation quality by computing the generation stage slowly. Moreover, observing that tokens on the details of an image often carry more semantic information than tokens in the salient regions, we further propose Frequency-Weighted Token Selection (FTS) to offer more computation budget to tokens on image details, which are localized based on the energy of high frequency information. Extensive experiments on ImageNet class-conditional and text-to-image generation demonstrate 3.72x speedup on MAR-H while maintaining comparable quality (e.g., FID: 1.59, IS: 304.4 vs. original 1.59, 299.1), substantially outperforming existing acceleration methods across various model scales and generation tasks. Our codes will be released in this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Combining ECG Foundation Model and XGBoost to Predict In-Hospital Malignant Ventricular Arrhythmias in AMI Patients", "authors": "Shun Huang, Wenlu Xing, Shijia Geng, Hailong Wang, Guangkun Nie, Gongzheng Tang, Chenyang He, Shenda Hong", "subjects": "Artificial Intelligence (cs.AI)", "abstract": "Malignant ventricular arrhythmias (VT/VF) following acute myocardial infarction (AMI) are a major cause of in-hospital death, yet early identification remains a clinical challenge. While traditional risk scores have limited performance, end-to-end deep learning models often lack the interpretability needed for clinical trust. This study aimed to develop a hybrid predictive framework that integrates a large-scale electrocardiogram (ECG) foundation model (ECGFounder) with an interpretable XGBoost classifier to improve both accuracy and interpretability. We analyzed 6,634 ECG recordings from AMI patients, among whom 175 experienced in-hospital VT/VF. The ECGFounder model was used to extract 150-dimensional diagnostic probability features , which were then refined through feature selection to train the XGBoost classifier. Model performance was evaluated using AUC and F1-score , and the SHAP method was used for interpretability. The ECGFounder + XGBoost hybrid model achieved an AUC of 0.801 , outperforming KNN (AUC 0.677), RNN (AUC 0.676), and an end-to-end 1D-CNN (AUC 0.720). SHAP analysis revealed that model-identified key features, such as \"premature ventricular complexes\" (risk predictor) and \"normal sinus rhythm\" (protective factor), were highly consistent with clinical knowledge. We conclude that this hybrid framework provides a novel paradigm for VT/VF risk prediction by validating the use of foundation model outputs as effective, automated feature engineering for building trustworthy, explainable AI-based clinical decision support systems."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Offline Policy Evaluation of Multi-Turn LLM Health Coaching with Real Users", "authors": "Melik Ozolcer, Sang Won Bae", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "abstract": "We study a web-deployed, tool-augmented LLM health coach with real users. In a pilot with seven users (280 rated turns), offline policy evaluation (OPE) over factorized decision heads (Tool/Style) shows that a uniform heavy-tool policy raises average value on logs but harms specific subgroups, most notably low-health-literacy/high-self-efficacy users. A lightweight simulator with hidden archetypes further shows that adding a small early information-gain bonus reliably shortens trait identification and improves goal success and pass@3. Together, these early findings indicate an evaluation-first path to personalization: freeze the generator, learn subgroup-aware decision heads on typed rewards (objective tool outcomes and satisfaction), and always report per-archetype metrics to surface subgroup harms that averages obscure."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          QR\u00efS: A Preemptive Novel Method for Quishing Detection Through Structural Features of QR", "authors": "Muhammad Wahid Akram, Keshav Sood, Muneeb Ul Hassan", "subjects": "Cryptography and Security (cs.CR); Machine Learning (cs.LG)", "abstract": "Globally, individuals and organizations employ Quick Response (QR) codes for swift and convenient communication. Leveraging this, cybercriminals embed falsify and misleading information in QR codes to launch various phishing attacks which termed as Quishing. Many former studies have introduced defensive approaches to preclude Quishing such as by classifying the embedded content of QR codes and then label the QR codes accordingly, whereas other studies classify them using visual features (i.e., deep features, histogram density analysis features). However, these approaches mainly rely on black-box techniques which do not clearly provide interpretability and transparency to fully comprehend and reproduce the intrinsic decision process; therefore, having certain obvious limitations includes the approaches' trust, accountability, issues in bias detection, and many more. We proposed QR\u00efS, the pioneer method to classify QR codes through the comprehensive structural analysis of a QR code which helps to identify phishing QR codes beforehand. Our classification method is clearly transparent which makes it reproducible, scalable, and easy to comprehend. First, we generated QR codes dataset (i.e. 400,000 samples) using recently published URLs datasets [1], [2]. Then, unlike black-box models, we developed a simple algorithm to extract 24 structural features from layout patterns present in QR codes. Later, we train the machine learning models on the harvested features and obtained accuracy of up to 83.18%. To further evaluate the effectiveness of our approach, we perform the comparative analysis of proposed method with relevant contemporary studies. Lastly, for real-world deployment and validation, we developed a mobile app which assures the feasibility of the proposed solution in real-world scenarios which eventually strengthen the applicability of the study."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Generalized Group Selection Strategies for Self-sustainable RIS-aided Communication", "authors": "Lakshmikanta Sau, Priyadarshi Mukherjee, Sasthi C. Ghosh", "subjects": "Systems and Control (eess.SY)", "abstract": "Reconfigurable intelligent surface (RIS) is a cutting-edge communication technology that has been proposed as aviable option for beyond fifth-generation wireless communication networks. This paper investigates various group selection strategies in the context of grouping-based self-sustainable RIS-aided device-to-device (D2D) communication with spatially correlated wireless channels. Specifically, we consider both power splitting (PS) and time switching (TS) configurations, of the self-sustainable RIS to analyze the system performance and propose appropriate bounds on the choice of system parameters. The analysis takes into account a simplified linear energy harvesting (EH) model as well as a practical non-linear EH model. Based on the application requirements, we propose various group selection strategies at the RIS. Notably, each strategy schedules the k-th best available group at the RIS based on the end-to-end signal-to-noise ratio (SNR) and also the energy harvested at a particular group of the RIS. Accordingly, by using tools from high order statistics, we derive analytical expressions for the outage probability of each selection strategy. Moreover, by applying the tools from extreme value theory, we also investigate an asymptotic scenario, where the number of groups available for selection at an RIS approaches infinity. The nontrivial insights obtained from this approach is especially beneficial in applications like large intelligent surface-aided wireless communication. Finally, the numerical results demonstrate the importance and benefits of the proposed approaches in terms of metrics such as the data throughput and the outage (both data and energy) performance."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Benchmarking Out-of-Distribution Detection for Plankton Recognition: A Systematic Evaluation of Advanced Methods in Marine Ecological Monitoring", "authors": "Yingzi Han, Jiakai He, Chuanlong Xie, Jianping Li", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "abstract": "Automated plankton recognition models face significant challenges during real-world deployment due to distribution shifts (Out-of-Distribution, OoD) between training and test data. This stems from plankton's complex morphologies, vast species diversity, and the continuous discovery of novel species, which leads to unpredictable errors during inference. Despite rapid advancements in OoD detection methods in recent years, the field of plankton recognition still lacks a systematic integration of the latest computer vision developments and a unified benchmark for large-scale evaluation. To address this, this paper meticulously designed a series of OoD benchmarks simulating various distribution shift scenarios based on the DYB-PlanktonNet dataset \\cite{875n-f104-21}, and systematically evaluated twenty-two OoD detection methods. Extensive experimental results demonstrate that the ViM \\cite{wang2022vim} method significantly outperforms other approaches in our constructed benchmarks, particularly excelling in Far-OoD scenarios with substantial improvements in key metrics. This comprehensive evaluation not only provides a reliable reference for algorithm selection in automated plankton recognition but also lays a solid foundation for future research in plankton OoD detection. To our knowledge, this study marks the first large-scale, systematic evaluation and analysis of Out-of-Distribution data detection methods in plankton recognition. Code is available at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Capturing Head Avatar with Hand Contacts from a Monocular Video", "authors": "Haonan He, Yufeng Zheng, Jie Song", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Photorealistic 3D head avatars are vital for telepresence, gaming, and VR. However, most methods focus solely on facial regions, ignoring natural hand-face interactions, such as a hand resting on the chin or fingers gently touching the cheek, which convey cognitive states like pondering. In this work, we present a novel framework that jointly learns detailed head avatars and the non-rigid deformations induced by hand-face interactions. There are two principal challenges in this task. First, naively tracking hand and face separately fails to capture their relative poses. To overcome this, we propose to combine depth order loss with contact regularization during pose tracking, ensuring correct spatial relationships between the face and hand. Second, no publicly available priors exist for hand-induced deformations, making them non-trivial to learn from monocular videos. To address this, we learn a PCA basis specific to hand-induced facial deformations from a face-hand interaction dataset. This reduces the problem to estimating a compact set of PCA parameters rather than a full spatial deformation field. Furthermore, inspired by physics-based simulation, we incorporate a contact loss that provides additional supervision, significantly reducing interpenetration artifacts and enhancing the physical plausibility of the results. We evaluate our approach on RGB(D) videos captured by an iPhone. Additionally, to better evaluate the reconstructed geometry, we construct a synthetic dataset of avatars with various types of hand interactions. We show that our method can capture better appearance and more accurate deforming geometry of the face than SOTA surface reconstruction methods."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Combinatorial Maximum Flow via Weighted Push-Relabel on Shortcut Graphs", "authors": "Aaron Bernstein, Joakim Blikstad, Jason Li, Thatchaphol Saranurak, Ta-Wei Tu", "subjects": "Data Structures and Algorithms (cs.DS)", "abstract": "We give a combinatorial algorithm for computing exact maximum flows in directed graphs with $n$ vertices and edge capacities from $\\{1,\\dots,U\\}$ in $\\tilde{O}(n^{2}\\log U)$ time, which is near-optimal on dense graphs. This shaves an $n^{o(1)}$ factor from the recent result of [Bernstein-Blikstad-Saranurak-Tu FOCS'24] and, more importantly, greatly simplifies their algorithm. We believe that ours is by a significant margin the simplest of all algorithms that go beyond $\\tilde{O}(m\\sqrt{n})$ time in general graphs. To highlight this relative simplicity, we provide a full implementation of the algorithm in C++. The only randomized component of our work is the cut-matching game. Via existing tools, we show how to derandomize it for vertex-capacitated max flow and obtain a deterministic $\\tilde{O}(n^2)$ time algorithm. This marks the first deterministic near-linear time algorithm for this problem (or even for the special case of bipartite matching) in any density regime."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          OLIVAW: ACIMOV's GitHub robot assisting agile collaborative ontology development", "authors": "Nicolas Robert (WIMMICS, Laboratoire I3S - SPARKS, UniCA, CNRS, I3S), Fabien Gandon (WIMMICS, Laboratoire I3S - SPARKS, CNRS, I3S), Maxime Lefran\u00e7ois (Mines Saint-\u00c9tienne MSE, LIMOS, FAYOL-ENSMSE, FAYOL-ENSMSE)", "subjects": "Software Engineering (cs.SE)", "abstract": "Agile and collaborative approaches to ontologies design are crucial because they contribute to making them userdriven, up-to-date, and able to evolve alongside the systems they support, hence proper continuous validation tooling is required to ensure ontologies match developers' requirements all along their development. We propose OLIVAW (Ontology Long-lived Integration Via ACIMOV Workflow), a tool supporting the ACIMOV methodology on GitHub. It relies on W3C Standards to assist the development of modular ontologies through GitHub Composite Actions, pre-commit hooks, or a command line interface. OLIVAW was tested on several ontology projects to ensure its usefulness, genericity and reusability. A template repository is available for a quick start. OLIVAW is"}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Robustness in Text-Attributed Graph Learning: Insights, Trade-offs, and New Defenses", "authors": "Runlin Lei, Lu Yi, Mingguo He, Pengyu Qiu, Zhewei Wei, Yongchao Liu, Chuntao Hong", "subjects": "Machine Learning (cs.LG)", "abstract": "While Graph Neural Networks (GNNs) and Large Language Models (LLMs) are powerful approaches for learning on Text-Attributed Graphs (TAGs), a comprehensive understanding of their robustness remains elusive. Current evaluations are fragmented, failing to systematically investigate the distinct effects of textual and structural perturbations across diverse models and attack scenarios. To address these limitations, we introduce a unified and comprehensive framework to evaluate robustness in TAG learning. Our framework evaluates classical GNNs, robust GNNs (RGNNs), and GraphLLMs across ten datasets from four domains, under diverse text-based, structure-based, and hybrid perturbations in both poisoning and evasion scenarios. Our extensive analysis reveals multiple findings, among which three are particularly noteworthy: 1) models have inherent robustness trade-offs between text and structure, 2) the performance of GNNs and RGNNs depends heavily on the text encoder and attack type, and 3) GraphLLMs are particularly vulnerable to training data corruption. To overcome the identified trade-offs, we introduce SFT-auto, a novel framework that delivers superior and balanced robustness against both textual and structural attacks within a single model. Our work establishes a foundation for future research on TAG security and offers practical solutions for robust TAG learning in adversarial environments. Our code is available at: this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          A Standardized Benchmark for Machine-Learned Molecular Dynamics using Weighted Ensemble Sampling", "authors": "Alexander Aghili, Andy Bruce, Daniel Sabo, Sanya Murdeshwar, Kevin Bachelor, Ionut Mistreanu, Ashwin Lokapally, Razvan Marinescu", "subjects": "Machine Learning (cs.LG); Biomolecules (q-bio.BM)", "abstract": "The rapid evolution of molecular dynamics (MD) methods, including machine-learned dynamics, has outpaced the development of standardized tools for method validation. Objective comparison between simulation approaches is often hindered by inconsistent evaluation metrics, insufficient sampling of rare conformational states, and the absence of reproducible benchmarks. To address these challenges, we introduce a modular benchmarking framework that systematically evaluates protein MD methods using enhanced sampling analysis. Our approach uses weighted ensemble (WE) sampling via The Weighted Ensemble Simulation Toolkit with Parallelization and Analysis (WESTPA), based on progress coordinates derived from Time-lagged Independent Component Analysis (TICA), enabling fast and efficient exploration of protein conformational space. The framework includes a flexible, lightweight propagator interface that supports arbitrary simulation engines, allowing both classical force fields and machine learning-based models. Additionally, the framework offers a comprehensive evaluation suite capable of computing more than 19 different metrics and visualizations across a variety of domains. We further contribute a dataset of nine diverse proteins, ranging from 10 to 224 residues, that span a variety of folding complexities and topologies. Each protein has been extensively simulated at 300K for one million MD steps per starting point (4 ns). To demonstrate the utility of our framework, we perform validation tests using classic MD simulations with implicit solvent and compare protein conformational sampling using a fully trained versus under-trained CGSchNet model. By standardizing evaluation protocols and enabling direct, reproducible comparisons across MD approaches, our open-source platform lays the groundwork for consistent, rigorous benchmarking across the molecular simulation community."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          HIDISC: A Hyperbolic Framework for Domain Generalization with Generalized Category Discovery", "authors": "Vaibhav Rathore, Divyam Gupta, Biplab Banerjee", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Generalized Category Discovery (GCD) aims to classify test-time samples into either seen categories** -- available during training -- or novel ones, without relying on label supervision. Most existing GCD methods assume simultaneous access to labeled and unlabeled data during training and arising from the same domain, limiting applicability in open-world scenarios involving distribution shifts. Domain Generalization with GCD (DG-GCD) lifts this constraint by requiring models to generalize to unseen domains containing novel categories, without accessing targetdomain data during training. The only prior DG-GCD method, DG2CD-Net, relies on episodic training with multiple synthetic domains and task vector aggregation, incurring high computational cost and error accumulation. We propose HIDISC, a hyperbolic representation learning framework that achieves domain and category-level generalization without episodic simulation. To expose the model to minimal but diverse domain variations, we augment the source domain using GPT-guided diffusion, avoiding overfitting while maintaining efficiency. To structure the representation space, we introduce Tangent CutMix, a curvature-aware interpolation that synthesizes pseudo-novel samples in tangent space, preserving manifold consistency. A unified loss -- combining penalized Busemann alignment, hybrid hyperbolic contrastive regularization, and adaptive outlier repulsion -- **facilitates compact, semantically structured embeddings. A learnable curvature parameter further adapts the geometry to dataset complexity. HIDISC achieves state-of-the-art results on PACS , Office-Home , and DomainNet, consistently outperforming the existing Euclidean and hyperbolic (DG)-GCD baselines."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          SOLE: Hardware-Software Co-design of Softmax and LayerNorm for Efficient Transformer Inference", "authors": "Wenxun Wang, Shuchang Zhou, Wenyu Sun, Peiqin Sun, Yongpan Liu", "subjects": "Machine Learning (cs.LG); Hardware Architecture (cs.AR)", "abstract": "Transformers have shown remarkable performance in both natural language processing (NLP) and computer vision (CV) tasks. However, their real-time inference speed and efficiency are limited due to the inefficiency in Softmax and Layer Normalization (LayerNorm). Previous works based on function approximation suffer from inefficient implementation as they place emphasis on computation while disregarding memory overhead concerns. Moreover, such methods rely on retraining to compensate for approximation error which can be costly and inconvenient. In this paper, we present SOLE, a hardware-software co-design for Softmax and LayerNorm which is composed of E2Softmax and AILayerNorm. E2Softmax utilizes log2 quantization of exponent function and log-based division to approximate Softmax while AILayerNorm adopts low-precision statistic calculation. Compared with state-of-the-art designs, we achieve both low-precision calculation and low bit-width storage on Softmax and LayerNorm. Experiments show that SOLE maintains inference accuracy without retraining while offering orders of magnitude speedup and energy savings over GPU, achieving 3.04x, 3.86x energy-efficiency improvements and 2.82x, 3.32x area-efficiency improvements over prior state-of-the-art custom hardware for Softmax and LayerNorm, respectively."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          SimpleVSF: VLM-Scoring Fusion for Trajectory Prediction of End-to-End Autonomous Driving", "authors": "Peiru Zheng, Yun Zhao, Zhan Gong, Hong Zhu, Shaohua Wu", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI)", "abstract": "End-to-end autonomous driving has emerged as a promising paradigm for achieving robust and intelligent driving policies. However, existing end-to-end methods still face significant challenges, such as suboptimal decision-making in complex scenarios. In this paper,we propose SimpleVSF (Simple VLM-Scoring Fusion), a novel framework that enhances end-to-end planning by leveraging the cognitive capabilities of Vision-Language Models (VLMs) and advanced trajectory fusion techniques. We utilize the conventional scorers and the novel VLM-enhanced scorers. And we leverage a robust weight fusioner for quantitative aggregation and a powerful VLM-based fusioner for qualitative, context-aware decision-making. As the leading approach in the ICCV 2025 NAVSIM v2 End-to-End Driving Challenge, our SimpleVSF framework demonstrates state-of-the-art performance, achieving a superior balance between safety, comfort, and efficiency."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Understanding and Improving Length Generalization in Hierarchical Sparse Attention Models", "authors": "Jiaqi Leng, Xiang Hu, Junxiong Wang, Jianguo Li, Wei Wu, Yucheng Lu", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "abstract": "Effectively processing long contexts is a critical challenge for language models. While standard Transformers are limited by quadratic complexity and poor length extrapolation, alternative architectures like sliding window attention and state space models sacrifice the ability to effectively utilize the full context due to their fixed-size memory. Chunk-based sparse attention has emerged as a promising paradigm for extreme length generalization, yet the key architectural principles underpinning its success are not yet fully understood. In this work, we present a systematic dissection of these models to identify the core components driving their performance. Through a unified framework and comprehensive ablation studies, we demonstrate that a combination of three design principles is critical: (1) an expressive, non-linear Chunk Encoder with a dedicated CLS token to produce representations for retrieval; (2) a Bypassing Residual Path to stably integrate retrieved global information without it being overridden by the local residual stream; and (3) enforced selection sparsity during pre-training to bridge the train-test distribution gap. We provide a theoretical motivation for intra-chunk information processing and landmark generation. By combining these principles, we establish a new state-of-the-art for training-free length extrapolation, successfully generalizing models trained on a 4K context to 32 million tokens on RULER and BABILong. Our findings provide a clear and empirically-grounded set of design principles for developing future, highly-capable long-context language models."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          ZSPAPrune: Zero-Shot Prompt-Aware Token Pruning for Vision-Language Models", "authors": "Pu Zhang, Yuwei Li, Xingyuan Xian, Guoming Tang", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "abstract": "As the capabilities of Vision-Language Models (VLMs) advance, they can process increasingly large inputs, which, unlike in LLMs, generates significant visual token redundancy and leads to prohibitive inference costs. While many methods aim to reduce these costs by pruning visual tokens, existing approaches, whether based on attention or diversity, typically neglect the guidance of the text prompt and thus fail to prioritize task relevance. In this work, we propose a novel, zero-shot method that reframes the problem by introducing a prompt-aware perspective, explicitly modeling visual token pruning as a balance between task relevance and information diversity. Our hierarchical approach first selects a core set of task-relevant visual tokens and then supplements them with diversity tokens to preserve broader context. Experiments across multiple models and benchmarks show that our method achieves performance that matches or surpasses the state-of-the-art with only minimal accuracy loss, even when pruning up to 90\\% of the tokens. Furthermore, these gains are accompanied by significant reductions in GPU memory footprint and inference latency."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          From Pixels to People: Satellite-Based Mapping and Quantification of Riverbank Erosion and Lost Villages in Bangladesh", "authors": "M Saifuzzaman Rafat, Mohd Ruhul Ameen, Akif Islam, Abu Saleh Musa Miah, Jungpil Shin", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "abstract": "The great rivers of Bangladesh, arteries of commerce and sustenance, are also agents of relentless destruction. Each year, they swallow whole villages and vast tracts of farmland, erasing communities from the map and displacing thousands of families. To track this slow-motion catastrophe has, until now, been a Herculean task for human analysts. Here we show how a powerful general-purpose vision model, the Segment Anything Model (SAM), can be adapted to this task with remarkable precision. To do this, we assembled a new dataset - a digital chronicle of loss compiled from historical Google Earth imagery of Bangladesh's most vulnerable regions, including Mokterer Char Union, Kedarpur Union, Balchipara village, and Chowhali Upazila, from 2003 to 2025. Crucially, this dataset is the first to include manually annotated data on the settlements that have vanished beneath the water. Our method first uses a simple color-channel analysis to provide a rough segmentation of land and water, and then fine-tunes SAM's mask decoder to recognize the subtle signatures of riverbank erosion. The resulting model demonstrates a keen eye for this destructive process, achieving a mean Intersection over Union of 86.30% and a Dice score of 92.60% - a performance that significantly surpasses traditional methods and off-the-shelf deep learning models. This work delivers three key contributions: the first annotated dataset of disappeared settlements in Bangladesh due to river erosion; a specialized AI model fine-tuned for this critical task; and a method for quantifying land loss with compelling visual evidence. Together, these tools provide a powerful new lens through which policymakers and disaster management agencies can monitor erosion, anticipate its trajectory, and ultimately protect the vulnerable communities in its path."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Round Outcome Prediction in VALORANT Using Tactical Features from Video Analysis", "authors": "Nirai Hayakawa, Kazumasa Shimari, Kazuma Yamasaki, Hirotatsu Hoshikawa, Rikuto Tsuchida, Kenichi Matsumoto", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "abstract": "Recently, research on predicting match outcomes in esports has been actively conducted, but much of it is based on match log data and statistical information. This research targets the FPS game VALORANT, which requires complex strategies, and aims to build a round outcome prediction model by analyzing minimap information in match footage. Specifically, based on the video recognition model TimeSformer, we attempt to improve prediction accuracy by incorporating detailed tactical features extracted from minimap information, such as character position information and other in-game events. This paper reports preliminary results showing that a model trained on a dataset augmented with such tactical event labels achieved approximately 81% prediction accuracy, especially from the middle phases of a round onward, significantly outperforming a model trained on a dataset with the minimap information itself. This suggests that leveraging tactical features from match footage is highly effective for predicting round outcomes in VALORANT."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          EndoCIL: A Class-Incremental Learning Framework for Endoscopic Image Classification", "authors": "Bingrong Liu, Jun Shi, Yushan Zheng", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Class-incremental learning (CIL) for endoscopic image analysis is crucial for real-world clinical applications, where diagnostic models should continuously adapt to evolving clinical data while retaining performance on previously learned ones. However, existing replay-based CIL methods fail to effectively mitigate catastrophic forgetting due to severe domain discrepancies and class imbalance inherent in endoscopic imaging. To tackle these challenges, we propose EndoCIL, a novel and unified CIL framework specifically tailored for endoscopic image diagnosis. EndoCIL incorporates three key components: Maximum Mean Discrepancy Based Replay (MDBR), employing a distribution-aligned greedy strategy to select diverse and representative exemplars, Prior Regularized Class Balanced Loss (PRCBL), designed to alleviate both inter-phase and intra-phase class imbalance by integrating prior class distributions and balance weights into the loss function, and Calibration of Fully-Connected Gradients (CFG), which adjusts the classifier gradients to mitigate bias toward new classes. Extensive experiments conducted on four public endoscopic datasets demonstrate that EndoCIL generally outperforms state-of-the-art CIL methods across varying buffer sizes and evaluation metrics. The proposed framework effectively balances stability and plasticity in lifelong endoscopic diagnosis, showing promising potential for clinical scalability and deployment."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Optimizing DINOv2 with Registers for Face Anti-Spoofing", "authors": "Mika Feng, Pierre Gallin-Martel, Koichi Ito, Takafumi Aoki", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Face recognition systems are designed to be robust against variations in head pose, illumination, and image blur during capture. However, malicious actors can exploit these systems by presenting a face photo of a registered user, potentially bypassing the authentication process. Such spoofing attacks must be detected prior to face recognition. In this paper, we propose a DINOv2-based spoofing attack detection method to discern minute differences between live and spoofed face images. Specifically, we employ DINOv2 with registers to extract generalizable features and to suppress perturbations in the attention mechanism, which enables focused attention on essential and minute features. We demonstrate the effectiveness of the proposed method through experiments conducted on the dataset provided by ``The 6th Face Anti-Spoofing Workshop: Unified Physical-Digital Attacks Detection@ICCV2025'' and SiW dataset."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Performance Evaluation of an Integrated System for Visible Light Communication and Positioning Using an Event Camera", "authors": "Ryota Soga, Masataka Kobayashi, Tsukasa Shimizu, Shintaro Shiba, Quan Kong, Shan Lu, Takaya Yamazato", "subjects": "Robotics (cs.RO)", "abstract": "Event cameras, featuring high temporal resolution and high dynamic range, offer visual sensing capabilities comparable to conventional image sensors while capturing fast-moving objects and handling scenes with extreme lighting contrasts such as tunnel exits. Leveraging these properties, this study proposes a novel self-localization system that integrates visible light communication (VLC) and visible light positioning (VLP) within a single event camera. The system enables a vehicle to estimate its position even in GPS-denied environments, such as tunnels, by using VLC to obtain coordinate information from LED transmitters and VLP to estimate the distance to each transmitter. Multiple LEDs are installed on the transmitter side, each assigned a unique pilot sequence based on Walsh-Hadamard codes. The event camera identifies individual LEDs within its field of view by correlating the received signal with these codes, allowing clear separation and recognition of each light source. This mechanism enables simultaneous high-capacity MISO (multi-input single-output) communication through VLC and precise distance estimation via phase-only correlation (POC) between multiple LED pairs. To the best of our knowledge, this is the first vehicle-mounted system to achieve simultaneous VLC and VLP functionalities using a single event camera. Field experiments were conducted by mounting the system on a vehicle traveling at 30 km/h (8.3 m/s). The results demonstrated robust real-world performance, with a root mean square error (RMSE) of distance estimation within 0.75 m for ranges up to 100 m and a bit error rate (BER) below 0.01 across the same range."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          $\\mathcal{V}isi\\mathcal{P}runer$: Decoding Discontinuous Cross-Modal Dynamics for Efficient Multimodal LLMs", "authors": "Yingqi Fan, Anhao Zhao, Jinlan Fu, Junlong Tong, Hui Su, Yijie Pan, Wei Zhang, Xiaoyu Shen", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Computation and Language (cs.CL)", "abstract": "Multimodal Large Language Models (MLLMs) have achieved strong performance across vision-language tasks, but suffer from significant computational overhead due to the quadratic growth of attention computations with the number of multimodal tokens. Though efforts have been made to prune tokens in MLLMs, \\textit{they lack a fundamental understanding of how MLLMs process and fuse multimodal information.} Through systematic analysis, we uncover a \\textbf{three-stage} cross-modal interaction process: (1) Shallow layers recognize task intent, with visual tokens acting as passive attention sinks; (2) Cross-modal fusion occurs abruptly in middle layers, driven by a few critical visual tokens; (3) Deep layers discard vision tokens, focusing solely on linguistic refinement. Based on these findings, we propose \\emph{VisiPruner}, a training-free pruning framework that reduces up to 99\\% of vision-related attention computations and 53.9\\% of FLOPs on LLaVA-v1.5 7B. It significantly outperforms existing token pruning methods and generalizes across diverse MLLMs. Beyond pruning, our insights further provide actionable guidelines for training efficient MLLMs by aligning model architecture with its intrinsic layer-wise processing dynamics. Our code is available at: this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Soft-Masked Diffusion Language Models", "authors": "Michael Hersche, Samuel Moor-Smith, Thomas Hofmann, Abbas Rahimi", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "abstract": "Diffusion models have demonstrated strong potential in language modeling, offering various advantages over traditional autoregressive approaches. Their ability to generate and revise entire responses in parallel enables faster generation and built-in self-correction mechanisms. Most modern diffusion-based language models employ masked diffusion, where decoding involves iteratively processing masked tokens based on a binary decision: either retaining the mask or replacing it with the predicted token. However, this binary choice discards valuable predictive information when the mask is retained. To address this limitation, we introduce soft-masking (SM), a novel method that dynamically blends the embedding of the mask token with the embeddings of the top-$k$ predicted tokens from the previous decoding step, for each retained mask. This provides the model with a more informative prior, preserving context from earlier computations and allowing partial information about masked tokens to propagate beyond a single step. We propose a training methodology that adapts a pretrained masked diffusion language model to incorporate SM. We demonstrate that continuing pretraining a 169M parameter model with SM leads to improved perplexity and MAUVE scores. Furthermore, we finetune two state-of-the-art diffusion models, Dream-7B and Dream-Coder-7B, with SM. SM consistently improves performance across multiple coding benchmarks, particularly in high-throughput settings."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Wisdom is Knowing What not to Say: Hallucination-Free LLMs Unlearning via Attention Shifting", "authors": "Chenchen Tan, Youyang Qu, Xinghao Li, Hui Zhang, Shujie Cui, Cunjian Chen, Longxiang Gao", "subjects": "Computation and Language (cs.CL)", "abstract": "The increase in computing power and the necessity of AI-assisted decision-making boost the growing application of large language models (LLMs). Along with this, the potential retention of sensitive data of LLMs has spurred increasing research into machine unlearning. However, existing unlearning approaches face a critical dilemma: Aggressive unlearning compromises model utility, while conservative strategies preserve utility but risk hallucinated responses. This significantly limits LLMs' reliability in knowledge-intensive applications. To address this, we introduce a novel Attention-Shifting (AS) framework for selective unlearning. AS is driven by two design objectives: (1) context-preserving suppression that attenuates attention to fact-bearing tokens without disrupting LLMs' linguistic structure; and (2) hallucination-resistant response shaping that discourages fabricated completions when queried about unlearning content. AS realizes these objectives through two attention-level interventions, which are importance-aware suppression applied to the unlearning set to reduce reliance on memorized knowledge and attention-guided retention enhancement that reinforces attention toward semantically essential tokens in the retained dataset to mitigate unintended degradation. These two components are jointly optimized via a dual-loss objective, which forms a soft boundary that localizes unlearning while preserving unrelated knowledge under representation superposition. Experimental results show that AS improves performance preservation over the state-of-the-art unlearning methods, achieving up to 15% higher accuracy on the ToFU benchmark and 10% on the TDEC benchmark, while maintaining competitive hallucination-free unlearning effectiveness. Compared to existing methods, AS demonstrates a superior balance between unlearning effectiveness, generalization, and response reliability."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Temporally Detailed Hypergraph Neural ODEs for Type 2 Diabetes Progression Modeling", "authors": "Tingsong Xiao, Yao An Lee, Zelin Xu, Yupu Zhang, Zibo Liu, Yu Huang, Jiang Bian, Serena Jingchuan Guo, Zhe Jiang", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "abstract": "Disease progression modeling aims to characterize and predict how a patient's disease complications worsen over time based on longitudinal electronic health records (EHRs). Accurate modeling of disease progression, such as type 2 diabetes, can enhance patient sub-phenotyping and inform effective and timely interventions. However, the problem is challenging due to the need to learn continuous-time dynamics of progression patterns based on irregular-time event samples and patient heterogeneity (\\eg different progression rates and pathways). Existing mechanistic and data-driven methods either lack adaptability to learn from real-world data or fail to capture complex continuous-time dynamics on progression trajectories. To address these limitations, we propose Temporally Detailed Hypergraph Neural Ordinary Differential Equation (TD-HNODE), which represents disease progression on clinically recognized trajectories as a temporally detailed hypergraph and learns the continuous-time progression dynamics via a neural ODE framework. TD-HNODE contains a learnable TD-Hypergraph Laplacian that captures the interdependency of disease complication markers within both intra- and inter-progression trajectories. Experiments on two real-world clinical datasets demonstrate that TD-HNODE outperforms multiple baselines in modeling the progression of type 2 diabetes and related cardiovascular diseases."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          D2C-HRHR: Discrete Actions with Double Distributional Critics for High-Risk-High-Return Tasks", "authors": "Jundong Zhang, Yuhui Situ, Fanji Zhang, Rongji Deng, Tianqi Wei", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "Tasks involving high-risk-high-return (HRHR) actions, such as obstacle crossing, often exhibit multimodal action distributions and stochastic returns. Most reinforcement learning (RL) methods assume unimodal Gaussian policies and rely on scalar-valued critics, which limits their effectiveness in HRHR settings. We formally define HRHR tasks and theoretically show that Gaussian policies cannot guarantee convergence to the optimal solution. To address this, we propose a reinforcement learning framework that (i) discretizes continuous action spaces to approximate multimodal distributions, (ii) employs entropy-regularized exploration to improve coverage of risky but rewarding actions, and (iii) introduces a dual-critic architecture for more accurate discrete value distribution estimation. The framework scales to high-dimensional action spaces, supporting complex control domains. Experiments on locomotion and manipulation benchmarks with high risks of failure demonstrate that our method outperforms baselines, underscoring the importance of explicitly modeling multimodality and risk in RL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Diagnosis of Fuel Cell Health Status with Deep Sparse Auto-Encoder Neural Network", "authors": "Chenyan Fei, Dalin Zhang, Chen Melinda Dang", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "Effective and accurate diagnosis of fuel cell health status is crucial for ensuring the stable operation of fuel cell stacks. Among various parameters, high-frequency impedance serves as a critical indicator for assessing fuel cell state and health conditions. However, its online testing is prohibitively complex and costly. This paper employs a deep sparse auto-encoding network for the prediction and classification of high-frequency impedance in fuel cells, achieving metric of accuracy rate above 92\\%. The network is further deployed on an FPGA, attaining a hardware-based recognition rate almost 90\\%."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          When One Moment Isn't Enough: Multi-Moment Retrieval with Cross-Moment Interactions", "authors": "Zhuo Cao, Heming Du, Bingqing Zhang, Xin Yu, Xue Li, Sen Wang", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "abstract": "Existing Moment retrieval (MR) methods focus on Single-Moment Retrieval (SMR). However, one query can correspond to multiple relevant moments in real-world applications. This makes the existing datasets and methods insufficient for video temporal grounding. By revisiting the gap between current MR tasks and real-world applications, we introduce a high-quality datasets called QVHighlights Multi-Moment Dataset (QV-M$^2$), along with new evaluation metrics tailored for multi-moment retrieval (MMR). QV-M$^2$ consists of 2,212 annotations covering 6,384 video segments. Building on existing efforts in MMR, we propose a framework called FlashMMR. Specifically, we propose a Multi-moment Post-verification module to refine the moment boundaries. We introduce constrained temporal adjustment and subsequently leverage a verification module to re-evaluate the candidate segments. Through this sophisticated filtering pipeline, low-confidence proposals are pruned, and robust multi-moment alignment is achieved. We retrain and evaluate 6 existing MR methods on QV-M$^2$ and QVHighlights under both SMR and MMR settings. Results show that QV-M$^2$ serves as an effective benchmark for training and evaluating MMR models, while FlashMMR provides a strong baseline. Specifically, on QV-M$^2$, it achieves improvements over prior SOTA method by 3.00% on G-mAP, 2.70% on mAP@3+tgt, and 2.56% on mR@3. The proposed benchmark and method establish a foundation for advancing research in more realistic and challenging video temporal grounding scenarios. Code is released at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Exploiting the Potential of Linearity in Automatic Differentiation and Computational Cryptography", "authors": "Giulia Giusti", "subjects": "Cryptography and Security (cs.CR); Logic in Computer Science (cs.LO); Programming Languages (cs.PL)", "abstract": "The concept of linearity plays a central role in both mathematics and computer science, with distinct yet complementary meanings. In mathematics, linearity underpins functions and vector spaces, forming the foundation of linear algebra and functional analysis. In computer science, it relates to resource-sensitive computation. Linear Logic (LL), for instance, models assumptions that must be used exactly once, providing a natural framework for tracking computational resources such as time, memory, or data access. This dual perspective makes linearity essential to programming languages, type systems, and formal models that express both computational complexity and composability. Bridging these interpretations enables rigorous yet practical methodologies for analyzing and verifying complex systems. This thesis explores the use of LL to model programming paradigms based on linearity. It comprises two parts: ADLL and CryptoBLL. The former applies LL to Automatic Differentiation (AD), modeling linear functions over the reals and the transposition operation. The latter uses LL to express complexity constraints on adversaries in computational cryptography. In AD, two main approaches use linear type systems: a theoretical one grounded in proof theory, and a practical one implemented in JAX, a Python library developed by Google for machine learning research. In contrast, frameworks like PyTorch and TensorFlow support AD without linear types. ADLL aims to bridge theory and practice by connecting JAX's type system to LL. In modern cryptography, several calculi aim to model cryptographic proofs within the computational paradigm. These efforts face a trade-off between expressiveness, to capture reductions, and simplicity, to abstract probability and complexity. CryptoBLL addresses this tension by proposing a framework for the automatic analysis of protocols in computational cryptography."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Opinion Maximization in Social Networks by Modifying Internal Opinions", "authors": "Gengyu Wang, Runze Zhang, Zhongzhi Zhang", "subjects": "Social and Information Networks (cs.SI); Data Structures and Algorithms (cs.DS)", "abstract": "Public opinion governance in social networks is critical for public health campaigns, political elections, and commercial marketing. In this paper, we addresse the problem of maximizing overall opinion in social networks by strategically modifying the internal opinions of key nodes. Traditional matrix inversion methods suffer from prohibitively high computational costs, prompting us to propose two efficient sampling-based algorithms. Furthermore, we develop a deterministic asynchronous algorithm that exactly identifies the optimal set of nodes through asynchronous update operations and progressive refinement, ensuring both efficiency and precision. Extensive experiments on real-world datasets demonstrate that our methods outperform baseline approaches. Notably, our asynchronous algorithm delivers exceptional efficiency and accuracy across all scenarios, even in networks with tens of millions of nodes."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          DSEBench: A Test Collection for Explainable Dataset Search with Examples", "authors": "Qing Shi, Jing He, Qiaosheng Chen, Gong Cheng", "subjects": "Information Retrieval (cs.IR)", "abstract": "Dataset search has been an established information retrieval task. Current paradigms either retrieve datasets that are relevant to a keyword query or find datasets that are similar to an input target dataset. To allow for their combined specification of information needs, in this article, we investigate the more generalized task of Dataset Search with Examples (DSE) and further extend it to Explainable DSE that requires identifying the metadata and content fields of a dataset that indicate its relevance to the query and similarity to the target datasets. To facilitate this research, we construct DSEBench, a test collection that provides high-quality dataset- and field-level annotations to enable the evaluation of explainable DSE. We also employ a large language model to generate numerous annotations to be used for training. We establish extensive baselines on DSEBench by adapting and evaluating a variety of sparse, dense, and LLM-based retrieval, reranking, and explanation methods."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Taming Modality Entanglement in Continual Audio-Visual Segmentation", "authors": "Yuyang Hong, Qi Yang, Tao Zhang, Zili Wang, Zhaojin Fu, Kun Ding, Bin Fan, Shiming Xiang", "subjects": "Multimedia (cs.MM); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Recently, significant progress has been made in multi-modal continual learning, aiming to learn new tasks sequentially in multi-modal settings while preserving performance on previously learned ones. However, existing methods mainly focus on coarse-grained tasks, with limitations in addressing modality entanglement in fine-grained continual learning settings. To bridge this gap, we introduce a novel Continual Audio-Visual Segmentation (CAVS) task, aiming to continuously segment new classes guided by audio. Through comprehensive analysis, two critical challenges are identified: 1) multi-modal semantic drift, where a sounding objects is labeled as background in sequential tasks; 2) co-occurrence confusion, where frequent co-occurring classes tend to be confused. In this work, a Collision-based Multi-modal Rehearsal (CMR) framework is designed to address these challenges. Specifically, for multi-modal semantic drift, a Multi-modal Sample Selection (MSS) strategy is proposed to select samples with high modal consistency for rehearsal. Meanwhile, for co-occurence confusion, a Collision-based Sample Rehearsal (CSR) mechanism is designed, allowing for the increase of rehearsal sample frequency of those confusable classes during training process. Moreover, we construct three audio-visual incremental scenarios to verify effectiveness of our method. Comprehensive experiments demonstrate that our method significantly outperforms single-modal continual learning methods."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Coinvisor: An RL-Enhanced Chatbot Agent for Interactive Cryptocurrency Investment Analysis", "authors": "Chong Chen, Ze Liu, Lingfeng Bao, Yanlin Wang, Ting Chen, Daoyuan Wu, Jiachi Chen", "subjects": "Artificial Intelligence (cs.AI)", "abstract": "The cryptocurrency market offers significant investment opportunities but faces challenges including high volatility and fragmented information. Data integration and analysis are essential for informed investment decisions. Currently, investors use three main approaches: (1) Manual analysis across various sources, which depends heavily on individual experience and is time-consuming and prone to bias; (2) Data aggregation platforms-limited in functionality and depth of analysis; (3) Large language model agents-based on static pretrained models, lacking real-time data integration and multi-step reasoning capabilities. To address these limitations, we present Coinvisor, a reinforcement learning-based chatbot that provides comprehensive analytical support for cryptocurrency investment through a multi-agent framework. Coinvisor integrates diverse analytical capabilities through specialized tools. Its key innovation is a reinforcement learning-based tool selection mechanism that enables multi-step planning and flexible integration of diverse data sources. This design supports real-time interaction and adaptive analysis of dynamic content, delivering accurate and actionable investment insights. We evaluated Coinvisor through automated benchmarks on tool calling accuracy and user studies with 20 cryptocurrency investors using our interface. Results show that Coinvisor improves recall by 40.7% and F1 score by 26.6% over the base model in tool orchestration. User studies show high satisfaction (4.64/5), with participants preferring Coinvisor to both general LLMs and existing crypto platforms (4.62/5)."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Pole-Image: A Self-Supervised Pole-Anchored Descriptor for Long-Term LiDAR Localization and Map Maintenance", "authors": "Wuhao Xie, Kanji Tanaka", "subjects": "Robotics (cs.RO)", "abstract": "Long-term autonomy for mobile robots requires both robust self-localization and reliable map maintenance. Conventional landmark-based methods face a fundamental trade-off between landmarks with high detectability but low distinctiveness (e.g., poles) and those with high distinctiveness but difficult stable detection (e.g., local point cloud structures). This work addresses the challenge of descriptively identifying a unique \"signature\" (local point cloud) by leveraging a detectable, high-precision \"anchor\" (like a pole). To solve this, we propose a novel canonical representation, \"Pole-Image,\" as a hybrid method that uses poles as anchors to generate signatures from the surrounding 3D structure. Pole-Image represents a pole-like landmark and its surrounding environment, detected from a LiDAR point cloud, as a 2D polar coordinate image with the pole itself as the origin. This representation leverages the pole's nature as a high-precision reference point, explicitly encoding the \"relative geometry\" between the stable pole and the variable surrounding point cloud. The key advantage of pole landmarks is that \"detection\" is extremely easy. This ease of detection allows the robot to easily track the same pole, enabling the automatic and large-scale collection of diverse observational data (positive pairs). This data acquisition feasibility makes \"Contrastive Learning (CL)\" applicable. By applying CL, the model learns a viewpoint-invariant and highly discriminative descriptor. The contributions are twofold: 1) The descriptor overcomes perceptual aliasing, enabling robust self-localization. 2) The high-precision encoding enables high-sensitivity change detection, contributing to map maintenance."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          StreamingThinker: Large Language Models Can Think While Reading", "authors": "Junlong Tong, Yingqi Fan, Anhao Zhao, Yunpu Ma, Xiaoyu Shen", "subjects": "Computation and Language (cs.CL)", "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities in chain of thought (CoT) reasoning. However, the current LLM reasoning paradigm initiates thinking only after the entire input is available, which introduces unnecessary latency and weakens attention to earlier information in dynamic scenarios. Inspired by human cognition of thinking while reading, we first design a \\textit{\\textbf{streaming thinking}} paradigm for LLMs, where reasoning unfolds in the order of input and further adjusts its depth once reading is complete. We instantiate this paradigm with \\textit{StreamingThinker}, a framework that enables LLMs to think while reading through the integration of streaming CoT generation, streaming-constraint training, and streaming parallel inference. Specifically, StreamingThinker employs streaming reasoning units with quality control for CoT generation, enforces order-preserving reasoning through streaming attention masks and position encoding, and leverages parallel KV caches that decouple input encoding from reasoning generation, thereby ensuring alignment and enabling true concurrency. We evaluate StreamingThinker on the Qwen3 model family across math reasoning, logical reasoning, and context-based QA reasoning tasks. Experimental results show that the StreamingThinker preserves performance comparable to batch thinking, while yielding an 80\\% reduction in token waiting before the onset of reasoning and a more than 60\\% reduction in time-level latency for producing the final answer, demonstrating the effectiveness of the streaming paradigm for LLM reasoning. Code will be released at \\href{this https URL}{this repository.}"}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Visibility Allocation Systems: How Algorithmic Design Shapes Online Visibility and Societal Outcomes", "authors": "Stefania Ionescu, Robin Forsberg, Elsa Lichtenegger, Salima Jaoua, Kshitijaa Jaglan, Florian Dorfler, Aniko Hannak", "subjects": "Computers and Society (cs.CY); Artificial Intelligence (cs.AI)", "abstract": "Throughout application domains, we now rely extensively on algorithmic systems to engage with ever-expanding datasets of information. Despite their benefits, these systems are often complex (comprising of many intricate tools, e.g., moderation, recommender systems, prediction models), of unknown structure (due to the lack of accompanying documentation), and having hard-to-predict yet potentially severe downstream consequences (due to the extensive use, systematic enactment of existing errors, and many comprising feedback loops). As such, understanding and evaluating these systems as a whole remains a challenge for both researchers and legislators. To aid ongoing efforts, we introduce a formal framework for such visibility allocation systems (VASs) which we define as (semi-)automated systems deciding which (processed) data to present a human user with. We review typical tools comprising VASs and define the associated computational problems they solve. By doing so, VASs can be decomposed into sub-processes and illustrated via data flow diagrams. Moreover, we survey metrics for evaluating VASs throughout the pipeline, thus aiding system diagnostics. Using forecasting-based recommendations in school choice as a case study, we demonstrate how our framework can support VAS evaluation. We also discuss how our framework can support ongoing AI-legislative efforts to locate obligations, quantify systemic risks, and enable adaptive compliance."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          On Efficiency-Effectiveness Trade-off of Diffusion-based Recommenders", "authors": "Wenyu Mao, Jiancan Wu, Guoqing Hu, Wei Ji, Xiang Wang", "subjects": "Information Retrieval (cs.IR)", "abstract": "Diffusion models have emerged as a powerful paradigm for generative sequential recommendation, which typically generate next items to recommend guided by user interaction histories with a multi-step denoising process. However, the multi-step process relies on discrete approximations, introducing discretization error that creates a trade-off between computational efficiency and recommendation effectiveness. To address this trade-off, we propose TA-Rec, a two-stage framework that achieves one-step generation by smoothing the denoising function during pretraining while alleviating trajectory deviation by aligning with user preferences during fine-tuning. Specifically, to improve the efficiency without sacrificing the recommendation performance, TA-Rec pretrains the denoising model with Temporal Consistency Regularization (TCR), enforcing the consistency between the denoising results across adjacent steps. Thus, we can smooth the denoising function to map the noise as oracle items in one step with bounded error. To further enhance effectiveness, TA-Rec introduces Adaptive Preference Alignment (APA) that aligns the denoising process with user preference adaptively based on preference pair similarity and timesteps. Extensive experiments prove that TA-Rec's two-stage objective effectively mitigates the discretization errors-induced trade-off, enhancing both efficiency and effectiveness of diffusion-based recommenders."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Numerical boundary control of multi-dimensional discrete-velocity kinetic models", "authors": "Haitian Yang, Wen-An Yong", "subjects": "Numerical Analysis (math.NA); Optimization and Control (math.OC)", "abstract": "This paper extends our recent results on multi-dimensional discrete-velocity models to the numerical level. By adopting an operator splitting scheme and introducing a suitable discrete Lyapunov function, we derive numerical control laws that ensure the corresponding numerical solutions decay exponentially in time. To handle the stiff source term, we also use an implicit scheme for the collision part and prove the stability of the resulting schemes. The theoretical results are validated through three numerical simulations for the two-dimensional coplanar model."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          From Preferences to Prejudice: The Role of Alignment Tuning in Shaping Social Bias in Video Diffusion Models", "authors": "Zefan Cai, Haoyi Qiu, Haozhe Zhao, Ke Wan, Jiachen Li, Jiuxiang Gu, Wen Xiao, Nanyun Peng, Junjie Hu", "subjects": "Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Recent advances in video diffusion models have significantly enhanced text-to-video generation, particularly through alignment tuning using reward models trained on human preferences. While these methods improve visual quality, they can unintentionally encode and amplify social biases. To systematically trace how such biases evolve throughout the alignment pipeline, we introduce VideoBiasEval, a comprehensive diagnostic framework for evaluating social representation in video generation. Grounded in established social bias taxonomies, VideoBiasEval employs an event-based prompting strategy to disentangle semantic content (actions and contexts) from actor attributes (gender and ethnicity). It further introduces multi-granular metrics to evaluate (1) overall ethnicity bias, (2) gender bias conditioned on ethnicity, (3) distributional shifts in social attributes across model variants, and (4) the temporal persistence of bias within videos. Using this framework, we conduct the first end-to-end analysis connecting biases in human preference datasets, their amplification in reward models, and their propagation through alignment-tuned video diffusion models. Our results reveal that alignment tuning not only strengthens representational biases but also makes them temporally stable, producing smoother yet more stereotyped portrayals. These findings highlight the need for bias-aware evaluation and mitigation throughout the alignment process to ensure fair and socially responsible video generation."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          An adaptive hierarchical control framework for quadrupedal robots in planetary exploration", "authors": "Franek Stark, Rohit Kumar, Shubham Vyas, Hannah Isermann, Jonas Haack, Mihaela Popescu, Jakob Middelberg, Dennis Mronga, Frank Kirchner", "subjects": "Robotics (cs.RO)", "abstract": "Planetary exploration missions require robots capable of navigating extreme and unknown environments. While wheeled rovers have dominated past missions, their mobility is limited to traversable surfaces. Legged robots, especially quadrupeds, can overcome these limitations by handling uneven, obstacle-rich, and deformable terrains. However, deploying such robots in unknown conditions is challenging due to the need for environment-specific control, which is infeasible when terrain and robot parameters are uncertain. This work presents a modular control framework that combines model-based dynamic control with online model adaptation and adaptive footstep planning to address uncertainties in both robot and terrain properties. The framework includes state estimation for quadrupeds with and without contact sensing, supports runtime reconfiguration, and is integrated into ROS 2 with open-source availability. Its performance was validated on two quadruped platforms, multiple hardware architectures, and in a volcano field test, where the robot walked over 700 m."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          A Prototypical Network with an Attention-based Encoder for Drivers Identification Application", "authors": "Wei-Hsun Lee (1), Che-Yu Chang (1), Kuang-Yu Li (2) ((1) Dept. of Transportation &amp; Communication Management Science, National Cheng Kung University, Taiwan (2) Institute of Data Science, National Cheng Kung University, Taiwan)", "subjects": "Machine Learning (cs.LG)", "abstract": "Driver identification has become an area of increasing interest in recent years, especially for data- driven applications, because biometric-based technologies may incur privacy issues. This study proposes a deep learning neural network architecture, an attention-based encoder (AttEnc), which uses an attention mechanism for driver identification and uses fewer model parameters than current methods. Most studies do not address the issue of data shortages for driver identification, and most of them are inflexible when encountering unknown drivers. In this study, an architecture that combines a prototypical network and an attention-based encoder (P-AttEnc) is proposed. It applies few-shot learning to overcome the data shortage issues and to enhance model generalizations. The experiments showed that the attention-based encoder can identify drivers with accuracies of 99.3%, 99.0% and 99.9% in three different datasets and has a prediction time that is 44% to 79% faster because it significantly reduces, on average, 87.6% of the model parameters. P-AttEnc identifies drivers based on few shot data, extracts driver fingerprints to address the issue of data shortages, and is able to classify unknown drivers. The first experiment showed that P-AttEnc can identify drivers with an accuracy of 69.8% in the one-shot scenario. The second experiment showed that P-AttEnc, in the 1-shot scenario, can classify unknown drivers with an average accuracy of 65.7%."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          SmaRTLy: RTL Optimization with Logic Inferencing and Structural Rebuilding", "authors": "Chengxi Li, Yang Sun, Lei Chen, Yiwen Wang, Mingxuan Yuan, Evangeline F.Y. Young", "subjects": "Hardware Architecture (cs.AR)", "abstract": "This paper proposes smaRTLy: a new optimization technique for multiplexers in Register-Transfer Level (RTL) logic synthesis. Multiplexer trees are very common in RTL designs, and traditional tools like Yosys optimize them by traversing the tree and monitoring control port values. However, this method does not fully exploit the intrinsic logical relationships among signals or the potential for structural optimization. To address these limitations, we develop innovative strategies to remove redundant multiplexer trees and restructure the remaining ones, significantly reducing the overall gate count. We evaluate smaRTLy on the IWLS-2005 and RISC-V benchmarks, achieving an additional 8.95% reduction in AIG area compared to Yosys. We also evaluate smaRTLy on an industrial benchmark in the scale of millions of gates, results show that smaRTLy can remove 47.2% more AIG area than Yosys. These results demonstrate the effectiveness of our logic inferencing and structural rebuilding techniques in enhancing the RTL optimization process, leading to more efficient hardware designs."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          How News Feels: Understanding Affective Bias in Multilingual Headlines for Human-Centered Media Design", "authors": "Mohd Ruhul Ameen, Akif Islam, Abu Saleh Musa Miah, Ayesha Siddiqua, Jungpil Shin", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "abstract": "News media often shape the public mood not only by what they report but by how they frame it. The same event can appear calm in one outlet and alarming in another, reflecting subtle emotional bias in reporting. Negative or emotionally charged headlines tend to attract more attention and spread faster, which in turn encourages outlets to frame stories in ways that provoke stronger reactions. This research explores that tendency through large-scale emotion analysis of Bengali news. Using zero-shot inference with Gemma-3 4B, we analyzed 300000 Bengali news headlines and their content to identify the dominant emotion and overall tone of each. The findings reveal a clear dominance of negative emotions, particularly anger, fear, and disappointment, and significant variation in how similar stories are emotionally portrayed across outlets. Based on these insights, we propose design ideas for a human-centered news aggregator that visualizes emotional cues and helps readers recognize hidden affective framing in daily news."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Augmented Web Usage Mining and User Experience Optimization with CAWAL's Enriched Analytics Data", "authors": "\u00d6zkan Canay (1 and 2), {\u00dc}mit Kocab\u0131cak (3 and 4) ((1) Institute of Natural Sciences, Sakarya University, Sakarya, Turkiye, (2) Vocational School of Sakarya, Sakarya University of Applied Sciences, Sakarya, Turkiye, (3) Faculty of Computer and IT Engineering, Sakarya University, Sakarya, Turkiye, (4) Turkish Higher Education Quality Council, Ankara, Turkiye)", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI)", "abstract": "Understanding user behavior on the web is increasingly critical for optimizing user experience (UX). This study introduces Augmented Web Usage Mining (AWUM), a methodology designed to enhance web usage mining and improve UX by enriching the interaction data provided by CAWAL (Combined Application Log and Web Analytics), a framework for advanced web analytics. Over 1.2 million session records collected in one month (~8.5GB of data) were processed and transformed into enriched datasets. AWUM analyzes session structures, page requests, service interactions, and exit methods. Results show that 87.16% of sessions involved multiple pages, contributing 98.05% of total pageviews; 40% of users accessed various services and 50% opted for secure exits. Association rule mining revealed patterns of frequently accessed services, highlighting CAWAL's precision and efficiency over conventional methods. AWUM offers a comprehensive understanding of user behavior and strong potential for large-scale UX optimization."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Explainability of Large Language Models: Opportunities and Challenges toward Generating Trustworthy Explanations", "authors": "Shahin Atakishiyev, Housam K.B. Babiker, Jiayi Dai, Nawshad Farruque, Teruaki Hayashi, Nafisa Sadaf Hriti, Md Abed Rahman, Iain Smith, Mi-Young Kim, Osmar R. Za\u00efane, Randy Goebel", "subjects": "Computation and Language (cs.CL)", "abstract": "Large language models have exhibited impressive performance across a broad range of downstream tasks in natural language processing. However, how a language model predicts the next token and generates content is not generally understandable by humans. Furthermore, these models often make errors in prediction and reasoning, known as hallucinations. These errors underscore the urgent need to better understand and interpret the intricate inner workings of language models and how they generate predictive outputs. Motivated by this gap, this paper investigates local explainability and mechanistic interpretability within Transformer-based large language models to foster trust in such models. In this regard, our paper aims to make three key contributions. First, we present a review of local explainability and mechanistic interpretability approaches and insights from relevant studies in the literature. Furthermore, we describe experimental studies on explainability and reasoning with large language models in two critical domains -- healthcare and autonomous driving -- and analyze the trust implications of such explanations for explanation receivers. Finally, we summarize current unaddressed issues in the evolving landscape of LLM explainability and outline the opportunities, critical challenges, and future directions toward generating human-aligned, trustworthy LLM explanations."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          High-Level Multi-Robot Trajectory Planning And Spurious Behavior Detection", "authors": "Fernando Salanova, Jes\u00fas Roche, Cristian Mahuela, Eduardo Montijano", "subjects": "Robotics (cs.RO); Machine Learning (cs.LG)", "abstract": "The reliable execution of high-level missions in multi-robot systems with heterogeneous agents, requires robust methods for detecting spurious behaviors. In this paper, we address the challenge of identifying spurious executions of plans specified as a Linear Temporal Logic (LTL) formula, as incorrect task sequences, violations of spatial constraints, timing inconsis- tencies, or deviations from intended mission semantics. To tackle this, we introduce a structured data generation framework based on the Nets-within-Nets (NWN) paradigm, which coordinates robot actions with LTL-derived global mission specifications. We further propose a Transformer-based anomaly detection pipeline that classifies robot trajectories as normal or anomalous. Experi- mental evaluations show that our method achieves high accuracy (91.3%) in identifying execution inefficiencies, and demonstrates robust detection capabilities for core mission violations (88.3%) and constraint-based adaptive anomalies (66.8%). An ablation experiment of the embedding and architecture was carried out, obtaining successful results where our novel proposition performs better than simpler representations."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Finding 4-Additive Spanners: Faster, Stronger, and Simpler", "authors": "Chuhan Qi", "subjects": "Data Structures and Algorithms (cs.DS)", "abstract": "Additive spanners are fundamental graph structures with wide applications in network design, graph sparsification, and distance approximation. In particular, a $4$-additive spanner is a subgraph that preserves all pairwise distances up to an additive error of $4$. In this paper, we present a new deterministic algorithm for constructing $4$-additive spanners that matches the best known edge bound of $\\tilde{O}(n^{7/5})$ (up to polylogarithmic factors), while improving the running time to $\\tilde{O}(\\min\\{mn^{3/5}, n^{11/5}\\})$, compared to the previous $\\tilde{O}(mn^{3/5})$ randomized construction. Our algorithm is not only faster in the dense regime but also fully deterministic, conceptually simpler, and easier to implement and analyze."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          TaxoAlign: Scholarly Taxonomy Generation Using Language Models", "authors": "Avishek Lahiri, Yufang Hou, Debarshi Kumar Sanyal", "subjects": "Computation and Language (cs.CL)", "abstract": "Taxonomies play a crucial role in helping researchers structure and navigate knowledge in a hierarchical manner. They also form an important part in the creation of comprehensive literature surveys. The existing approaches to automatic survey generation do not compare the structure of the generated surveys with those written by human experts. To address this gap, we present our own method for automated taxonomy creation that can bridge the gap between human-generated and automatically-created taxonomies. For this purpose, we create the CS-TaxoBench benchmark which consists of 460 taxonomies that have been extracted from human-written survey papers. We also include an additional test set of 80 taxonomies curated from conference survey papers. We propose TaxoAlign, a three-phase topic-based instruction-guided method for scholarly taxonomy generation. Additionally, we propose a stringent automated evaluation framework that measures the structural alignment and semantic coherence of automatically generated taxonomies in comparison to those created by human experts. We evaluate our method and various baselines on CS-TaxoBench, using both automated evaluation metrics and human evaluation studies. The results show that TaxoAlign consistently surpasses the baselines on nearly all metrics. The code and data can be found at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Fair and Interpretable Deepfake Detection in Videos", "authors": "Akihito Yoshii, Ryosuke Sonoda, Ramya Srinivasan", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)", "abstract": "Existing deepfake detection methods often exhibit bias, lack transparency, and fail to capture temporal information, leading to biased decisions and unreliable results across different demographic groups. In this paper, we propose a fairness-aware deepfake detection framework that integrates temporal feature learning and demographic-aware data augmentation to enhance fairness and interpretability. Our method leverages sequence-based clustering for temporal modeling of deepfake videos and concept extraction to improve detection reliability while also facilitating interpretable decisions for non-expert users. Additionally, we introduce a demography-aware data augmentation method that balances underrepresented groups and applies frequency-domain transformations to preserve deepfake artifacts, thereby mitigating bias and improving generalization. Extensive experiments on FaceForensics++, DFD, Celeb-DF, and DFDC datasets using state-of-the-art (SoTA) architectures (Xception, ResNet) demonstrate the efficacy of the proposed method in obtaining the best tradeoff between fairness and accuracy when compared to SoTA."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Adaptive Discretization for Consistency Models", "authors": "Jiayu Bai, Zhanbo Feng, Zhijie Deng, Tianqi Hou, Robert C. Qiu, Zenan Ling", "subjects": "Machine Learning (cs.LG); Machine Learning (stat.ML)", "abstract": "Consistency Models (CMs) have shown promise for efficient one-step generation. However, most existing CMs rely on manually designed discretization schemes, which can cause repeated adjustments for different noise schedules and datasets. To address this, we propose a unified framework for the automatic and adaptive discretization of CMs, formulating it as an optimization problem with respect to the discretization step. Concretely, during the consistency training process, we propose using local consistency as the optimization objective to ensure trainability by avoiding excessive discretization, and taking global consistency as a constraint to ensure stability by controlling the denoising error in the training target. We establish the trade-off between local and global consistency with a Lagrange multiplier. Building on this framework, we achieve adaptive discretization for CMs using the Gauss-Newton method. We refer to our approach as ADCMs. Experiments demonstrate that ADCMs significantly improve the training efficiency of CMs, achieving superior generative performance with minimal training overhead on both CIFAR-10 and ImageNet. Moreover, ADCMs exhibit strong adaptability to more advanced DM variants. Code is available at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Uncertainty-aware data assimilation through variational inference", "authors": "Anthony Frion, David S Greenberg", "subjects": "Machine Learning (cs.LG); Machine Learning (stat.ML)", "abstract": "Data assimilation, consisting in the combination of a dynamical model with a set of noisy and incomplete observations in order to infer the state of a system over time, involves uncertainty in most settings. Building upon an existing deterministic machine learning approach, we propose a variational inference-based extension in which the predicted state follows a multivariate Gaussian distribution. Using the chaotic Lorenz-96 dynamics as a testing ground, we show that our new model enables to obtain nearly perfectly calibrated predictions, and can be integrated in a wider variational data assimilation pipeline in order to achieve greater benefit from increasing lengths of data assimilation windows. Our code is available at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          FineVision: Open Data Is All You Need", "authors": "Luis Wiedmann, Orr Zohar, Amir Mahla, Xiaohan Wang, Rui Li, Thibaud Frere, Leandro von Werra, Aritra Roy Gosthipaty, Andr\u00e9s Marafioti", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "abstract": "The advancement of vision-language models (VLMs) is hampered by a fragmented landscape of inconsistent and contaminated public datasets. We introduce FineVision, a meticulously collected, curated, and unified corpus of 24 million samples - the largest open resource of its kind. We unify more than 200 sources into 185 subsets via a semi-automated, human-in-the-loop pipeline: automation performs bulk ingestion and schema mapping, while reviewers audit mappings and spot-check outputs to verify faithful consumption of annotations, appropriate formatting and diversity, and safety; issues trigger targeted fixes and re-runs. The workflow further applies rigorous de-duplication within and across sources and decontamination against 66 public benchmarks. FineVision also encompasses agentic/GUI tasks with a unified action space; reviewers validate schemas and inspect a sample of trajectories to confirm executable fidelity. Models trained on FineVision consistently outperform those trained on existing open mixtures across a broad evaluation suite, underscoring the benefits of scale, data hygiene, and balanced automation with human oversight. We release the corpus and curation tools to accelerate data-centric VLM research."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Floating-Base Deep Lagrangian Networks", "authors": "Lucas Schulze, Juliano Decico Negri, Victor Barasuol, Vivian Suzano Medeiros, Marcelo Becker, Jan Peters, Oleg Arenz", "subjects": "Robotics (cs.RO); Systems and Control (eess.SY)", "abstract": "Grey-box methods for system identification combine deep learning with physics-informed constraints, capturing complex dependencies while improving out-of-distribution generalization. Yet, despite the growing importance of floating-base systems such as humanoids and quadrupeds, current grey-box models ignore their specific physical constraints. For instance, the inertia matrix is not only positive definite but also exhibits branch-induced sparsity and input independence. Moreover, the 6x6 composite spatial inertia of the floating base inherits properties of single-rigid-body inertia matrices. As we show, this includes the triangle inequality on the eigenvalues of the composite rotational inertia. To address the lack of physical consistency in deep learning models of floating-base systems, we introduce a parameterization of inertia matrices that satisfies all these constraints. Inspired by Deep Lagrangian Networks (DeLaN), we train neural networks to predict physically plausible inertia matrices that minimize inverse dynamics error under Lagrangian mechanics. For evaluation, we collected and released a dataset on multiple quadrupeds and humanoids. In these experiments, our Floating-Base Deep Lagrangian Networks (FeLaN) achieve highly competitive performance on both simulated and real robots, while providing greater physical interpretability."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Enhanced Motion Forecasting with Plug-and-Play Multimodal Large Language Models", "authors": "Katie Luo, Jingwei Ji, Tong He, Runsheng Xu, Yichen Xie, Dragomir Anguelov, Mingxing Tan", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Current autonomous driving systems rely on specialized models for perceiving and predicting motion, which demonstrate reliable performance in standard conditions. However, generalizing cost-effectively to diverse real-world scenarios remains a significant challenge. To address this, we propose Plug-and-Forecast (PnF), a plug-and-play approach that augments existing motion forecasting models with multimodal large language models (MLLMs). PnF builds on the insight that natural language provides a more effective way to describe and handle complex scenarios, enabling quick adaptation to targeted behaviors. We design prompts to extract structured scene understanding from MLLMs and distill this information into learnable embeddings to augment existing behavior prediction models. Our method leverages the zero-shot reasoning capabilities of MLLMs to achieve significant improvements in motion prediction performance, while requiring no fine-tuning -- making it practical to adopt. We validate our approach on two state-of-the-art motion forecasting models using the Waymo Open Motion Dataset and the nuScenes Dataset, demonstrating consistent performance improvements across both benchmarks."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Breaking and Fixing Defenses Against Control-Flow Hijacking in Multi-Agent Systems", "authors": "Rishi Jha, Harold Triedman, Justin Wagle, Vitaly Shmatikov", "subjects": "Machine Learning (cs.LG); Cryptography and Security (cs.CR); Systems and Control (eess.SY)", "abstract": "Control-flow hijacking attacks manipulate orchestration mechanisms in multi-agent systems into performing unsafe actions that compromise the system and exfiltrate sensitive information. Recently proposed defenses, such as LlamaFirewall, rely on alignment checks of inter-agent communications to ensure that all agent invocations are \"related to\" and \"likely to further\" the original objective. We start by demonstrating control-flow hijacking attacks that evade these defenses even if alignment checks are performed by advanced LLMs. We argue that the safety and functionality objectives of multi-agent systems fundamentally conflict with each other. This conflict is exacerbated by the brittle definitions of \"alignment\" and the checkers' incomplete visibility into the execution context. We then propose, implement, and evaluate ControlValve, a new defense inspired by the principles of control-flow integrity and least privilege. ControlValve (1) generates permitted control-flow graphs for multi-agent systems, and (2) enforces that all executions comply with these graphs, along with contextual rules (generated in a zero-shot manner) for each agent invocation."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Multimodal Safety Is Asymmetric: Cross-Modal Exploits Unlock Black-Box MLLMs Jailbreaks", "authors": "Xinkai Wang, Beibei Li, Zerui Shao, Ao Liu, Shouling Ji", "subjects": "Cryptography and Security (cs.CR)", "abstract": "Multimodal large language models (MLLMs) have demonstrated significant utility across diverse real-world applications. But MLLMs remain vulnerable to jailbreaks, where adversarial inputs can collapse their safety constraints and trigger unethical responses. In this work, we investigate jailbreaks in the text-vision multimodal setting and pioneer the observation that visual alignment imposes uneven safety constraints across modalities in MLLMs, thereby giving rise to multimodal safety asymmetry. We then develop PolyJailbreak, a black-box jailbreak method grounded in reinforcement learning. Initially, we probe the model's attention dynamics and latent representation space, assessing how visual inputs reshape cross-modal information flow and diminish the model's ability to separate harmful from benign inputs, thereby exposing exploitable vulnerabilities. On this basis, we systematize them into generalizable and reusable operational rules that constitute a structured library of Atomic Strategy Primitives, which translate harmful intents into jailbreak inputs through step-wise transformations. Guided by the primitives, PolyJailbreak employs a multi-agent optimization process that automatically adapts inputs against the target models. We conduct comprehensive evaluations on a variety of open-source and closed-source MLLMs, demonstrating that PolyJailbreak outperforms state-of-the-art baselines."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          SG-CLDFF: A Novel Framework for Automated White Blood Cell Classification and Segmentation", "authors": "Mehdi Zekriyapanah Gashti, Mostafa Mohammadpour, Ghasem Farjamnia", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Accurate segmentation and classification of white blood cells (WBCs) in microscopic images are essential for diagnosis and monitoring of many hematological disorders, yet remain challenging due to staining variability, complex backgrounds, and class imbalance. In this paper, we introduce a novel Saliency-Guided Cross-Layer Deep Feature Fusion framework (SG-CLDFF) that tightly integrates saliency-driven preprocessing with multi-scale deep feature aggregation to improve both robustness and interpretability for WBC analysis. SG-CLDFF first computes saliency priors to highlight candidate WBC regions and guide subsequent feature extraction. A lightweight hybrid backbone (EfficientSwin-style) produces multi-resolution representations, which are fused by a ResNeXt-CC-inspired cross-layer fusion module to preserve complementary information from shallow and deep layers. The network is trained in a multi-task setup with concurrent segmentation and cell-type classification heads, using class-aware weighted losses and saliency-alignment regularization to mitigate imbalance and suppress background activation. Interpretability is enforced through Grad-CAM visualizations and saliency consistency checks, allowing model decisions to be inspected at the regional level. We validate the framework on standard public benchmarks (BCCD, LISC, ALL-IDB), reporting consistent gains in IoU, F1, and classification accuracy compared to strong CNN and transformer baselines. An ablation study also demonstrates the individual contributions of saliency preprocessing and cross-layer fusion. SG-CLDFF offers a practical and explainable path toward more reliable automated WBC analysis in clinical workflows."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          StrengthLawExtractor: A Fiji plugin for 3D morphological feature extraction from X-ray micro-CT data", "authors": "Qinyi Tian, Laura E. Dalton", "subjects": "Computational Engineering, Finance, and Science (cs.CE)", "abstract": "Non-destructive methods are essential for linking the microstructural geometry of porous materials to their mechanical behavior, as destructive testing is often infeasible due to limited material availability or irreproducible conditions. Micro-computed tomography (micro-CT) provides high resolution three dimensional reconstructions of porous microstructures, enabling direct quantification of geometric descriptors. Recent advances in morphometric theory have demonstrated that four independent morphometric measures (porosity, surface area, mean curvature, and Euler characteristic) are required to capture the relationship between microstructure and strength, thereby forming the basis of generalized strength laws. To facilitate practical application of this framework, a Fiji plugin was developed to extract the four morphometric measures (porosity, surface area, mean curvature, Euler characteristic) from micro-CT datasets automatically. The plugin integrates within the Fiji platform to provide reproducible, accessible, and user friendly analysis. The application of the tool demonstrates that the extracted descriptors can be readily incorporated into constitutive models and machine learning workflows, enabling the forward prediction of stress-strain behavior as well as the inverse design of microstructures. This approach supports non-destructive evaluation, accelerates materials selection, and advances the integration of imaging with predictive modeling in porous media research."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          MemoryBench: A Benchmark for Memory and Continual Learning in LLM Systems", "authors": "Qingyao Ai, Yichen Tang, Changyue Wang, Jianming Long, Weihang Su, Yiqun Liu", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)", "abstract": "Scaling up data, parameters, and test-time computation has been the mainstream methods to improve LLM systems (LLMsys), but their upper bounds are almost reached due to the gradual depletion of high-quality data and marginal gains obtained from larger computational resource consumption. Inspired by the abilities of human and traditional AI systems in learning from practice, constructing memory and continual learning frameworks for LLMsys has become an important and popular research direction in recent literature. Yet, existing benchmarks for LLM memory often focus on evaluating the system on homogeneous reading comprehension tasks with long-form inputs rather than testing their abilities to learn from accumulated user feedback in service time. Therefore, we propose a user feedback simulation framework and a comprehensive benchmark covering multiple domains, languages, and types of tasks to evaluate the continual learning abilities of LLMsys. Experiments show that the effectiveness and efficiency of state-of-the-art baselines are far from satisfying, and we hope this benchmark could pave the way for future studies on LLM memory and optimization algorithms."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Analysis of Input-Output Mappings in Coinjoin Transactions with Arbitrary Values", "authors": "Jiri Gavenda, Petr Svenda, Stanislav Bobon, Vladimir Sedlacek", "subjects": "Cryptography and Security (cs.CR)", "abstract": "A coinjoin protocol aims to increase transactional privacy for Bitcoin and Bitcoin-like blockchains via collaborative transactions, by violating assumptions behind common analysis heuristics. Estimating the resulting privacy gain is a crucial yet unsolved problem due to a range of influencing factors and large computational complexity. We adapt the BlockSci on-chain analysis software to coinjoin transactions, demonstrating a significant (10-50%) average post-mix anonymity set size decrease for all three major designs with a central coordinator: Whirlpool, Wasabi 1.x, and Wasabi 2.x. The decrease is highest during the first day and negligible after one year from a coinjoin creation. Moreover, we design a precise, parallelizable privacy estimation method, which takes into account coinjoin fees, implementation-specific limitations and users' post-mix behavior. We evaluate our method in detail on a set of emulated and real-world Wasabi 2.x coinjoins and extrapolate to its largest real-world coinjoins with hundreds of inputs and outputs. We conclude that despite the users' undesirable post-mix behavior, correctly attributing the coins to their owners is still very difficult, even with our improved analysis algorithm."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Eliciting Truthful Feedback for Preference-Based Learning via the VCG Mechanism", "authors": "Leo Landolt, Anna Maddux, Andreas Schlaginhaufen, Saurabh Vaishampayan, Maryam Kamgarpour", "subjects": "Computer Science and Game Theory (cs.GT)", "abstract": "We study resource allocation problems in which a central planner allocates resources among strategic agents with private cost functions in order to minimize a social cost, defined as an aggregate of the agents' costs. This setting poses two main challenges: (i) the agents' cost functions may be unknown to them or difficult to specify explicitly, and (ii) agents may misreport their costs strategically. To address these challenges, we propose an algorithm that combines preference-based learning with Vickrey-Clarke-Groves (VCG) payments to incentivize truthful reporting. Our algorithm selects informative preference queries via D-optimal design, estimates cost parameters through maximum likelihood, and computes VCG allocations and payments based on these estimates. In a one-shot setting, we prove that the mechanism is approximately truthful, individually rational, and efficient up to an error of $\\tilde{\\mathcal O}(K^{-1/2})$ for $K$ preference queries per agent. In an online setting, these guarantees hold asymptotically with sublinear regret at a rate of $\\tilde{\\mathcal O}(T^{2/3})$ after $T$ rounds. Finally, we validate our approach through a numerical case study on demand response in local electricity markets."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Machine Vision-Based Surgical Lighting System:Design and Implementation", "authors": "Amir Gharghabi, Mahdi Hakiminezhad, Maryam Shafaei, Shaghayegh Gharghabi", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Human-Computer Interaction (cs.HC)", "abstract": "Effortless and ergonomically designed surgical lighting is critical for precision and safety during procedures. However, traditional systems often rely on manual adjustments, leading to surgeon fatigue, neck strain, and inconsistent illumination due to drift and shadowing. To address these challenges, we propose a novel surgical lighting system that leverages the YOLOv11 object detection algorithm to identify a blue marker placed above the target surgical site. A high-power LED light source is then directed to the identified location using two servomotors equipped with tilt-pan brackets. The YOLO model achieves 96.7% mAP@50 on the validation set consisting of annotated images simulating surgical scenes with the blue spherical marker. By automating the lighting process, this machine vision-based solution reduces physical strain on surgeons, improves consistency in illumination, and supports improved surgical outcomes."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Addressing Antisocial Behavior in Multi-Party Dialogs Through Multimodal Representation Learning", "authors": "Hajar Bakarou, Mohamed Sinane El Messoussi, Ana\u00efs Ollagnier", "subjects": "Computation and Language (cs.CL)", "abstract": "Antisocial behavior (ASB) on social media -- including hate speech, harassment, and cyberbullying -- poses growing risks to platform safety and societal well-being. Prior research has focused largely on networks such as X and Reddit, while \\textit{multi-party conversational settings} remain underexplored due to limited data. To address this gap, we use \\textit{CyberAgressionAdo-Large}, a French open-access dataset simulating ASB in multi-party conversations, and evaluate three tasks: \\textit{abuse detection}, \\textit{bullying behavior analysis}, and \\textit{bullying peer-group identification}. We benchmark six text-based and eight graph-based \\textit{representation-learning methods}, analyzing lexical cues, interactional dynamics, and their multimodal fusion. Results show that multimodal models outperform unimodal baselines. The late fusion model \\texttt{mBERT + WD-SGCN} achieves the best overall results, with top performance on abuse detection (0.718) and competitive scores on peer-group identification (0.286) and bullying analysis (0.606). Error analysis highlights its effectiveness in handling nuanced ASB phenomena such as implicit aggression, role transitions, and context-dependent hostility."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Enhanced Ground-Satellite Direct Access via Onboard Rydberg Atomic Quantum Receivers", "authors": "Qihao Peng, Tierui Gong, Zihang Song, Qu Luo, Zihuai Lin, Pei Xiao, Chau Yuen", "subjects": "Systems and Control (eess.SY)", "abstract": "Ground-satellite links for 6G networks face critical challenges, including severe path loss, tight size-weight-power limits, and congested spectrum, all of which significantly hinder the performance of traditional radio frequency (RF) front ends. This article introduces the Rydberg Atomic Quantum Receiver (RAQR) for onboard satellite systems, a millimeter-scale front end that converts radio fields to optical signals through atomic electromagnetically induced transparency. RAQR's high sensitivity and high frequency selectivity address link budget, payload, and interference challenges while fitting within space constraints. A hybrid atomic-electronic design and supporting signal model demonstrate enhanced data rate, coverage, and sensing accuracy relative to conventional RF receivers. The article concludes with integration strategies, distributed-satellite concepts, and open research problems for bringing RAQR-enabled satellite payloads into service."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Exploring Structural Degradation in Dense Representations for Self-supervised Learning", "authors": "Siran Dai, Qianqian Xu, Peisong Wen, Yang Liu, Qingming Huang", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "In this work, we observe a counterintuitive phenomenon in self-supervised learning (SSL): longer training may impair the performance of dense prediction tasks (e.g., semantic segmentation). We refer to this phenomenon as Self-supervised Dense Degradation (SDD) and demonstrate its consistent presence across sixteen state-of-the-art SSL methods with various losses, architectures, and datasets. When the model performs suboptimally on dense tasks at the end of training, measuring the performance during training becomes essential. However, evaluating dense performance effectively without annotations remains an open challenge. To tackle this issue, we introduce a Dense representation Structure Estimator (DSE), composed of a class-relevance measure and an effective dimensionality measure. The proposed DSE is both theoretically grounded and empirically validated to be closely correlated with the downstream performance. Based on this metric, we introduce a straightforward yet effective model selection strategy and a DSE-based regularization method. Experiments on sixteen SSL methods across four benchmarks confirm that model selection improves mIoU by $3.0\\%$ on average with negligible computational cost. Additionally, DSE regularization consistently mitigates the effects of dense degradation. Code is available at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Counterexamples to the conjecture of the upper bound of the derivative of a rational B\u00e9zier curve", "authors": "Mao Shi", "subjects": "Numerical Analysis (math.NA)", "abstract": "In this paper, we present counterexamples to the upper bound of the first-order derivative of rational B\u00e9zier curves and further investigate the supremum of derivatives of all orders for such curves."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Comprehending Spatio-temporal Data via Cinematic Storytelling using Large Language Models", "authors": "Panos Kalnis. Shuo Shang, Christian S. Jensen", "subjects": "Databases (cs.DB); Artificial Intelligence (cs.AI)", "abstract": "Spatio-temporal data captures complex dynamics across both space and time, yet traditional visualizations are complex, require domain expertise and often fail to resonate with broader audiences. Here, we propose MapMuse, a storytelling-based framework for interpreting spatio-temporal datasets, transforming them into compelling, narrative-driven experiences. We utilize large language models and employ retrieval augmented generation (RAG) and agent-based techniques to generate comprehensive stories. Drawing on principles common in cinematic storytelling, we emphasize clarity, emotional connection, and audience-centric design. As a case study, we analyze a dataset of taxi trajectories. Two perspectives are presented: a captivating story based on a heat map that visualizes millions of taxi trip endpoints to uncover urban mobility patterns; and a detailed narrative following a single long taxi journey, enriched with city landmarks and temporal shifts. By portraying locations as characters and movement as plot, we argue that data storytelling drives insight, engagement, and action from spatio-temporal information. The case study illustrates how MapMuse can bridge the gap between data complexity and human understanding. The aim of this short paper is to provide a glimpse to the potential of the cinematic storytelling technique as an effective communication tool for spatio-temporal data, as well as to describe open problems and opportunities for future research."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Symmetries in PAC-Bayesian Learning", "authors": "Armin Beck, Peter Ochs", "subjects": "Machine Learning (cs.LG); Machine Learning (stat.ML)", "abstract": "Symmetries are known to improve the empirical performance of machine learning models, yet theoretical guarantees explaining these gains remain limited. Prior work has focused mainly on compact group symmetries and often assumes that the data distribution itself is invariant, an assumption rarely satisfied in real-world applications. In this work, we extend generalization guarantees to the broader setting of non-compact symmetries, such as translations and to non-invariant data distributions. Building on the PAC-Bayes framework, we adapt and tighten existing bounds, demonstrating the approach on McAllester's PAC-Bayes bound while showing that it applies to a wide range of PAC-Bayes bounds. We validate our theory with experiments on a rotated MNIST dataset with a non-uniform rotation group, where the derived guarantees not only hold but also improve upon prior results. These findings provide theoretical evidence that, for symmetric data, symmetric models are preferable beyond the narrow setting of compact groups and invariant distributions, opening the way to a more general understanding of symmetries in machine learning."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          LongInsightBench: A Comprehensive Benchmark for Evaluating Omni-Modal Models on Human-Centric Long-Video Understanding", "authors": "ZhaoYang Han, Qihan Lin, Hao Liang, Bowen Chen, Zhou Liu, Wentao Zhang", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Multimedia (cs.MM)", "abstract": "We introduce \\textbf{LongInsightBench}, the first benchmark designed to assess models' ability to understand long videos, with a focus on human language, viewpoints, actions, and other contextual elements, while integrating \\textbf{visual, audio, and text} modalities. Our benchmark excels in three key areas: \\textbf{a) Long-Duration, Information-Dense Videos:} We carefully select approximately 1,000 videos from open-source datasets FineVideo based on duration limit and the information density of both visual and audio modalities, focusing on content like lectures, interviews, and vlogs, which contain rich language elements. \\textbf{b) Diverse and Challenging Task Scenarios:} We have designed six challenging task scenarios, including both Intra-Event and Inter-Event Tasks. \\textbf{c) Rigorous and Comprehensive Quality Assurance Pipelines:} We have developed a three-step, semi-automated data quality assurance pipeline to ensure the difficulty and validity of the synthesized questions and answer options. Based on LongInsightBench, we designed a series of experiments. Experimental results shows that Omni-modal models(OLMs) still face challenge in tasks requiring precise temporal localization (T-Loc) and long-range causal inference (CE-Caus). Extended experiments reveal the information loss and processing bias in multi-modal fusion of OLMs. Our dataset and code is available at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          ATL*AS: An Automata-Theoretic Approach and Tool for the Verification of Strategic Abilities in Multi-Agent Systems", "authors": "Sofia Garcia de Blas Garcia-Alcalde, Francesco Belardinelli", "subjects": "Logic in Computer Science (cs.LO); Multiagent Systems (cs.MA)", "abstract": "We present two novel symbolic algorithms for model checking the Alternating-time Temporal Logic ATL*, over both the infinite-trace and the finite-trace semantics. In particular, for infinite traces we design a novel symbolic reduction to parity games. We implement both methods in the ATL*AS model checker and evaluate it using synthetic benchmarks as well as a cybersecurity scenario. Our results demonstrate that the symbolic approach significantly outperforms the explicit-state representation and we find that our parity-game-based algorithm offers a more scalable and efficient solution for infinite-trace verification, outperforming previously available tools. Our results also confirm that finite-trace model checking yields substantial performance benefits over infinite-trace verification. As such, we provide a comprehensive toolset for verifying multiagent systems against specifications in ATL*."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Single-Shuffle Full-Open Card-Based Protocols for Any Function", "authors": "Reo Eriguchi, Kazumasa Shinagawa", "subjects": "Cryptography and Security (cs.CR)", "abstract": "A card-based secure computation protocol is a method for $n$ parties to compute a function $f$ on their private inputs $(x_1,\\ldots,x_n)$ using physical playing cards, in such a way that the suits of revealed cards leak no information beyond the value of $f(x_1,\\ldots,x_n)$. A \\textit{single-shuffle full-open} protocol is a minimal model of card-based secure computation in which, after the parties place face-down cards representing their inputs, a single shuffle operation is performed and then all cards are opened to derive the output. Despite the simplicity of this model, the class of functions known to admit single-shuffle full-open protocols has been limited to a few small examples. In this work, we prove for the first time that every function admits a single-shuffle full-open protocol. We present two constructions that offer a trade-off between the number of cards and the complexity of the shuffle operation. These feasibility results are derived from a novel connection between single-shuffle full-open protocols and a cryptographic primitive known as \\textit{Private Simultaneous Messages} protocols, which has rarely been studied in the context of card-based cryptography. We also present variants of single-shuffle protocols in which only a subset of cards are revealed. These protocols reduce the complexity of the shuffle operation compared to existing protocols in the same setting."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          RubiSCoT: A Framework for AI-Supported Academic Assessment", "authors": "Thorsten Fr\u00f6hlich, Tim Schlippe", "subjects": "Artificial Intelligence (cs.AI)", "abstract": "The evaluation of academic theses is a cornerstone of higher education, ensuring rigor and integrity. Traditional methods, though effective, are time-consuming and subject to evaluator variability. This paper presents RubiSCoT, an AI-supported framework designed to enhance thesis evaluation from proposal to final submission. Using advanced natural language processing techniques, including large language models, retrieval-augmented generation, and structured chain-of-thought prompting, RubiSCoT offers a consistent, scalable solution. The framework includes preliminary assessments, multidimensional assessments, content extraction, rubric-based scoring, and detailed reporting. We present the design and implementation of RubiSCoT, discussing its potential to optimize academic assessment processes through consistent, scalable, and transparent evaluation."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          The Hidden Dangers of Public Serverless Repositories: An Empirical Security Assessment", "authors": "Eduard Marin, Jinwoo Kim, Alessio Pavoni, Mauro Conti, Roberto Di Pietro", "subjects": "Cryptography and Security (cs.CR)", "abstract": "Serverless computing has rapidly emerged as a prominent cloud paradigm, enabling developers to focus solely on application logic without the burden of managing servers or underlying infrastructure. Public serverless repositories have become key to accelerating the development of serverless applications. However, their growing popularity makes them attractive targets for adversaries. Despite this, the security posture of these repositories remains largely unexplored, exposing developers and organizations to potential risks. In this paper, we present the first comprehensive analysis of the security landscape of serverless components hosted in public repositories. We analyse 2,758 serverless components from five widely used public repositories popular among developers and enterprises, and 125,936 Infrastructure as Code (IaC) templates across three widely used IaC frameworks. Our analysis reveals systemic vulnerabilities including outdated software packages, misuse of sensitive parameters, exploitable deployment configurations, susceptibility to typo-squatting attacks and opportunities to embed malicious behaviour within compressed serverless components. Finally, we provide practical recommendations to mitigate these threats."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Disentanglement Beyond Static vs. Dynamic: A Benchmark and Evaluation Framework for Multi-Factor Sequential Representations", "authors": "Tal Barami, Nimrod Berman, Ilan Naiman, Amos H. Hason, Rotem Ezra, Omri Azencot", "subjects": "Machine Learning (cs.LG)", "abstract": "Learning disentangled representations in sequential data is a key goal in deep learning, with broad applications in vision, audio, and time series. While real-world data involves multiple interacting semantic factors over time, prior work has mostly focused on simpler two-factor static and dynamic settings, primarily because such settings make data collection easier, thereby overlooking the inherently multi-factor nature of real-world data. We introduce the first standardized benchmark for evaluating multi-factor sequential disentanglement across six diverse datasets spanning video, audio, and time series. Our benchmark includes modular tools for dataset integration, model development, and evaluation metrics tailored to multi-factor analysis. We additionally propose a post-hoc Latent Exploration Stage to automatically align latent dimensions with semantic factors, and introduce a Koopman-inspired model that achieves state-of-the-art results. Moreover, we show that Vision-Language Models can automate dataset annotation and serve as zero-shot disentanglement evaluators, removing the need for manual labels and human intervention. Together, these contributions provide a robust and scalable foundation for advancing multi-factor sequential disentanglement."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Auto-Rubric: Learning to Extract Generalizable Criteria for Reward Modeling", "authors": "Lipeng Xie, Sen Huang, Zhuo Zhang, Anni Zou, Yunpeng Zhai, Dingchao Ren, Kezun Zhang, Haoyuan Hu, Boyin Liu, Haoran Chen, Zhaoyang Liu, Bolin Ding", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "Reward models are essential for aligning Large Language Models (LLMs) with human values, yet their development is hampered by costly preference datasets and poor interpretability. While recent rubric-based approaches offer transparency, they often lack systematic quality control and optimization, creating a trade-off between scalability and reliability. We address these limitations with a novel, training-free framework built on a key assumption: \\textit{evaluation rubrics underlying human preferences exhibit significant generalization ability across diverse queries}, a property that enables remarkable data efficiency. Our two-stage approach first infers high-quality, query-specific rubrics using a validation-guided \\textbf{Propose-Evaluate-Revise} pipeline. Second, it generalizes these granular rubrics into a compact, non-redundant core set by maximizing an \\textbf{information-theoretic coding rate}. The final output is an interpretable, hierarchical \"Theme-Tips\" rubric set. Extensive experiments demonstrate the framework's exceptional data efficiency and performance. Critically, using just 70 preference pairs (1.5\\% of the source data), our method also empowers smaller models like Qwen3-8B to outperform specialized, fully-trained counterparts. This work pioneers a scalable, interpretable, and data-efficient path for reward modeling."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Implicit State Estimation via Video Replanning", "authors": "Po-Chen Ko, Jiayuan Mao, Yu-Hsiang Fu, Hsien-Jeng Yeh, Chu-Rong Chen, Wei-Chiu Ma, Yilun Du, Shao-Hua Sun", "subjects": "Robotics (cs.RO)", "abstract": "Video-based representations have gained prominence in planning and decision-making due to their ability to encode rich spatiotemporal dynamics and geometric relationships. These representations enable flexible and generalizable solutions for complex tasks such as object manipulation and navigation. However, existing video planning frameworks often struggle to adapt to failures at interaction time due to their inability to reason about uncertainties in partially observed environments. To overcome these limitations, we introduce a novel framework that integrates interaction-time data into the planning process. Our approach updates model parameters online and filters out previously failed plans during generation. This enables implicit state estimation, allowing the system to adapt dynamically without explicitly modeling unknown state variables. We evaluate our framework through extensive experiments on a new simulated manipulation benchmark, demonstrating its ability to improve replanning performance and advance the field of video-based decision-making."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          CausalMamba: Scalable Conditional State Space Models for Neural Causal Inference", "authors": "Sangyoon Bae, Jiook Cha", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "We introduce CausalMamba, a scalable framework that addresses fundamental limitations in fMRI-based causal inference: the ill-posed nature of inferring neural causality from hemodynamically distorted BOLD signals and the computational intractability of existing methods like Dynamic Causal Modeling (DCM). Our approach decomposes this complex inverse problem into two tractable stages: BOLD deconvolution to recover latent neural activity, followed by causal graph inference using a novel Conditional Mamba architecture. On simulated data, CausalMamba achieves 37% higher accuracy than DCM. Critically, when applied to real task fMRI data, our method recovers well-established neural pathways with 88% fidelity, whereas conventional approaches fail to identify these canonical circuits in over 99% of subjects. Furthermore, our network analysis of working memory data reveals that the brain strategically shifts its primary causal hub-recruiting executive or salience networks depending on the stimulus-a sophisticated reconfiguration that remains undetected by traditional methods. This work provides neuroscientists with a practical tool for large-scale causal inference that captures both fundamental circuit motifs and flexible network dynamics underlying cognitive function."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Optimal error estimates of the diffuse domain method for semilinear parabolic equations", "authors": "Yuejin Xu", "subjects": "Numerical Analysis (math.NA)", "abstract": "In this paper, we mainly discuss the convergence behavior of diffuse domain method (DDM) for solving semilinear parabolic equations with Neumann boundary condition defined in general irregular domains. We use a phasefield function to approximate the irregular domain and when the interface thickness tends to zero, the phasefield function will converge to indicator function of the original domain. With this function, we can modify the problem to another one defined on a larger rectangular domain that contains the targer physical domain. Based on the weighted Sobolev spaces, we prove that when the interface thickness parameter goes to zero, the numerical solution will converge to the exact solution. Also, we derive the corresponding optimal error estimates under the weighted L2 and H1 norms. Some numerical experiments are also carried out to validate the theoretical results."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          A Single Set of Adversarial Clothes Breaks Multiple Defense Methods in the Physical World", "authors": "Wei Zhang, Zhanhao Hu, Xiao Li, Xiaopei Zhu, Xiaolin Hu", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "In recent years, adversarial attacks against deep learning-based object detectors in the physical world have attracted much attention. To defend against these attacks, researchers have proposed various defense methods against adversarial patches, a typical form of physically-realizable attack. However, our experiments showed that simply enlarging the patch size could make these defense methods fail. Motivated by this, we evaluated various defense methods against adversarial clothes which have large coverage over the human body. Adversarial clothes provide a good test case for adversarial defense against patch-based attacks because they not only have large sizes but also look more natural than a large patch on humans. Experiments show that all the defense methods had poor performance against adversarial clothes in both the digital world and the physical world. In addition, we crafted a single set of clothes that broke multiple defense methods on Faster R-CNN. The set achieved an Attack Success Rate (ASR) of 96.06% against the undefended detector and over 64.84% ASRs against nine defended models in the physical world, unveiling the common vulnerability of existing adversarial defense methods against adversarial clothes. Code is available at: this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Approximate Nearest Neighbor Search of Large Scale Vectors on Distributed Storage", "authors": "Kun Yu, Jiabao Jin, Xiaoyao Zhong, Peng Cheng, Lei Chen, Zhitao Shen, Jingkuan Song, Hengtao Shen, Xuemin Lin", "subjects": "Databases (cs.DB)", "abstract": "Approximate Nearest Neighbor Search (ANNS) in high-dimensional space is an essential operator in many online services, such as information retrieval and recommendation. Indices constructed by the state-of-the-art ANNS algorithms must be stored in single machine's memory or disk for high recall rate and throughput, suffering from substantial storage cost, constraint of limited scale and single point of failure. While distributed storage can provide a cost-effective and robust solution, there is no efficient and effective algorithms for indexing vectors in distributed storage scenarios. In this paper, we present a new graph-cluster hybrid indexing and search system which supports Distributed Storage Approximate Nearest Neighbor Search, called DSANN. DSANN can efficiently index, store, search billion-scale vector database in distributed storage and guarantee the high availability of index service. DSANN employs the concurrent index construction method to significantly reduces the complexity of index building. Then, DSANN applies Point Aggregation Graph to leverage the structural information of graph to aggregate similar vectors, optimizing storage efficiency and improving query throughput via asynchronous I/O in distributed storage. Through extensive experiments, we demonstrate DSANN can efficiently and effectively index, store and search large-scale vector datasets in distributed storage scenarios."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          CharDiff: A Diffusion Model with Character-Level Guidance for License Plate Image Restoration", "authors": "Gyuhwan Park, Kihyun Na, Injung Kim", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "abstract": "The significance of license plate image restoration goes beyond the preprocessing stage of License Plate Recognition (LPR) systems, as it also serves various purposes, including increasing evidential value, enhancing the clarity of visual interface, and facilitating further utilization of license plate images. We propose a novel diffusion-based framework with character-level guidance, CharDiff, which effectively restores and recognizes severely degraded license plate images captured under realistic conditions. CharDiff leverages fine-grained character-level priors extracted through external segmentation and Optical Character Recognition (OCR) modules tailored for low-quality license plate images. For precise and focused guidance, CharDiff incorporates a novel Character-guided Attention through Region-wise Masking (CHARM) module, which ensures that each character's guidance is restricted to its own region, thereby avoiding interference with other regions. In experiments, CharDiff significantly outperformed the baseline restoration models in both restoration quality and recognition accuracy, achieving a 28% relative reduction in CER on the Roboflow-LP dataset, compared to the best-performing baseline model. These results indicate that the structured character-guided conditioning effectively enhances the robustness of diffusion-based license plate restoration and recognition in practical deployment scenarios."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          A Review of Equation-Based and Data-Driven Reduced Order Models featuring a Hybrid cardiovascular application", "authors": "Pierfrancesco Siena, Pasquale Claudio Africa, Michele Girfoglio, Gianluigi Rozza", "subjects": "Numerical Analysis (math.NA); Medical Physics (physics.med-ph)", "abstract": "Cardiovascular diseases are a leading cause of death in the world, driving the development of patient-specific and benchmark models for blood flow analysis. This chapter provides a theoretical overview of the main categories of Reduced Order Models (ROMs), focusing on both projection-based and data-driven approaches within a classical setup. We then present a hybrid ROM tailored for simulating blood flow in a patient-specific aortic geometry. The proposed methodology integrates projection-based techniques with neural network-enhanced data-driven components, incorporating a lifting function strategy to enforce physiologically realistic outflow pressure conditions. This hybrid methodology enables a substantial reduction in computational cost while mantaining high fidelity in reconstructing both velocity and pressure fields. We compare the full- and reduced-order solutions in details and critically assess the advantages and limitations of ROMs in patient-specific cardiovascular modeling."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          iDETEX: Empowering MLLMs for Intelligent DETailed EXplainable IQA", "authors": "Zhaoran Zhao, Xinli Yue, Jianhui Sun, Yuhao Xie, Tao Shao, Liangchao Yao, Fan Xia, Yuetang Deng", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Image Quality Assessment (IQA) has progressed from scalar quality prediction to more interpretable, human-aligned evaluation paradigms. In this work, we address the emerging challenge of detailed and explainable IQA by proposing iDETEX-a unified multimodal large language model (MLLM) capable of simultaneously performing three key tasks: quality grounding, perception, and description. To facilitate efficient and generalizable training across these heterogeneous subtasks, we design a suite of task-specific offline augmentation modules and a data mixing strategy. These are further complemented by online enhancement strategies to fully exploit multi-sourced supervision. We validate our approach on the large-scale ViDA-UGC benchmark, where iDETEX achieves state-of-the-art performance across all subtasks. Our model ranks first in the ICCV MIPI 2025 Detailed Image Quality Assessment Challenge, demonstrating its effectiveness and robustness in delivering accurate and interpretable quality assessments."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Comparison and performance analysis of dynamic encrypted control approaches", "authors": "Sebastian Schlor, Frank Allg\u00f6wer", "subjects": "Systems and Control (eess.SY); Cryptography and Security (cs.CR); Optimization and Control (math.OC)", "abstract": "Encrypted controllers using homomorphic encryption have proven to guarantee the privacy of measurement and control signals, as well as system and controller parameters, while regulating the system as intended. However, encrypting dynamic controllers has remained a challenge due to growing noise and overflow issues in the encoding. In this paper, we review recent approaches to dynamic encrypted control, such as bootstrapping, periodic resets of the controller state, integer reformulations, and FIR controllers, and equip them with a stability and performance analysis to evaluate their suitability. We complement the analysis with a numerical performance comparison on a benchmark system."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          ParaSLRF: A High Performance Rational Filter Method for Solving Large Scale Eigenvalue Problems", "authors": "Biyi Wang, Karl Meerbergen, Raf Vandebril, Hengbin An, Zeyao Mo", "subjects": "Numerical Analysis (math.NA)", "abstract": "In \\emph{Wang et al., A Shifted Laplace Rational Filter for Large-Scale Eigenvalue Problems}, the SLRF method was proposed to compute all eigenvalues of a symmetric definite generalized eigenvalue problem lying in an interval on the real positive axis. The current paper discusses a parallel implementation of this method, abbreviated as ParaSLRF. The parallelization consists of two levels: (1) on the highest level, the application of the rational filter to the various vectors is partitioned among groups of processors; (2) within each group, every linear system is solved in parallel. In ParaSLRF, the linear systems are solved by iterative methods instead of direct ones, in contrast to other rational filter methods, such as, PFEAST. Because of the specific selection of poles in ParaSLRF, the computational cost of solving the associated linear systems for each pole, is almost the same. This intrinsically leads to a better load balance between each group of resources, and reduces waiting times of processes. We show numerical experiments from finite element models of mechanical vibrations, and show a detailed parallel performance analysis. ParaSLRF shows the best parallel efficiency, compared to other rational filter methods based on quadrature rules for contour integration. To further improve performance, the converged eigenpairs are locked, and a good initial guess of iterative linear solver is proposed. These enhancements of ParaSLRF show good two-level strong scalability and excellent load balance in our experiments."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          DDBot: Differentiable Physics-based Digging Robot for Unknown Granular Materials", "authors": "Xintong Yang, Minglun Wei, Ze Ji, Yu-Kun Lai", "subjects": "Robotics (cs.RO)", "abstract": "Automating the manipulation of granular materials poses significant challenges due to complex contact dynamics, unpredictable material properties, and intricate system states. Existing approaches often fail to achieve efficiency and accuracy in such tasks. To fill the research gap, this paper studies the small-scale and high-precision granular material digging task with unknown physical properties. A new framework, named differentiable digging robot (DDBot), is proposed to manipulate granular materials, including sand and soil. Specifically, we equip DDBot with a differentiable physics-based simulator, tailored for granular material manipulation, powered by GPU-accelerated parallel computing and automatic differentiation. DDBot can perform efficient differentiable system identification and high-precision digging skill optimisation for unknown granular materials, which is enabled by a differentiable skill-to-action mapping, a task-oriented demonstration method, gradient clipping and line search-based gradient descent. Experimental results show that DDBot can efficiently (converge within 5 to 20 minutes) identify unknown granular material dynamics and optimise digging skills, with high-precision results in zero-shot real-world deployments, highlighting its practicality. Benchmark results against state-of-the-art baselines also confirm the robustness and efficiency of DDBot in such digging tasks."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Nearest-Class Mean and Logits Agreement for Wildlife Open-Set Recognition", "authors": "Jiahao Huo, Mufhumudzi Muthivhi, Terence L. van Zyl, Fredrik Gustafsson", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Current state-of-the-art Wildlife classification models are trained under the closed world setting. When exposed to unknown classes, they remain overconfident in their predictions. Open-set Recognition (OSR) aims to classify known classes while rejecting unknown samples. Several OSR methods have been proposed to model the closed-set distribution by observing the feature, logit, or softmax probability space. A significant drawback of many existing approaches is the requirement to retrain the pre-trained classification model with the OSR-specific strategy. This study contributes a post-processing OSR method that measures the agreement between the models' features and predicted logits. We propose a probability distribution based on an input's distance to its Nearest Class Mean (NCM). The NCM-based distribution is then compared with the softmax probabilities from the logit space to measure agreement between the NCM and the classification head. Our proposed strategy ranks within the top three on two evaluated datasets, showing consistent performance across the two datasets. In contrast, current state-of-the-art methods excel on a single dataset. We achieve an AUROC of 93.41 and 95.35 for African and Swedish animals. The code can be found this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Interactive Force-Impedance Control", "authors": "Fan Shao, Satoshi Endo, Sandra Hirche, Fanny Ficuciello", "subjects": "Robotics (cs.RO)", "abstract": "Human collaboration with robots requires flexible role adaptation, enabling robot to switch between active leader and passive follower. Effective role switching depends on accurately estimating human intention, which is typically achieved through external force analysis, nominal robot dynamics, or data-driven approaches. However, these methods are primarily effective in contact-sparse environments. When robots under hybrid or unified force-impedance control physically interact with active humans or non-passive environments, the robotic system may lose passivity and thus compromise safety. To address this challenge, this paper proposes the unified Interactive Force-Impedance Control (IFIC) framework that adapts to the interaction power flow, ensuring effortless and safe interaction in contact-rich environments. The proposed control architecture is formulated within a port-Hamiltonian framework, incorporating both interaction and task control ports, through which system passivity is guaranteed."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          AoA Services in 5G Networks: A Framework for Real-World Implementation and Systematic Testing", "authors": "Alberto Ceresoli, Viola Bernazzoli, Roberto Pegurri, Ilario Filippini", "subjects": "Networking and Internet Architecture (cs.NI)", "abstract": "Accurate positioning is a key enabler for emerging 5G applications. While the standardized Location Management Function (LMF) operates centrally within the core network, its scalability and latency limitations hinder low-latency and fine-grained localization. A practical alternative is to shift positioning intelligence toward the radio access network (RAN), where uplink sounding reference signal (SRS)-based angle-of-arrival (AoA) estimation offers a lightweight, network-native solution. In this work, we present the first fully open-source 5G testbed for AoA estimation, enabling systematic and repeatable experimentation under realistic yet controllable channel conditions. The framework integrates the NVIDIA Sionna RT with a Keysight PROPSIM channel emulator and includes a novel phase calibration procedure for USRP N310 devices. Experimental results show sub-degree to few-degree accuracy, validating the feasibility of lightweight, single-anchor, network-native localization within next-generation 5G systems."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          On Algorithmic Meta-Theorems for Solution Discovery: Tractability and Barriers", "authors": "Nicolas Bousquet, Amer E. Mouawad, Stephanie Maaz, Naomi Nishimura, Sebastian Siebertz", "subjects": "Data Structures and Algorithms (cs.DS)", "abstract": "Solution discovery asks whether a given (infeasible) starting configuration to a problem can be transformed into a feasible solution using a limited number of transformation steps. This paper investigates meta-theorems for solution discovery for graph problems definable in monadic second-order logic (MSO$_1$ and MSO$_2$) and first-order logic (FO) where the transformation step is to slide a token to an adjacent vertex, focusing on parameterized complexity and structural graph parameters that do not involve the transformation budget $b$. We present both positive and negative results. On the algorithmic side, we prove that MSO$_2$-Discovery is in XP when parameterized by treewidth and that MSO$_1$-Discovery is fixed-parameter tractable when parameterized by neighborhood diversity. On the hardness side, we establish that FO-Discovery is W[1]-hard when parameterized by modulator to stars, modulator to paths, as well as twin cover, numbers. Additionally, we prove that MSO$_1$-Discovery is W[1]-hard when parameterized by bandwidth. These results complement the straightforward observation that solution discovery for the studied problems is fixed-parameter tractable when the budget $b$ is included in the parameter (in particular, parameterized by cliquewidth$+b$, where the cliquewidth of a graph is at most any of the studied parameters), and provide a near-complete (fixed-parameter tractability) meta-theorems investigation for solution discovery problems for MSO- and FO-definable graph problems and structural parameters larger than cliquewidth."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          DDSC: Dynamic Dual-Signal Curriculum for Data-Efficient Acoustic Scene Classification under Domain Shift", "authors": "Peihong Zhang, Yuxuan Liu, Rui Sang, Zhixin Li, Yiqiang Cai, Yizhou Tan, Shengchen Li", "subjects": "Sound (cs.SD); Artificial Intelligence (cs.AI)", "abstract": "Acoustic scene classification (ASC) suffers from device-induced domain shift, especially when labels are limited. Prior work focuses on curriculum-based training schedules that structure data presentation by ordering or reweighting training examples from easy-to-hard to facilitate learning; however, existing curricula are static, fixing the ordering or the weights before training and ignoring that example difficulty and marginal utility evolve with the learned representation. To overcome this limitation, we propose the Dynamic Dual-Signal Curriculum (DDSC), a training schedule that adapts the curriculum online by combining two signals computed each epoch: a domain-invariance signal and a learning-progress signal. A time-varying scheduler fuses these signals into per-example weights that prioritize domain-invariant examples in early epochs and progressively emphasize device-specific cases. DDSC is lightweight, architecture-agnostic, and introduces no additional inference overhead. Under the official DCASE 2024 Task~1 protocol, DDSC consistently improves cross-device performance across diverse ASC baselines and label budgets, with the largest gains on unseen-device splits."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          TopSeg: A Multi-Scale Topological Framework for Data-Efficient Heart Sound Segmentation", "authors": "Peihong Zhang, Zhixin Li, Yuxuan Liu, Rui Sang, Yiqiang Cai, Yizhou Tan, Shengchen Li", "subjects": "Sound (cs.SD); Artificial Intelligence (cs.AI)", "abstract": "Deep learning approaches for heart-sound (PCG) segmentation built on time--frequency features can be accurate but often rely on large expert-labeled datasets, limiting robustness and deployment. We present TopSeg, a topological representation-centric framework that encodes PCG dynamics with multi-scale topological features and decodes them using a lightweight temporal convolutional network (TCN) with an order- and duration-constrained inference step. To evaluate data efficiency and generalization, we train exclusively on PhysioNet 2016 dataset with subject-level subsampling and perform external validation on CirCor dataset. Under matched-capacity decoders, the topological features consistently outperform spectrogram and envelope inputs, with the largest margins at low data budgets; as a full system, TopSeg surpasses representative end-to-end baselines trained on their native inputs under the same budgets while remaining competitive at full data. Ablations at 10% training confirm that all scales contribute and that combining H_0 and H_1 yields more reliable S1/S2 localization and boundary stability. These results indicate that topology-aware representations provide a strong inductive bias for data-efficient, cross-dataset PCG segmentation, supporting practical use when labeled data are limited."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Exploring The Missing Semantics In Event Modality", "authors": "Jingqian Wu, Shengpeng Xu, Yunbo Jia, Edmund Y. Lam", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Event cameras offer distinct advantages such as low latency, high dynamic range, and efficient motion capture. However, event-to-video reconstruction (E2V), a fundamental event-based vision task, remains challenging, particularly for reconstructing and recovering semantic information. This is primarily due to the nature of the event camera, as it only captures intensity changes, ignoring static objects and backgrounds, resulting in a lack of semantic information in captured event modality. Further, semantic information plays a crucial role in video and frame reconstruction, yet is often overlooked by existing E2V approaches. To bridge this gap, we propose Semantic-E2VID, an E2V framework that explores the missing visual semantic knowledge in event modality and leverages it to enhance event-to-video reconstruction. Specifically, Semantic-E2VID introduces a cross-modal feature alignment (CFA) module to transfer the robust visual semantics from a frame-based vision foundation model, the Segment Anything Model (SAM), to the event encoder, while aligning the high-level features from distinct modalities. To better utilize the learned semantic feature, we further propose a semantic-aware feature fusion (SFF) block to integrate learned semantics in frame modality to form event representations with rich semantics that can be decoded by the event decoder. Further, to facilitate the reconstruction of semantic information, we propose a novel Semantic Perceptual E2V Supervision that helps the model to reconstruct semantic details by leveraging SAM-generated categorical labels. Extensive experiments demonstrate that Semantic-E2VID significantly enhances frame quality, outperforming state-of-the-art E2V methods across multiple benchmarks. The sample code is included in the supplementary material."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Modelling complexity in system safety: generalizing the D2T2 methodology", "authors": "Silvia Tolo, John Andrews", "subjects": "Computational Engineering, Finance, and Science (cs.CE)", "abstract": "Although Fault Tree and Event Tree analysis are still today the standard approach to system safety analysis for many engineering sectors, these techniques lack the capabilities of fully capturing the realistic, dynamic behaviour of complex systems, which results in a dense network of dependencies at any level, i.e. between components, trains of components or subsystems. While these limitations are well recognised across both industry and academia, the shortage of alternative tools able to tackle such challenges while retaining the computational feasibility of the analysis keeps fuelling the long-lived success of Fault Tree and Event Tree modelling. Analysts and regulators often rely on the use of conservative assumptions to mitigate the effect of oversimplifications associated with the use of such techniques. However, this results in the analysis output to be characterised by an unknown level of conservatism, with potential consequences on market competitiveness (i.e., over-conservatism) or safety (i.e., under-conservatism). This study proposes a generalization of the Dynamic and Dependent Tree Theory, which offers theoretical tools for the systematic integration of dependency modelling within the traditional Fault and Event Tree analysis framework. This is achieved by marrying the traditional combinatorial nature of failure analysis, formalised by the Fault and Event Tree language, with more flexible modelling solutions, which provide the flexibility required to capture complex system features. The main advantage of the proposed approach in comparison to existent solutions is the ability to take into account, under the same modelling framework, any type of dependency regardless of its nature and location, while retaining the familiarity and effectiveness of traditional safety modelling."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Towards Mixed-Modal Retrieval for Universal Retrieval-Augmented Generation", "authors": "Chenghao Zhang, Guanting Dong, Xinyu Yang, Zhicheng Dou", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Information Retrieval (cs.IR); Machine Learning (cs.LG)", "abstract": "Retrieval-Augmented Generation (RAG) has emerged as a powerful paradigm for enhancing large language models (LLMs) by retrieving relevant documents from an external corpus. However, existing RAG systems primarily focus on unimodal text documents, and often fall short in real-world scenarios where both queries and documents may contain mixed modalities (such as text and images). In this paper, we address the challenge of Universal Retrieval-Augmented Generation (URAG), which involves retrieving and reasoning over mixed-modal information to improve vision-language generation. To this end, we propose Nyx, a unified mixed-modal to mixed-modal retriever tailored for URAG scenarios. To mitigate the scarcity of realistic mixed-modal data, we introduce a four-stage automated pipeline for generation and filtering, leveraging web documents to construct NyxQA, a dataset comprising diverse mixed-modal question-answer pairs that better reflect real-world information needs. Building on this high-quality dataset, we adopt a two-stage training framework for Nyx: we first perform pre-training on NyxQA along with a variety of open-source retrieval datasets, followed by supervised fine-tuning using feedback from downstream vision-language models (VLMs) to align retrieval outputs with generative preferences. Experimental results demonstrate that Nyx not only performs competitively on standard text-only RAG benchmarks, but also excels in the more general and realistic URAG setting, significantly improving generation quality in vision-language tasks."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          SmartSustain Recommender System: Navigating Sustainability Trade-offs in Personalized City Trip Planning", "authors": "Ashmi Banerjee, Melih Mert Aksoy, Wolfgang W\u00f6rndl", "subjects": "Human-Computer Interaction (cs.HC)", "abstract": "Tourism is a major contributor to global carbon emissions and over-tourism, creating an urgent need for recommender systems that not only inform but also gently steer users toward more sustainable travel decisions. Such choices, however, often require balancing complex trade-offs between environmental impact, cost, convenience, and personal interests. To address this, we present the SmartSustain Recommender, a web application designed to nudge users toward eco-friendlier options through an interactive, user-centric interface. The system visualizes the broader consequences of travel decisions by combining CO2e emissions, destination popularity, and seasonality with personalized interest matching. It employs mechanisms such as interactive city cards for quick comparisons, dynamic banners that surface sustainable alternatives in specific trade-off scenarios, and real-time impact feedback using animated environmental indicators. A preliminary user study with 21 participants indicated strong usability and perceived effectiveness. The system is accessible at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Localist LLMs with Recruitment Learning", "authors": "Joachim Diederich", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "We present a novel framework for training large language models with continuously adjustable internal representations that span the full spectrum from localist (interpretable, rule-based) to distributed (generalizable, efficient) encodings. The key innovations are (1) a locality dial, a tunable parameter that dynamically controls the degree of localization during both training and inference without requiring model retraining, (2) an information-theoretic recruitment mechanism that adaptively allocates semantic blocks as needed, eliminating the requirement for complete domain knowledge at initialization, and (3) a hierarchical recruitment framework that extends capacity allocation to entire specialized LLMs, enabling multi-granularity architectural adaptation. This is achieved through group sparsity penalties on attention mechanisms, information-theoretic anchor design, dynamic rule injection, and principled recruitment  criteria based on penalized likelihood with explicit units. We provide rigorous mathematical results establishing explicit threshold conditions under which attention provably concentrates on semantically relevant blocks at stationary points, with exact bounds on attention entropy and pointer fidelity. The hierarchical recruitment mechanism provides convergence guarantees at both the block level (fine-grained, within-LLM) and the LLM level (coarse-grained, cross-domain), ensuring the system discovers semantic partitions that balance model complexity against data encoding efficiency. This framework enables practitioners to continuously interpolate between interpretable and high-performance modes while adapting architectural capacity at multiple granularities, supporting applications in regulated domains requiring both transparency and capability."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          M2H: Multi-Task Learning with Efficient Window-Based Cross-Task Attention for Monocular Spatial Perception", "authors": "U.V.B.L Udugama, George Vosselman, Francesco Nex", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Robotics (cs.RO)", "abstract": "Deploying real-time spatial perception on edge devices requires efficient multi-task models that leverage complementary task information while minimizing computational overhead. This paper introduces Multi-Mono-Hydra (M2H), a novel multi-task learning framework designed for semantic segmentation and depth, edge, and surface normal estimation from a single monocular image. Unlike conventional approaches that rely on independent single-task models or shared encoder-decoder architectures, M2H introduces a Window-Based Cross-Task Attention Module that enables structured feature exchange while preserving task-specific details, improving prediction consistency across tasks. Built on a lightweight ViT-based DINOv2 backbone, M2H is optimized for real-time deployment and serves as the foundation for monocular spatial perception systems supporting 3D scene graph construction in dynamic environments. Comprehensive evaluations show that M2H outperforms state-of-the-art multi-task models on NYUDv2, surpasses single-task depth and semantic baselines on Hypersim, and achieves superior performance on the Cityscapes dataset, all while maintaining computational efficiency on laptop hardware. Beyond benchmarks, M2H is validated on real-world data, demonstrating its practicality in spatial perception tasks."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Recurrent Attention-based Token Selection for Efficient Streaming Video-LLMs", "authors": "Vaggelis Dorovatas, Soroush Seifi, Gunshi Gupta, Rahaf Aljundi", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)", "abstract": "Video Large Language Models (Video-LLMs) excel at understanding videos in-context, provided they have full access to the video when answering queries. However, these models face challenges in streaming scenarios where hour-long videos must be processed online, and questions need timely responses. In this work, we propose a training-free approach compatible with standard Video-LLMs, leveraging three key concepts: 1) LLM-informed selection of visual tokens to identify those that the LLM has attended to and contributed to its understanding of each short clip. Our attention-based selection allows us to discard up to ~95% of unimportant visual tokens with minimal performance loss; 2) Recurrent processing of past selected tokens to generate temporally coherent understanding of each processed clip; 3) Caption-based question answering for lightweight and accurate responses. Our method achieves state-of-the-art performance on streaming video benchmarks, striking a balance between efficiency and effectiveness."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Bridging Embodiment Gaps: Deploying Vision-Language-Action Models on Soft Robots", "authors": "Haochen Su, Cristian Meo, Francesco Stella, Andrea Peirone, Kai Junge, Josie Hughes", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "abstract": "Robotic systems are increasingly expected to operate in human-centered, unstructured environments where safety, adaptability, and generalization are essential. Vision-Language-Action (VLA) models have been proposed as a language guided generalized control framework for real robots. However, their deployment has been limited to conventional serial link manipulators. Coupled by their rigidity and unpredictability of learning based control, the ability to safely interact with the environment is missing yet critical. In this work, we present the deployment of a VLA model on a soft continuum manipulator to demonstrate autonomous safe human-robot interaction. We present a structured finetuning and deployment pipeline evaluating two state-of-the-art VLA models (OpenVLA-OFT and $\\pi_0$) across representative manipulation tasks, and show while out-of-the-box policies fail due to embodiment mismatch, through targeted finetuning the soft robot performs equally to the rigid counterpart. Our findings highlight the necessity of finetuning for bridging embodiment gaps, and demonstrate that coupling VLA models with soft robots enables safe and flexible embodied AI in human-shared environments."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Accelerating Adaptive Systems via Normalized Parameter Estimation Laws", "authors": "Mohammad Boveiri, Mohammad Khosravi, Peyman Mohajerin Esfahan", "subjects": "Systems and Control (eess.SY); Optimization and Control (math.OC)", "abstract": "In this paper, we propose a new class of parameter estimation laws for adaptive systems, called \\emph{normalized parameter estimation laws}. A key feature of these estimation laws is that they accelerate the convergence of the system state, $\\mathit{x(t)}$, to the origin. We quantify this improvement by showing that our estimation laws guarantee finite integrability of the $\\mathit{r}$-th root of the squared norm of the system state, i.e., \\( \\mathit{\\|x(t)\\|}_2^{2/\\mathit{r}} \\in \\mathcal{L}_1, \\) where $\\mathit{r} \\geq 1$ is a pre-specified parameter that, for a broad class of systems, can be chosen arbitrarily large. In contrast, standard Lyapunov-based estimation laws only guarantee integrability of $\\mathit{\\|x(t)\\|}_2^2$ (i.e., $\\mathit{r} = 1$). We motivate our method by showing that, for large values of $r$, this guarantee serves as a sparsity-promoting mechanism in the time domain, meaning that it penalizes prolonged signal duration and slow decay, thereby promoting faster convergence of $\\mathit{x(t)}$. The proposed estimation laws do not rely on time-varying or high adaptation gains and do not require persistent excitation. Moreover, they can be applied to systems with matched and unmatched uncertainties, regardless of their dynamic structure, as long as a control Lyapunov function (CLF) exists. Finally, they are compatible with any CLF-based certainty equivalence controllers. We further develop higher-order extensions of our estimation laws by incorporating momentum into the estimation dynamics. We illustrate the performance improvements achieved with the proposed scheme through various numerical experiments."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Beyond Real Faces: Synthetic Datasets Can Achieve Reliable Recognition Performance without Privacy Compromise", "authors": "Pawe\u0142 Borsukiewicz, Fadi Boutros, Iyiola E. Olatunji, Charles Beumier, Wendk\u00fbuni C. Ouedraogo, Jacques Klein, Tegawend\u00e9 F. Bissyand\u00e9", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "The deployment of facial recognition systems has created an ethical dilemma: achieving high accuracy requires massive datasets of real faces collected without consent, leading to dataset retractions and potential legal liabilities under regulations like GDPR. While synthetic facial data presents a promising privacy-preserving alternative, the field lacks comprehensive empirical evidence of its viability. This study addresses this critical gap through extensive evaluation of synthetic facial recognition datasets. We present a systematic literature review identifying 25 synthetic facial recognition datasets (2018-2025), combined with rigorous experimental validation. Our methodology examines seven key requirements for privacy-preserving synthetic data: identity leakage prevention, intra-class variability, identity separability, dataset scale, ethical data sourcing, bias mitigation, and benchmark reliability. Through experiments involving over 10 million synthetic samples, extended by a comparison of results reported on five standard benchmarks, we provide the first comprehensive empirical assessment of synthetic data's capability to replace real datasets. Best-performing synthetic datasets (VariFace, VIGFace) achieve recognition accuracies of 95.67% and 94.91% respectively, surpassing established real datasets including CASIA-WebFace (94.70%). While those images remain private, publicly available alternatives Vec2Face (93.52%) and CemiFace (93.22%) come close behind. Our findings reveal that they ensure proper intra-class variability while maintaining identity separability. Demographic bias analysis shows that, even though synthetic data inherits limited biases, it offers unprecedented control for bias mitigation through generation parameters. These results establish synthetic facial data as a scientifically viable and ethically imperative alternative for facial recognition research."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Facial Expression-based Parkinson's Disease Severity Diagnosis via Feature Fusion and Adaptive Class Balancing", "authors": "Yintao Zhou, Wei Huang, Zhengyu Li, Jing Huang, Meng Pang", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Parkinson's disease (PD) severity diagnosis is crucial for early detecting potential patients and adopting tailored interventions. Diagnosing PD based on facial expression is grounded in PD patients' \"masked face\" symptom and gains growing interest recently for its convenience and affordability. However, current facial expression-based approaches often rely on single type of expression which can lead to misdiagnosis, and ignore the class imbalance across different PD stages which degrades the prediction performance. Moreover, most existing methods focus on binary classification (i.e., PD / non-PD) rather than diagnosing the severity of PD. To address these issues, we propose a new facial expression-based method for PD severity diagnosis which integrates multiple facial expression features through attention-based feature fusion. Moreover, we mitigate the class imbalance problem via an adaptive class balancing strategy which dynamically adjusts the contribution of training samples based on their class distribution and classification difficulty. Experimental results demonstrate the promising performance of the proposed method for PD severity diagnosis, as well as the efficacy of attention-based feature fusion and adaptive class balancing."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          AdapTrack: Constrained Decoding without Distorting LLM's Output Intent", "authors": "Yongmin Li, Jia Li, Ge Li, Zhi Jin", "subjects": "Software Engineering (cs.SE)", "abstract": "Language model-based code generation and completion tools have been widely adopted, but they may sometimes produce code that does not meet necessary constraints, such as syntactic correctness or API existence. Constrained decoding techniques are developed to help the model generate code adhering to the constraints by greedily eliminating generation options that violate constraints at each step of the generation process. However, there is a severe limitation of constrained decoding, that it distorts the model's output intent, forcing it to produce code that may satisfy the constraint but does not match the development intent and is therefore incorrect. In response to this challenge, we propose AdapTrack. By incorporating backtracking into the generation process, AdapTrack avoids distorting the output intent of the model, thereby producing results that are not only constraint-compliant but also more semantically aligned with model's output intent. On our synthetic API completion dataset, AdapTrack can achieve up to 360.87% improvement compared to constrained decoding; on the real-world API completion dataset we collect that exhibits similar issues, AdapTrack can achieve up to 38.93% improvement over constrained decoding; in general code genration benchmarks, compared to constrained decoding, AdapTrack can achieve up to 7.84% improvement on HumanEval, and up to 6.42% improvement on MBPP. This indicates that, simply by better adhering to the model's output intent, AdapTrack can achieve significant improvements. We provide a theoretical proof that the distribution produced by AdapTrack aligns with the model's distribution given the generated tokens, thereby ensuring that the model's output intent is not distorted. Experiments on DSL problems show that, compared to existing methods, our approach can provide generation results that are more consistent with the language model's distribution."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Model Metamers Reveal Invariances in Graph Neural Networks", "authors": "Wei Xu, Xiaoyi Jiang, Lixiang Xu, Dechao Tang", "subjects": "Machine Learning (cs.LG)", "abstract": "In recent years, deep neural networks have been extensively employed in perceptual systems to learn representations endowed with invariances, aiming to emulate the invariance mechanisms observed in the human brain. However, studies in the visual and auditory domains have confirmed that significant gaps remain between the invariance properties of artificial neural networks and those of humans. To investigate the invariance behavior within graph neural networks (GNNs), we introduce a model ``metamers'' generation technique. By optimizing input graphs such that their internal node activations match those of a reference graph, we obtain graphs that are equivalent in the model's representation space, yet differ significantly in both structure and node features. Our theoretical analysis focuses on two aspects: the local metamer dimension for a single node and the activation-induced volume change of the metamer manifold. Utilizing this approach, we uncover extreme levels of representational invariance across several classic GNN architectures. Although targeted modifications to model architecture and training strategies can partially mitigate this excessive invariance, they fail to fundamentally bridge the gap to human-like invariance. Finally, we quantify the deviation between metamer graphs and their original counterparts, revealing unique failure modes of current GNNs and providing a complementary benchmark for model evaluation."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Optimizing Energy Management of Smart Grid using Reinforcement Learning aided by Surrogate models built using Physics-informed Neural Networks", "authors": "Julen Cestero, Carmine Delle Femine, Kenji S. Muro, Marco Quartulli, Marcello Restelli", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "Optimizing the energy management within a smart grids scenario presents significant challenges, primarily due to the complexity of real-world systems and the intricate interactions among various components. Reinforcement Learning (RL) is gaining prominence as a solution for addressing the challenges of Optimal Power Flow in smart grids. However, RL needs to iterate compulsively throughout a given environment to obtain the optimal policy. This means obtaining samples from a, most likely, costly simulator, which can lead to a sample efficiency problem. In this work, we address this problem by substituting costly smart grid simulators with surrogate models built using Phisics-informed Neural Networks (PINNs), optimizing the RL policy training process by arriving to convergent results in a fraction of the time employed by the original environment."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Beyond Binary Out-of-Distribution Detection: Characterizing Distributional Shifts with Multi-Statistic Diffusion Trajectories", "authors": "Achref Jaziri, Martin Rogmann, Martin Mundt, Visvanathan Ramesh", "subjects": "Machine Learning (cs.LG)", "abstract": "Detecting out-of-distribution (OOD) data is critical for machine learning, be it for safety reasons or to enable open-ended learning. However, beyond mere detection, choosing an appropriate course of action typically hinges on the type of OOD data encountered. Unfortunately, the latter is generally not distinguished in practice, as modern OOD detection methods collapse distributional shifts into single scalar outlier scores. This work argues that scalar-based methods are thus insufficient for OOD data to be properly contextualized and prospectively exploited, a limitation we overcome with the introduction of DISC: Diffusion-based Statistical Characterization. DISC leverages the iterative denoising process of diffusion models to extract a rich, multi-dimensional feature vector that captures statistical discrepancies across multiple noise levels. Extensive experiments on image and tabular benchmarks show that DISC matches or surpasses state-of-the-art detectors for OOD detection and, crucially, also classifies OOD type, a capability largely absent from prior work. As such, our work enables a shift from simple binary OOD detection to a more granular detection."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Graph Attention-Guided Search for Dense Multi-Agent Pathfinding", "authors": "Rishabh Jain, Keisuke Okumura, Michael Amir, Amanda Prorok", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multiagent Systems (cs.MA); Robotics (cs.RO)", "abstract": "Finding near-optimal solutions for dense multi-agent pathfinding (MAPF) problems in real-time remains challenging even for state-of-the-art planners. To this end, we develop a hybrid framework that integrates a learned heuristic derived from MAGAT, a neural MAPF policy with a graph attention scheme, into a leading search-based algorithm, LaCAM. While prior work has explored learning-guided search in MAPF, such methods have historically underperformed. In contrast, our approach, termed LaGAT, outperforms both purely search-based and purely learning-based methods in dense scenarios. This is achieved through an enhanced MAGAT architecture, a pre-train-then-fine-tune strategy on maps of interest, and a deadlock detection scheme to account for imperfect neural guidance. Our results demonstrate that, when carefully designed, hybrid search offers a powerful solution for tightly coupled, challenging multi-agent coordination problems."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Latent Spaces Beyond Synthesis: From GANs to Diffusion Models", "authors": "Ludovica Schaerf", "subjects": "Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV); Computers and Society (cs.CY)", "abstract": "This paper examines the evolving nature of internal representations in generative visual models, focusing on the conceptual and technical shift from GANs and VAEs to diffusion-based architectures. Drawing on Beatrice Fazi's account of synthesis as the amalgamation of distributed representations, we propose a distinction between \"synthesis in a strict sense\", where a compact latent space wholly determines the generative process, and \"synthesis in a broad sense,\" which characterizes models whose representational labor is distributed across layers. Through close readings of model architectures and a targeted experimental setup that intervenes in layerwise representations, we show how diffusion models fragment the burden of representation and thereby challenge assumptions of unified internal space. By situating these findings within media theoretical frameworks and critically engaging with metaphors such as the latent space and the Platonic Representation Hypothesis, we argue for a reorientation of how generative AI is understood: not as a direct synthesis of content, but as an emergent configuration of specialized processes."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Closed-Loop Transfer for Weakly-supervised Affordance Grounding", "authors": "Jiajin Tang, Zhengxuan Wei, Ge Zheng, Sibei Yang", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Humans can perform previously unexperienced interactions with novel objects simply by observing others engage with them. Weakly-supervised affordance grounding mimics this process by learning to locate object regions that enable actions on egocentric images, using exocentric interaction images with image-level annotations. However, extracting affordance knowledge solely from exocentric images and transferring it one-way to egocentric images limits the applicability of previous works in complex interaction scenarios. Instead, this study introduces LoopTrans, a novel closed-loop framework that not only transfers knowledge from exocentric to egocentric but also transfers back to enhance exocentric knowledge extraction. Within LoopTrans, several innovative mechanisms are introduced, including unified cross-modal localization and denoising knowledge distillation, to bridge domain gaps between object-centered egocentric and interaction-centered exocentric images while enhancing knowledge transfer. Experiments show that LoopTrans achieves consistent improvements across all metrics on image and video benchmarks, even handling challenging scenarios where object interaction regions are fully occluded by the human body."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          TabR1: Taming GRPO for tabular reasoning LLMs", "authors": "Pengxiang Cai, Zihao Gao, Jintai Chen", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "Tabular prediction has traditionally relied on gradient-boosted decision trees and specialized deep learning models, which excel within tasks but provide limited interpretability and weak transfer across tables. Reasoning large language models (LLMs) promise cross-task adaptability with trans- parent reasoning traces, yet their potential has not been fully realized for tabular data. This paper presents TabR1, the first reasoning LLM for tabular prediction with multi-step reasoning. At its core is Permutation Relative Policy Optimization (PRPO), a simple yet efficient reinforcement learning method that encodes column-permutation invariance as a structural prior. By construct- ing multiple label-preserving permutations per sample and estimating advantages both within and across permutations, PRPO transforms sparse rewards into dense learning signals and improves generalization. With limited supervision, PRPO activates the reasoning ability of LLMs for tabular prediction, enhancing few-shot and zero-shot performance as well as interpretability. Comprehensive experiments demonstrate that TabR1 achieves performance comparable to strong baselines under full-supervision fine-tuning. In the zero-shot setting, TabR1 approaches the performance of strong baselines under the 32-shot setting. Moreover, TabR1 (8B) substantially outperforms much larger LLMs across various tasks, achieving up to 53.17% improvement over DeepSeek-R1 (685B)."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Inference of Deterministic Finite Automata via Q-Learning", "authors": "Elaheh Hosseinkhani, Martin Leucker", "subjects": "Formal Languages and Automata Theory (cs.FL); Artificial Intelligence (cs.AI)", "abstract": "Traditional approaches to inference of deterministic finite-state automata (DFA) stem from symbolic AI, including both active learning methods (e.g., Angluin's L* algorithm and its variants) and passive techniques (e.g., Biermann and Feldman's method, RPNI). Meanwhile, sub-symbolic AI, particularly machine learning, offers alternative paradigms for learning from data, such as supervised, unsupervised, and reinforcement learning (RL). This paper investigates the use of Q-learning, a well-known reinforcement learning algorithm, for the passive inference of deterministic finite automata. It builds on the core insight that the learned Q-function, which maps state-action pairs to rewards, can be reinterpreted as the transition function of a DFA over a finite domain. This provides a novel bridge between sub-symbolic learning and symbolic representations. The paper demonstrates how Q-learning can be adapted for automaton inference and provides an evaluation on several examples."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          The Atomic Instruction Gap: Instruction-Tuned LLMs Struggle with Simple, Self-Contained Directives", "authors": "Henry Lim, Kwan Hui Lim", "subjects": "Computation and Language (cs.CL)", "abstract": "Instruction-tuned large language models (IT-LLMs) exhibit strong zero-shot reasoning, yet their ability to execute simple, self-contained instructions remains underexplored, despite this being foundational to complex instruction-following. We evaluate 20 IT-LLMs on modified MMLU and MMLU-Pro benchmarks, by systematically varying the format of option labels (alphabetic, numeric, Roman) while keeping their meaning identical under four paradigms, namely: (1) With explicit instructions, label changes cause large performance shifts (e.g., -30.45\\% for Roman vs. numeric), revealing instruction-format bias. (2) Without instructions, performance drops further (up to -10.84\\%) and label sensitivity intensifies, underscoring the role of explicit guidance. (3) When option contents are removed, models fail random-choice baselines except with numeric labels, suggesting weak adherence to atomic directives. (4) Three-shot exemplars yield no significant gains in robustness or fidelity, and generation analyses show persistent label errors, especially for non-numeric formats. Across model sizes, larger LLMs achieve higher accuracy but remain inconsistent in instruction adherence. These results expose the insufficiencies of current instruction-tuning paradigms and highlight the need for evaluation methods and training strategies that explicitly target atomic instruction-following."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          EduAdapt: A Question Answer Benchmark Dataset for Evaluating Grade-Level Adaptability in LLMs", "authors": "Numaan Naeem, Abdellah El Mekki, Muhammad Abdul-Mageed", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "abstract": "Large language models (LLMs) are transforming education by answering questions, explaining complex concepts, and generating content across a wide range of subjects. Despite strong performance on academic benchmarks, they often fail to tailor responses to students' grade levels. This is a critical need in K-12 education, where age-appropriate vocabulary and explanation are essential for effective learning. Existing models frequently produce outputs that are too advanced or vague for younger learners, and there are no standardized benchmarks to evaluate their ability to adjust across cognitive and developmental stages. To address this gap, we introduce EduAdapt, a benchmark of nearly 48k grade-labeled QA pairs across nine science subjects, spanning Grades 1-12 and grouped into four grade levels. We evaluate a diverse set of open-source LLMs on EduAdapt and find that while larger models generally perform better, they still struggle with generating suitable responses for early-grade students (Grades 1-5). Our work presents the first dataset and evaluation framework for assessing grade-level adaptability in LLMs, aiming to foster more developmentally aligned educational AI systems through better training and prompting strategies. EduAdapt code and datasets are publicly available at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Exploration via Feature Perturbation in Contextual Bandits", "authors": "Seouh-won Yi, Min-hwan Oh", "subjects": "Machine Learning (cs.LG); Machine Learning (stat.ML)", "abstract": "We propose feature perturbation, a simple yet powerful technique that injects randomness directly into feature inputs, instead of randomizing unknown parameters or adding noise to rewards. Remarkably, this algorithm achieves $\\tilde{\\mathcal{O}}(d\\sqrt{T})$ worst-case regret bound for generalized linear bandits, while avoiding the $\\tilde{\\mathcal{O}}(d^{3/2}\\sqrt{T})$ regret typical of existing randomized bandit algorithms. Because our algorithm eschews parameter sampling, it is both computationally efficient and naturally extends to non-parametric or neural network models. We verify these advantages through empirical evaluations, demonstrating that feature perturbation not only surpasses existing methods but also unifies strong practical performance with best-known theoretical guarantees."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Finite-Time Bounds for Average-Reward Fitted Q-Iteration", "authors": "Jongmin Lee, Ernest K. Ryu", "subjects": "Machine Learning (cs.LG)", "abstract": "Although there is an extensive body of work characterizing the sample complexity of discounted-return offline RL with function approximations, prior work on the average-reward setting has received significantly less attention, and existing approaches rely on restrictive assumptions, such as ergodicity or linearity of the MDP. In this work, we establish the first sample complexity results for average-reward offline RL with function approximation for weakly communicating MDPs, a much milder assumption. To this end, we introduce Anchored Fitted Q-Iteration, which combines the standard Fitted Q-Iteration with an anchor mechanism. We show that the anchor, which can be interpreted as a form of weight decay, is crucial for enabling finite-time analysis in the average-reward setting. We also extend our finite-time analysis to the setup where the dataset is generated from a single-trajectory rather than IID transitions, again leveraging the anchor mechanism."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          ReLACE: A Resource-Efficient Low-Latency Cortical Acceleration Engine", "authors": "Sonu Kumar, Arjun S. Nair, Bhawna Chaudhary, Mukul Lokhande, Santosh Kumar Vishvakarma", "subjects": "Neural and Evolutionary Computing (cs.NE); Hardware Architecture (cs.AR)", "abstract": "We present a Cortical Neural Pool (CNP) architecture featuring a high-speed, resource-efficient CORDIC-based Hodgkin Huxley (RCHH) neuron model. Unlike shared CORDIC-based DNN approaches, the proposed neuron leverages modular and performance-optimised CORDIC stages with a latency-area trade-off. The FPGA implementation of the RCHH neuron shows 24.5% LUT reduction and 35.2% improved speed, compared to SoTA designs, with 70% better normalised root mean square error (NRMSE). Furthermore, the CNP exhibits 2.85x higher throughput (12.69 GOPS) compared to a functionally equivalent CORDIC-based DNN engine, with only a 0.35% accuracy drop compared to the DNN counterpart on the MNIST dataset. The overall results indicate that the design shows biologically accurate, low-resource spiking neural network implementations for resource-constrained edge AI applications."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          MILES: Modality-Informed Learning Rate Scheduler for Balancing Multimodal Learning", "authors": "Alejandro Guerra-Manzanares, Farah E. Shamout", "subjects": "Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV)", "abstract": "The aim of multimodal neural networks is to combine diverse data sources, referred to as modalities, to achieve enhanced performance compared to relying on a single modality. However, training of multimodal networks is typically hindered by modality overfitting, where the network relies excessively on one of the available modalities. This often yields sub-optimal performance, hindering the potential of multimodal learning and resulting in marginal improvements relative to unimodal models. In this work, we present the Modality-Informed Learning ratE Scheduler (MILES) for training multimodal joint fusion models in a balanced manner. MILES leverages the differences in modality-wise conditional utilization rates during training to effectively balance multimodal learning. The learning rate is dynamically adjusted during training to balance the speed of learning from each modality by the multimodal model, aiming for enhanced performance in both multimodal and unimodal predictions. We extensively evaluate MILES on four multimodal joint fusion tasks and compare its performance to seven state-of-the-art baselines. Our results show that MILES outperforms all baselines across all tasks and fusion methods considered in our study, effectively balancing modality usage during training. This results in improved multimodal performance and stronger modality encoders, which can be leveraged when dealing with unimodal samples or absent modalities. Overall, our work highlights the impact of balancing multimodal learning on improving model performance."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Enhancing 5G V2X Mode 2 for Sporadic Traffic", "authors": "Dmitry Bankov, Artem Krasilov, Artem Otmakhov, Aleksei Shashin, Evgeny Khorov", "subjects": "Networking and Internet Architecture (cs.NI)", "abstract": "The emerging road safety and autonomous vehicle applications require timely and reliable data delivery between vehicles and between vehicles and infrastructure. To satisfy this demand, 3GPP develops a 5G Vehicle-to-Everything (V2X) technology. Depending on the served traffic type, 5G V2X specifications propose two channel access methods: (i) Mode 1, according to which a base station allocates resources to users, and (ii) Mode 2, according to which users autonomously select resources for their transmissions. In the paper, we consider a scenario with sporadic traffic, e.g., a vehicle generates a packet at a random time moment when it detects a dangerous situation, which imposes strict requirements on delay and reliability. To satisfy strict delay requirements, vehicles use Mode 2. We analyze the performance of Mode 2 for sporadic traffic and propose several approaches to improve it. Simulation results show that the proposed approaches can increase the system capacity by up to 40% with a low impact on complexity."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          RINS-T: Robust Implicit Neural Solvers for Time Series Linear Inverse Problems", "authors": "Keivan Faghih Niresi, Zepeng Zhang, Olga Fink", "subjects": "Machine Learning (cs.LG); Signal Processing (eess.SP); Machine Learning (stat.ML)", "abstract": "Time series data are often affected by various forms of corruption, such as missing values, noise, and outliers, which pose significant challenges for tasks such as forecasting and anomaly detection. To address these issues, inverse problems focus on reconstructing the original signal from corrupted data by leveraging prior knowledge about its underlying structure. While deep learning methods have demonstrated potential in this domain, they often require extensive pretraining and struggle to generalize under distribution shifts. In this work, we propose RINS-T (Robust Implicit Neural Solvers for Time Series Linear Inverse Problems), a novel deep prior framework that achieves high recovery performance without requiring pretraining data. RINS-T leverages neural networks as implicit priors and integrates robust optimization techniques, making it resilient to outliers while relaxing the reliance on Gaussian noise assumptions. To further improve optimization stability and robustness, we introduce three key innovations: guided input initialization, input perturbation, and convex output combination techniques. Each of these contributions strengthens the framework's optimization stability and robustness. These advancements make RINS-T a flexible and effective solution for addressing complex real-world time series challenges. Our code is available at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          MiCRO for Multilateral Negotiations", "authors": "David Aguilera-Luzon, Dave de Jonge, Javier Larrosa", "subjects": "Multiagent Systems (cs.MA)", "abstract": "Recently, a very simple new bilateral negotiation strategy called MiCRO was introduced that does not make use of any kind of opponent modeling or machine learning techniques and that does not require fine-tuning of any parameters. Despite its simplicity, it was shown that MiCRO performs similar to -- or even better than -- most state-of-the-art negotiation strategies. This lead its authors to argue that the benchmark domains on which negotiation algorithms are typically tested may be too simplistic. However, one question that was left open, was how MiCRO could be generalized to multilateral negotiations. In this paper we fill this gap by introducing a multilateral variant of MiCRO. We compare it with the winners of the Automated Negotiating Agents Competitions (ANAC) of 2015, 2017 and 2018 and show that it outperforms them. Furthermore, we perform an empirical game-theoretical analysis to show that our new version of MiCRO forms an empirical Nash equilibrium."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Leveraging Group Relative Policy Optimization to Advance Large Language Models in Traditional Chinese Medicine", "authors": "Jiacheng Xie, Shuai Zeng, Yang Yu, Xiaoting Tang, Guanghui An, Dong Xu", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "abstract": "Traditional Chinese Medicine (TCM) presents a rich and structurally unique knowledge system that challenges conventional applications of large language models (LLMs). Although previous TCM-specific LLMs have shown progress through supervised fine-tuning, they often face limitations in alignment, data quality, and evaluation consistency. In this study, we introduce Ladder-base, the first TCM-focused LLM trained with Group Relative Policy Optimization (GRPO), a reinforcement learning method that improves reasoning and factual consistency by optimizing response selection based on intra-group comparisons. Ladder-base is built upon the Qwen2.5-7B-Instruct foundation model and trained exclusively on the textual subset of the TCM-Ladder benchmark, using 80 percent of the data for training and the remaining 20 percent split evenly between validation and test sets. Through standardized evaluation, Ladder-base demonstrates superior performance across multiple reasoning metrics when compared to both state-of-the-art general-purpose LLMs such as GPT-4, Gemini 2.5, Claude 3, and Qwen3 and domain-specific TCM models including BenTsao, HuatuoGPT2, and Zhongjing. These findings suggest that GRPO provides an effective and efficient strategy for aligning LLMs with expert-level reasoning in traditional medical domains and supports the development of trustworthy and clinically grounded TCM artificial intelligence systems."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Process Automation Architecture Using RFID for Transparent Voting Systems", "authors": "Stella N. Arinze, Patrick U. Okafor, Onyekachi M. Egwuagu, Augustine O. Nwajana", "subjects": "Cryptography and Security (cs.CR); Systems and Control (eess.SY)", "abstract": "This paper presents the development of a process automation architecture leveraging Radio Frequency Identification (RFID) technology for secure, transparent and efficient voting systems. The proposed architecture automates the voting workflow through RFID-enabled voter identification, encrypted vote casting, and secure data transmission. Each eligible voter receives a smart RFID card containing a uniquely encrypted identifier, which is verified using an RC522 reader interfaced with a microcontroller. Upon successful verification, the voter interacts with a touchscreen interface to cast a vote, which is then encrypted using AES-128 and securely stored on a local SD card or transmitted via GSM to a central server. A tamper-proof monitoring mechanism records each session with time-stamped digital signatures, ensuring auditability and data integrity. The architecture is designed to function in both online and offline modes, with an automated batch synchronization mechanism that updates vote records once network connectivity is restored. System testing in simulated environments confirmed 100% voter authentication accuracy, minimized latency (average voting time of 11.5 seconds), and robustness against cloning, double voting, and data interception. The integration of real-time monitoring and secure process control modules enables electoral authorities to automate data logging, detect anomalies, and validate system integrity dynamically. This work demonstrates a scalable, automation-driven solution for voting infrastructure, offering enhanced transparency, resilience, and deployment flexibility, especially in environments where digital transformation of electoral processes is critically needed."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          AFRICAPTION: Establishing a New Paradigm for Image Captioning in African Languages", "authors": "Mardiyyah Oduwole, Prince Mireku, Fatimo Adebanjo, Oluwatosin Olajide, Mahi Aminu Aliyu, Jekaterina Novikova", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "abstract": "Multimodal AI research has overwhelmingly focused on high-resource languages, hindering the democratization of advancements in the field. To address this, we present AfriCaption, a comprehensive framework for multilingual image captioning in 20 African languages and our contributions are threefold: (i) a curated dataset built on Flickr8k, featuring semantically aligned captions generated via a context-aware selection and translation process; (ii) a dynamic, context-preserving pipeline that ensures ongoing quality through model ensembling and adaptive substitution; and (iii) the AfriCaption model, a 0.5B parameter vision-to-text architecture that integrates SigLIP and NLLB200 for caption generation across under-represented languages. This unified framework ensures ongoing data quality and establishes the first scalable image-captioning resource for under-represented African languages, laying the groundwork for truly inclusive multimodal AI."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          S4ECG: Exploring the impact of long-range interactions for arrhythmia prediction", "authors": "Tiezhi Wang, Wilhelm Haverkamp, Nils Strodthoff", "subjects": "Machine Learning (cs.LG); Signal Processing (eess.SP)", "abstract": "The electrocardiogram (ECG) exemplifies biosignal-based time series with continuous, temporally ordered structure reflecting cardiac physiological and pathophysiological dynamics. Detailed analysis of these dynamics has proven challenging, as conventional methods capture either global trends or local waveform features but rarely their simultaneous interplay at high temporal resolution. To bridge global and local signal analysis, we introduce S4ECG, a novel deep learning architecture leveraging structured state space models for multi-epoch arrhythmia classification. Our joint multi-epoch predictions significantly outperform single-epoch approaches by 1.0-11.6% in macro-AUROC, with atrial fibrillation specificity improving from 0.718-0.979 to 0.967-0.998, demonstrating superior performance in-distribution and enhanced out-of-distribution robustness. Systematic investigation reveals optimal temporal dependency windows spanning 10-20 minutes for peak performance. This work contributes to a paradigm shift toward temporally-aware arrhythmia detection algorithms, opening new possibilities for ECG interpretation, in particular for complex arrhythmias like atrial fibrillation and atrial flutter."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Integrating Trustworthy Artificial Intelligence with Energy-Efficient Robotic Arms for Waste Sorting", "authors": "Halima I. Kure, Jishna Retnakumari, Augustine O. Nwajana, Umar M. Ismail, Bilyaminu A. Romo, Ehigiator Egho-Promise", "subjects": "Robotics (cs.RO); Systems and Control (eess.SY)", "abstract": "This paper presents a novel methodology that integrates trustworthy artificial intelligence (AI) with an energy-efficient robotic arm for intelligent waste classification and sorting. By utilizing a convolutional neural network (CNN) enhanced through transfer learning with MobileNetV2, the system accurately classifies waste into six categories: plastic, glass, metal, paper, cardboard, and trash. The model achieved a high training accuracy of 99.8% and a validation accuracy of 80.5%, demonstrating strong learning and generalization. A robotic arm simulator is implemented to perform virtual sorting, calculating the energy cost for each action using Euclidean distance to ensure optimal and efficient movement. The framework incorporates key elements of trustworthy AI, such as transparency, robustness, fairness, and safety, making it a reliable and scalable solution for smart waste management systems in urban settings."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Monitoring Horses in Stalls: From Object to Event Detection", "authors": "Dmitrii Galimzianov, Viacheslav Vyshegorodtsev, Ivan Nezhivykh", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Monitoring the behavior of stalled horses is essential for early detection of health and welfare issues but remains labor-intensive and time-consuming. In this study, we present a prototype vision-based monitoring system that automates the detection and tracking of horses and people inside stables using object detection and multi-object tracking techniques. The system leverages YOLOv11 and BoT-SORT for detection and tracking, while event states are inferred based on object trajectories and spatial relations within the stall. To support development, we constructed a custom dataset annotated with assistance from foundation models CLIP and GroundingDINO. The system distinguishes between five event types and accounts for the camera's blind spots. Qualitative evaluation demonstrated reliable performance for horse-related events, while highlighting limitations in detecting people due to data scarcity. This work provides a foundation for real-time behavioral monitoring in equine facilities, with implications for animal welfare and stable management."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Is It Worth to Use Feedback Channel in 5G V2X Platoon Scenarios?", "authors": "Dmitry Bankov, Artem Krasilov, Artem Otmakhov, Pavel Savlukovich, Evgeny Khorov", "subjects": "Networking and Internet Architecture (cs.NI)", "abstract": "5G Vehicle-to-Everything (V2X) is a new technology developed by 3GPP to support inter-vehicle communication. In contrast to 4G V2X which allows only broadcast communication, 5G V2X enables groupcast and unicast communication. Such types of communication are needed for new V2X scenarios: platooning, extended sensors, remote driving, etc. To improve the data transmission reliability and assist in the selection of the transmission parameters in these scenarios, 5G V2X introduces a feedback channel that allows receivers to send acknowledgments in response to data packets. However, some part of the overall resource shall be allocated for the feedback channel, which reduces the amount of channel resources available for data transmission. In this paper, we consider a scenario with a platoon, which generates groupcast traffic, and surrounding vehicles, which generate legacy broadcast traffic. Using extensive simulations in NS-3, we analyze how the usage of the feedback channel influences the overall system capacity. Our results show that depending on the platoon size, groupcast, and broadcast traffic intensities, and their quality of service requirements, the usage of the feedback channel can in some cases significantly increase the system capacity (up to 2x), while in other cases it almost halves the system capacity. We explain the reasons for such effects and discuss how to adaptively select the feedback channel parameters."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          A Conditional Diffusion Model for Probabilistic Prediction of Battery Capacity Degradation", "authors": "Hequn Li, Zhongwei Deng, Chunlin Jiang, Yvxin He andZhansheng Ning", "subjects": "Machine Learning (cs.LG)", "abstract": "Accurate prediction of lithium-ion battery capacity and its associated uncertainty is essential for reliable battery management but remains challenging due to the stochastic nature of aging. This paper presents a novel method, termed the Condition Diffusion U-Net with Attention (CDUA), which integrates feature engineering and deep learning to address this challenge. The proposed approach employs a diffusion-based generative model for time-series forecasting and incorporates attention mechanisms to enhance predictive performance. Battery capacity is first derived from real-world vehicle operation data. The most relevant features are then identified using the Pearson correlation coefficient and the XGBoost algorithm. These features are used to train the CDUA model, which comprises two core components: (1) a contextual U-Net with self-attention to capture complex temporal dependencies, and (2) a denoising network to reconstruct accurate capacity values from noisy observations. Experimental validation on the real-world vehicle data demonstrates that the proposed CDUA model achieves a relative Mean Absolute Error (MAE) of 0.94% and a relative Root Mean Square Error (RMSE) of 1.14%, with a narrow 95% confidence interval of 3.74% in relative width. These results confirm that CDUA provides both accurate capacity estimation and reliable uncertainty quantification. Comparative experiments further verify its robustness and superior performance over existing mainstream approaches."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          BenCao: An Instruction-Tuned Large Language Model for Traditional Chinese Medicine", "authors": "Jiacheng Xie, Yang Yu, Yibo Chen, Hanyao Zhang, Lening Zhao, Jiaxuan He, Lei Jiang, Xiaoting Tang, Guanghui An, Dong Xu", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA); Multimedia (cs.MM); Software Engineering (cs.SE)", "abstract": "Traditional Chinese Medicine (TCM), with a history spanning over two millennia, plays a role in global healthcare. However, applying large language models (LLMs) to TCM remains challenging due to its reliance on holistic reasoning, implicit logic, and multimodal diagnostic cues. Existing TCM-domain LLMs have made progress in text-based understanding but lack multimodal integration, interpretability, and clinical applicability. To address these limitations, we developed BenCao, a ChatGPT-based multimodal assistant for TCM, integrating structured knowledge bases, diagnostic data, and expert feedback refinement. BenCao was trained through natural language instruction tuning rather than parameter retraining, aligning with expert-level reasoning and ethical norms specific to TCM. The system incorporates a comprehensive knowledge base of over 1,000 classical and modern texts, a scenario-based instruction framework for diverse interactions, a chain-of-thought simulation mechanism for interpretable reasoning, and a feedback refinement process involving licensed TCM practitioners. BenCao connects to external APIs for tongue-image classification and multimodal database retrieval, enabling dynamic access to diagnostic resources. In evaluations across single-choice question benchmarks and multimodal classification tasks, BenCao achieved superior accuracy to general-domain and TCM-domain models, particularly in diagnostics, herb recognition, and constitution classification. The model was deployed as an interactive application on the OpenAI GPTs Store, accessed by nearly 1,000 users globally as of October 2025. This study demonstrates the feasibility of developing a TCM-domain LLM through natural language-based instruction tuning and multimodal integration, offering a practical framework for aligning generative AI with traditional medical reasoning and a scalable pathway for real-world deployment."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Diverse Planning with Simulators via Linear Temporal Logic", "authors": "Mustafa F. Abdelwahed, Alice Toniolo, Joan Espasa, Ian P. Gent", "subjects": "Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "abstract": "Autonomous agents rely on automated planning algorithms to achieve their objectives. Simulation-based planning offers a significant advantage over declarative models in modelling complex environments. However, relying solely on a planner that produces a single plan may not be practical, as the generated plans may not always satisfy the agent's preferences. To address this limitation, we introduce $\\texttt{FBI}_\\texttt{LTL}$, a diverse planner explicitly designed for simulation-based planning problems. $\\texttt{FBI}_\\texttt{LTL}$ utilises Linear Temporal Logic (LTL) to define semantic diversity criteria, enabling agents to specify what constitutes meaningfully different plans. By integrating these LTL-based diversity models directly into the search process, $\\texttt{FBI}_\\texttt{LTL}$ ensures the generation of semantically diverse plans, addressing a critical limitation of existing diverse planning approaches that may produce syntactically different but semantically identical solutions. Extensive evaluations on various benchmarks consistently demonstrate that $\\texttt{FBI}_\\texttt{LTL}$ generates more diverse plans compared to a baseline approach. This work establishes the feasibility of semantically-guided diverse planning in simulation-based environments, paving the way for innovative approaches in realistic, non-symbolic domains where traditional model-based approaches fail."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Diffusion Models as Dataset Distillation Priors", "authors": "Duo Su, Huyu Wu, Huanran Chen, Yiming Shi, Yuzhu Wang, Xi Ye, Jun Zhu", "subjects": "Machine Learning (cs.LG)", "abstract": "Dataset distillation aims to synthesize compact yet informative datasets from large ones. A significant challenge in this field is achieving a trifecta of diversity, generalization, and representativeness in a single distilled dataset. Although recent generative dataset distillation methods adopt powerful diffusion models as their foundation models, the inherent representativeness prior in diffusion models is overlooked. Consequently, these approaches often necessitate the integration of external constraints to enhance data quality. To address this, we propose Diffusion As Priors (DAP), which formalizes representativeness by quantifying the similarity between synthetic and real data in feature space using a Mercer kernel. We then introduce this prior as guidance to steer the reverse diffusion process, enhancing the representativeness of distilled samples without any retraining. Extensive experiments on large-scale datasets, such as ImageNet-1K and its subsets, demonstrate that DAP outperforms state-of-the-art methods in generating high-fidelity datasets while achieving superior cross-architecture generalization. Our work not only establishes a theoretical connection between diffusion priors and the objectives of dataset distillation but also provides a practical, training-free framework for improving the quality of the distilled dataset."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          DeepDetect: Learning All-in-One Dense Keypoints", "authors": "Shaharyar Ahmed Khan Tareen, Filza Khan Tareen", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Keypoint detection is the foundation of many computer vision tasks, including image registration, structure-from motion, 3D reconstruction, visual odometry, and SLAM. Traditional detectors (SIFT, SURF, ORB, BRISK, etc.) and learning based methods (SuperPoint, R2D2, LF-Net, D2-Net, etc.) have shown strong performance yet suffer from key limitations: sensitivity to photometric changes, low keypoint density and repeatability, limited adaptability to challenging scenes, and lack of semantic understanding, often failing to prioritize visually important regions. We present DeepDetect, an intelligent, all-in-one, dense keypoint detector that unifies the strengths of classical detectors using deep learning. Firstly, we create ground-truth masks by fusing outputs of 7 keypoint and 2 edge detectors, extracting diverse visual cues from corners and blobs to prominent edges and textures in the images. Afterwards, a lightweight and efficient model: ESPNet, is trained using these masks as labels, enabling DeepDetect to focus semantically on images while producing highly dense keypoints, that are adaptable to diverse and visually degraded conditions. Evaluations on the Oxford Affine Covariant Regions dataset demonstrate that DeepDetect surpasses other detectors in keypoint density, repeatability, and the number of correct matches, achieving maximum values of 0.5143 (average keypoint density), 0.9582 (average repeatability), and 59,003 (correct matches)."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Quantifying Climate Policy Action and Its Links to Development Outcomes: A Cross-National Data-Driven Analysis", "authors": "Aditi Dutta", "subjects": "Computers and Society (cs.CY); Machine Learning (cs.LG)", "abstract": "Addressing climate change effectively requires more than cataloguing the number of policies in place; it calls for tools that can reveal their thematic priorities and their tangible impacts on development outcomes. Existing assessments often rely on qualitative descriptions or composite indices, which can mask crucial differences between key domains such as mitigation, adaptation, disaster risk management, and loss and damage. To bridge this gap, we develop a quantitative indicator of climate policy orientation by applying a multilingual transformer-based language model to official national policy documents, achieving a classification accuracy of 0.90 (F1-score). Linking these indicators with World Bank development data in panel regressions reveals that mitigation policies are associated with higher GDP and GNI; disaster risk management correlates with greater GNI and debt but reduced foreign direct investment; adaptation and loss and damage show limited measurable effects. This integrated NLP-econometric framework enables comparable, theme-specific analysis of climate governance, offering a scalable method to monitor progress, evaluate trade-offs, and align policy emphasis with development goals."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Navigating the Alignment-Calibration Trade-off: A Pareto-Superior Frontier via Model Merging", "authors": "Tiancheng Hu, Benjamin Minixhofer, Nigel Collier", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "abstract": "The \"alignment tax\" of post-training is typically framed as a drop in task accuracy. We show it also involves a severe loss of calibration, making models overconfident, less reliable, and model outputs less diverse. We show that this trade-off can be navigated effectively via a simple post-hoc intervention: interpolating between a model's weights before and after alignment. Crucially, this is not a strict trade-off. We find that the process consistently reveals Pareto-optimal interpolations - models that improve accuracy beyond both parents while substantially recovering the calibration lost during alignment. Our work demonstrates that simple model merging provides a computationally efficient method for mitigating the full scope of the alignment tax, yielding models that are more capable and more reliable."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Introducing Linear Implication Types to $\u03bb_{GT}$ for Computing With Incomplete Graphs", "authors": "Jin Sano, Naoki Yamamoto, Kazunori Ueda", "subjects": "Programming Languages (cs.PL)", "abstract": "Designing programming languages that enable intuitive and safe manipulation of data structures is a critical research challenge. Conventional destructive memory operations using pointers are complex and prone to errors. Existing type systems, such as affine types and shape types, address this problem towards safe manipulation of heaps and pointers, but design of high-level declarative languages that allow us to manipulate complex pointer data structures at a higher level of abstraction is largely an open problem. The $\\lambda_{GT}$ language, a purely functional programming language that treats hypergraphs (hereafter referred to as graphs) as primary data structures, addresses some of these challenges. By abstracting data with shared references and cycles as graphs, it enables declarative operations through pattern matching and leverages its type system to guarantee safety of these operations. Nevertheless, the previously proposed type system of $\\lambda_{GT}$ leaves two significant open challenges. First, the type system does not support \\emph{incomplete graphs}, that is, graphs in which some elements are missing from the graphs of user-defined types. Second, the type system relies on dynamic type checking during pattern matching. This study addresses these two challenges by incorporating linear implication into the $\\lambda_{GT}$ type system, while introducing new constraints to ensure its soundness."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Scalable CI/CD for Legacy Modernization: An Industrial Experience Addressing Internal Challenges Related to the 2025 Japan Cliff", "authors": "Kuniaki Kudo, Sherine Devi", "subjects": "Software Engineering (cs.SE)", "abstract": "We have developed a Scalable CI/CD Pipeline to address internal challenges related to Japan 2025 cliff problem, a critical issue where the mass end of service life of legacy core IT systems threatens to significantly increase the maintenance cost and black box nature of these system also leads to difficult update moreover replace, which leads to lack of progress in Digital Transformation (DX). If not addressed, Japan could potentially lose up to 12 trillion yen per year after 2025, which is 3 times more than the cost in previous years. Asahi also faced the same internal challenges regarding legacy system, where manual maintenance workflows and limited QA environment have left critical systems outdated and difficult to update. Middleware and OS version have remained unchanged for years, leading to now its nearing end of service life which require huge maintenance cost and effort to continue its operation. To address this problem, we have developed and implemented a Scalable CI/CD Pipeline where isolated development environments can be created and deleted dynamically and is scalable as needed. This Scalable CI/CD Pipeline incorporate GitHub for source code control and branching, Jenkins for pipeline automation, Amazon Web Services for scalable environment, and Docker for environment containerization. This paper presents the design and architecture of the Scalable CI/CD Pipeline, with the implementation along with some use cases. Through Scalable CI/CD, developers can freely and safely test maintenance procedures and do experiments with new technology in their own environment, reducing maintenance cost and drive Digital Transformation (DX). key words: 2025 Japan Cliff, Scalable CI/CD, DevOps, Legacy IT Modernization."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Agentic Reinforcement Learning for Search is Unsafe", "authors": "Yushi Yang, Shreyansh Padarha, Andrew Lee, Adam Mahdi", "subjects": "Computation and Language (cs.CL)", "abstract": "Agentic reinforcement learning (RL) trains large language models to autonomously call tools during reasoning, with search as the most common application. These models excel at multi-step reasoning tasks, but their safety properties are not well understood. In this study, we show that RL-trained search models inherit refusal from instruction tuning and often deflect harmful requests by turning them into safe queries. However, this safety is fragile. Two simple attacks, one that forces the model to begin response with search (Search attack), another that encourages models to repeatedly search (Multi-search attack), trigger cascades of harmful searches and answers. Across two model families (Qwen, Llama) with both local and web search, these attacks lower refusal rates by up to 60.0%, answer safety by 82.5%, and search-query safety by 82.4%. The attacks succeed by triggering models to generate harmful, request-mirroring search queries before they can generate the inherited refusal tokens. This exposes a core weakness of current RL training: it rewards continued generation of effective queries without accounting for their harmfulness. As a result, RL search models have vulnerabilities that users can easily exploit, making it urgent to develop safety-aware agentic RL pipelines optimising for safe search."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Leveraging AV1 motion vectors for Fast and Dense Feature Matching", "authors": "Julien Zouein, Hossein Javidnia, Fran\u00e7ois Piti\u00e9, Anil Kokaram", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "We repurpose AV1 motion vectors to produce dense sub-pixel correspondences and short tracks filtered by cosine consistency. On short videos, this compressed-domain front end runs comparably to sequential SIFT while using far less CPU, and yields denser matches with competitive pairwise geometry. As a small SfM demo on a 117-frame clip, MV matches register all images and reconstruct 0.46-0.62M points at 0.51-0.53,px reprojection error; BA time grows with match density. These results show compressed-domain correspondences are a practical, resource-efficient front end with clear paths to scaling in full pipelines."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Strategyproof Facility Location for Five Agents on a Circle using PCD", "authors": "Ido Farjoun, Reshef Meir", "subjects": "Multiagent Systems (cs.MA)", "abstract": "We consider the strategyproof facility location problem on a circle. We focus on the case of 5 agents, and find a tight bound for the PCD strategyproof mechanism, which selects the reported location of an agent in proportion to the length of the arc in front of it. We methodically \"reduce\" the size of the instance space and then use standard optimization techniques to find and prove the bound is tight. Moreover we hypothesize the approximation ratio of PCD for general odd $n$."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Multilingual Clinical NER for Diseases and Medications Recognition in Cardiology Texts using BERT Embeddings", "authors": "Manuela Daniela Danu, George Marica, Constantin Suciu, Lucian Mihai Itu, Oladimeji Farri", "subjects": "Computation and Language (cs.CL)", "abstract": "The rapidly increasing volume of electronic health record (EHR) data underscores a pressing need to unlock biomedical knowledge from unstructured clinical texts to support advancements in data-driven clinical systems, including patient diagnosis, disease progression monitoring, treatment effects assessment, prediction of future clinical events, etc. While contextualized language models have demonstrated impressive performance improvements for named entity recognition (NER) systems in English corpora, there remains a scarcity of research focused on clinical texts in low-resource languages. To bridge this gap, our study aims to develop multiple deep contextual embedding models to enhance clinical NER in the cardiology domain, as part of the BioASQ MultiCardioNER shared task. We explore the effectiveness of different monolingual and multilingual BERT-based models, trained on general domain text, for extracting disease and medication mentions from clinical case reports written in English, Spanish, and Italian. We achieved an F1-score of 77.88% on Spanish Diseases Recognition (SDR), 92.09% on Spanish Medications Recognition (SMR), 91.74% on English Medications Recognition (EMR), and 88.9% on Italian Medications Recognition (IMR). These results outperform the mean and median F1 scores in the test leaderboard across all subtasks, with the mean/median values being: 69.61%/75.66% for SDR, 81.22%/90.18% for SMR, 89.2%/88.96% for EMR, and 82.8%/87.76% for IMR."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Castor Ministerialis", "authors": "Christian Hercher", "subjects": "Formal Languages and Automata Theory (cs.FL)", "abstract": "The famous problem of Busy Beavers can be stated as the question on how long a $n$-state Turing machine (using a 2-symbol alphabet or -- in a generalization -- a $m$-symbol alphabet) can run if it is started on the blank tape before it holds. Thus, not halting Turing machines are excluded. For up to four states the answer to this question is well-known. Recently, it could be verified that the widely assumed candidate for five states is in fact the champion. And there is progress in searching for good candidates with six or more states. We investigate a variant of this problem: Additionally to the requirement that the Turing machines have to start from the blank tape we only consider such Turing machines that hold on the blank tape, too. For this variant we give definitive answers on how long such a Turing machine with up to five states can run, analyze the behavior of a six-states candidate and give some findings on the generalization of Turing-machines with $m$-symbol alphabet."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          From Spatial to Actions: Grounding Vision-Language-Action Model in Spatial Foundation Priors", "authors": "Zhengshen Zhang, Hao Li, Yalun Dai, Zhengbang Zhu, Lei Zhou, Chenchen Liu, Dong Wang, Francis E. H. Tay, Sijin Chen, Ziwei Liu, Yuxiao Liu, Xinghang Li, Pan Zhou", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)", "abstract": "Existing vision-language-action (VLA) models act in 3D real-world but are typically built on 2D encoders, leaving a spatial reasoning gap that limits generalization and adaptability. Recent 3D integration techniques for VLAs either require specialized sensors and transfer poorly across modalities, or inject weak cues that lack geometry and degrade vision-language alignment. In this work, we introduce FALCON (From Spatial to Action), a novel paradigm that injects rich 3D spatial tokens into the action head. FALCON leverages spatial foundation models to deliver strong geometric priors from RGB alone, and includes an Embodied Spatial Model that can optionally fuse depth, or pose for higher fidelity when available, without retraining or architectural changes. To preserve language reasoning, spatial tokens are consumed by a Spatial-Enhanced Action Head rather than being concatenated into the vision-language backbone. These designs enable FALCON to address limitations in spatial representation, modality transferability, and alignment. In comprehensive evaluations across three simulation benchmarks and eleven real-world tasks, our proposed FALCON achieves state-of-the-art performance, consistently surpasses competitive baselines, and remains robust under clutter, spatial-prompt conditioning, and variations in object scale and height."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Rethinking Nighttime Image Deraining via Learnable Color Space Transformation", "authors": "Qiyuan Guan, Xiang Chen, Guiyue Jin, Jiyu Jin, Shumin Fan, Tianyu Song, Jinshan Pan", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Compared to daytime image deraining, nighttime image deraining poses significant challenges due to inherent complexities of nighttime scenarios and the lack of high-quality datasets that accurately represent the coupling effect between rain and illumination. In this paper, we rethink the task of nighttime image deraining and contribute a new high-quality benchmark, HQ-NightRain, which offers higher harmony and realism compared to existing datasets. In addition, we develop an effective Color Space Transformation Network (CST-Net) for better removing complex rain from nighttime scenes. Specifically, we propose a learnable color space converter (CSC) to better facilitate rain removal in the Y channel, as nighttime rain is more pronounced in the Y channel compared to the RGB color space. To capture illumination information for guiding nighttime deraining, implicit illumination guidance is introduced enabling the learned features to improve the model's robustness in complex scenarios. Extensive experiments show the value of our dataset and the effectiveness of our method. The source code and datasets are available at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Adaptive Local Combining with Decentralized Decoding for Distributed Massive MIMO", "authors": "Mohd Saif Ali Khan, Karthik RM, Samar Agnihotri", "subjects": "Networking and Internet Architecture (cs.NI); Information Theory (cs.IT)", "abstract": "A major bottleneck in uplink distributed massive multiple-input multiple-output networks is the sub-optimal performance of local combining schemes, coupled with high fronthaul load and computational cost inherent in centralized large scale fading decoding (LSFD) architectures. This paper introduces a decentralized decoding architecture that fundamentally breaks from the conventional LSFD, by allowing each AP calculates interference-suppressing local weights independently and applies them to its data estimates before transmission. Furthermore, two generalized local zero-forcing (ZF) framework, generalized partial full-pilot ZF (G-PFZF) and generalized protected weak PFZF (G-PWPFZF), are introduced, where each access point (AP) adaptively and independently determines its combining strategy through a local sum spectral efficiency optimization that classifies user equipments (UEs) as strong or weak using only local information, eliminating the fixed thresholds used in PFZF and PWPFZF. To further enhance scalability, pilot-dependent combining vectors instead of user-dependent ones are introduced and are shared among users with the same pilot. The corresponding closed-form spectral efficiency expressions are derived. Numerical results show that the proposed generalized schemes consistently outperform fixed-threshold counterparts, while the introduction of local weights yields lower overhead and computation costs with minimal performance penalty compared to them."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          A Generalization of Input-Output Linearization via Dynamic Switching Between Melds of Output Functions", "authors": "Mirko Mizzoni, Pieter van Goor, Barbara Bazzana, Antonio Franchi", "subjects": "Robotics (cs.RO); Dynamical Systems (math.DS)", "abstract": "This letter presents a systematic framework for switching between different sets of outputs for the control of nonlinear systems via feedback linearization. We introduce the concept of a meld to formally define a valid, feedback-linearizable subset of outputs that can be selected from a larger deck of possible outputs. The main contribution is a formal proof establishing that under suitable dwell-time and compatibility conditions, it is possible to switch between different melds while guaranteeing the uniform boundedness of the system state. We further show that the error dynamics of the active outputs remain exponentially stable within each switching interval and that outputs common to consecutive melds are tracked seamlessly through transitions. The proposed theory is valid for any feedback linearizable nonlinear system, such as, e.g., robots, aerial and terrestrial vehicles, etc.. We demonstrate it on a simple numerical simulation of a robotic manipulator."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Active Inference for an Intelligent Agent in Autonomous Reconnaissance Missions", "authors": "Johan Schubert, Farzad Kamrani, Tove Gustavi", "subjects": "Artificial Intelligence (cs.AI)", "abstract": "We develop an active inference route-planning method for the autonomous control of intelligent agents. The aim is to reconnoiter a geographical area to maintain a common operational picture. To achieve this, we construct an evidence map that reflects our current understanding of the situation, incorporating both positive and \"negative\" sensor observations of possible target objects collected over time, and diffusing the evidence across the map as time progresses. The generative model of active inference uses Dempster-Shafer theory and a Gaussian sensor model, which provides input to the agent. The generative process employs a Bayesian approach to update a posterior probability distribution. We calculate the variational free energy for all positions within the area by assessing the divergence between a pignistic probability distribution of the evidence map and a posterior probability distribution of a target object based on the observations, including the level of surprise associated with receiving new observations. Using the free energy, we direct the agents' movements in a simulation by taking an incremental step toward a position that minimizes the free energy. This approach addresses the challenge of exploration and exploitation, allowing agents to balance searching extensive areas of the geographical map while tracking identified target objects."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          The Parameterized Complexity of Computing the VC-Dimension", "authors": "Florent Foucaud, Harmender Gahlawat, Fionn Mc Inerney, Prafullkumar Tale", "subjects": "Computational Complexity (cs.CC); Artificial Intelligence (cs.AI); Discrete Mathematics (cs.DM); Machine Learning (cs.LG); Combinatorics (math.CO)", "abstract": "The VC-dimension is a fundamental and well-studied measure of the complexity of a set system (or hypergraph) that is central to many areas of machine learning. We establish several new results on the complexity of computing the VC-dimension. In particular, given a hypergraph $\\mathcal{H}=(\\mathcal{V},\\mathcal{E})$, we prove that the naive $2^{\\mathcal{O}(|\\mathcal{V}|)}$-time algorithm is asymptotically tight under the Exponential Time Hypothesis (ETH). We then prove that the problem admits a 1-additive fixed-parameter approximation algorithm when parameterized by the maximum degree of $\\mathcal{H}$ and a fixed-parameter algorithm when parameterized by its dimension, and that these are essentially the only such exploitable structural parameters. Lastly, we consider a generalization of the problem, formulated using graphs, which captures the VC-dimension of both set systems and graphs. We show that it is fixed-parameter tractable parameterized by the treewidth of the graph (which, in the case of set systems, applies to the treewidth of its incidence graph). In contrast with closely related problems whose dependency on the treewidth is necessarily double-exponential (assuming the ETH), our algorithm has a relatively low dependency on the treewidth."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Deeper with Riemannian Geometry: Overcoming Oversmoothing and Oversquashing for Graph Foundation Models", "authors": "Li Sun, Zhenhao Huang, Ming Zhang, Philip S. Yu", "subjects": "Machine Learning (cs.LG)", "abstract": "Message Passing Neural Networks (MPNNs) is the building block of graph foundation models, but fundamentally suffer from oversmoothing and oversquashing. There has recently been a surge of interest in fixing both issues. Existing efforts primarily adopt global approaches, which may be beneficial in some regions but detrimental in others, ultimately leading to the suboptimal expressiveness. In this paper, we begin by revisiting oversquashing through a global measure -- spectral gap $\\lambda$ -- and prove that the increase of $\\lambda$ leads to gradient vanishing with respect to the input features, thereby undermining the effectiveness of message passing. Motivated by such theoretical insights, we propose a \\textbf{local} approach that adaptively adjusts message passing based on local structures. To achieve this, we connect local Riemannian geometry with MPNNs, and establish a novel nonhomogeneous boundary condition to address both oversquashing and oversmoothing. Building on the Robin condition, we design a GBN network with local bottleneck adjustment, coupled with theoretical guarantees. Extensive experiments on homophilic and heterophilic graphs show the expressiveness of GBN. Furthermore, GBN does not exhibit performance degradation even when the network depth exceeds $256$ layers."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Explainable AI for microseismic event detection", "authors": "Ayrat Abdullin, Denis Anikiev, Umair bin Waheed", "subjects": "Machine Learning (cs.LG); Geophysics (physics.geo-ph)", "abstract": "Deep neural networks like PhaseNet show high accuracy in detecting microseismic events, but their black-box nature is a concern in critical applications. We apply explainable AI (XAI) techniques, such as Gradient-weighted Class Activation Mapping (Grad-CAM) and Shapley Additive Explanations (SHAP), to interpret the PhaseNet model's decisions and improve its reliability. Grad-CAM highlights that the network's attention aligns with P- and S-wave arrivals. SHAP values quantify feature contributions, confirming that vertical-component amplitudes drive P-phase picks while horizontal components dominate S-phase picks, consistent with geophysical principles. Leveraging these insights, we introduce a SHAP-gated inference scheme that combines the model's output with an explanation-based metric to reduce errors. On a test set of 9,000 waveforms, the SHAP-gated model achieved an F1-score of 0.98 (precision 0.99, recall 0.97), outperforming the baseline PhaseNet (F1-score 0.97) and demonstrating enhanced robustness to noise. These results show that XAI can not only interpret deep learning models but also directly enhance their performance, providing a template for building trust in automated seismic detectors."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Evaluating Large Language Models on Urdu Idiom Translation", "authors": "Muhammad Farmal Khan, Mousumi Akter", "subjects": "Computation and Language (cs.CL)", "abstract": "Idiomatic translation remains a significant challenge in machine translation, especially for low resource languages such as Urdu, and has received limited prior attention. To advance research in this area, we introduce the first evaluation datasets for Urdu to English idiomatic translation, covering both Native Urdu and Roman Urdu scripts and annotated with gold-standard English equivalents. We evaluate multiple open-source Large Language Models (LLMs) and Neural Machine Translation (NMT) systems on this task, focusing on their ability to preserve idiomatic and cultural meaning. Automatic metrics including BLEU, BERTScore, COMET, and XCOMET are used to assess translation quality. Our findings indicate that prompt engineering enhances idiomatic translation compared to direct translation, though performance differences among prompt types are relatively minor. Moreover, cross script comparisons reveal that text representation substantially affects translation quality, with Native Urdu inputs producing more accurate idiomatic translations than Roman Urdu."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Label Indeterminacy in AI & Law", "authors": "Cor Steging, Tadeusz Zbiegie\u0144", "subjects": "Artificial Intelligence (cs.AI)", "abstract": "Machine learning is increasingly used in the legal domain, where it typically operates retrospectively by treating past case outcomes as ground truth. However, legal outcomes are often shaped by human interventions that are not captured in most machine learning approaches. A final decision may result from a settlement, an appeal, or other procedural actions. This creates label indeterminacy: the outcome could have been different if the intervention had or had not taken place. We argue that legal machine learning applications need to account for label indeterminacy. Methods exist that can impute these indeterminate labels, but they are all grounded in unverifiable assumptions. In the context of classifying cases from the European Court of Human Rights, we show that the way that labels are constructed during training can significantly affect model behaviour. We therefore position label indeterminacy as a relevant concern in AI & Law and demonstrate how it can shape model behaviour."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Delay-Doppler Pulse Shaping in Zak-OTFS Using Hermite Basis Functions", "authors": "Fathima Jesbin, Ananthanarayanan Chockalingam", "subjects": "Information Theory (cs.IT); Signal Processing (eess.SP)", "abstract": "The performance of Zak-OTFS modulation is critically dependent on the choice of the delay-Doppler (DD) domain pulse shaping filter. The design of pulses for $L^2(\\mathbb{R})$ is constrained by the Balian-Low Theorem, which imposes an inescapable trade-off between time-frequency localization and orthogonality for spectrally efficient systems. In Zak-OTFS, this trade-off requires balancing the need for localization for input/output (I/O) relation estimation with the need for orthogonality for reliable data detection when operating without time or bandwidth expansion. The well-known sinc and Gaussian pulse shapes represent the canonical extremes of this trade-off, while composite constructions such as the Gaussian-sinc (GS) pulse shape offer a good compromise. In this work, we propose a systematic DD pulse design framework for Zak-OTFS that expresses the pulse as a linear combination of Hermite basis functions. We obtain the optimal coefficients for the Hermite basis functions that minimize the inter-symbol interference (ISI) energy at the DD sampling points by solving a constrained optimization problem via singular value decomposition. For the proposed class of Hermite pulses, we derive closed-form expressions for the I/O relation and noise covariance in Zak-OTFS. Simulation results of Zak-OTFS with embedded pilot and model-free I/O relation estimation in Vehicular-A channels with fractional DDs demonstrate that the optimized pulse shape achieves a bit error rate performance that is significantly superior compared to those of the canonical sinc and Gaussian pulses and is on par with that of the state-of-the-art GS pulse, validating the proposed framework which provides greater design flexibility in terms of control of ISI and sidelobe energies."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          CrossStateECG: Multi-Scale Deep Convolutional Network with Attention for Rest-Exercise ECG Biometrics", "authors": "Dan Zheng, Jing Feng, Juan Liu", "subjects": "Machine Learning (cs.LG)", "abstract": "Current research in Electrocardiogram (ECG) biometrics mainly emphasizes resting-state conditions, leaving the performance decline in rest-exercise scenarios largely unresolved. This paper introduces CrossStateECG, a robust ECG-based authentication model explicitly tailored for cross-state (rest-exercise) conditions. The proposed model creatively combines multi-scale deep convolutional feature extraction with attention mechanisms to ensure strong identification across different physiological states. Experimental results on the exercise-ECGID dataset validate the effectiveness of CrossStateECG, achieving an identification accuracy of 92.50% in the Rest-to-Exercise scenario (training on resting ECG and testing on post-exercise ECG) and 94.72% in the Exercise-to-Rest scenario (training on post-exercise ECG and testing on resting ECG). Furthermore, CrossStateECG demonstrates exceptional performance across both state combinations, reaching an accuracy of 99.94% in Rest-to-Rest scenarios and 97.85% in Mixed-to-Mixed scenarios. Additional validations on the ECG-ID and MIT-BIH datasets further confirmed the generalization abilities of CrossStateECG, underscoring its potential as a practical solution for post-exercise ECG-based authentication in dynamic real-world settings."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Layer Specialization Underlying Compositional Reasoning in Transformers", "authors": "Jing Liu", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "Transformers exhibit compositional reasoning on sequences not observed during training, a capability often attributed to in-context learning (ICL) and skill composition. We investigate this phenomenon using the Random Hierarchy Model (RHM), a probabilistic context-free grammar that generates sequences through recursive rule application. Models are trained on subsets of sequences and evaluated across four generalization conditions: memorization, in-distribution generalization, out-of-distribution generalization with the same rules, and cross-layer transfer. Behaviorally, performance improves systematically with task complexity and the number of in-context examples, with out-of-distribution tasks requiring substantially more examples than in-distribution scenarios. Mechanistically, we identify a progressive emergence of layer specialization during training that correlates with generalization performance. Principal component analysis and attention pattern clustering reveal that transformers develop structured, hierarchically organized representations in specialized layers. These results demonstrate that transformers develop modular, interpretable mechanisms supporting compositional reasoning, linking internal algorithmic structure to observed behavioral capabilities."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Not All Deepfakes Are Created Equal: Triaging Audio Forgeries for Robust Deepfake Singer Identification", "authors": "Davide Salvi, Hendrik Vincent Koops, Elio Quinton", "subjects": "Sound (cs.SD)", "abstract": "The proliferation of highly realistic singing voice deepfakes presents a significant challenge to protecting artist likeness and content authenticity. Automatic singer identification in vocal deepfakes is a promising avenue for artists and rights holders to defend against unauthorized use of their voice, but remains an open research problem. Based on the premise that the most harmful deepfakes are those of the highest quality, we introduce a two-stage pipeline to identify a singer's vocal likeness. It first employs a discriminator model to filter out low-quality forgeries that fail to accurately reproduce vocal likeness. A subsequent model, trained exclusively on authentic recordings, identifies the singer in the remaining high-quality deepfakes and authentic audio. Experiments show that this system consistently outperforms existing baselines on both authentic and synthetic content."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          DAMSDAN: Distribution-Aware Multi-Source Domain Adaptation Network for Cross-Domain EEG-based Emotion Recognition", "authors": "Fo Hu, Can Wang, Qinxu Zheng, Xusheng Yang, Bin Zhou, Gang Li, Yu Sun, Wen-an Zhang", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "Significant inter-individual variability limits the generalization of EEG-based emotion recognition under cross-domain settings. We address two core challenges in multi-source adaptation: (1) dynamically modeling distributional heterogeneity across sources and quantifying their relevance to a target to reduce negative transfer; and (2) achieving fine-grained semantic consistency to strengthen class discrimination. We propose a distribution-aware multi-source domain adaptation network (DAMSDAN). DAMSDAN integrates prototype-based constraints with adversarial learning to drive the encoder toward discriminative, domain-invariant emotion representations. A domain-aware source weighting strategy based on maximum mean discrepancy (MMD) dynamically estimates inter-domain shifts and reweights source contributions. In addition, a prototype-guided conditional alignment module with dual pseudo-label interaction enhances pseudo-label reliability and enables category-level, fine-grained alignment, mitigating noise propagation and semantic drift. Experiments on SEED and SEED-IV show average accuracies of 94.86\\% and 79.78\\% for cross-subject, and 95.12\\% and 83.15\\% for cross-session protocols. On the large-scale FACED dataset, DAMSDAN achieves 82.88\\% (cross-subject). Extensive ablations and interpretability analyses corroborate the effectiveness of the proposed framework for cross-domain EEG-based emotion recognition."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Disparities in Multilingual LLM-Based Healthcare Q&A", "authors": "Ipek Baris Schlicht, Burcu Sayin, Zhixue Zhao, Frederik M. Labont\u00e9, Cesare Barbera, Marco Viviani, Paolo Rosso, Lucie Flek", "subjects": "Computation and Language (cs.CL)", "abstract": "Equitable access to reliable health information is vital when integrating AI into healthcare. Yet, information quality varies across languages, raising concerns about the reliability and consistency of multilingual Large Language Models (LLMs). We systematically examine cross-lingual disparities in pre-training source and factuality alignment in LLM answers for multilingual healthcare Q&A across English, German, Turkish, Chinese (Mandarin), and Italian. We (i) constructed Multilingual Wiki Health Care (MultiWikiHealthCare), a multilingual dataset from Wikipedia; (ii) analyzed cross-lingual healthcare coverage; (iii) assessed LLM response alignment with these references; and (iv) conducted a case study on factual alignment through the use of contextual information and Retrieval-Augmented Generation (RAG). Our findings reveal substantial cross-lingual disparities in both Wikipedia coverage and LLM factual alignment. Across LLMs, responses align more with English Wikipedia, even when the prompts are non-English. Providing contextual excerpts from non-English Wikipedia at inference time effectively shifts factual alignment toward culturally relevant knowledge. These results highlight practical pathways for building more equitable, multilingual AI systems for healthcare."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Towards geological inference with process-based and deep generative modeling, part 2: inversion of fluvial deposits and latent-space disentanglement", "authors": "Guillaume Rongier, Luk Peeters", "subjects": "Machine Learning (cs.LG); Geophysics (physics.geo-ph)", "abstract": "High costs and uncertainties make subsurface decision-making challenging, as acquiring new data is rarely scalable. Embedding geological knowledge directly into predictive models offers a valuable alternative. A joint approach enables just that: process-based models that mimic geological processes can help train generative models that make predictions more efficiently. This study explores whether a generative adversarial network (GAN) - a type of deep-learning algorithm for generative modeling - trained to produce fluvial deposits can be inverted to match well and seismic data. Four inversion approaches applied to three test samples with 4, 8, and 20 wells struggled to match these well data, especially as the well number increased or as the test sample diverged from the training data. The key bottleneck lies in the GAN's latent representation: it is entangled, so samples with similar sedimentological features are not necessarily close in the latent space. Label conditioning or latent overparameterization can partially disentangle the latent space during training, although not yet sufficiently for a successful inversion. Fine-tuning the GAN to restructure the latent space locally reduces mismatches to acceptable levels for all test cases, with and without seismic data. But this approach depends on an initial, partially successful inversion step, which influences the quality and diversity of the final samples. Overall, GANs can already handle the tasks required for their integration into geomodeling workflows. We still need to further assess their robustness, and how to best leverage them in support of geological interpretation."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Initialize to Generalize: A Stronger Initialization Pipeline for Sparse-View 3DGS", "authors": "Feng Zhou, Wenkai Guo, Pu Cao, Zhicheng Zhang, Jianqin Yin", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Sparse-view 3D Gaussian Splatting (3DGS) often overfits to the training views, leading to artifacts like blurring in novel view rendering. Prior work addresses it either by enhancing the initialization (\\emph{i.e.}, the point cloud from Structure-from-Motion (SfM)) or by adding training-time constraints (regularization) to the 3DGS optimization. Yet our controlled ablations reveal that initialization is the decisive factor: it determines the attainable performance band in sparse-view 3DGS, while training-time constraints yield only modest within-band improvements at extra cost. Given initialization's primacy, we focus our design there. Although SfM performs poorly under sparse views due to its reliance on feature matching, it still provides reliable seed points. Thus, building on SfM, our effort aims to supplement the regions it fails to cover as comprehensively as possible. Specifically, we design: (i) frequency-aware SfM that improves low-texture coverage via low-frequency view augmentation and relaxed multi-view correspondences; (ii) 3DGS self-initialization that lifts photometric supervision into additional points, compensating SfM-sparse regions with learned Gaussian centers; and (iii) point-cloud regularization that enforces multi-view consistency and uniform spatial coverage through simple geometric/visibility priors, yielding a clean and reliable point cloud. Our experiments on LLFF and Mip-NeRF360 demonstrate consistent gains in sparse-view settings, establishing our approach as a stronger initialization strategy. Code is available at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Unified Privacy Guarantees for Decentralized Learning via Matrix Factorization", "authors": "Aur\u00e9lien Bellet, Edwige Cyffers, Davide Frey, Romaric Gaudel, Dimitri Ler\u00e9v\u00e9rend, Fran\u00e7ois Ta\u00efani", "subjects": "Machine Learning (cs.LG)", "abstract": "Decentralized Learning (DL) enables users to collaboratively train models without sharing raw data by iteratively averaging local updates with neighbors in a network graph. This setting is increasingly popular for its scalability and its ability to keep data local under user control. Strong privacy guarantees in DL are typically achieved through Differential Privacy (DP), with results showing that DL can even amplify privacy by disseminating noise across peer-to-peer communications. Yet in practice, the observed privacy-utility trade-off often appears worse than in centralized training, which may be due to limitations in current DP accounting methods for DL. In this paper, we show that recent advances in centralized DP accounting based on Matrix Factorization (MF) for analyzing temporal noise correlations can also be leveraged in DL. By generalizing existing MF results, we show how to cast both standard DL algorithms and common trust models into a unified formulation. This yields tighter privacy accounting for existing DP-DL algorithms and provides a principled way to develop new ones. To demonstrate the approach, we introduce MAFALDA-SGD, a gossip-based DL algorithm with user-level correlated noise that outperforms existing methods on synthetic and real-world graphs."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          SparseWorld: A Flexible, Adaptive, and Efficient 4D Occupancy World Model Powered by Sparse and Dynamic Queries", "authors": "Chenxu Dang, Haiyan Liu, Guangjun Bao, Pei An, Xinyue Tang, Jie Ma, Bingchuan Sun, Yan Wang", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "abstract": "Semantic occupancy has emerged as a powerful representation in world models for its ability to capture rich spatial semantics. However, most existing occupancy world models rely on static and fixed embeddings or grids, which inherently limit the flexibility of perception. Moreover, their ``in-place classification\" over grids exhibits a potential misalignment with the dynamic and continuous nature of real this http URL this paper, we propose SparseWorld, a novel 4D occupancy world model that is flexible, adaptive, and efficient, powered by sparse and dynamic queries. We propose a Range-Adaptive Perception module, in which learnable queries are modulated by the ego vehicle states and enriched with temporal-spatial associations to enable extended-range perception. To effectively capture the dynamics of the scene, we design a State-Conditioned Forecasting module, which replaces classification-based forecasting with regression-guided formulation, precisely aligning the dynamic queries with the continuity of the 4D environment. In addition, We specifically devise a Temporal-Aware Self-Scheduling training strategy to enable smooth and efficient training. Extensive experiments demonstrate that SparseWorld achieves state-of-the-art performance across perception, forecasting, and planning tasks. Comprehensive visualizations and ablation studies further validate the advantages of SparseWorld in terms of flexibility, adaptability, and efficiency. The code is available at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          ReXMoE: Reusing Experts with Minimal Overhead in Mixture-of-Experts", "authors": "Zheyue Tan, Zhiyuan Li, Tao Yuan, Dong Zhou, Weilin Liu, Yueqing Zhuang, Yadong Li, Guowei Niu, Cheng Qin, Zhuyu Yao, Congyi Liu, Haiyang Xu, Boxun Li, Guohao Dai, Bo Zhao, Yu Wang", "subjects": "Computation and Language (cs.CL)", "abstract": "Mixture-of-Experts (MoE) architectures have emerged as a promising approach to scale Large Language Models (LLMs). MoE boosts the efficiency by activating a subset of experts per token. Recent works show that fine-grained experts substantially enriches the combinatorial flexibility of active experts and enhances model expressiveness. However, such a design is fundamentally limited by the layer-local routing mechanism: each layer is restricted to its own expert pool. This requires a careful trade-off between expert dimensionality and routing diversity given fixed parameter budgets. We describe ReXMoE, a novel MoE architecture that improves routing beyond the existing layer-local approaches by allowing routers to reuse experts across adjacent layers. ReXMoE decouples expert dimensionality from per-layer budgets, enabling richer expert combinations without sacrificing individual expert capacity or inflating overall parameters. To this end, we propose a new progressive scaling routing (PSR) strategy to gradually increase the candidate expert pool during training. As a result, ReXMoE improves both language modeling and downstream task performance. Extensive experiments on models ranging from 0.5B to 7B parameters across different architectures demonstrate that ReXMoE consistently improves performance under fixed architectural dimensions, confirming ReXMoE as new design paradigm for parameter-efficient and scalable MoE-based LLMs."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Split-Fuse-Transport: Annotation-Free Saliency via Dual Clustering and Optimal Transport Alignment", "authors": "Muhammad Umer Ramzan, Ali Zia, Abdelwahed Khamis, Noman Ali, Usman Ali, Wei Xiang", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Salient object detection (SOD) aims to segment visually prominent regions in images and serves as a foundational task for various computer vision applications. We posit that SOD can now reach near-supervised accuracy without a single pixel-level label, but only when reliable pseudo-masks are available. We revisit the prototype-based line of work and make two key observations. First, boundary pixels and interior pixels obey markedly different geometry; second, the global consistency enforced by optimal transport (OT) is underutilized if prototype quality is weak. To address this, we introduce POTNet, an adaptation of Prototypical Optimal Transport that replaces POT's single k-means step with an entropy-guided dual-clustering head: high-entropy pixels are organized by spectral clustering, low-entropy pixels by k-means, and the two prototype sets are subsequently aligned by OT. This split-fuse-transport design yields sharper, part-aware pseudo-masks in a single forward pass, without handcrafted priors. Those masks supervise a standard MaskFormer-style encoder-decoder, giving rise to AutoSOD, an end-to-end unsupervised SOD pipeline that eliminates SelfMask's offline voting yet improves both accuracy and training efficiency. Extensive experiments on five benchmarks show that AutoSOD outperforms unsupervised methods by up to 26% and weakly supervised methods by up to 36% in F-measure, further narrowing the gap to fully supervised models."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Local properties of neural networks through the lens of layer-wise Hessians", "authors": "Maxim Bolshim (1), Alexander Kugaevskikh (1) ((1) ITMO University, Saint Petersburg, Russia)", "subjects": "Machine Learning (cs.LG)", "abstract": "We introduce a methodology for analyzing neural networks through the lens of layer-wise Hessian matrices. The local Hessian of each functional block (layer) is defined as the matrix of second derivatives of a scalar function with respect to the parameters of that layer. This concept provides a formal tool for characterizing the local geometry of the parameter space. We show that the spectral properties of local Hessians, such as the distribution of eigenvalues, reveal quantitative patterns associated with overfitting, underparameterization, and expressivity in neural network architectures. We conduct an extensive empirical study involving 111 experiments across 37 datasets. The results demonstrate consistent structural regularities in the evolution of local Hessians during training and highlight correlations between their spectra and generalization performance. These findings establish a foundation for using local geometric analysis to guide the diagnosis and design of deep neural networks. The proposed framework connects optimization geometry with functional behavior and offers practical insight for improving network architectures and training stability."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          DETree: DEtecting Human-AI Collaborative Texts via Tree-Structured Hierarchical Representation Learning", "authors": "Yongxin He, Shan Zhang, Yixuan Cao, Lei Ma, Ping Luo", "subjects": "Computation and Language (cs.CL); Machine Learning (cs.LG)", "abstract": "Detecting AI-involved text is essential for combating misinformation, plagiarism, and academic misconduct. However, AI text generation includes diverse collaborative processes (AI-written text edited by humans, human-written text edited by AI, and AI-generated text refined by other AI), where various or even new LLMs could be involved. Texts generated through these varied processes exhibit complex characteristics, presenting significant challenges for detection. Current methods model these processes rather crudely, primarily employing binary classification (purely human vs. AI-involved) or multi-classification (treating human-AI collaboration as a new class). We observe that representations of texts generated through different processes exhibit inherent clustering relationships. Therefore, we propose DETree, a novel approach that models the relationships among different processes as a Hierarchical Affinity Tree structure, and introduces a specialized loss function that aligns text representations with this tree. To facilitate this learning, we developed RealBench, a comprehensive benchmark dataset that automatically incorporates a wide spectrum of hybrid texts produced through various human-AI collaboration processes. Our method improves performance in hybrid text detection tasks and significantly enhances robustness and generalization in out-of-distribution scenarios, particularly in few-shot learning conditions, further demonstrating the promise of training-based approaches in OOD settings. Our code and dataset are available at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Empowering Real-World: A Survey on the Technology, Practice, and Evaluation of LLM-driven Industry Agents", "authors": "Yihong Tang, Kehai Chen, Liang Yue, Jinxin Fan, Caishen Zhou, Xiaoguang Li, Yuyang Zhang, Mingming Zhao, Shixiong Kai, Kaiyang Guo, Xingshan Zeng, Wenjing Cun, Lifeng Shang, Min Zhang", "subjects": "Computation and Language (cs.CL)", "abstract": "With the rise of large language models (LLMs), LLM agents capable of autonomous reasoning, planning, and executing complex tasks have become a frontier in artificial intelligence. However, how to translate the research on general agents into productivity that drives industry transformations remains a significant challenge. To address this, this paper systematically reviews the technologies, applications, and evaluation methods of industry agents based on LLMs. Using an industry agent capability maturity framework, it outlines the evolution of agents in industry applications, from \"process execution systems\" to \"adaptive social systems.\" First, we examine the three key technological pillars that support the advancement of agent capabilities: Memory, Planning, and Tool Use. We discuss how these technologies evolve from supporting simple tasks in their early forms to enabling complex autonomous systems and collective intelligence in more advanced forms. Then, we provide an overview of the application of industry agents in real-world domains such as digital engineering, scientific discovery, embodied intelligence, collaborative business execution, and complex system simulation. Additionally, this paper reviews the evaluation benchmarks and methods for both fundamental and specialized capabilities, identifying the challenges existing evaluation systems face regarding authenticity, safety, and industry specificity. Finally, we focus on the practical challenges faced by industry agents, exploring their capability boundaries, developmental potential, and governance issues in various scenarios, while providing insights into future directions. By combining technological evolution with industry practices, this review aims to clarify the current state and offer a clear roadmap and theoretical foundation for understanding and building the next generation of industry agents."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          A Judgmental Construction of Directed Type Theory", "authors": "Jacob Neumann", "subjects": "Logic in Computer Science (cs.LO)", "abstract": "We reformulate recent advances in directed type theory--a type theory where the types have the structure of synthetic (higher) categories--as a logical calculus with multiple context 'zones', following the example of Pfenning and Davies. This allows us to have two kinds of variables--'neutral' and 'polar'--with different functoriality requirements. We focus on the lowest-dimension version of this theory (where types are synthetic preorders) and apply the logical language to articulate concepts from the theory of rewriting. We also take the occasion to develop the categorical semantics of dual-context systems, proposing a notion of dual CwF to serve as a common structural base for the model theories of such logics."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          I-RAVEN-X: Benchmarking Generalization and Robustness of Analogical and Mathematical Reasoning in Large Language and Reasoning Models", "authors": "Giacomo Camposampiero, Michael Hersche, Roger Wattenhofer, Abu Sebastian, Abbas Rahimi", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "We introduce I-RAVEN-X, a symbolic benchmark designed to evaluate generalization and robustness in analogical and mathematical reasoning for Large Language Models (LLMs) and Large Reasoning Models (LRMs). I-RAVEN-X extends I-RAVEN by increasing operand complexity, attribute range, and introducing perceptual uncertainty. Compared to LLMs, empirical results show that LRMs achieve improved productivity and systematicity on longer reasoning relations and wider attribute ranges, respectively. However, LRMs are still significantly challenged by reasoning under uncertainty and cannot effectively explore multiple probabilistic outcomes."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Deep Self-Evolving Reasoning", "authors": "Zihan Liu, Shun Zheng, Xumeng Wen, Yang Wang, Jiang Bian, Mao Yang", "subjects": "Computation and Language (cs.CL)", "abstract": "Long-form chain-of-thought reasoning has become a cornerstone of advanced reasoning in large language models. While recent verification-refinement frameworks have enabled proprietary models to solve Olympiad-level problems, their effectiveness hinges on strong, reliable verification and correction capabilities, which remain fragile in open-weight, smaller-scale models. This work demonstrates that even with weak verification and refinement capabilities on hard tasks, the reasoning limits of such models can be substantially extended through a probabilistic paradigm we call Deep Self-Evolving Reasoning (DSER). We conceptualize iterative reasoning as a Markov chain, where each step represents a stochastic transition in the solution space. The key insight is that convergence to a correct solution is guaranteed as long as the probability of improvement marginally exceeds that of degradation. By running multiple long-horizon, self-evolving processes in parallel, DSER amplifies these small positive tendencies, enabling the model to asymptotically approach correct answers. Empirically, we apply DSER to the DeepSeek-R1-0528-Qwen3-8B model. On the challenging AIME 2024-2025 benchmark, DSER solves 5 out of 9 previously unsolvable problems and boosts overall performance, enabling this compact model to surpass the single-turn accuracy of its 600B-parameter teacher through majority voting. Beyond its immediate utility for test-time scaling, the DSER framework serves to diagnose the fundamental limitations of current open-weight reasoners. By clearly delineating their shortcomings in self-verification, refinement, and stability, our findings establish a clear research agenda for developing next-generation models with powerful, intrinsic self-evolving capabilities."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          A non-local model for heterogeneous material flow on conveyor belts", "authors": "Paola Goatin (1), Simone G\u00f6ttlich (2), Fabian Ziegler (2) ((1) Universit\u00e9 C\u00f4te d'Azur Inria, (2) University of Mannheim)", "subjects": "Numerical Analysis (math.NA)", "abstract": "In this paper, a finite volume approximation scheme is used to solve a non-local macroscopic material flow model in two space dimensions, accounting for the presence of boundaries in the non-local terms. Based on a previous result for the scalar case, we extend the setting to a system of heterogeneous material on bounded domains. We prove the convergence of the approximate solutions constructed using the Roe scheme with dimensiona splitting, where the major challenge lies in the treatment of the discontinuity occurring in the flux function. Numerical tests show a good agreement with microscopic simulations."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Context-Aware Pseudo-Label Scoring for Zero-Shot Video Summarization", "authors": "Yuanli Wu, Long Zhang, Yue Du, Bin Li", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "abstract": "With the rapid proliferation of video content across social media, surveillance, and education platforms, efficiently summarizing long videos into concise yet semantically faithful surrogates has become increasingly vital. Existing supervised methods achieve strong in-domain accuracy by learning from dense annotations but suffer from high labeling costs and limited cross-dataset generalization, while unsupervised approaches, though label-free, often fail to capture high-level human semantics and fine-grained narrative cues. More recently, zero-shot prompting pipelines have leveraged large language models (LLMs) for training-free video summarization, yet remain highly sensitive to handcrafted prompt templates and dataset-specific score normalization. To overcome these limitations, we introduce a rubric-guided, pseudo-labeled prompting framework that transforms a small subset of ground-truth annotations into high-confidence pseudo labels, which are aggregated into structured, dataset-adaptive scoring rubrics guiding interpretable scene evaluation. During inference, first and last segments are scored based solely on their descriptions, whereas intermediate ones incorporate brief contextual summaries of adjacent scenes to assess narrative progression and redundancy. This contextual prompting enables the LLM to balance local salience and global coherence without parameter tuning. On SumMe and TVSum, our method achieves F1 scores of \\textbf{57.58} and \\textbf{63.05}, surpassing unsupervised and prior zero-shot baselines while approaching supervised performance. The results demonstrate that rubric-guided pseudo labeling effectively stabilizes LLM-based scoring and establishes a general, interpretable zero-shot paradigm for video summarization."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Stochastic Difference-of-Convex Optimization with Momentum", "authors": "El Mahdi Chayti, Martin Jaggi", "subjects": "Machine Learning (cs.LG); Optimization and Control (math.OC); Machine Learning (stat.ML)", "abstract": "Stochastic difference-of-convex (DC) optimization is prevalent in numerous machine learning applications, yet its convergence properties under small batch sizes remain poorly understood. Existing methods typically require large batches or strong noise assumptions, which limit their practical use. In this work, we show that momentum enables convergence under standard smoothness and bounded variance assumptions (of the concave part) for any batch size. We prove that without momentum, convergence may fail regardless of stepsize, highlighting its necessity. Our momentum-based algorithm achieves provable convergence and demonstrates strong empirical performance."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Lingua Custodi's participation at the WMT 2025 Terminology shared task", "authors": "Jingshu Liu, Raheel Qader, Ga\u00ebtan Caillaut, Mariam Nakhl\u00e9", "subjects": "Computation and Language (cs.CL)", "abstract": "While BERT is an effective method for learning monolingual sentence embeddings for semantic similarity and embedding based transfer learning BERT based cross-lingual sentence embeddings have yet to be explored. We systematically investigate methods for learning multilingual sentence embeddings by combining the best methods for learning monolingual and cross-lingual representations including: masked language modeling (MLM), translation language modeling (TLM), dual encoder translation ranking, and additive margin softmax. We show that introducing a pre-trained multilingual language model dramatically reduces the amount of parallel training data required to achieve good performance by 80%. Composing the best of these methods produces a model that achieves 83.7% bi-text retrieval accuracy over 112 languages on Tatoeba, well above the 65.5 achieved by LASER, while still performing competitively on monolingual transfer learning benchmarks. Parallel data mined from CommonCrawl using our best model is shown to train competitive NMT models for en-zh and en-de. We publicly release our best multilingual sentence embedding model for 109+ languages at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Insum: Sparse GPU Kernels Simplified and Optimized with Indirect Einsums", "authors": "Jaeyeon Won, Willow Ahrens, Joel S. Emer, Saman Amarasinghe", "subjects": "Programming Languages (cs.PL); Performance (cs.PF)", "abstract": "Programming high-performance sparse GPU kernels is notoriously difficult, requiring both substantial effort and deep expertise. Sparse compilers aim to simplify this process, but existing systems fall short in two key ways. First, they are primarily designed for CPUs and rarely produce high-performance GPU code. Second, when computations involve both sparse and dense regions, these compilers often fail to optimize the dense portions effectively. In this paper, we propose a new approach for expressing sparse computations. We start from format-agnostic Einsums over sparse tensors and rewrite them into format-conscious indirect Einsums, which explicitly encode format information by mapping sparse data and metadata onto dense tensor operations through indirect indexing. To execute indirect Einsums, we introduce the Insum compiler, which generates efficient GPU code for these Einsums by lowering to the PyTorch compiler, extended to better support Tensor Core-enabled indirect Einsums. We also present two fixed-length sparse formats, GroupCOO and BlockGroupCOO, designed to fit naturally with indirect Einsums. Our approach achieves 1.14x to 3.81x speedups across a range of sparse GPU applications while reducing lines of code by 202x to 4491x compared to hand-written implementations."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Convergence Rates for Gradient Descent on the Edge of Stability in Overparametrised Least Squares", "authors": "Lachlan Ewen MacDonald, Hancheng Min, Leandro Palma, Salma Tarmoun, Ziqing Xu, Ren\u00e9 Vidal", "subjects": "Machine Learning (cs.LG); Optimization and Control (math.OC)", "abstract": "Classical optimisation theory guarantees monotonic objective decrease for gradient descent (GD) when employed in a small step size, or ``stable\", regime. In contrast, gradient descent on neural networks is frequently performed in a large step size regime called the ``edge of stability\", in which the objective decreases non-monotonically with an observed implicit bias towards flat minima. In this paper, we take a step toward quantifying this phenomenon by providing convergence rates for gradient descent with large learning rates in an overparametrised least squares setting. The key insight behind our analysis is that, as a consequence of overparametrisation, the set of global minimisers forms a Riemannian manifold $M$, which enables the decomposition of the GD dynamics into components parallel and orthogonal to $M$. The parallel component corresponds to Riemannian gradient descent on the objective sharpness, while the orthogonal component is a bifurcating dynamical system. This insight allows us to derive convergence rates in three regimes characterised by the learning rate size: (a) the subcritical regime, in which transient instability is overcome in finite time before linear convergence to a suboptimally flat global minimum; (b) the critical regime, in which instability persists for all time with a power-law convergence toward the optimally flat global minimum; and (c) the supercritical regime, in which instability persists for all time with linear convergence to an orbit of period two centred on the optimally flat global minimum."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Annotation-Efficient Universal Honesty Alignment", "authors": "Shiyu Ni, Keping Bi, Jiafeng Guo, Minghao Tang, Jingtong Wu, Zengxin Han, Xueqi Cheng", "subjects": "Computation and Language (cs.CL)", "abstract": "Honesty alignment-the ability of large language models (LLMs) to recognize their knowledge boundaries and express calibrated confidence-is essential for trustworthy deployment. Existing methods either rely on training-free confidence estimation (e.g., token probabilities, self-consistency) or training-based calibration with correctness annotations. While effective, achieving universal honesty alignment with training-based calibration requires costly, large-scale labeling. To support annotation-efficient training, we introduce Elicitation-Then-Calibration (EliCal), a two-stage framework that first elicits internal confidence using inexpensive self-consistency supervision, then calibrates this confidence with a small set of correctness annotations. To support a large-scale study, we release HonestyBench, a benchmark covering ten free-form QA datasets with 560k training and 70k evaluation instances annotated with correctness and self-consistency signals. Experiments show that EliCal achieves near-optimal alignment with only 1k correctness annotations (0.18% of full supervision) and better alignment performance on unseen MMLU tasks than the calibration-only baseline, offering a scalable solution toward universal honesty alignment in LLMs."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          AWARE: Audio Watermarking with Adversarial Resistance to Edits", "authors": "Kosta Pavlovi\u0107, Lazar Stanarevi\u0107, Petar Nedi\u0107, Slavko Kova\u010devi\u0107, Igor Djurovi\u0107", "subjects": "Sound (cs.SD); Machine Learning (cs.LG); Multimedia (cs.MM); Audio and Speech Processing (eess.AS)", "abstract": "Prevailing practice in learning-based audio watermarking is to pursue robustness by expanding the set of simulated distortions during training. However, such surrogates are narrow and prone to overfitting. This paper presents AWARE (Audio Watermarking with Adversarial Resistance to Edits), an alternative approach that avoids reliance on attack-simulation stacks and handcrafted differentiable distortions. Embedding is obtained via adversarial optimization in the time-frequency domain under a level-proportional perceptual budget. Detection employs a time-order-agnostic detector with a Bitwise Readout Head (BRH) that aggregates temporal evidence into one score per watermark bit, enabling reliable watermark decoding even under desynchronization and temporal cuts. Empirically, AWARE attains high audio quality and speech intelligibility (PESQ/STOI) and consistently low BER across various audio edits, often surpassing representative state-of-the-art learning-based audio watermarking systems."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          The Graphon Limit Hypothesis: Understanding Neural Network Pruning via Infinite Width Analysis", "authors": "Hoang Pham, The-Anh Ta, Tom Jacobs, Rebekka Burkholz, Long Tran-Thanh", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "Sparse neural networks promise efficiency, yet training them effectively remains a fundamental challenge. Despite advances in pruning methods that create sparse architectures, understanding why some sparse structures are better trainable than others with the same level of sparsity remains poorly understood. Aiming to develop a systematic approach to this fundamental problem, we propose a novel theoretical framework based on the theory of graph limits, particularly graphons, that characterizes sparse neural networks in the infinite-width regime. Our key insight is that connectivity patterns of sparse neural networks induced by pruning methods converge to specific graphons as networks' width tends to infinity, which encodes implicit structural biases of different pruning methods. We postulate the Graphon Limit Hypothesis and provide empirical evidence to support it. Leveraging this graphon representation, we derive a Graphon Neural Tangent Kernel (Graphon NTK) to study the training dynamics of sparse networks in the infinite width limit. Graphon NTK provides a general framework for the theoretical analysis of sparse networks. We empirically show that the spectral analysis of Graphon NTK correlates with observed training dynamics of sparse networks, explaining the varying convergence behaviours of different pruning methods. Our framework provides theoretical insights into the impact of connectivity patterns on the trainability of various sparse network architectures."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          SimBench: Benchmarking the Ability of Large Language Models to Simulate Human Behaviors", "authors": "Tiancheng Hu, Joachim Baumann, Lorenzo Lupo, Dirk Hovy, Nigel Collier, Paul R\u00f6ttger", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Machine Learning (cs.LG)", "abstract": "Large language model (LLM) simulations of human behavior have the potential to revolutionize the social and behavioral sciences, if and only if they faithfully reflect real human behaviors. Current evaluations are fragmented, based on bespoke tasks and metrics, creating a patchwork of incomparable results. To address this, we introduce SimBench, the first large-scale, standardized benchmark for a robust, reproducible science of LLM simulation. By unifying 20 diverse datasets covering tasks from moral decision-making to economic choice across a large global participant pool, SimBench provides the necessary foundation to ask fundamental questions about when, how, and why LLM simulations succeed or fail. We show that, while even the best LLMs today have limited simulation ability (score: 40.80/100), performance scales log-linearly with model size. Simulation performance is not improved by increased inference-time compute. We demonstrate an alignment-simulation trade-off: instruction-tuning improves performance on low-entropy (consensus) questions but degrades it on high-entropy (diverse) ones. Models particularly struggle when simulating specific demographic groups. Finally, we demonstrate that simulation ability correlates most strongly with deep, knowledge-intensive reasoning (MMLU-Pro, r=0.939). By making progress measurable, we aim to accelerate the development of more faithful LLM simulators."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          SAFE-D: A Spatiotemporal Detection Framework for Abnormal Driving Among Parkinson's Disease-like Drivers", "authors": "Hangcheng Cao, Baixiang Huang, Longzhi Yuan, Haonan An, Zihan Fang, Xianhao Chen, Yuguang Fang", "subjects": "Machine Learning (cs.LG); Human-Computer Interaction (cs.HC)", "abstract": "A driver's health state serves as a determinant factor in driving behavioral regulation. Subtle deviations from normalcy can lead to operational anomalies, posing risks to public transportation safety. While prior efforts have developed detection mechanisms for functionally-driven temporary anomalies such as drowsiness and distraction, limited research has addressed pathologically-triggered deviations, especially those stemming from chronic medical conditions. To bridge this gap, we investigate the driving behavior of Parkinson's disease patients and propose SAFE-D, a novel framework for detecting Parkinson-related behavioral anomalies to enhance driving safety. Our methodology starts by performing analysis of Parkinson's disease symptomatology, focusing on primary motor impairments, and establishes causal links to degraded driving performance. To represent the subclinical behavioral variations of early-stage Parkinson's disease, our framework integrates data from multiple vehicle control components to build a behavioral profile. We then design an attention-based network that adaptively prioritizes spatiotemporal features, enabling robust anomaly detection under physiological variability. Finally, we validate SAFE-D on the Logitech G29 platform and CARLA simulator, using data from three road maps to emulate real-world driving. Our results show SAFE-D achieves 96.8% average accuracy in distinguishing normal and Parkinson-affected driving patterns."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          MUG-V 10B: High-efficiency Training Pipeline for Large Video Generation Models", "authors": "Yongshun Zhang, Zhongyi Fan, Yonghang Zhang, Zhangzikang Li, Weifeng Chen, Zhongwei Feng, Chaoyue Wang, Peng Hou, Anxiang Zeng", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "abstract": "In recent years, large-scale generative models for visual content (\\textit{e.g.,} images, videos, and 3D objects/scenes) have made remarkable progress. However, training large-scale video generation models remains particularly challenging and resource-intensive due to cross-modal text-video alignment, the long sequences involved, and the complex spatiotemporal dependencies. To address these challenges, we present a training framework that optimizes four pillars: (i) data processing, (ii) model architecture, (iii) training strategy, and (iv) infrastructure for large-scale video generation models. These optimizations delivered significant efficiency gains and performance improvements across all stages of data preprocessing, video compression, parameter scaling, curriculum-based pretraining, and alignment-focused post-training. Our resulting model, MUG-V 10B, matches recent state-of-the-art video generators overall and, on e-commerce-oriented video generation tasks, surpasses leading open-source baselines in human evaluations. More importantly, we open-source the complete stack, including model weights, Megatron-Core-based large-scale training code, and inference pipelines for video generation and enhancement. To our knowledge, this is the first public release of large-scale video generation training code that exploits Megatron-Core to achieve high training efficiency and near-linear multi-node scaling, details are available in \\href{this https URL}{our webpage}."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Curiosity Meets Cooperation: A Game-Theoretic Approach to Long-Tail Multi-Label Learning", "authors": "Canran Xiao, Chuangxin Zhao, Zong Ke, Fei Shen", "subjects": "Machine Learning (cs.LG)", "abstract": "Long-tail imbalance is endemic to multi-label learning: a few head labels dominate the gradient signal, while the many rare labels that matter in practice are silently ignored. We tackle this problem by casting the task as a cooperative potential game. In our Curiosity-Driven Game-Theoretic Multi-Label Learning (CD-GTMLL) framework, the label space is split among several cooperating players that share a global accuracy payoff yet earn additional curiosity rewards that rise with label rarity and inter-player disagreement. These curiosity bonuses inject gradient on under-represented tags without hand-tuned class weights. We prove that gradient best-response updates ascend a differentiable potential and converge to tail-aware stationary points that tighten a lower bound on the expected Rare-F1. Extensive experiments on conventional benchmarks and three extreme-scale datasets show consistent state-of-the-art gains, delivering up to +4.3% Rare-F1 and +1.6% P@3 over the strongest baselines, while ablations reveal emergent division of labour and faster consensus on rare classes. CD-GTMLL thus offers a principled, scalable route to long-tail robustness in multi-label prediction."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Cybersecurity AI: Evaluating Agentic Cybersecurity in Attack/Defense CTFs", "authors": "Francesco Balassone, V\u00edctor Mayoral-Vilches, Stefan Rass, Martin Pinzger, Gaetano Perrone, Simon Pietro Romano, Peter Schartner", "subjects": "Cryptography and Security (cs.CR)", "abstract": "We empirically evaluate whether AI systems are more effective at attacking or defending in cybersecurity. Using CAI (Cybersecurity AI)'s parallel execution framework, we deployed autonomous agents in 23 Attack/Defense CTF battlegrounds. Statistical analysis reveals defensive agents achieve 54.3% unconstrained patching success versus 28.3% offensive initial access (p=0.0193), but this advantage disappears under operational constraints: when defense requires maintaining availability (23.9%) and preventing all intrusions (15.2%), no significant difference exists (p>0.05). Exploratory taxonomy analysis suggests potential patterns in vulnerability exploitation, though limited sample sizes preclude definitive conclusions. This study provides the first controlled empirical evidence challenging claims of AI attacker advantage, demonstrating that defensive effectiveness critically depends on success criteria, a nuance absent from conceptual analyses but essential for deployment. These findings underscore the urgency for defenders to adopt open-source Cybersecurity AI frameworks to maintain security equilibrium against accelerating offensive automation."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Mitigating Clever Hans Strategies in Image Classifiers through Generating Counterexamples", "authors": "Sidney Bender, Ole Delzer, Jan Herrmann, Heike Antje Marxfeld, Klaus-Robert M\u00fcller, Gr\u00e9goire Montavon", "subjects": "Machine Learning (cs.LG)", "abstract": "Deep learning models remain vulnerable to spurious correlations, leading to so-called Clever Hans predictors that undermine robustness even in large-scale foundation and self-supervised models. Group distributional robustness methods, such as Deep Feature Reweighting (DFR) rely on explicit group labels to upweight underrepresented subgroups, but face key limitations: (1) group labels are often unavailable, (2) low within-group sample sizes hinder coverage of the subgroup distribution, and (3) performance degrades sharply when multiple spurious correlations fragment the data into even smaller groups. We propose Counterfactual Knowledge Distillation (CFKD), a framework that sidesteps these issues by generating diverse counterfactuals, enabling a human annotator to efficiently explore and correct the model's decision boundaries through a knowledge distillation step. Unlike DFR, our method not only reweights the undersampled groups, but it also enriches them with new data points. Our method does not require any confounder labels, achieves effective scaling to multiple confounders, and yields balanced generalization across groups. We demonstrate CFKD's efficacy across five datasets, spanning synthetic tasks to an industrial application, with particularly strong gains in low-data regimes with pronounced spurious correlations. Additionally, we provide an ablation study on the effect of the chosen counterfactual explainer and teacher model, highlighting their impact on robustness."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          HumanMPC - Safe and Efficient MAV Navigation among Humans", "authors": "Simon Schaefer, Helen Oleynikova, Sandra Hirche, Stefan Leutenegger", "subjects": "Robotics (cs.RO)", "abstract": "Safe and efficient robotic navigation among humans is essential for integrating robots into everyday environments. Most existing approaches focus on simplified 2D crowd navigation and fail to account for the full complexity of human body dynamics beyond root motion. We present HumanMPC, a Model Predictive Control (MPC) framework for 3D Micro Air Vehicle (MAV) navigation among humans that combines theoretical safety guarantees with data-driven models for realistic human motion forecasting. Our approach introduces a novel twist to reachability-based safety formulation that constrains only the initial control input for safety while modeling its effects over the entire planning horizon, enabling safe yet efficient navigation. We validate HumanMPC in both simulated experiments using real human trajectories and in the real-world, demonstrating its effectiveness across tasks ranging from goal-directed navigation to visual servoing for human tracking. While we apply our method to MAVs in this work, it is generic and can be adapted by other platforms. Our results show that the method ensures safety without excessive conservatism and outperforms baseline approaches in both efficiency and reliability."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          How Does Label Noise Gradient Descent Improve Generalization in the Low SNR Regime?", "authors": "Wei Huang, Andi Han, Yujin Song, Yilan Chen, Denny Wu, Difan Zou, Taiji Suzuki", "subjects": "Machine Learning (cs.LG)", "abstract": "The capacity of deep learning models is often large enough to both learn the underlying statistical signal and overfit to noise in the training set. This noise memorization can be harmful especially for data with a low signal-to-noise ratio (SNR), leading to poor generalization. Inspired by prior observations that label noise provides implicit regularization that improves generalization, in this work, we investigate whether introducing label noise to the gradient updates can enhance the test performance of neural network (NN) in the low SNR regime. Specifically, we consider training a two-layer NN with a simple label noise gradient descent (GD) algorithm, in an idealized signal-noise data setting. We prove that adding label noise during training suppresses noise memorization, preventing it from dominating the learning process; consequently, label noise GD enjoys rapid signal growth while the overfitting remains controlled, thereby achieving good generalization despite the low SNR. In contrast, we also show that NN trained with standard GD tends to overfit to noise in the same low SNR setting and establish a non-vanishing lower bound on its test error, thus demonstrating the benefit of introducing label noise in gradient-based training."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          MambaX-Net: Dual-Input Mamba-Enhanced Cross-Attention Network for Longitudinal MRI Segmentation", "authors": "Yovin Yahathugoda, Davide Prezzi, Piyalitt Ittichaiwong, Vicky Goh, Sebastien Ourselin, Michela Antonelli", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "abstract": "Active Surveillance (AS) is a treatment option for managing low and intermediate-risk prostate cancer (PCa), aiming to avoid overtreatment while monitoring disease progression through serial MRI and clinical follow-up. Accurate prostate segmentation is an important preliminary step for automating this process, enabling automated detection and diagnosis of PCa. However, existing deep-learning segmentation models are often trained on single-time-point and expertly annotated datasets, making them unsuitable for longitudinal AS analysis, where multiple time points and a scarcity of expert labels hinder their effective fine-tuning. To address these challenges, we propose MambaX-Net, a novel semi-supervised, dual-scan 3D segmentation architecture that computes the segmentation for time point t by leveraging the MRI and the corresponding segmentation mask from the previous time point. We introduce two new components: (i) a Mamba-enhanced Cross-Attention Module, which integrates the Mamba block into cross attention to efficiently capture temporal evolution and long-range spatial dependencies, and (ii) a Shape Extractor Module that encodes the previous segmentation mask into a latent anatomical representation for refined zone delination. Moreover, we introduce a semi-supervised self-training strategy that leverages pseudo-labels generated from a pre-trained nnU-Net, enabling effective learning without expert annotations. MambaX-Net was evaluated on a longitudinal AS dataset, and results showed that it significantly outperforms state-of-the-art U-Net and Transformer-based models, achieving superior prostate zone segmentation even when trained on limited and noisy data."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Navigate in Demanding Missions: Integrating Human Intelligence and Brain-Inspired Intelligence", "authors": "Xu He, Xiaolin Meng, Youdong Zhang, Lingfei Mo, Wenxuan Yin", "subjects": "Emerging Technologies (cs.ET); Human-Computer Interaction (cs.HC)", "abstract": "This perspective analyzes the intricate interplay among neuroscience, Brain-Inspired Intelligence (BII), and Brain-Inspired Navigation (BIN), revealing a current lack of cooperative relationship between Brain-Computer Interfaces (BCIs) and BIN fields. We advocate for the integration of neuromorphic-empowered BCI into BIN, thereby bolstering the unmanned systems' reliable navigation in demanding missions, such as deep space exploration, etc. We highlight that machine intelligence, reinforced by brain-inspired artificial consciousness, can extend human intelligence, with human intelligence mediated by neuromorphic-enabled BCI acting as a safeguard in case machine intelligence failures. This study also discusses the potentials of the proposed approach to enhance unmanned systems' capabilities and facilitate the diagnostics of spatial cognition disorders, while considering associated ethical and security concerns."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          OncoReason: Structuring Clinical Reasoning in LLMs for Robust and Interpretable Survival Prediction", "authors": "Raghu Vamshi Hemadri, Geetha Krishna Guruju, Kristi Topollai, Anna Ewa Choromanska", "subjects": "Computation and Language (cs.CL); Machine Learning (cs.LG)", "abstract": "Predicting cancer treatment outcomes requires models that are both accurate and interpretable, particularly in the presence of heterogeneous clinical data. While large language models (LLMs) have shown strong performance in biomedical NLP, they often lack structured reasoning capabilities critical for high-stakes decision support. We present a unified, multi-task learning framework that aligns autoregressive LLMs with clinical reasoning for outcome prediction on the MSK-CHORD dataset. Our models are trained to jointly perform binary survival classification, continuous survival time regression, and natural language rationale generation. We evaluate three alignment strategies: (1) standard supervised fine-tuning (SFT), (2) SFT with Chain-of-Thought (CoT) prompting to elicit step-by-step reasoning, and (3) Group Relative Policy Optimization (GRPO), a reinforcement learning method that aligns model outputs to expert-derived reasoning trajectories. Experiments with LLaMa3-8B and Med42-8B backbones demonstrate that CoT prompting improves F1 by +6.0 and reduces MAE by 12%, while GRPO achieves state-of-the-art interpretability and predictive performance across BLEU, ROUGE, and BERTScore. We further show that existing biomedical LLMs often fail to produce valid reasoning traces due to architectural constraints. Our findings underscore the importance of reasoning-aware alignment in multi-task clinical modeling and set a new benchmark for interpretable, trustworthy LLMs in precision oncology."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          NieNie: Adaptive Rhythmic System for Stress Relief with LLM-Based Guidance", "authors": "Yichen Yu, Qiaoran Wang", "subjects": "Human-Computer Interaction (cs.HC)", "abstract": "Today's young people are facing increasing psychological stress due to various social issues. Traditional stress management tools often rely on static scripts or passive content, which are ineffective in alleviating stress. NieNie addresses this gap by combining rhythm biofeedback with real-time psychological guidance through a large language model (LLM), offering an interactive, tactile response. The system is specifically designed for young people experiencing emotional stress, collecting physiological signals such as heart rate variability and generating adaptive squeeze-release rhythms via soft, tactile devices. Utilising LLM, the system provides timely squeezing rhythms and psychologically guided feedback prompts, offering personalised rhythm games while reinforcing stress restructuring. Unlike traditional mental health apps, NieNie places users within an embodied interactive loop, leveraging tactile interaction, biofeedback, and adaptive language support to create an immersive stress regulation experience. This study demonstrates how embodied systems can connect bodily actions with mental health in everyday contexts."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          How role-play shapes relevance judgment in zero-shot LLM rankers", "authors": "Yumeng Wang, Jirui Qi, Catherine Chen, Panagiotis Eustratiadis, Suzan Verberne", "subjects": "Information Retrieval (cs.IR)", "abstract": "Large Language Models (LLMs) have emerged as promising zero-shot rankers, but their performance is highly sensitive to prompt formulation. In particular, role-play prompts, where the model is assigned a functional role or identity, often give more robust and accurate relevance rankings. However, the mechanisms and diversity of role-play effects remain underexplored, limiting both effective use and interpretability. In this work, we systematically examine how role-play variations influence zero-shot LLM rankers. We employ causal intervention techniques from mechanistic interpretability to trace how role-play information shapes relevance judgments in LLMs. Our analysis reveals that (1) careful formulation of role descriptions have a large effect on the ranking quality of the LLM; (2) role-play signals are predominantly encoded in early layers and communicate with task instructions in middle layers, while receiving limited interaction with query or document representations. Specifically, we identify a group of attention heads that encode information critical for role-conditioned relevance. These findings not only shed light on the inner workings of role-play in LLM ranking but also offer guidance for designing more effective prompts in IR and beyond, pointing toward broader opportunities for leveraging role-play in zero-shot applications."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          A general framework for Krylov ODE residuals with applications to randomized Krylov methods", "authors": "Emil Krieger, Marcel Schweitzer", "subjects": "Numerical Analysis (math.NA)", "abstract": "Randomized Krylov subspace methods that employ the sketch-and-solve paradigm to substantially reduce orthogonalization cost have recently shown great promise in speeding up computations for many core linear algebra tasks (e.g., solving linear systems, eigenvalue problems and matrix equations, as well as approximating the action of matrix functions on vectors) whenever a nonsymmetric matrix is involved. An important application that requires approximating the action of matrix functions on vectors is the implementation of exponential integration schemes for ordinary differential equations. In this paper, we specifically analyze randomized Krylov methods from this point of view. In particular, we use the residual of the underlying differential equation to derive a new, reliable a posteriori error estimate that can be used to monitor convergence and decide when to stop the iteration. To do so, we first develop a very general framework for Krylov ODE residuals that unifies existing results, simplifies their derivation and allows extending the concept to a wide variety of methods beyond randomized Arnoldi (e.g., rational Krylov methods, Krylov methods using a non-standard inner product, ...). In addition, we discuss certain aspects regarding the efficient implementation of sketched Krylov methods. Numerical experiments on large-scale ODE models from real-world applications illustrate the quality of the error estimate as well as the general competitiveness of sketched Krylov methods for ODEs in comparison to other Krylov-based methods."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Volumetric Non-Invasive Cardiac Mapping for Accessible Global Arrhythmia Characterization", "authors": "Jorge Vicente-Puig (1 and 2), Judit Chamorro-Servent (1), Ernesto Zacur (2), In\u00e9s Llorente-Lipe (3), Marta Mart\u00ednez (3), Jorge Sanchez (4,5,6), Jana Revent\u00f3s (2,3,7), Ivo Roca-Luque (7), Lluis Mont (7), Felipe Atienza (8,9), Andreu M. Climent (2,3), Maria S. Guillem (2,3), Ismael Hern\u00e1ndez-Romero (2,3) ((1) Universitat Aut\u00f2noma de Barcelona, Spain, (2) Corify Care S.L, Madrid, Spain, (3) ITACA Institute, Universitat Polit\u00e8cnica de Val\u00e8ncia, Valencia, Spain, (4) Centro de Investigaci\u00f3n e Innovaci\u00f3n en Bioingenier\u00eda, Universidad Politecnica de Valencia, Valencia, Spain, (5) Institute of biomedical engineering, Karlsruhe Institute of Technology, Karlsruhe, Germany, (6) Universidad Internacional de Valencia, Valencia, Spain, (7) Arrhythmia Section, Cardiology Department, Hospital Cl\u00ednic, Universitat de Barcelona, Barcelona, Catalonia, Spain, (8) Department of Cardiology, Hospital General Universitario Gregorio Mara\u00f1\u00f3n, Instituto de Investigaci\u00f3n Sanitaria Gregorio Mara\u00f1\u00f3n (IISGM), Madrid, Spain, (9) Centro de Investigaci\u00f3n Biom\u00e9dica en Red de Enfermedades Cardiovasculares (CIBERCV), Madrid, Spain)", "subjects": "Computational Engineering, Finance, and Science (cs.CE)", "abstract": "Cardiac arrhythmias are a major cause of morbidity and mortality increasing the risk of stroke, heart failure, and sudden cardiac death. Imageless electrocardiographic imaging (ECGI) provides a non invasive alternative to electrical mapping from body surface potentials, but conventional ECGI is confined to epicardial reconstructions and can miss arrhythmias originating in deeper myocardium. We address this by reconstructing three dimensional cardiac activity with a volumetric formulation that solves an inverse source problem via Green's functions, enabling full volume activation mapping and improved localization in anatomically complex regions. We evaluate the approach on simulated premature ventricular beats and on four challenging patient cases, a right ventricular outflow tract premature ventricular contraction, a left bundle branch block, a ventricular tachycardia, and Wolff Parkinson White, and additionally assess performance on an open source myocardial infarction dataset. Results show that volumetric ECGI recovers 3D activation and sharpens arrhythmia origin localization, achieving a 59.3% reduction in geodesic error between estimated and simulated origins relative to surface only methods; in patient cases, activation patterns align with clinical diagnoses. Overall, imageless volumetric ECGI offers accessible, non invasive 3D activation mapping that overcomes a core limitation of surface restricted techniques and may improve preprocedural planning, ablation target guidance, and selection or optimization of cardiac resynchronization therapy."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Distributed Spatial-Temporal Trajectory Optimization for Unmanned-Aerial-Vehicle Swarm", "authors": "Xiaobo Zheng, Pan Tang, Defu Lin, Shaoming He", "subjects": "Robotics (cs.RO)", "abstract": "Swarm trajectory optimization problems are a well-recognized class of multi-agent optimal control problems with strong nonlinearity. However, the heuristic nature of needing to set the final time for agents beforehand and the time-consuming limitation of the significant number of iterations prohibit the application of existing methods to large-scale swarm of Unmanned Aerial Vehicles (UAVs) in practice. In this paper, we propose a spatial-temporal trajectory optimization framework that accomplishes multi-UAV consensus based on the Alternating Direction Multiplier Method (ADMM) and uses Differential Dynamic Programming (DDP) for fast local planning of individual UAVs. The introduced framework is a two-level architecture that employs Parameterized DDP (PDDP) as the trajectory optimizer for each UAV, and ADMM to satisfy the local constraints and accomplish the spatial-temporal parameter consensus among all UAVs. This results in a fully distributed algorithm called Distributed Parameterized DDP (D-PDDP). In addition, an adaptive tuning criterion based on the spectral gradient method for the penalty parameter is proposed to reduce the number of algorithmic iterations. Several simulation examples are presented to verify the effectiveness of the proposed algorithm."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Reliable Inference in Edge-Cloud Model Cascades via Conformal Alignment", "authors": "Jiayi Huang, Sangwoo Park, Nicola Paoletti, Osvaldo Simeone", "subjects": "Machine Learning (cs.LG); Signal Processing (eess.SP); Machine Learning (stat.ML)", "abstract": "Edge intelligence enables low-latency inference via compact on-device models, but assuring reliability remains challenging. We study edge-cloud cascades that must preserve conditional coverage: whenever the edge returns a prediction set, it should contain the true label with a user-specified probability, as if produced by the cloud model. We formalize conditional coverage with respect to the cloud predictive distribution, and introduce a conformal alignment-based (CAb) cascading mechanism that certifies this property with user control over the risk level. Our method casts escalation from edge to cloud models as a multiple-hypothesis testing (MHT) problem, tailoring conformal alignment (CA) to select which inputs can be safely handled at the edge. The proposed CAb model cascading method yields statistical guarantees on the average fraction of edge decisions that satisfy cloud-level conditional coverage. The procedure applies to arbitrary edge prediction sets, including variants of conformal prediction (CP), and exposes a tunable trade-off among coverage, deferral rate, and set size. Experiments on CIFAR-100 image classification and the TeleQnA question-answering (QA) benchmark show that the proposed CAb cascade maintains the target conditional coverage for edge predictions while substantially reducing offloading to the cloud and incurring modest increases in prediction-set size."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Multihead Finite-State Compression", "authors": "Neil Lutz", "subjects": "Information Theory (cs.IT); Formal Languages and Automata Theory (cs.FL)", "abstract": "This paper develops multihead finite-state compression, a generalization of finite-state compression, complementary to the multihead finite-state dimensions of Huang, Li, Lutz, and Lutz (2025). In this model, an infinite sequence of symbols is compressed by a compressor that produces outputs according to finite-state rules, based on the symbols read by a constant number of finite-state read heads moving forward obliviously through the sequence. The main theorem of this work establishes that for every sequence and every positive integer $h$, the infimum of the compression ratios achieved by $h$-head finite-state information-lossless compressors equals the $h$-head finite-state predimension of the sequence. As an immediate corollary, the infimum of these ratios over all $h$ is the multihead finite-state dimension of the sequence."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          TrajMamba: An Efficient and Semantic-rich Vehicle Trajectory Pre-training Model", "authors": "Yichen Liu, Yan Lin, Shengnan Guo, Zeyu Zhou, Youfang Lin, Huaiyu Wan", "subjects": "Machine Learning (cs.LG)", "abstract": "Vehicle GPS trajectories record how vehicles move over time, storing valuable travel semantics, including movement patterns and travel purposes. Learning travel semantics effectively and efficiently is crucial for real-world applications of trajectory data, which is hindered by two major challenges. First, travel purposes are tied to the functions of the roads and points-of-interest (POIs) involved in a trip. Such information is encoded in textual addresses and descriptions and introduces heavy computational burden to modeling. Second, real-world trajectories often contain redundant points, which harm both computational efficiency and trajectory embedding quality. To address these challenges, we propose TrajMamba, a novel approach for efficient and semantically rich vehicle trajectory learning. TrajMamba introduces a Traj-Mamba Encoder that captures movement patterns by jointly modeling both GPS and road perspectives of trajectories, enabling robust representations of continuous travel behaviors. It also incorporates a Travel Purpose-aware Pre-training procedure to integrate travel purposes into the learned embeddings without introducing extra overhead to embedding calculation. To reduce redundancy in trajectories, TrajMamba features a Knowledge Distillation Pre-training scheme to identify key trajectory points through a learnable mask generator and obtain effective compressed trajectory embeddings. Extensive experiments on two real-world datasets and three downstream tasks show that TrajMamba outperforms state-of-the-art baselines in both efficiency and accuracy."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          When Annotators Disagree, Topology Explains: Mapper, a Topological Tool for Exploring Text Embedding Geometry and Ambiguity", "authors": "Nisrine Rair, Alban Goupil, Valeriu Vrabie, Emmanuel Chochoy", "subjects": "Computation and Language (cs.CL)", "abstract": "Language models are often evaluated with scalar metrics like accuracy, but such measures fail to capture how models internally represent ambiguity, especially when human annotators disagree. We propose a topological perspective to analyze how fine-tuned models encode ambiguity and more generally instances. Applied to RoBERTa-Large on the MD-Offense dataset, Mapper, a tool from topological data analysis, reveals that fine-tuning restructures embedding space into modular, non-convex regions aligned with model predictions, even for highly ambiguous cases. Over $98\\%$ of connected components exhibit $\\geq 90\\%$ prediction purity, yet alignment with ground-truth labels drops in ambiguous data, surfacing a hidden tension between structural confidence and label uncertainty. Unlike traditional tools such as PCA or UMAP, Mapper captures this geometry directly uncovering decision regions, boundary collapses, and overconfident clusters. Our findings position Mapper as a powerful diagnostic tool for understanding how models resolve ambiguity. Beyond visualization, it also enables topological metrics that may inform proactive modeling strategies in subjective NLP tasks."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Dynamic Switched Quantum Key Distribution Networkwith PUF-based authentication", "authors": "Persefoni Konteli, Nikolaos Makris, Evgenia Niovi Sassalou, Stylianos A. Kazazis, Alkinoos Papageorgopoulos, Stefanos Vasileiadis, Konstantinos Tsimvrakidis, Symeon Tsintzos, Georgios M. Nikolopoulos, George T. Kanellos", "subjects": "Cryptography and Security (cs.CR)", "abstract": "We demonstrate a centrally controlled dynamic switched-QKD network, withintegrated PUF-based dynamic authentication for each QKD link. The performance of the dynamicswitched-QKD network with real-time PUF-based authentication is analyzed."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Language Confusion Gate: Language-Aware Decoding Through Model Self-Distillation", "authors": "Collin Zhang, Fei Huang, Chenhan Yuan, Junyang Lin", "subjects": "Computation and Language (cs.CL)", "abstract": "Large language models (LLMs) often experience language confusion, which is the unintended mixing of languages during text generation. Current solutions to this problem either necessitate model retraining or cannot differentiate between harmful confusion and acceptable code-switching. This paper introduces the Language Confusion Gate (LCG), a lightweight, plug-in solution that filters tokens during decoding without altering the base LLM. The LCG is trained using norm-adjusted self-distillation to predict appropriate language families and apply masking only when needed. Our method is based on the findings that language confusion is infrequent, correct-language tokens are usually among the top predictions, and output token embedding norms are larger for high-resource languages, which biases sampling. When evaluated across various models, including Qwen3, GPT-OSS, Gemma3, Llama3.1, LCG decreases language confusion significantly, often by an order of magnitude, without negatively impacting task performance. Code is available at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          The Free Transformer", "authors": "Fran\u00e7ois Fleuret", "subjects": "Machine Learning (cs.LG)", "abstract": "We propose an extension of the decoder Transformer that conditions its generative process on random latent variables which are learned without supervision thanks to a variational procedure. Experimental evaluations show that allowing such a conditioning translates into substantial improvements on downstream tasks."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Formally Exploring Time-Series Anomaly Detection Evaluation Metrics", "authors": "Dennis Wagner, Arjun Nair, Billy Joe Franks, Justus Arweiler, Aparna Muraleedharan, Indra Jungjohann, Fabian Hartung, Mayank C. Ahuja, Andriy Balinskyy, Saurabh Varshneya, Nabeel Hussain Syed, Mayank Nagda, Phillip Liznerski, Steffen Reithermann, Maja Rudolph, Sebastian Vollmer, Ralf Schulz, Torsten Katz, Stephan Mandt, Michael Bortz, Heike Leitte, Daniel Neider, Jakob Burger, Fabian Jirasek, Hans Hasse, Sophie Fellenz, Marius Kloft", "subjects": "Machine Learning (cs.LG)", "abstract": "Undetected anomalies in time series can trigger catastrophic failures in safety-critical systems, such as chemical plant explosions or power grid outages. Although many detection methods have been proposed, their performance remains unclear because current metrics capture only narrow aspects of the task and often yield misleading results. We address this issue by introducing verifiable properties that formalize essential requirements for evaluating time-series anomaly detection. These properties enable a theoretical framework that supports principled evaluations and reliable comparisons. Analyzing 37 widely used metrics, we show that most satisfy only a few properties, and none satisfy all, explaining persistent inconsistencies in prior results. To close this gap, we propose LARM, a flexible metric that provably satisfies all properties, and extend it to ALARM, an advanced variant meeting stricter requirements."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          An Empirical Study of Lagrangian Methods in Safe Reinforcement Learning", "authors": "Lindsay Spoor, \u00c1lvaro Serra-G\u00f3mez, Aske Plaat, Thomas Moerland", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Robotics (cs.RO); Systems and Control (eess.SY)", "abstract": "In safety-critical domains such as robotics, navigation and power systems, constrained optimization problems arise where maximizing performance must be carefully balanced with associated constraints. Safe reinforcement learning provides a framework to address these challenges, with Lagrangian methods being a popular choice. However, the effectiveness of Lagrangian methods crucially depends on the choice of the Lagrange multiplier $\\lambda$, which governs the trade-off between return and constraint cost. A common approach is to update the multiplier automatically during training. Although this is standard in practice, there remains limited empirical evidence on the robustness of an automated update and its influence on overall performance. Therefore, we analyze (i) optimality and (ii) stability of Lagrange multipliers in safe reinforcement learning across a range of tasks. We provide $\\lambda$-profiles that give a complete visualization of the trade-off between return and constraint cost of the optimization problem. These profiles show the highly sensitive nature of $\\lambda$ and moreover confirm the lack of general intuition for choosing the optimal value $\\lambda^*$. Our findings additionally show that automated multiplier updates are able to recover and sometimes even exceed the optimal performance found at $\\lambda^*$ due to the vast difference in their learning trajectories. Furthermore, we show that automated multiplier updates exhibit oscillatory behavior during training, which can be mitigated through PID-controlled updates. However, this method requires careful tuning to achieve consistently better performance across tasks. This highlights the need for further research on stabilizing Lagrangian methods in safe reinforcement learning. The code used to reproduce our results can be found at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          WP-CrackNet: A Collaborative Adversarial Learning Framework for End-to-End Weakly-Supervised Road Crack Detection", "authors": "Nachuan Ma, Zhengfei Song, Qiang Hu, Xiaoyu Tang, Chengxi Zhang, Rui Fan, Lihua Xie", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Road crack detection is essential for intelligent infrastructure maintenance in smart cities. To reduce reliance on costly pixel-level annotations, we propose WP-CrackNet, an end-to-end weakly-supervised method that trains with only image-level labels for pixel-wise crack detection. WP-CrackNet integrates three components: a classifier generating class activation maps (CAMs), a reconstructor measuring feature inferability, and a detector producing pixel-wise road crack detection results. During training, the classifier and reconstructor alternate in adversarial learning to encourage crack CAMs to cover complete crack regions, while the detector learns from pseudo labels derived from post-processed crack CAMs. This mutual feedback among the three components improves learning stability and detection accuracy. To further boost detection performance, we design a path-aware attention module (PAAM) that fuses high-level semantics from the classifier with low-level structural cues from the reconstructor by modeling spatial and channel-wise dependencies. Additionally, a center-enhanced CAM consistency module (CECCM) is proposed to refine crack CAMs using center Gaussian weighting and consistency constraints, enabling better pseudo-label generation. We create three image-level datasets and extensive experiments show that WP-CrackNet achieves comparable results to supervised methods and outperforms existing weakly-supervised methods, significantly advancing scalable road inspection. The source code package and datasets are available at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          PAGE-4D: Disentangled Pose and Geometry Estimation for 4D Perception", "authors": "Kaichen Zhou, Yuhan Wang, Grace Chen, Xinhai Chang, Gaspard Beaudouin, Fangneng Zhan, Paul Pu Liang, Mengyu Wang", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Recent 3D feed-forward models, such as the Visual Geometry Grounded Transformer (VGGT), have shown strong capability in inferring 3D attributes of static scenes. However, since they are typically trained on static datasets, these models often struggle in real-world scenarios involving complex dynamic elements, such as moving humans or deformable objects like umbrellas. To address this limitation, we introduce PAGE-4D, a feedforward model that extends VGGT to dynamic scenes, enabling camera pose estimation, depth prediction, and point cloud reconstruction -- all without post-processing. A central challenge in multi-task 4D reconstruction is the inherent conflict between tasks: accurate camera pose estimation requires suppressing dynamic regions, while geometry reconstruction requires modeling them. To resolve this tension, we propose a dynamics-aware aggregator that disentangles static and dynamic information by predicting a dynamics-aware mask -- suppressing motion cues for pose estimation while amplifying them for geometry reconstruction. Extensive experiments show that PAGE-4D consistently outperforms the original VGGT in dynamic scenarios, achieving superior results in camera pose estimation, monocular and video depth estimation, and dense point map reconstruction."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Semi-supervised Latent Bayesian Optimization for Designing Antimicrobial Peptides", "authors": "Jyler Menard, R. A. Mansbach", "subjects": "Machine Learning (cs.LG); Computational Physics (physics.comp-ph)", "abstract": "Antimicrobial peptides (AMPs) are a promising class of therapeutics to treat bacterial infections. Discovering and designing such peptides is difficult because of the vast number of possible sequences of amino acids. Deep generative models, such as variational autoencoders, have shown value in peptide design due to their ability to model sequence space with a continuous-valued latent space. Although such models have already been used to great effect in biomolecular design, they still suffer from a lack of interpretability and rigorous quantification of latent space quality as a search space. We investigate (1) whether further compression of the design space via dimensionality reduction may facilitate optimization, (2) the interpretability of the spaces, and (3) how organizing latent spaces with physicochemical properties may improve the efficiency of optimizing antimicrobial activity. We find that further reduction of the latent space via dimensionality reduction can be advantageous when organizing the space with more relevant information at data availability, that using the dimensionality reduction search space can be more interpretable, and that we can organize the latent space with different physicochemical properties even at different percentages of available labels."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          DeTAILS: Deep Thematic Analysis with Iterative LLM Support", "authors": "Ash Sharma, Karen Cochrane, James R. Wallace", "subjects": "Human-Computer Interaction (cs.HC)", "abstract": "Thematic analysis is widely used in qualitative research but can be difficult to scale because of its iterative, interpretive demands. We introduce DeTAILS, a toolkit that integrates large language model (LLM) assistance into a workflow inspired by Braun and Clarke's thematic analysis framework. DeTAILS supports researchers in generating and refining codes, reviewing clusters, and synthesizing themes through interactive feedback loops designed to preserve analytic agency. We evaluated the system with 18 qualitative researchers analyzing Reddit data. Quantitative results showed strong alignment between LLM-supported outputs and participants' refinements, alongside reduced workload and high perceived usefulness. Qualitatively, participants reported that DeTAILS accelerated analysis, prompted reflexive engagement with AI outputs, and fostered trust through transparency and control. We contribute: (1) an interactive human-LLM workflow for large-scale qualitative analysis, (2) empirical evidence of its feasibility and researcher experience, and (3) design implications for trustworthy AI-assisted qualitative research."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Intent-Driven LLM Ensemble Planning for Flexible Multi-Robot Disassembly: Demonstration on EV Batteries", "authors": "Cansu Erdogan, Cesar Alan Contreras, Alireza Rastegarpanah, Manolis Chiou, Rustam Stolkin", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Multiagent Systems (cs.MA)", "abstract": "This paper addresses the problem of planning complex manipulation tasks, in which multiple robots with different end-effectors and capabilities, informed by computer vision, must plan and execute concatenated sequences of actions on a variety of objects that can appear in arbitrary positions and configurations in unstructured scenes. We propose an intent-driven planning pipeline which can robustly construct such action sequences with varying degrees of supervisory input from a human using simple language instructions. The pipeline integrates: (i) perception-to-text scene encoding, (ii) an ensemble of large language models (LLMs) that generate candidate removal sequences based on the operator's intent, (iii) an LLM-based verifier that enforces formatting and precedence constraints, and (iv) a deterministic consistency filter that rejects hallucinated objects. The pipeline is evaluated on an example task in which two robot arms work collaboratively to dismantle an Electric Vehicle battery for recycling applications. A variety of components must be grasped and removed in specific sequences, determined by human instructions and/or by task-order feasibility decisions made by the autonomous system. On 200 real scenes with 600 operator prompts across five component classes, we used metrics of full-sequence correctness and next-task correctness to evaluate and compare five LLM-based planners (including ablation analyses of pipeline components). We also evaluated the LLM-based human interface in terms of time to execution and NASA TLX with human participant experiments. Results indicate that our ensemble-with-verification approach reliably maps operator intent to safe, executable multi-robot plans while maintaining low user effort."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Numerical Error Analysis of the Poisson Equation under RHS Inaccuracies in Particle-in-Cell Simulations", "authors": "Kai Zhang, Tao Xiao, Weizong Wang, Bijiao He", "subjects": "Numerical Analysis (math.NA)", "abstract": "Particle-in-Cell (PIC) simulations rely on accurate solutions of the electrostatic Poisson equation, yet accuracy often deteriorates near irregular Dirichlet boundaries on Cartesian meshes. While much research has addressed discretization errors on the left-hand side (LHS) of the Poisson equation, the impact of right-hand-side (RHS) inaccuracies - arising from charge density sampling near boundaries in PIC methods - remains largely unexplored. This study analyzes the numerical errors induced by underestimated RHS values at near-boundary nodes when solving the Poisson equation using embedded boundary finite difference schemes with linear and quadratic treatments. Analytical derivations in one dimension and truncation error analyses in two dimensions reveal that such RHS inaccuracies modify local truncation behavior differently: they reduce the dominant truncation error in the linear scheme but introduce a zeroth-order term in the quadratic scheme, leading to larger global errors. Numerical experiments in one-, two-, and three-dimensional domains confirm these findings. Contrary to expectations, the linear scheme yields superior overall accuracy under typical PIC-induced RHS inaccuracies. A simple RHS calibration strategy is further proposed to restore the accuracy of the quadratic scheme. These results offer new insight into the interplay between boundary-induced RHS errors and discretization accuracy in Poisson-type problems."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Non-interference analysis of bounded labeled Petri nets", "authors": "Ning Ran, Zhengguang Wu, Shaokang Zhang, Zhou He, Carla Seatzu", "subjects": "Formal Languages and Automata Theory (cs.FL)", "abstract": "This paper focuses on a fundamental problem on information security of bounded labeled Petri nets: non-interference analysis. As in hierarchical control, we assume that a system is observed by users at different levels, namely high-level users and low-level users. The output events produced by the firing of transitions are also partitioned into high-level output events and low-level output events. In general, high-level users can observe the occurrence of all the output events, while low-level users can only observe the occurrence of low-level output events. A system is said to be non-interferent if low-level users cannot infer the firing of transitions labeled with high-level output events by looking at low-level outputs. In this paper, we study a particular non-interference property, namely strong non-deterministic non-interference (SNNI), using a special automaton called SNNI Verifier, and propose a necessary and sufficient condition for SNNI."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          CEPerFed: Communication-Efficient Personalized Federated Learning for Multi-Pulse MRI Classification", "authors": "Ludi Li, Junbin Mao, Hanhe Lin, Xu Tian, Fang-Xiang Wu, Jin Liu", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "Multi-pulse magnetic resonance imaging (MRI) is widely utilized for clinical practice such as Alzheimer's disease diagnosis. To train a robust model for multi-pulse MRI classification, it requires large and diverse data from various medical institutions while protecting privacy by preventing raw data sharing across institutions. Although federated learning (FL) is a feasible solution to address this issue, it poses challenges of model convergence due to the effect of data heterogeneity and substantial communication overhead due to large numbers of parameters transmitted within the model. To address these challenges, we propose CEPerFed, a communication-efficient personalized FL method. It mitigates the effect of data heterogeneity by incorporating client-side historical risk gradients and historical mean gradients to coordinate local and global optimization. The former is used to weight the contributions from other clients, enhancing the reliability of local updates, while the latter enforces consistency between local updates and the global optimization direction to ensure stable convergence across heterogeneous data distributions. To address the high communication overhead, we propose a hierarchical SVD (HSVD) strategy that transmits only the most critical information required for model updates. Experiments on five classification tasks demonstrate the effectiveness of the CEPerFed method. The code will be released upon acceptance at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Expose Camouflage in the Water: Underwater Camouflaged Instance Segmentation and Dataset", "authors": "Chuhong Wang, Hua Li, Chongyi Li, Huazhong Liu, Xiongxin Tang, Sam Kwong", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "With the development of underwater exploration and marine protection, underwater vision tasks are widespread. Due to the degraded underwater environment, characterized by color distortion, low contrast, and blurring, camouflaged instance segmentation (CIS) faces greater challenges in accurately segmenting objects that blend closely with their surroundings. Traditional camouflaged instance segmentation methods, trained on terrestrial-dominated datasets with limited underwater samples, may exhibit inadequate performance in underwater scenes. To address these issues, we introduce the first underwater camouflaged instance segmentation (UCIS) dataset, abbreviated as UCIS4K, which comprises 3,953 images of camouflaged marine organisms with instance-level annotations. In addition, we propose an Underwater Camouflaged Instance Segmentation network based on Segment Anything Model (UCIS-SAM). Our UCIS-SAM includes three key modules. First, the Channel Balance Optimization Module (CBOM) enhances channel characteristics to improve underwater feature learning, effectively addressing the model's limited understanding of underwater environments. Second, the Frequency Domain True Integration Module (FDTIM) is proposed to emphasize intrinsic object features and reduce interference from camouflage patterns, enhancing the segmentation performance of camouflaged objects blending with their surroundings. Finally, the Multi-scale Feature Frequency Aggregation Module (MFFAM) is designed to strengthen the boundaries of low-contrast camouflaged instances across multiple frequency bands, improving the model's ability to achieve more precise segmentation of camouflaged objects. Extensive experiments on the proposed UCIS4K and public benchmarks show that our UCIS-SAM outperforms state-of-the-art approaches."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          DeepEye-SQL: A Software-Engineering-Inspired Text-to-SQL Framework", "authors": "Boyan Li, Chong Chen, Zhujun Xue, Yinan Mei, Yuyu Luo", "subjects": "Databases (cs.DB)", "abstract": "Large language models (LLMs) have advanced Text-to-SQL, yet existing solutions still fall short of system-level reliability. The limitation is not merely in individual modules - e.g., schema linking, reasoning, and verification - but more critically in the lack of structured orchestration that enforces correctness across the entire workflow. This gap motivates a paradigm shift: treating Text-to-SQL not as free-form language generation but as a software-engineering problem that demands structured, verifiable orchestration. We present DeepEye-SQL, a software-engineering-inspired framework that reframes Text-to-SQL as the development of a small software program, executed through a verifiable process guided by the Software Development Life Cycle (SDLC). DeepEye-SQL integrates four synergistic stages: it grounds ambiguous user intent through semantic value retrieval and robust schema linking; enhances fault tolerance with N-version SQL generation using diverse reasoning paradigms; ensures deterministic verification via a tool-chain of unit tests and targeted LLM-guided revision; and introduces confidence-aware selection that clusters execution results to estimate confidence and then takes a high-confidence shortcut or runs unbalanced pairwise adjudication in low-confidence cases, yielding a calibrated, quality-gated output. This SDLC-aligned workflow transforms ad hoc query generation into a disciplined engineering process. Using ~30B open-source LLMs without any fine-tuning, DeepEye-SQL achieves 73.5% execution accuracy on BIRD-Dev and 89.8% on Spider-Test, outperforming state-of-the-art solutions. This highlights that principled orchestration, rather than LLM scaling alone, is key to achieving system-level reliability in Text-to-SQL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          MIRAGE: Agentic Framework for Multimodal Misinformation Detection with Web-Grounded Reasoning", "authors": "Mir Nafis Sharear Shopnil, Sharad Duwal, Abhishek Tyagi, Adiba Mahbub Proma", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Computers and Society (cs.CY); Machine Learning (cs.LG)", "abstract": "Misinformation spreads across web platforms through billions of daily multimodal posts that combine text and images, overwhelming manual fact-checking capacity. Supervised detection models require domain-specific training data and fail to generalize across diverse manipulation tactics. We present MIRAGE, an inference-time, model-pluggable agentic framework that decomposes multimodal verification into four sequential modules: visual veracity assessment detects AI-generated images, cross-modal consistency analysis identifies out-of-context repurposing, retrieval-augmented factual checking grounds claims in web evidence through iterative question generation, and a calibrated judgment module integrates all signals. MIRAGE orchestrates vision-language model reasoning with targeted web retrieval, outputs structured and citation-linked rationales. On MMFakeBench validation set (1,000 samples), MIRAGE with GPT-4o-mini achieves 81.65% F1 and 75.1% accuracy, outperforming the strongest zero-shot baseline (GPT-4V with MMD-Agent at 74.0% F1) by 7.65 points while maintaining 34.3% false positive rate versus 97.3% for a judge-only baseline. Test set results (5,000 samples) confirm generalization with 81.44% F1 and 75.08% accuracy. Ablation studies show visual verification contributes 5.18 F1 points and retrieval-augmented reasoning contributes 2.97 points. Our results demonstrate that decomposed agentic reasoning with web retrieval can match supervised detector performance without domain-specific training, enabling misinformation detection across modalities where labeled data remains scarce."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          HGAdapter: Hypergraph-based Adapters in Language Models for Code Summarization and Clone Detection", "authors": "Guang Yang, Yujie Zhu", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Software Engineering (cs.SE)", "abstract": "Pre-trained language models (PLMs) are increasingly being applied to code-related tasks. Although PLMs have achieved good results, they do not take into account potential high-order data correlations within the code. We propose three types of high-order correlations in code tokens, i.e. abstract syntax tree family correlation, lexical correlation, and line correlation. We design a tokens and hyperedges generator to capture these high-order data correlations. We improve the architecture of hypergraph neural networks and combine it with adapter tuning to propose a novel hypergraph-based adapter (HGAdapter) to fine-tune PLMs. HGAdapter can encode high-order data correlations and is allowed to be inserted into various PLMs to enhance performance. Experiments were conducted on several public datasets, including six languages of code summarization and code clone detection tasks. Our methods improved the performance of PLMs in datasets to varying degrees. Experimental results validate the introduction of high-order data correlations that contribute to improved effectiveness."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Approximating Asymmetric A Priori TSP beyond the Adaptivity Gap", "authors": "Manuel Christalla, Luise Puhlmann, Vera Traub", "subjects": "Data Structures and Algorithms (cs.DS)", "abstract": "In Asymmetric A Priori TSP (with independent activation probabilities) we are given an instance of the Asymmetric Traveling Salesman Problem together with an activation probability for each vertex. The task is to compute a tour that minimizes the expected length after short-cutting to the randomly sampled set of active vertices. We prove a polynomial lower bound on the adaptivity gap for Asymmetric A Priori TSP. Moreover, we show that a poly-logarithmic approximation ratio, and hence an approximation ratio below the adaptivity gap, can be achieved by a randomized algorithm with quasi-polynomial running time. To achieve this, we provide a series of polynomial-time reductions. First we reduce to a novel generalization of the Asymmetric Traveling Salesman Problem, called Hop-ATSP. Next, we use directed low-diameter decompositions to obtain structured instances, for which we then provide a reduction to a covering problem. Eventually, we obtain a polynomial-time reduction of Asymmetric A Priori TSP to a problem of finding a path in an acyclic digraph minimizing a particular objective function, for which we give an O(log n)-approximation algorithm in quasi-polynomial time."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Reasoning Distillation and Structural Alignment for Improved Code Generation", "authors": "Amir Jalilifard, Anderson de Rezende Rocha, Marcos Medeiros Raimundo", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)", "abstract": "Effective code generation with language models hinges on two critical factors: accurately understanding the intent of the prompt and generating code that applies algorithmic reasoning to produce correct solutions capable of passing diverse test cases while adhering to the syntax of the target programming language. Unlike other language tasks, code generation requires more than accurate token prediction; it demands comprehension of solution-level and structural relationships rather than merely generating the most likely tokens. very large language model (VLLM) are capable of generating detailed steps toward the correct solution of complex tasks where reasoning is crucial in solving the problem. Such reasoning capabilities may be absent in smaller language models. Therefore, in this work, we distill the reasoning capabilities of a VLLM into a smaller, more efficient model that is faster and cheaper to deploy. Our approach trains the model to emulate the reasoning and problem-solving abilities of the VLLM by learning to identify correct solution pathways and establishing a structural correspondence between problem definitions and potential solutions through a novel method of structure-aware loss optimization. This enables the model to transcend token-level generation and to deeply grasp the overarching structure of solutions for given problems. Experimental results show that our fine-tuned model, developed through a cheap and simple to implement process, significantly outperforms our baseline model in terms of pass@1, average data flow, and average syntax match metrics across the MBPP, MBPP Plus, and HumanEval benchmarks."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Conveying Meaning through Gestures: An Investigation into Semantic Co-Speech Gesture Generation", "authors": "Hendric Voss, Lisa Michelle Bohnenkamp, Stefan Kopp", "subjects": "Human-Computer Interaction (cs.HC); Computer Vision and Pattern Recognition (cs.CV)", "abstract": "This study explores two frameworks for co-speech gesture generation, AQ-GT and its semantically-augmented variant AQ-GT-a, to evaluate their ability to convey meaning through gestures and how humans perceive the resulting movements. Using sentences from the SAGA spatial communication corpus, contextually similar sentences, and novel movement-focused sentences, we conducted a user-centered evaluation of concept recognition and human-likeness. Results revealed a nuanced relationship between semantic annotations and performance. The original AQ-GT framework, lacking explicit semantic input, was surprisingly more effective at conveying concepts within its training domain. Conversely, the AQ-GT-a framework demonstrated better generalization, particularly for representing shape and size in novel contexts. While participants rated gestures from AQ-GT-a as more expressive and helpful, they did not perceive them as more human-like. These findings suggest that explicit semantic enrichment does not guarantee improved gesture generation and that its effectiveness is highly dependent on the context, indicating a potential trade-off between specialization and generalization."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          LawChain: Modeling Legal Reasoning Chains for Chinese Tort Case Analysis", "authors": "Huiyuan Xie, Chenyang Li, Huining Zhu, Chubin Zhang, Yuxiao Ye, Zhenghao Liu, Zhiyuan Liu", "subjects": "Computation and Language (cs.CL)", "abstract": "Legal reasoning is a fundamental component of legal analysis and decision-making. Existing computational approaches to legal reasoning predominantly rely on generic reasoning frameworks such as syllogism and IRAC, which do not comprehensively examine the nuanced processes that underpin legal reasoning. Moreover, current research has largely focused on criminal cases, with insufficient modeling for civil cases. In this work, we present a novel framework for explicitly modeling legal reasoning in the analysis of Chinese tort-related civil cases. We first operationalize the legal reasoning processes used in tort analysis into the LawChain framework. LawChain is a three-module reasoning framework, with each module consisting of multiple finer-grained sub-steps. Informed by the LawChain framework, we introduce the task of tort legal reasoning and construct an evaluation benchmark, LawChain$_{eval}$, to systematically assess the critical steps within analytical reasoning chains for tort analysis. Leveraging this benchmark, we evaluate state-of-the-art large language models for their legal reasoning ability in civil tort contexts. Our results indicate that current models still fall short in accurately handling crucial elements of tort legal reasoning. Furthermore, we introduce several baseline approaches that explicitly incorporate LawChain-style reasoning through prompting or post-training. We conduct further experiments on additional legal analysis tasks, such as Legal Named-Entity Recognition and Criminal Damages Calculation, to verify the generalizability of these baselines. The proposed baseline approaches achieve significant improvements in tort-related legal reasoning and generalize well to related legal analysis tasks, thus demonstrating the value of explicitly modeling legal reasoning chains to enhance the reasoning capabilities of language models."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          ShapeCraft: LLM Agents for Structured, Textured and Interactive 3D Modeling", "authors": "Shuyuan Zhang, Chenhan Jiang, Zuoou Li, Jiankang Deng", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "3D generation from natural language offers significant potential to reduce expert manual modeling efforts and enhance accessibility to 3D assets. However, existing methods often yield unstructured meshes and exhibit poor interactivity, making them impractical for artistic workflows. To address these limitations, we represent 3D assets as shape programs and introduce ShapeCraft, a novel multi-agent framework for text-to-3D generation. At its core, we propose a Graph-based Procedural Shape (GPS) representation that decomposes complex natural language into a structured graph of sub-tasks, thereby facilitating accurate LLM comprehension and interpretation of spatial relationships and semantic shape details. Specifically, LLM agents hierarchically parse user input to initialize GPS, then iteratively refine procedural modeling and painting to produce structured, textured, and interactive 3D assets. Qualitative and quantitative experiments demonstrate ShapeCraft's superior performance in generating geometrically accurate and semantically rich 3D assets compared to existing LLM-based agents. We further show the versatility of ShapeCraft through examples of animated and user-customized editing, highlighting its potential for broader interactive applications."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Learned Inertial Odometry for Cycling Based on Mixture of Experts Algorithm", "authors": "Hao Qiao, Yan Wang, Shuo Yang, Xiaoyao Yu, Jian kuang, Xiaoji Niu", "subjects": "Robotics (cs.RO)", "abstract": "With the rapid growth of bike sharing and the increasing diversity of cycling applications, accurate bicycle localization has become essential. traditional GNSS-based methods suffer from multipath effects, while existing inertial navigation approaches rely on precise modeling and show limited robustness. Tight Learned Inertial Odometry (TLIO) achieves low position drift by combining raw IMU data with predicted displacements by neural networks, but its high computational cost restricts deployment on mobile devices. To overcome this, we extend TLIO to bicycle localization and introduce an improved Mixture-of Experts (MoE) model that reduces both training and inference costs. Experiments show that, compared to the state-of-the-art LLIO framework, our method achieves comparable accuracy while reducing parameters by 64.7% and computational cost by 81.8%."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Integrating BIM and UAV-based photogrammetry for Automated 3D Structure Model Segmentation", "authors": "Siqi Chen, Shanyue Guan", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "The advancement of UAV technology has enabled efficient, non-contact structural health monitoring. Combined with photogrammetry, UAVs can capture high-resolution scans and reconstruct detailed 3D models of infrastructure. However, a key challenge remains in segmenting specific structural components from these models-a process traditionally reliant on time-consuming and error-prone manual labeling. To address this issue, we propose a machine learning-based framework for automated segmentation of 3D point clouds. Our approach uses the complementary strengths of real-world UAV-scanned point clouds and synthetic data generated from Building Information Modeling (BIM) to overcome the limitations associated with manual labeling. Validation on a railroad track dataset demonstrated high accuracy in identifying and segmenting major components such as rails and crossties. Moreover, by using smaller-scale datasets supplemented with BIM data, the framework significantly reduced training time while maintaining reasonable segmentation accuracy. This automated approach improves the precision and efficiency of 3D infrastructure model segmentation and advances the integration of UAV and BIM technologies in structural health monitoring and infrastructure management."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          One Dinomaly2 Detect Them All: A Unified Framework for Full-Spectrum Unsupervised Anomaly Detection", "authors": "Jia Guo, Shuai Lu, Lei Fan, Zelin Li, Donglin Di, Yang Song, Weihang Zhang, Wenbing Zhu, Hong Yan, Fang Chen, Huiqi Li, Hongen Liao", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Unsupervised anomaly detection (UAD) has evolved from building specialized single-class models to unified multi-class models, yet existing multi-class models significantly underperform the most advanced one-for-one counterparts. Moreover, the field has fragmented into specialized methods tailored to specific scenarios (multi-class, 3D, few-shot, etc.), creating deployment barriers and highlighting the need for a unified solution. In this paper, we present Dinomaly2, the first unified framework for full-spectrum image UAD, which bridges the performance gap in multi-class models while seamlessly extending across diverse data modalities and task settings. Guided by the \"less is more\" philosophy, we demonstrate that the orchestration of five simple element achieves superior performance in a standard reconstruction-based framework. This methodological minimalism enables natural extension across diverse tasks without modification, establishing that simplicity is the foundation of true universality. Extensive experiments on 12 UAD benchmarks demonstrate Dinomaly2's full-spectrum superiority across multiple modalities (2D, multi-view, RGB-3D, RGB-IR), task settings (single-class, multi-class, inference-unified multi-class, few-shot) and application domains (industrial, biological, outdoor). For example, our multi-class model achieves unprecedented 99.9% and 99.3% image-level (I-) AUROC on MVTec-AD and VisA respectively. For multi-view and multi-modal inspection, Dinomaly2 demonstrates state-of-the-art performance with minimum adaptations. Moreover, using only 8 normal examples per class, our method surpasses previous full-shot models, achieving 98.7% and 97.4% I-AUROC on MVTec-AD and VisA. The combination of minimalistic design, computational scalability, and universal applicability positions Dinomaly2 as a unified solution for the full spectrum of real-world anomaly detection applications."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Mode Switching-based STAR-RIS with Discrete Phase Shifters", "authors": "MohammadHossein Alishahi, Ming Zeng, Paul Fortier, Ji Wang, Nian Xia, Gongpu Wang", "subjects": "Information Theory (cs.IT)", "abstract": "The increasing demand for cost-effective, high-speed Internet of Things (IoT) applications in the coming sixth-generation (6G) networks has driven research toward maximizing spectral efficiency and simplifying hardware designs. In this context, we investigate the sum rate maximization problem for a mode-switching discrete-phase shifters simultaneously transmitting and reflecting reconfigurable intelligent surface (STAR-RIS)-aided multi-antenna access point network, emphasizing hardware efficiency and reduced cost. A mixed-integer nonlinear optimization framework is formulated for joint optimization of the active beamforming matrix, user power allocation, and STAR-RIS phase shift vectors, including binary transmission/reflection amplitudes and discrete phase shifters. To solve the formulated problem, we employ a block coordinate descent method, dividing it into three subproblems tackled using difference-of-concave programming and combinatorial optimization techniques. Numerical results validate the effectiveness of the proposed joint optimization approach, consistently achieving superior sum rate performance compared to partial optimization methods, thereby underscoring its potential for efficient and scalable 6G IoT systems."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          OG-Rank: Learning to Rank Fast and Slow with Uncertainty and Reward-Trend Guided Adaptive Exploration", "authors": "Praphul Singh, Corey Barrett, Sumana Srivasta, Irfan Bulu, Sri Gadde, Krishnaram Kenthapadi", "subjects": "Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)", "abstract": "Clinicians need ranking systems that work in real time and still justify their choices. Motivated by the need for a low-latency, decoder-based reranker, we present OG-Rank, a single-decoder approach that pairs a pooled first-token scoring signal with an uncertainty-gated explanation step. The model scores all candidates in one pass and generates a brief, structured rationale only when the list is genuinely ambiguous, keeping latency predictable. Trained with a curriculum that concentrates effort on hard cases, OG-Rank delivers strong effectiveness on encounter-scoped order selection (fast path: Recall@1~0.45, nDCG@20~0.625) and improves further when the gate activates (Recall@1~0.56, nDCG@20~0.699 at a 45\\% gate rate), while compact backbones show similar gains under the same policy. Encoder baselines trail in both effectiveness and flexibility. The result is a practical recipe: rank fast by default and explain when it helps, a pattern that applies broadly to decision tasks where selective generation buys accuracy at acceptable cost. The single-policy design simplifies deployment and budget planning, and the curriculum principle (spend more on the hard cases, less on the easy ones) readily transfers beyond clinical order selection."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          ImaGGen: Zero-Shot Generation of Co-Speech Semantic Gestures Grounded in Language and Image Input", "authors": "Hendric Voss, Stefan Kopp", "subjects": "Human-Computer Interaction (cs.HC); Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Human communication combines speech with expressive nonverbal cues such as hand gestures that serve manifold communicative functions. Yet, current generative gesture generation approaches are restricted to simple, repetitive beat gestures that accompany the rhythm of speaking but do not contribute to communicating semantic meaning. This paper tackles a core challenge in co-speech gesture synthesis: generating iconic or deictic gestures that are semantically coherent with a verbal utterance. Such gestures cannot be derived from language input alone, which inherently lacks the visual meaning that is often carried autonomously by gestures. We therefore introduce a zero-shot system that generates gestures from a given language input and additionally is informed by imagistic input, without manual annotation or human intervention. Our method integrates an image analysis pipeline that extracts key object properties such as shape, symmetry, and alignment, together with a semantic matching module that links these visual details to spoken text. An inverse kinematics engine then synthesizes iconic and deictic gestures and combines them with co-generated natural beat gestures for coherent multimodal communication. A comprehensive user study demonstrates the effectiveness of our approach. In scenarios where speech alone was ambiguous, gestures generated by our system significantly improved participants' ability to identify object properties, confirming their interpretability and communicative value. While challenges remain in representing complex shapes, our results highlight the importance of context-aware semantic gestures for creating expressive and collaborative virtual agents or avatars, marking a substantial step forward towards efficient and robust, embodied human-agent interaction. More information and example videos are available here: this https URL"}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Artificial magnetic conductor backed dual-mode sectoral cylindrical DRA for off-body biomedical telemetry", "authors": "Nayab Gogosh, Sohail Khalid, Bilal Tariq Malik, Slawomir Koziel", "subjects": "Systems and Control (eess.SY)", "abstract": "This research investigates the potential of a sectoral Cylindrical Dielectric Resonator Antenna (CDRA) for biomedical telemetry. CDRAs are known for their low loss, ruggedness, and stability, but their limited bandwidth and size make them unsuitable for wearable devices. The research addresses these limitations by proposing a dual mode antenna that operates in EH110 and TE210 modes. The sectoral CDRA is a quarter segment with Perfect Electric Conductor boundaries, reducing its size by a factor of four. Mathematical derivations of the field components for both modes are derived to support the design. To minimize specific absorption rate (SAR), an Artificial Magnetic Conductor (AMC) surface is applied to the antennas backside, enhancing compatibility with the transverse electric modes. The antenna achieves a bandwidth of 0.7 GHz (5.2-5.9 GHz), suitable for biomedical applications, with a measured peak gain of 7.9 dBi and a SAR of 1.24 W/kg when applied to a human arm."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Forget to Know, Remember to Use: Context-Aware Unlearning for Large Language Models", "authors": "Yuefeng Peng, Parnian Afshar, Megan Ganji, Thomas Butler, Amir Houmansadr, Mingxian Wang, Dezhi Hong", "subjects": "Computation and Language (cs.CL)", "abstract": "Large language models may encode sensitive information or outdated knowledge that needs to be removed, to ensure responsible and compliant model responses. Unlearning has emerged as an efficient alternative to full retraining, aiming to remove specific knowledge while preserving overall model utility. Existing evaluations of unlearning methods focus on (1) the extent of forgetting of the target knowledge (forget set) and (2) maintaining performance on the retain set (i.e., utility). However, these evaluations overlook an important usability aspect: users may still want the model to leverage the removed information if it is re-introduced in the prompt. In a systematic evaluation of six state-of-the-art unlearning methods, we find that they consistently impair such contextual utility. To address this, we augment unlearning objectives with a plug-in term that preserves the model's ability to use forgotten knowledge when it is present in context. Extensive experiments demonstrate that our approach restores contextual utility to near original levels while still maintaining effective forgetting and retain-set utility."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          GUIDE: Enhancing Gradient Inversion Attacks in Federated Learning with Denoising Models", "authors": "Vincenzo Carletti, Pasquale Foggia, Carlo Mazzocca, Giuseppe Parrella, Mario Vento", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "abstract": "Federated Learning (FL) enables collaborative training of Machine Learning (ML) models across multiple clients while preserving their privacy. Rather than sharing raw data, federated clients transmit locally computed updates to train the global model. Although this paradigm should provide stronger privacy guarantees than centralized ML, client updates remain vulnerable to privacy leakage. Adversaries can exploit them to infer sensitive properties about the training data or even to reconstruct the original inputs via Gradient Inversion Attacks (GIAs). Under the honest-butcurious threat model, GIAs attempt to reconstruct training data by reversing intermediate updates using optimizationbased techniques. We observe that these approaches usually reconstruct noisy approximations of the original inputs, whose quality can be enhanced with specialized denoising models. This paper presents Gradient Update Inversion with DEnoising (GUIDE), a novel methodology that leverages diffusion models as denoising tools to improve image reconstruction attacks in FL. GUIDE can be integrated into any GIAs that exploits surrogate datasets, a widely adopted assumption in GIAs literature. We comprehensively evaluate our approach in two attack scenarios that use different FL algorithms, models, and datasets. Our results demonstrate that GUIDE integrates seamlessly with two state-ofthe- art GIAs, substantially improving reconstruction quality across multiple metrics. Specifically, GUIDE achieves up to 46% higher perceptual similarity, as measured by the DreamSim metric."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Just-In-Time Piecewise-Linear Semantics for ReLU-type Networks", "authors": "Hongyi Duan, Haoyang Liu, Jian'an Zhang, Fengrui Liu, Yiyi Wang", "subjects": "Logic in Computer Science (cs.LO); Machine Learning (cs.LG)", "abstract": "We present a JIT PL semantics for ReLU-type networks that compiles models into a guarded CPWL transducer with shared guards. The system adds hyperplanes only when operands are affine on the current cell, maintains global lower/upper envelopes, and uses a budgeted branch-and-bound. We obtain anytime soundness, exactness on fully refined cells, monotone progress, guard-linear complexity (avoiding global $\\binom{k}{2}$), dominance pruning, and decidability under finite refinement. The shared carrier supports region extraction, decision complexes, Jacobians, exact/certified Lipschitz, LP/SOCP robustness, and maximal causal influence. A minimal prototype returns certificates or counterexamples with cost proportional to visited subdomains."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Space-Time Rate-Splitting Multiple Access for Multibeam LEO Satellite Networks", "authors": "Jaehyup Seong, Byungju Lee, Aryan Kaushik, Wonjae Shin", "subjects": "Information Theory (cs.IT)", "abstract": "This paper proposes a novel space-time rate-splitting multiple access (ST-RSMA) framework for multibeam low Earth orbit (LEO) satellite communications (SATCOM) systems, where space-time coding is integrated into the common stream transmission. This design enables full diversity gain in the common stream transmission for all users, regardless of the uncertainty of the channel state information (CSI) and network load conditions, thereby overcoming the performance limitations of conventional RSMA that employs a single beamforming vector for all users. To further enhance performance, we develop a weighted minimum mean square error (WMMSE)-based algorithm tailored to ST-RSMA that jointly optimizes the power allocation for the common stream and the power/beamforming vectors for private streams, aiming to maximize the minimum user rate. Numerical results show that ST-RSMA significantly outperforms conventional RSMA and other multiple access techniques, offering a robust and scalable solution for LEO SATCOM."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          CaMiT: A Time-Aware Car Model Dataset for Classification and Generation", "authors": "Fr\u00e9d\u00e9ric LIN, Biruk Abere Ambaw, Adrian Popescu, Hejer Ammar, Romaric Audigier, Herv\u00e9 Le Borgne (Universit\u00e9 Paris-Saclay, CEA, List, F-91120, Palaiseau, France)", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "abstract": "AI systems must adapt to evolving visual environments, especially in domains where object appearances change over time. We introduce Car Models in Time (CaMiT), a fine-grained dataset capturing the temporal evolution of car models, a representative class of technological artifacts. CaMiT includes 787K labeled samples of 190 car models (2007-2023) and 5.1M unlabeled samples (2005-2023), supporting both supervised and self-supervised learning. Static pretraining on in-domain data achieves competitive performance with large-scale generalist models while being more resource-efficient, yet accuracy declines when models are tested across years. To address this, we propose a time-incremental classification setting, a realistic continual learning scenario with emerging, evolving, and disappearing classes. We evaluate two strategies: time-incremental pretraining, which updates the backbone, and time-incremental classifier learning, which updates only the final layer, both improving temporal robustness. Finally, we explore time-aware image generation that leverages temporal metadata during training, yielding more realistic outputs. CaMiT offers a rich benchmark for studying temporal adaptation in fine-grained visual recognition and generation."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          SARSteer: Safeguarding Large Audio Language Models via Safe-Ablated Refusal Steering", "authors": "Weilin Lin, Jianze Li, Hui Xiong, Li Liu", "subjects": "Sound (cs.SD); Cryptography and Security (cs.CR)", "abstract": "Large Audio-Language Models (LALMs) are becoming essential as a powerful multimodal backbone for real-world applications. However, recent studies show that audio inputs can more easily elicit harmful responses than text, exposing new risks toward deployment. While safety alignment has made initial advances in LLMs and Large Vision-Language Models (LVLMs), we find that vanilla adaptation of these approaches to LALMs faces two key limitations: 1) LLM-based steering fails under audio input due to the large distributional gap between activations, and 2) prompt-based defenses induce over-refusals on benign-speech queries. To address these challenges, we propose Safe-Ablated Refusal Steering (SARSteer), the first inference-time defense framework for LALMs. Specifically, SARSteer leverages text-derived refusal steering to enforce rejection without manipulating audio inputs and introduces decomposed safe-space ablation to mitigate over-refusal. Extensive experiments demonstrate that SARSteer significantly improves harmful-query refusal while preserving benign responses, establishing a principled step toward safety alignment in LALMs."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          LLM-as-a-Prophet: Understanding Predictive Intelligence with Prophet Arena", "authors": "Qingchuan Yang, Simon Mahns, Sida Li, Anri Gu, Jibang Wu, Haifeng Xu", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)", "abstract": "Forecasting is not only a fundamental intellectual pursuit but also is of significant importance to societal systems such as finance and economics. With the rapid advances of large language models (LLMs) trained on Internet-scale data, it raises the promise of employing LLMs to forecast real-world future events, an emerging paradigm we call \"LLM-as-a-Prophet\". This paper systematically investigates such predictive intelligence of LLMs. To this end, we build Prophet Arena, a general evaluation benchmark that continuously collects live forecasting tasks and decomposes each task into distinct pipeline stages, in order to support our controlled and large-scale experimentation. Our comprehensive evaluation reveals that many LLMs already exhibit impressive forecasting capabilities, reflected in, e.g., their small calibration errors, consistent prediction confidence and promising market returns. However, we also uncover key bottlenecks towards achieving superior predictive intelligence via LLM-as-a-Prophet, such as LLMs' inaccurate event recalls, misunderstanding of data sources and slower information aggregation compared to markets when resolution nears."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          On the Universality of Round Elimination Fixed Points", "authors": "Alkida Balliu, Sebastian Brandt, Ole Gabsdil, Dennis Olivetti, Jukka Suomela", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC)", "abstract": "Recent work on distributed graph algorithms [e.g. STOC 2022, ITCS 2022, PODC 2020] has drawn attention to the following open question: are round elimination fixed points a universal technique for proving lower bounds? That is, given a locally checkable problem $\\Pi$ that requires at least $\\Omega(\\log n)$ rounds in the deterministic LOCAL model, can we always find a relaxation $\\Pi'$ of $\\Pi$ that is a nontrivial fixed point for the round elimination technique [see STOC 2016, PODC 2019]? If yes, then a key part of distributed computational complexity would be also decidable. The key obstacle so far has been a certain family of homomorphism problems [ITCS 2022], which require $\\Omega(\\log n)$ rounds, but the only known proof is based on Marks' technique [this http URL 2016]. We develop a new technique for constructing round elimination lower bounds systematically. Using so-called tripotent inputs we show that the aforementioned homomorphism problems indeed admit a lower bound proof that is based on round elimination fixed points. Hence we eliminate the only known obstacle for the universality of round elimination. Yet we also present a new obstacle: we show that there are some problems with inputs that require $\\Omega(\\log n)$ rounds, yet there is no proof that is based on relaxations to nontrivial round elimination fixed points. Hence round elimination cannot be a universal technique for problems with inputs (but it might be universal for problems without inputs). We also prove the first fully general lower bound theorem that is applicable to any problem, with or without inputs, that is a fixed point in round elimination. Prior results of this form were only able to handle certain very restricted inputs."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          RESample: A Robust Data Augmentation Framework via Exploratory Sampling for Robotic Manipulation", "authors": "Yuquan Xue, Guanxing Lu, Zhenyu Wu, Chuanrui Zhang, Bofang Jia, Zhengyi Gu, Yansong Tang, Ziwei Wang", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "abstract": "Vision-Language-Action models (VLAs) have demonstrated remarkable performance on complex robotic manipulation tasks through imitation learning. However, existing imitation learning datasets contain only successful trajectories and lack failure or recovery data, especially for out-of-distribution (OOD) states where the robot deviates from the main policy due to minor perturbations or errors, leading VLA models to struggle with states deviating from the training distribution. To this end, we propose an automated OOD data augmentation framework named RESample through exploratory sampling. Specifically, we first leverage offline reinforcement learning to obtain an action-value network that accurately identifies sub-optimal actions under the current manipulation policy. We further sample potential OOD states from trajectories via rollout, and design an exploratory sampling mechanism that adaptively incorporates these action proxies into the training dataset to ensure efficiency. Subsequently, our framework explicitly encourages the VLAs to recover from OOD states and enhances their robustness against distributional shifts. We conduct extensive experiments on the LIBERO benchmark as well as real-world robotic manipulation tasks, demonstrating that RESample consistently improves the stability and generalization ability of VLA models."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Self-supervised Pre-training for Mapping of Archaeological Stone Wall in Historic Landscapes Using High-Resolution DEM Derivatives", "authors": "Zexian Huang, Mashnoon Islam, Brian Armstrong, Kourosh Khoshelham, Martin Tomko", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Dry-stone walls hold significant heritage and environmental value. Mapping these structures is essential for ecosystem preservation and wildfire management in Australia. Yet, many walls remain unidentified due to their inaccessibility and the high cost of manual mapping. Deep learning-based segmentation offers a scalable solution, but two major challenges persist: (1) visual occlusion of low-lying walls by dense vegetation, and (2) limited labeled data for supervised training. We propose DINO-CV, a segmentation framework for automatic mapping of low-lying dry-stone walls using high-resolution Airborne LiDAR-derived digital elevation models (DEMs). DEMs overcome visual occlusion by capturing terrain structures hidden beneath vegetation, enabling analysis of structural rather than spectral cues. DINO-CV introduces a self-supervised cross-view pre-training strategy based on knowledge distillation to mitigate data scarcity. It learns invariant visual and geometric representations across multiple DEM derivatives, supporting various vision backbones including ResNet, Wide ResNet, and Vision Transformers. Applied to the UNESCO World Heritage cultural landscape of Budj Bim, Victoria, the method identifies one of Australia's densest collections of colonial dry-stone walls beyond Indigenous heritage contexts. DINO-CV achieves a mean Intersection over Union (mIoU) of 68.6% on test areas and maintains 63.8% mIoU when fine-tuned with only 10% labeled data. These results demonstrate the potential of self-supervised learning on high-resolution DEM derivatives for automated dry-stone wall mapping in vegetated and heritage-rich environments with scarce annotations."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Near-Optimal Property Testers for Pattern Matching", "authors": "Ce Jin, Tomasz Kociumaka", "subjects": "Data Structures and Algorithms (cs.DS)", "abstract": "The classic exact pattern matching problem, given two strings -- a pattern $P$ of length $m$ and a text $T$ of length $n$ -- asks whether $P$ occurs as a substring of $T$. A property tester for the problem needs to distinguish (with high probability) the following two cases for some threshold $k$: the YES case, where $P$ occurs as a substring of $T$, and the NO case, where $P$ has Hamming distance greater than $k$ from every substring of $T$, that is, $P$ has no $k$-mismatch occurrence in $T$. In this work, we provide adaptive and non-adaptive property testers for the exact pattern matching problem, jointly covering the whole spectrum of parameters. We further establish unconditional lower bounds demonstrating that the time and query complexities of our algorithms are optimal, up to $\\mathrm{polylog}\\, n$ factors hidden within the $\\tilde O(\\cdot)$ notation below. In the most studied regime of $n=m+\\Theta(m)$, our non-adaptive property tester has the time complexity of $\\tilde O(n/\\sqrt{k})$, and a matching lower bound remains valid for the query complexity of adaptive algorithms. This improves both upon a folklore solution that attains the optimal query complexity but requires $\\Omega(n)$ time, and upon the only previously known sublinear-time property tester, by Chan, Golan, Kociumaka, Kopelowitz, and Porat [STOC 2020], with time complexity $\\tilde O(n/\\sqrt[3]{k})$. The aforementioned results remain valid for $n=m+\\Omega(m)$, where our optimal running time $\\tilde O(\\sqrt{nm/k}+n/k)$ improves upon the previously best time complexity of $\\tilde O(\\sqrt[3]{n^2m/k}+n/k)$. In the regime of $n=m+o(m)$, which has not been targeted in any previous work, we establish a surprising separation between adaptive and non-adaptive algorithms, whose optimal time and query complexities are $\\tilde O(\\sqrt{(n-m+1)m/k}+n/k)$ and $\\tilde O(\\min(n\\sqrt{n-m+1}/k,\\sqrt{nm/k}+n/k))$, respectively."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Pointing-Error-Induced Fading in an Open-Loop THz Uplink with Hardware Impairments", "authors": "P. Brach del Prever, P. Testolina, A. Masihi, S. Petrushkevich, M. Polese, T. Melodia, J. M. Jornet", "subjects": "Networking and Internet Architecture (cs.NI)", "abstract": "We analyze the open-loop mechanical tracking performance of a sub-Terahertz (sub-THz) and Terahertz (THz) uplink communication system. These high-frequency bands enable multi-gigabit links through large bandwidths and narrow beams, but require precise pointing to overcome spreading loss. A tracking system can be used to orient horn antennas toward mobile targets. We develop a mathematical model that captures the mechanical dynamics of a real tracking system, which includes motion latency and acceleration and velocity limits, to quantify pointing errors during satellite passes and integrate these effects into the link budget. We evaluate the trade-offs between beam directionality and pointing tolerance across different Low Earth Orbit (LEO) satellite trajectories and control strategies. The results link the hardware limitations to the communications performance, providing design guidelines for high-frequency Non-Terrestrial Network (NTN) uplink under practical mechanical constraints."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          ZACH-ViT: A Zero-Token Vision Transformer with ShuffleStrides Data Augmentation for Robust Lung Ultrasound Classification", "authors": "Athanasios Angelakis, Amne Mousa, Micah L. A. Heldeweg, Laurens A. Biesheuvel, Mark A. Haaksma, Jasper M. Smit, Pieter R. Tuinman, Paul W. G. Elbers", "subjects": "Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Differentiating cardiogenic pulmonary oedema (CPE) from non-cardiogenic and structurally normal lungs in lung ultrasound (LUS) videos remains challenging due to the high visual variability of non-cardiogenic inflammatory patterns (NCIP/ARDS-like), interstitial lung disease, and healthy lungs. This heterogeneity complicates automated classification as overlapping B-lines and pleural artefacts are common. We introduce ZACH-ViT (Zero-token Adaptive Compact Hierarchical Vision Transformer), a 0.25 M-parameter Vision Transformer variant that removes both positional embeddings and the [CLS] token, making it fully permutation-invariant and suitable for unordered medical image data. To enhance generalization, we propose ShuffleStrides Data Augmentation (SSDA), which permutes probe-view sequences and frame orders while preserving anatomical validity. ZACH-ViT was evaluated on 380 LUS videos from 95 critically ill patients against nine state-of-the-art baselines. Despite the heterogeneity of the non-cardiogenic group, ZACH-ViT achieved the highest validation and test ROC-AUC (0.80 and 0.79) with balanced sensitivity (0.60) and specificity (0.91), while all competing models collapsed to trivial classification. It trains 1.35x faster than Minimal ViT (0.62M parameters) with 2.5x fewer parameters, supporting real-time clinical deployment. These results show that aligning architectural design with data structure can outperform scale in small-data medical imaging."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Frugal Federated Learning for Violence Detection: A Comparison of LoRA-Tuned VLMs and Personalized CNNs", "authors": "S\u00e9bastien Thuau, Siba Haidar, Ayush Bajracharya, Rachid Chelouah", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "abstract": "We examine frugal federated learning approaches to violence detection by comparing two complementary strategies: (i) zero-shot and federated fine-tuning of vision-language models (VLMs), and (ii) personalized training of a compact 3D convolutional neural network (CNN3D). Using LLaVA-7B and a 65.8M parameter CNN3D as representative cases, we evaluate accuracy, calibration, and energy usage under realistic non-IID settings. Both approaches exceed 90% accuracy. CNN3D slightly outperforms Low-Rank Adaptation(LoRA)-tuned VLMs in ROC AUC and log loss, while using less energy. VLMs remain favorable for contextual reasoning and multimodal inference. We quantify energy and CO$_2$ emissions across training and inference, and analyze sustainability trade-offs for deployment. To our knowledge, this is the first comparative study of LoRA-tuned vision-language models and personalized CNNs for federated violence detection, with an emphasis on energy efficiency and environmental metrics. These findings support a hybrid model: lightweight CNNs for routine classification, with selective VLM activation for complex or descriptive scenarios. The resulting framework offers a reproducible baseline for responsible, resource-aware AI in video surveillance, with extensions toward real-time, multimodal, and lifecycle-aware systems."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Qomhra: A Bilingual Irish-English Large Language Model", "authors": "Joseph McInerney", "subjects": "Computation and Language (cs.CL)", "abstract": "This paper introduces Qomhr\u00e1, a bilingual Irish-English large language model (LLM), developed under low-resource constraints presenting a complete pipeline spanning bilingual continued pre-training, instruction tuning, and alignment from human preferences. Newly accessible Irish corpora and English text are mixed and curated to improve Irish performance while preserving English ability. 6 closed-weight LLMs are judged for their Irish text generation by a native speaker, a learner and other LLMs. Google's Gemini-2.5-Pro is ranked the highest and is subsequently used to synthesise instruction tuning and human preference datasets. Two datasets are contributed leveraging Gemini-2.5-Pro: a 30K Irish-English parallel instruction tuning dataset and a 1K human preference dataset, generating accepted and rejected responses that show near perfect alignment with a native Irish speaker. Qomhr\u00e1 is comprehensively evaluated across benchmarks testing translation, gender understanding, topic identification and world knowledge with gains of up to 29% in Irish and 44% in English. Qomhr\u00e1 also undergoes instruction tuning and demonstrates clear progress in instruction following, crucial for chatbot functionality."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          PDE-Free Mass-Constrained Learning of Complex Systems with Hidden States: The crowd dynamics case", "authors": "Gianmaria Viola, Alessandro Della Pia, Lucia Russo, Ioannis Kevrekidis, Constantinos Siettos", "subjects": "Numerical Analysis (math.NA); Fluid Dynamics (physics.flu-dyn)", "abstract": "We introduce a machine learning framework for modeling the spatio-temporal dynamics of mass-constrained complex systems with hidden states, whose behavior can, in principle, be described by PDEs but lack explicit models. The method extends the Equation-Free approach, enabling the data-driven reconstruction of reduced-order models (ROMs) without needing to identify governing equations. Using manifold learning, we obtain a latent space representation of system evolution from data via delayed coordinates, in accordance with Takens/Whitney's embedding theorems. Linear (Proper Orthogonal Decomposition, POD) and nonlinear (Diffusion Maps, DMs) methods are employed to extract low-dimensional embeddings that capture the essential dynamics. Predictive ROMs are then learned within this latent space, and their evolution is lifted back to the original high-dimensional space by solving a pre-image problem. We show that both POD and k-nearest neighbor (k-NN) lifting operators preserve mass, a key physical constraint in systems such as computational fluid dynamics and crowd dynamics. Our framework effectively reconstructs the solution operator of the underlying PDE without discovering the PDE itself, by leveraging a manifold-informed objective map that bridges multiple scales. For our illustrations, we use synthetic spatio-temporal data from the Hughes model, which couples a continuity PDE with an Eikonal equation describing optimal path selection in crowds. Results show that DM-based nonlinear embeddings outperform POD in reconstruction accuracy, producing more parsimonious and stable ROMs that remain accurate and integrable over long time horizons."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Muscle Anatomy-aware Geometric Deep Learning for sEMG-based Gesture Decoding", "authors": "Adyasha Dash, Giulia Zappoli, Laya Das, Robert Riener", "subjects": "Human-Computer Interaction (cs.HC)", "abstract": "Robust and accurate decoding of gesture from non-invasive surface electromyography (sEMG) is important for various applications including spatial computing, healthcare, and entertainment, and has been actively pursued by researchers and industry. Majority of sEMG-based gesture decoding algorithms employ deep neural networks that are designed for Euclidean data, and may not be suitable for analyzing multi-dimensional, non-stationary time-series with long-range dependencies such as sEMG. State-of-the-art sEMG-based decoding methods also demonstrate high variability across subjects and sessions, requiring re-calibration and adaptive fine-tuning to boost performance. To address these shortcomings, this work proposes a geometric deep learning model that learns on symmetric positive definite (SPD) manifolds and leverages unsupervised domain adaptation to desensitize the model to subjects and sessions. The model captures the features in time and across sensors with multiple kernels, projects the features onto SPD manifold, learns on manifolds and projects back to Euclidean space for classification. It uses a domain-specific batch normalization layer to address variability between sessions, alleviating the need for re-calibration or fine-tuning. Experiments with publicly available benchmark gesture decoding datasets (Ninapro DB6, Flexwear-HD) demonstrate the superior generalizability of the model compared to Euclidean and other SPD-based models in the inter-session scenario, with up to 8.83 and 4.63 points improvement in accuracy, respectively. Detailed analyses reveal that the model extracts muscle-specific information for different tasks and ablation studies highlight the importance of modules introduced in the work. The proposed method pushes the state-of-the-art in sEMG-based gesture recognition and opens new research avenues for manifold-based learning for muscle signals."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Handling Extreme Class Imbalance: Using GANs in Data Augmentation for Suicide Prediction", "authors": "Vaishnavi Visweswaraiah, Tanvi Banerjee, William Romine", "subjects": "Machine Learning (cs.LG)", "abstract": "Suicide prediction is the key for prevention, but real data with sufficient positive samples is rare and causes extreme class imbalance. We utilized machine learning (ML) to build the model and deep learning (DL) techniques, like Generative Adversarial Networks (GAN), to generate synthetic data samples to enhance the dataset. The initial dataset contained 656 samples, with only four positive cases, prompting the need for data augmentation. A variety of machine learning models, ranging from interpretable data models to black box algorithmic models, were used. On real test data, Logistic Regression (LR) achieved a weighted precision of 0.99, a weighted recall of 0.85, and a weighted F1 score of 0.91; Random Forest (RF) showed 0.98, 0.99, and 0.99, respectively; and Support Vector Machine (SVM) achieved 0.99, 0.76, and 0.86. LR and SVM correctly identified one suicide attempt case (sensitivity:1.0) and misclassified LR(20) and SVM (31) non-attempts as attempts (specificity: 0.85 & 0.76, respectively). RF identified 0 suicide attempt cases (sensitivity: 0.0) with 0 false positives (specificity: 1.0). These results highlight the models' effectiveness, with GAN playing a key role in generating synthetic data to support suicide prevention modeling efforts."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          DELULU: Discriminative Embedding Learning Using Latent Units for Speaker-Aware Self-Supervised Speech Foundational Model", "authors": "Massa Baali, Rita Singh, Bhiksha Raj", "subjects": "Sound (cs.SD); Computation and Language (cs.CL)", "abstract": "Self-supervised speech models have achieved remarkable success on content-driven tasks, yet they remain limited in capturing speaker-discriminative features critical for verification, diarization, and profiling applications. We introduce DELULU, a speaker-aware self-supervised foundational model that addresses this limitation by integrating external supervision into the pseudo-label generation process. DELULU leverages frame-level embeddings from ReDimNet, a state-of-the-art speaker verification model, to guide the k-means clustering step during pre-training, introducing a strong speaker-discriminative inductive bias that aligns representation learning with speaker identity. The model is trained using a dual objective that combines masked prediction and denoising, further enhancing robustness and generalization. DELULU significantly outperforms prior self-supervised learning (SSL) models across a range of speaker-centric tasks, achieving up to 62% relative improvement in equal error rate (EER) for speaker verification and consistent gains on zero-shot profiling tasks such as gender, age, accent, and speaker counting. Our findings demonstrate that DELULU is a strong universal encoder for speaker-aware speech processing, enabling superior performance even without task-specific fine-tuning."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          4DSegStreamer: Streaming 4D Panoptic Segmentation via Dual Threads", "authors": "Ling Liu, Jun Tian, Li Yi", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "4D panoptic segmentation in a streaming setting is critical for highly dynamic environments, such as evacuating dense crowds and autonomous driving in complex scenarios, where real-time, fine-grained perception within a constrained time budget is essential. In this paper, we introduce 4DSegStreamer, a novel framework that employs a Dual-Thread System to efficiently process streaming frames. The framework is general and can be seamlessly integrated into existing 3D and 4D segmentation methods to enable real-time capability. It also demonstrates superior robustness compared to existing streaming perception approaches, particularly under high FPS conditions. The system consists of a predictive thread and an inference thread. The predictive thread leverages historical motion and geometric information to extract features and forecast future dynamics. The inference thread ensures timely prediction for incoming frames by aligning with the latest memory and compensating for ego-motion and dynamic object movements. We evaluate 4DSegStreamer on the indoor HOI4D dataset and the outdoor SemanticKITTI and nuScenes datasets. Comprehensive experiments demonstrate the effectiveness of our approach, particularly in accurately predicting dynamic objects in complex scenes."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Efficient recognition algorithms for $(1,2)$-, $(2,1)$- and $(2,2)$-graphs", "authors": "Flavia Bonomo-Braberman, Min Chih Lin, Ignacio Maqueda", "subjects": "Discrete Mathematics (cs.DM)", "abstract": "A graph $G$ is said to be a $(k,\\ell)$-graph if its vertex set can be partitioned into $k$ independent sets and $\\ell$ cliques. It is well established that the recognition problem for $(k,\\ell)$-graphs is NP-complete whenever $k \\geq 3$ or $\\ell \\geq 3$, while it is solvable in polynomial time otherwise. In particular, for the case $k+\\ell \\leq 2$, recognition can be carried out in linear time, since split graphs coincide with the class of $(1,1)$-graphs, bipartite graphs correspond precisely to $(2,0)$-graphs, and $(\\ell,k)$-graphs are the complements of $(k,\\ell)$-graphs. Recognition algorithms for $(2,1)$- and $(1,2)$-graphs were provided by Brandst\u00e4dt, Le and Szymczak in 1998, while the case of $(2,2)$-graphs was addressed by Feder, Hell, Klein, and Motwani in 1999. In this work, we refine these results by presenting improved recognition algorithms with lower time complexity. Specifically, we reduce the running time from $O((n+m)^2)$ to $O(n^2+nm)$ for $(2,1)$-graphs, from $O((n+\\overline{m})^2)$ to $O(n^2+n\\overline{m})$ for $(1,2)$-graphs, and from $O(n^{10}(n+m))$ to $O(n^4 (n+\\min\\{m,\\overline{m}\\})^3)$ for $(2,2)$-graphs. Here, $n$ and $m$ denote the number of vertices and edges of the input graph $G$, respectively, and $\\overline{m}$ denotes the number of edges in the complement of $G$."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          On-the-Fly OVD Adaptation with FLAME: Few-shot Localization via Active Marginal-Samples Exploration", "authors": "Yehonathan Refael, Amit Aides, Aviad Barzilai, George Leifman, Genady Beryozkin, Vered Silverman, Bolous Jaber, Tomer Shekel", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)", "abstract": "Open-vocabulary object detection (OVD) models offer remarkable flexibility by detecting objects from arbitrary text queries. However, their zero-shot performance in specialized domains like Remote Sensing (RS) is often compromised by the inherent ambiguity of natural language, limiting critical downstream applications. For instance, an OVD model may struggle to distinguish between fine-grained classes such as \"fishing boat\" and \"yacht\" since their embeddings are similar and often inseparable. This can hamper specific user goals, such as monitoring illegal fishing, by producing irrelevant detections. To address this, we propose a cascaded approach that couples the broad generalization of a large pre-trained OVD model with a lightweight few-shot classifier. Our method first employs the zero-shot model to generate high-recall object proposals. These proposals are then refined for high precision by a compact classifier trained in real-time on only a handful of user-annotated examples - drastically reducing the high costs of RS imagery this http URL core of our framework is FLAME, a one-step active learning strategy that selects the most informative samples for training. FLAME identifies, on the fly, uncertain marginal candidates near the decision boundary using density estimation, followed by clustering to ensure sample diversity. This efficient sampling technique achieves high accuracy without costly full-model fine-tuning and enables instant adaptation, within less then a minute, which is significantly faster than state-of-the-art this http URL method consistently surpasses state-of-the-art performance on RS benchmarks, establishing a practical and resource-efficient framework for adapting foundation models to specific user needs."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          LILO: Bayesian Optimization with Interactive Natural Language Feedback", "authors": "Katarzyna Kobalczyk, Zhiyuan Jerry Lin, Benjamin Letham, Zhuokai Zhao, Maximilian Balandat, Eytan Bakshy", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "abstract": "For many real-world applications, feedback is essential in translating complex, nuanced, or subjective goals into quantifiable optimization objectives. We propose a language-in-the-loop framework that uses a large language model (LLM) to convert unstructured feedback in the form of natural language into scalar utilities to conduct BO over a numeric search space. Unlike preferential BO, which only accepts restricted feedback formats and requires customized models for each domain-specific problem, our approach leverages LLMs to turn varied types of textual feedback into consistent utility signals and to easily include flexible user priors without manual kernel design. At the same time, our method maintains the sample efficiency and principled uncertainty quantification of BO. We show that this hybrid method not only provides a more natural interface to the decision maker but also outperforms conventional BO baselines and LLM-only optimizers, particularly in feedback-limited regimes."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          A decoupled meshless Nystr\u00f6m scheme for 2D Fredholm integral equations of the second kind with smooth kernels", "authors": "Bruno Degli Esposti, Alessandra Sestini", "subjects": "Numerical Analysis (math.NA)", "abstract": "The Nystr\u00f6m method for the numerical solution of Fredholm integral equations of the second kind is generalized by decoupling the set of solution nodes from the set of quadrature nodes. The accuracy and efficiency of the new method is investigated for smooth kernels and complex 2D domains using recently developed moment-free meshless quadrature formulas on scattered nodes. Compared to the classical Nystr\u00f6m method, our variant has a clear performance advantage, especially for narrow kernels. The decoupled Nystr\u00f6m method requires the choice of a reconstruction scheme to approximate values at quadrature nodes from values at solution nodes. We prove that, under natural assumptions, the overall order of convergence is the minimum between that of the quadrature scheme and of the reconstruction scheme."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          PICABench: How Far Are We from Physically Realistic Image Editing?", "authors": "Yuandong Pu, Le Zhuo, Songhao Han, Jinbo Xing, Kaiwen Zhu, Shuo Cao, Bin Fu, Si Liu, Hongsheng Li, Yu Qiao, Wenlong Zhang, Xi Chen, Yihao Liu", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "abstract": "Image editing has achieved remarkable progress recently. Modern editing models could already follow complex instructions to manipulate the original content. However, beyond completing the editing instructions, the accompanying physical effects are the key to the generation realism. For example, removing an object should also remove its shadow, reflections, and interactions with nearby objects. Unfortunately, existing models and benchmarks mainly focus on instruction completion but overlook these physical effects. So, at this moment, how far are we from physically realistic image editing? To answer this, we introduce PICABench, which systematically evaluates physical realism across eight sub-dimension (spanning optics, mechanics, and state transitions) for most of the common editing operations (add, remove, attribute change, etc). We further propose the PICAEval, a reliable evaluation protocol that uses VLM-as-a-judge with per-case, region-level human annotations and questions. Beyond benchmarking, we also explore effective solutions by learning physics from videos and construct a training dataset PICA-100K. After evaluating most of the mainstream models, we observe that physical realism remains a challenging problem with large rooms to explore. We hope that our benchmark and proposed solutions can serve as a foundation for future work moving from naive content editing toward physically consistent realism."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Intelligent Communication Mixture-of-Experts Boosted-Medical Image Segmentation Foundation Model", "authors": "Xinwei Zhang, Hu Chen, Zhe Yuan, Sukun Tian, Peng Feng", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "abstract": "Foundation models for medical image segmentation have achieved remarkable performance. Adaptive fine-tuning of natural image segmentation foundation models is crucial for medical image segmentation tasks. However, some limitations exist in existing fine-tuning methods: 1) insufficient representation of high-level features and 2) the fine-tuning process disrupts the structural integrity of pretrained weights. Inspired by these critical problems, we propose an intelligent communication mixture-of-experts boosted-medical image segmentation foundation model, named IC-MoE, with twofold ideas: 1) We construct basic experts, semantic experts, and adaptive experts. Moreover, we implement a pixel probability adaptive voting strategy, which enables expert selection and fusion through label consistency and load balancing. This approach preliminarily enhances the representation capability of high-level features while preserving the structural integrity of pretrained weights. 2) We propose a semantic-guided contrastive learning method to address the issue of weak supervision in contrastive learning. This method further enhances the representation capability of high-level features while preserving the structural integrity of pretrained weights. Extensive experiments across three public medical image segmentation datasets demonstrate that the IC-MoE outperforms other SOTA models. Consequently, the proposed IC-MoE effectively supplements foundational medical image segmentation models with high-level features and pretrained structural integrity. We also validate the superior generalizability of the IC-MoE across diverse medical image segmentation scenarios."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Multilingual Text-to-Image Person Retrieval via Bidirectional Relation Reasoning and Aligning", "authors": "Min Cao, Xinyu Zhou, Ding Jiang, Bo Du, Mang Ye, Min Zhang", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "abstract": "Text-to-image person retrieval (TIPR) aims to identify the target person using textual descriptions, facing challenge in modality heterogeneity. Prior works have attempted to address it by developing cross-modal global or local alignment strategies. However, global methods typically overlook fine-grained cross-modal differences, whereas local methods require prior information to explore explicit part alignments. Additionally, current methods are English-centric, restricting their application in multilingual contexts. To alleviate these issues, we pioneer a multilingual TIPR task by developing a multilingual TIPR benchmark, for which we leverage large language models for initial translations and refine them by integrating domain-specific knowledge. Correspondingly, we propose Bi-IRRA: a Bidirectional Implicit Relation Reasoning and Aligning framework to learn alignment across languages and modalities. Within Bi-IRRA, a bidirectional implicit relation reasoning module enables bidirectional prediction of masked image and text, implicitly enhancing the modeling of local relations across languages and modalities, a multi-dimensional global alignment module is integrated to bridge the modality heterogeneity. The proposed method achieves new state-of-the-art results on all multilingual TIPR datasets. Data and code are presented in this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Towards 3D Objectness Learning in an Open World", "authors": "Taichi Liu, Zhenyu Wang, Ruofeng Liu, Guang Wang, Desheng Zhang", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Recent advancements in 3D object detection and novel category detection have made significant progress, yet research on learning generalized 3D objectness remains insufficient. In this paper, we delve into learning open-world 3D objectness, which focuses on detecting all objects in a 3D scene, including novel objects unseen during training. Traditional closed-set 3D detectors struggle to generalize to open-world scenarios, while directly incorporating 3D open-vocabulary models for open-world ability struggles with vocabulary expansion and semantic overlap. To achieve generalized 3D object discovery, We propose OP3Det, a class-agnostic Open-World Prompt-free 3D Detector to detect any objects within 3D scenes without relying on hand-crafted text prompts. We introduce the strong generalization and zero-shot capabilities of 2D foundation models, utilizing both 2D semantic priors and 3D geometric priors for class-agnostic proposals to broaden 3D object discovery. Then, by integrating complementary information from point cloud and RGB image in the cross-modal mixture of experts, OP3Det dynamically routes uni-modal and multi-modal features to learn generalized 3D objectness. Extensive experiments demonstrate the extraordinary performance of OP3Det, which significantly surpasses existing open-world 3D detectors by up to 16.0% in AR and achieves a 13.5% improvement compared to closed-world 3D detectors."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          CrossGuard: Safeguarding MLLMs against Joint-Modal Implicit Malicious Attacks", "authors": "Xu Zhang, Hao Li, Zhichao Lu", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "abstract": "Multimodal Large Language Models (MLLMs) achieve strong reasoning and perception capabilities but are increasingly vulnerable to jailbreak attacks. While existing work focuses on explicit attacks, where malicious content resides in a single modality, recent studies reveal implicit attacks, in which benign text and image inputs jointly express unsafe intent. Such joint-modal threats are difficult to detect and remain underexplored, largely due to the scarcity of high-quality implicit data. We propose ImpForge, an automated red-teaming pipeline that leverages reinforcement learning with tailored reward modules to generate diverse implicit samples across 14 domains. Building on this dataset, we further develop CrossGuard, an intent-aware safeguard providing robust and comprehensive defense against both explicit and implicit threats. Extensive experiments across safe and unsafe benchmarks, implicit and explicit attacks, and multiple out-of-domain settings demonstrate that CrossGuard significantly outperforms existing defenses, including advanced MLLMs and guardrails, achieving stronger security while maintaining high utility. This offers a balanced and practical solution for enhancing MLLM robustness against real-world multimodal threats."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Quantum Synthetic Data Generation for Industrial Bioprocess Monitoring", "authors": "Shawn M. Gibford, Mohammad Reza Boskabadi, Christopher J. Savoie, Seyed Soheil Mansouri", "subjects": "Emerging Technologies (cs.ET); Machine Learning (cs.LG)", "abstract": "Data scarcity and sparsity in bio-manufacturing poses challenges for accurate model development, process monitoring, and optimization. We aim to replicate and capture the complex dynamics of industrial bioprocesses by proposing the use of a Quantum Wasserstein Generative Adversarial Network with Gradient Penalty (QWGAN-GP) to generate synthetic time series data for industrially relevant processes. The generator within our GAN is comprised of a Parameterized Quantum Circuit (PQC). This methodology offers potential advantages in process monitoring, modeling, forecasting, and optimization, enabling more efficient bioprocess management by reducing the dependence on scarce experimental data. Our results demonstrate acceptable performance in capturing the temporal dynamics of real bioprocess data. We focus on Optical Density, a key measurement for Dry Biomass estimation. The data generated showed high fidelity to the actual historical experimental data. This intersection of quantum computing and machine learning has opened new frontiers in data analysis and generation, particularly in computationally intensive fields, for use cases such as increasing prediction accuracy for soft sensor design or for use in predictive control."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Efficient Algorithms for Mitigating Uncertainty and Risk in Reinforcement Learning", "authors": "Xihong Su", "subjects": "Machine Learning (cs.LG)", "abstract": "This dissertation makes three main contributions. First, We identify a new connection between policy gradient and dynamic programming in MMDPs and propose the Coordinate Ascent Dynamic Programming (CADP) algorithm to compute a Markov policy that maximizes the discounted return averaged over the uncertain models. CADP adjusts model weights iteratively to guarantee monotone policy improvements to a local maximum. Second, We establish sufficient and necessary conditions for the exponential ERM Bellman operator to be a contraction and prove the existence of stationary deterministic optimal policies for ERM-TRC and EVaR-TRC. We also propose exponential value iteration, policy iteration, and linear programming algorithms for computing optimal stationary policies for ERM-TRC and EVaR-TRC. Third, We propose model-free Q-learning algorithms for computing policies with risk-averse objectives: ERM-TRC and EVaR-TRC. The challenge is that Q-learning ERM Bellman may not be a contraction. Instead, we use the monotonicity of Q-learning ERM Bellman operators to derive a rigorous proof that the ERM-TRC and the EVaR-TRC Q-learning algorithms converge to the optimal risk-averse value functions. The proposed Q-learning algorithms compute the optimal stationary policy for ERM-TRC and EVaR-TRC."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          A Mimamsa Inspired Framework For Instruction Sequencing In AI Agents", "authors": "Bama Srinivasan", "subjects": "Logic in Computer Science (cs.LO)", "abstract": "This paper presents a formal framework for sequencing instructions in AI agents, inspired by the Indian philosophical system of Mimamsa. The framework formalizes sequencing mechanisms through action object pairs in three distinct ways: direct assertion (Srutikrama) for temporal precedence, purpose driven sequencing (Arthakrama) for functional dependencies, and iterative procedures (Pravrittikrama) for distinguishing between parallel and sequential execution in repetitive tasks. It introduces the syntax and semantics of an action object imperative logic, extending the MIRA formalism (Srinivasan and Parthasarathi, 2021) with explicit deduction rules for sequencing. The correctness of instruction sequencing is established through a validated theorem, which is based on object dependencies across successive instructions. This is further supported by proofs of soundness and completeness. This formal verification enables reliable instruction sequencing, impacting AI applications across areas like task planning and robotics by addressing temporal reasoning and dependency modeling."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          A Principle of Targeted Intervention for Multi-Agent Reinforcement Learning", "authors": "Anjie Liu, Jianhong Wang, Samuel Kaski, Jun Wang, Mengyue Yang", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multiagent Systems (cs.MA)", "abstract": "Steering cooperative multi-agent reinforcement learning (MARL) towards desired outcomes is challenging, particularly when the global guidance from a human on the whole multi-agent system is impractical in a large-scale MARL. On the other hand, designing mechanisms to coordinate agents most relies on empirical studies, lacking a easy-to-use research tool. In this work, we employ multi-agent influence diagrams (MAIDs) as a graphical framework to address the above issues. First, we introduce interaction paradigms that leverage MAIDs to analyze and visualize existing approaches in MARL. Then, we design a new interaction paradigm based on MAIDs, referred to as targeted intervention that is applied to only a single targeted agent, so the problem of global guidance can be mitigated. In our implementation, we introduce a causal inference technique-referred to as Pre-Strategy Intervention (PSI)-to realize the targeted intervention paradigm. Since MAIDs can be regarded as a special class of causal diagrams, a composite desired outcome that integrates the primary task goal and an additional desired outcome can be achieved by maximizing the corresponding causal effect through the PSI. Moreover, the bundled relevance graph analysis of MAIDs provides a tool to identify whether an MARL learning paradigm is workable under the design of an interaction paradigm. In experiments, we demonstrate the effectiveness of our proposed targeted intervention, and verify the result of relevance graph analysis."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Towards Mining Effective Pedagogical Strategies from Learner-LLM Educational Dialogues", "authors": "Liqun He, Manolis Mavrikis, Mutlu Cukurova", "subjects": "Computation and Language (cs.CL)", "abstract": "Dialogue plays a crucial role in educational settings, yet existing evaluation methods for educational applications of large language models (LLMs) primarily focus on technical performance or learning outcomes, often neglecting attention to learner-LLM interactions. To narrow this gap, this AIED Doctoral Consortium paper presents an ongoing study employing a dialogue analysis approach to identify effective pedagogical strategies from learner-LLM dialogues. The proposed approach involves dialogue data collection, dialogue act (DA) annotation, DA pattern mining, and predictive model building. Early insights are outlined as an initial step toward future research. The work underscores the need to evaluate LLM-based educational applications by focusing on dialogue dynamics and pedagogical strategies."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          GAS: Improving Discretization of Diffusion ODEs via Generalized Adversarial Solver", "authors": "Aleksandr Oganov, Ilya Bykov, Eva Neudachina, Mishan Aliev, Alexander Tolmachev, Alexander Sidorov, Aleksandr Zuev, Andrey Okhotin, Denis Rakitin, Aibek Alanov", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)", "abstract": "While diffusion models achieve state-of-the-art generation quality, they still suffer from computationally expensive sampling. Recent works address this issue with gradient-based optimization methods that distill a few-step ODE diffusion solver from the full sampling process, reducing the number of function evaluations from dozens to just a few. However, these approaches often rely on intricate training techniques and do not explicitly focus on preserving fine-grained details. In this paper, we introduce the Generalized Solver: a simple parameterization of the ODE sampler that does not require additional training tricks and improves quality over existing approaches. We further combine the original distillation loss with adversarial training, which mitigates artifacts and enhances detail fidelity. We call the resulting method the Generalized Adversarial Solver and demonstrate its superior performance compared to existing solver training methods under similar resource constraints. Code is available at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Elastic ViTs from Pretrained Models without Retraining", "authors": "Walter Simoncini, Michael Dorkenwald, Tijmen Blankevoort, Cees G.M. Snoek, Yuki M. Asano", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Vision foundation models achieve remarkable performance but are only available in a limited set of pre-determined sizes, forcing sub-optimal deployment choices under real-world constraints. We introduce SnapViT: Single-shot network approximation for pruned Vision Transformers, a new post-pretraining structured pruning method that enables elastic inference across a continuum of compute budgets. Our approach efficiently combines gradient information with cross-network structure correlations, approximated via an evolutionary algorithm, does not require labeled data, generalizes to models without a classification head, and is retraining-free. Experiments on DINO, SigLIPv2, DeIT, and AugReg models demonstrate superior performance over state-of-the-art methods across various sparsities, requiring less than five minutes on a single A100 GPU to generate elastic models that can be adjusted to any computational budget. Our key contributions include an efficient pruning strategy for pretrained Vision Transformers, a novel evolutionary approximation of Hessian off-diagonal structures, and a self-supervised importance scoring mechanism that maintains strong performance without requiring retraining or labels. Code and pruned models are available at: this https URL"}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Improving Cross-Patient Generalization in Parkinson's Disease Detection through Chunk-Based Analysis of Hand-Drawn Patterns", "authors": "Mhd Adnan Albani, Riad Sonbol", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "abstract": "Parkinson's disease (PD) is a neurodegenerative disease affecting about 1% of people over the age of 60, causing motor impairments that impede hand coordination activities such as writing and drawing. Many approaches have tried to support early detection of Parkinson's disease based on hand-drawn images; however, we identified two major limitations in the related works: (1) the lack of sufficient datasets, (2) the robustness when dealing with unseen patient data. In this paper, we propose a new approach to detect Parkinson's disease that consists of two stages: The first stage classifies based on their drawing type(circle, meander, spiral), and the second stage extracts the required features from the images and detects Parkinson's disease. We overcame the previous two limitations by applying a chunking strategy where we divide each image into 2x2 chunks. Each chunk is processed separately when extracting features and recognizing Parkinson's disease indicators. To make the final classification, an ensemble method is used to merge the decisions made from each chunk. Our evaluation shows that our proposed approach outperforms the top performing state-of-the-art approaches, in particular on unseen patients. On the NewHandPD dataset our approach, it achieved 97.08% accuracy for seen patients and 94.91% for unseen patients, our proposed approach maintained a gap of only 2.17 percentage points, compared to the 4.76-point drop observed in prior work."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Contextual Attention Modulation: Towards Efficient Multi-Task Adaptation in Large Language Models", "authors": "Dayan Pan, Zhaoyang Fu, Jingyuan Wang, Xiao Han, Yue Zhu, Xiangyu Zhao", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "abstract": "Large Language Models (LLMs) possess remarkable generalization capabilities but struggle with multi-task adaptation, particularly in balancing knowledge retention with task-specific specialization. Conventional fine-tuning methods suffer from catastrophic forgetting and substantial resource consumption, while existing parameter-efficient methods perform suboptimally in complex multi-task scenarios. To address this, we propose Contextual Attention Modulation (CAM), a novel mechanism that dynamically modulates the representations of self-attention modules in LLMs. CAM enhances task-specific features while preserving general knowledge, thereby facilitating more effective and efficient adaptation. For effective multi-task adaptation, CAM is integrated into our Hybrid Contextual Attention Modulation (HyCAM) framework, which combines a shared, full-parameter CAM module with multiple specialized, lightweight CAM modules, enhanced by a dynamic routing strategy for adaptive knowledge fusion. Extensive experiments on heterogeneous tasks, including question answering, code generation, and logical reasoning, demonstrate that our approach significantly outperforms existing approaches, achieving an average performance improvement of 3.65%. The implemented code and data are available to ease reproducibility at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Closing the Sim2Real Performance Gap in RL", "authors": "Akhil S Anand, Shambhuraj Sawant, Jasper Hoffmann, Dirk Reinhardt, Sebastien Gros", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "Sim2Real aims at training policies in high-fidelity simulation environments and effectively transferring them to the real world. Despite the developments of accurate simulators and Sim2Real RL approaches, the policies trained purely in simulation often suffer significant performance drops when deployed in real environments. This drop is referred to as the Sim2Real performance gap. Current Sim2Real RL methods optimize the simulator accuracy and variability as proxies for real-world performance. However, these metrics do not necessarily correlate with the real-world performance of the policy as established theoretically and empirically in the literature. We propose a novel framework to address this issue by directly adapting the simulator parameters based on real-world performance. We frame this problem as a bi-level RL framework: the inner-level RL trains a policy purely in simulation, and the outer-level RL adapts the simulation model and in-sim reward parameters to maximize real-world performance of the in-sim policy. We derive and validate in simple examples the mathematical tools needed to develop bi-level RL algorithms that close the Sim2Real performance gap."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Mensen aanwijzen maar niet bij naam noemen: behavioural targeting, persoonsgegevens, en de nieuwe Privacyverordening", "authors": "Frederik Zuiderveen Borgesius", "subjects": "Computers and Society (cs.CY)", "abstract": "Information about millions of people is collected for behavioural targeting, a type of marketing that involves tracking people's online behaviour for targeted advertising. It is hotly debated whether data protection law applies to behavioural targeting. Many behavioural targeting companies say that, as long as they do not tie names to data they hold about individuals, they do not process any personal data, and that, therefore, data protection law does not apply to them. European Data Protection Authorities, however, take the view that a company processes personal data if it uses data to single out a person, even if it cannot tie a name to these data. This paper argues that data protection law should indeed apply to behavioural targeting. Companies can often tie a name to nameless data about individuals. Furthermore, behavioural targeting relies on collecting information about individuals, singling out individuals, and targeting ads to individuals. Many privacy risks remain, regardless of whether companies tie a name to the information they hold about a person. A name is merely one of the identifiers that can be tied to data about a person, and it is not even the most practical identifier for behavioural targeting. Seeing data used to single out a person as personal data fits the rationale for data protection law: protecting fairness and privacy."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Discrimination, intelligence artificielle et decisions algorithmiques", "authors": "Frederik Zuiderveen Borgesius", "subjects": "Computers and Society (cs.CY)", "abstract": "Artificial intelligence (AI) has a huge impact on our personal lives and also on our democratic society as a whole. While AI offers vast opportunities for the benefit of people, its potential to embed and perpetuate bias and discrimination remains one of the most pressing challenges deriving from its increasing use. This new study, which was prepared by Prof. Frederik Zuiderveen Borgesius for the Anti-discrimination Department of the Council of Europe, elaborates on the risks of discrimination caused by algorithmic decision-making and other types of artificial intelligence (AI)."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Online Political Microtargeting: Promises and Threats for Democracy", "authors": "Frederik J. Zuiderveen Borgesius, Judith M\u00f6ller, Sanne Kruikemeier, Ronan \u00d3 Fathaigh, Kristina Irion, Tom Dobber, Balazs Bodo, Claes de Vreese", "subjects": "Computers and Society (cs.CY)", "abstract": "Online political microtargeting involves monitoring people's online behaviour, and using the collected data, sometimes enriched with other data, to show people-targeted political advertisements. Online political microtargeting is widely used in the US; Europe may not be far behind. This paper maps microtargeting's promises and threats to democracy. For example, microtargeting promises to optimise the match between the electorate's concerns and political campaigns, and to boost campaign engagement and political participation. But online microtargeting could also threaten democracy. For instance, a political party could, misleadingly, present itself as a different one-issue party to different individuals. And data collection for microtargeting raises privacy concerns. We sketch possibilities for policymakers if they seek to regulate online political microtargeting. We discuss which measures would be possible, while complying with the right to freedom of expression under the European Convention on Human Rights."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          The Marked Edge Walk: A Novel MCMC Algorithm for Sampling of Graph Partitions", "authors": "Atticus McWhorter, Daryl DeFord", "subjects": "Data Structures and Algorithms (cs.DS); Machine Learning (cs.LG); Physics and Society (physics.soc-ph)", "abstract": "Novel Markov Chain Monte Carlo (MCMC) methods have enabled the generation of large ensembles of redistricting plans through graph partitioning. However, existing algorithms such as Reversible Recombination (RevReCom) and Metropolized Forest Recombination (MFR) are constrained to sampling from distributions related to spanning trees. We introduce the marked edge walk (MEW), a novel MCMC algorithm for sampling from the space of graph partitions under a tunable distribution. The walk operates on the space of spanning trees with marked edges, allowing for calculable transition probabilities for use in the Metropolis-Hastings algorithm. Empirical results on real-world dual graphs show convergence under target distributions unrelated to spanning trees. For this reason, MEW represents an advancement in flexible ensemble generation."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          QueST: Incentivizing LLMs to Generate Difficult Problems", "authors": "Hanxu Hu, Xingxing Zhang, Jannis Vamvas, Rico Sennrich, Furu Wei", "subjects": "Computation and Language (cs.CL)", "abstract": "Large Language Models have achieved strong performance on reasoning tasks, solving competition-level coding and math problems. However, their scalability is limited by human-labeled datasets and the lack of large-scale, challenging coding problem training data. Existing competitive coding datasets contain only thousands to tens of thousands of problems. Previous synthetic data generation methods rely on either augmenting existing instruction datasets or selecting challenging problems from human-labeled data. In this paper, we propose QueST, a novel framework which combines difficulty-aware graph sampling and difficulty-aware rejection fine-tuning that directly optimizes specialized generators to create challenging coding problems. Our trained generators demonstrate superior capability compared to even GPT-4o at creating challenging problems that benefit downstream performance. We leverage QueST to generate large-scale synthetic coding problems, which we then use to distill from strong teacher models with long chain-of-thought or to conduct reinforcement learning for smaller models, proving effective in both scenarios. Our distillation experiments demonstrate significant performance gains. Specifically, after fine-tuning Qwen3-8B-base on 100K difficult problems generated by QueST, we surpass the performance of the original Qwen3-8B on LiveCodeBench. With an additional 112K examples (i.e., 28K human-written problems paired with multiple synthetic solutions), our 8B model matches the performance of the much larger DeepSeek-R1-671B. These findings indicate that generating complex problems via QueST offers an effective and scalable approach to advancing the frontiers of competitive coding and reasoning for large language models."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Automatic Classification of Circulating Blood Cell Clusters based on Multi-channel Flow Cytometry Imaging", "authors": "Suqiang Ma, Subhadeep Sengupta, Yao Lee, Beikang Gu, Xianyan Chen, Xianqiao Wang, Yang Liu, Mengjia Xu, Galit H. Frydman, He Li", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Circulating blood cell clusters (CCCs) containing red blood cells (RBCs), white blood cells(WBCs), and platelets are significant biomarkers linked to conditions like thrombosis, infection, and inflammation. Flow cytometry, paired with fluorescence staining, is commonly used to analyze these cell clusters, revealing cell morphology and protein profiles. While computational approaches based on machine learning have advanced the automatic analysis of single-cell flow cytometry images, there is a lack of effort to build tools to automatically analyze images containing CCCs. Unlike single cells, cell clusters often exhibit irregular shapes and sizes. In addition, these cell clusters often consist of heterogeneous cell types, which require multi-channel staining to identify the specific cell types within the clusters. This study introduces a new computational framework for analyzing CCC images and identifying cell types within clusters. Our framework uses a two-step analysis strategy. First, it categorizes images into cell cluster and non-cluster groups by fine-tuning the You Only Look Once(YOLOv11) model, which outperforms traditional convolutional neural networks (CNNs), Vision Transformers (ViT). Then, it identifies cell types by overlaying cluster contours with regions from multi-channel fluorescence stains, enhancing accuracy despite cell debris and staining artifacts. This approach achieved over 95% accuracy in both cluster classification and phenotype identification. In summary, our automated framework effectively analyzes CCC images from flow cytometry, leveraging both bright-field and fluorescence data. Initially tested on blood cells, it holds potential for broader applications, such as analyzing immune and tumor cell clusters, supporting cellular research across various diseases."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Unifying the Landscape of Super-Logarithmic Dynamic Cell-Probe Lower Bounds", "authors": "Young Kun Ko", "subjects": "Computational Complexity (cs.CC); Data Structures and Algorithms (cs.DS)", "abstract": "We prove a general translation theorem for converting one-way communication lower bounds over a product distribution to dynamic cell-probe lower bounds. Specifically, we consider a class of problems considered in [Pat10] where: 1. $S_1, \\ldots, S_m \\in \\{0, 1\\}^n$ are given and publicly known. 2. $T \\in \\{0, 1\\}^n$ is a sequence of updates, each taking $t_u$ time. 3. For a given $Q \\in [m]$, we must output $f(S_Q, T)$ in $t_q$ time. Our main result shows that for a \"hard\" function $f$, for which it is difficult to obtain a non-trivial advantage over random guessing with one-way communication under some product distribution over $S_Q$ and $T$ (for example, a uniform distribution), then the above explicit dynamic cell-probe problem must have $\\max \\{ t_u, t_q \\} \\geq \\tilde{\\Omega}(\\log^{3/2}(n))$ if $m = \\Omega(n^{0.99})$. This result extends and unifies the super-logarithmic dynamic data structure lower bounds from [LWY20] and [LY25] into a more general framework. From a technical perspective, our approach merges the cell-sampling and chronogram techniques developed in [LWY20] and [LY25] with the new static data structure lower bound methods from [KW20] and [Ko25], thereby merging all known state-of-the-art cell-probe lower-bound techniques into one. As a direct consequence of our method, we establish a super-logarithmic lower bound against the Multiphase Problem [Pat10] for the case where the data structure outputs the Inner Product (mod 2) of $S_Q$ and $T$. We suspect further applications of this general method towards showing super-logarithmic dynamic cell-probe lower bounds. We list some example applications of our general method, including a novel technique for a one-way communication lower bound against small-advantage protocols for a product distribution using average min-entropy, which could be of independent interest."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Raindrop GS: A Benchmark for 3D Gaussian Splatting under Raindrop Conditions", "authors": "Zhiqiang Teng, Beibei Lin, Tingting Chen, Zifeng Yuan, Xuanyi Li, Xuanyu Zhang, Shunli Zhang", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "3D Gaussian Splatting (3DGS) under raindrop conditions suffers from severe occlusions and optical distortions caused by raindrop contamination on the camera lens, substantially degrading reconstruction quality. Existing benchmarks typically evaluate 3DGS using synthetic raindrop images with known camera poses (constrained images), assuming ideal conditions. However, in real-world scenarios, raindrops often interfere with accurate camera pose estimation and point cloud initialization. Moreover, a significant domain gap between synthetic and real raindrops further impairs generalization. To tackle these issues, we introduce RaindropGS, a comprehensive benchmark designed to evaluate the full 3DGS pipeline-from unconstrained, raindrop-corrupted images to clear 3DGS reconstructions. Specifically, the whole benchmark pipeline consists of three parts: data preparation, data processing, and raindrop-aware 3DGS evaluation, including types of raindrop interference, camera pose estimation and point cloud initialization, single image rain removal comparison, and 3D Gaussian training comparison. First, we collect a real-world raindrop reconstruction dataset, in which each scene contains three aligned image sets: raindrop-focused, background-focused, and rain-free ground truth, enabling a comprehensive evaluation of reconstruction quality under different focus conditions. Through comprehensive experiments and analyses, we reveal critical insights into the performance limitations of existing 3DGS methods on unconstrained raindrop images and the varying impact of different pipeline components: the impact of camera focus position on 3DGS reconstruction performance, and the interference caused by inaccurate pose and point cloud initialization on reconstruction. These insights establish clear directions for developing more robust 3DGS methods under raindrop conditions."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          PANER: A Paraphrase-Augmented Framework for Low-Resource Named Entity Recognition", "authors": "Nanda Kumar Rengarajan, Jun Yan, Chun Wang", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "abstract": "Named Entity Recognition (NER) is a critical task that requires substantial annotated data, making it challenging in low-resource scenarios where label acquisition is expensive. While zero-shot and instruction-tuned approaches have made progress, they often fail to generalize to domain-specific entities and do not effectively utilize limited available data. We present a lightweight few-shot NER framework that addresses these challenges through two key innovations: (1) a new instruction tuning template with a simplified output format that combines principles from prior IT approaches to leverage the large context window of recent state-of-the-art LLMs; (2) introducing a strategic data augmentation technique that preserves entity information while paraphrasing the surrounding context, thereby expanding our training data without compromising semantic relationships. Experiments on benchmark datasets show that our method achieves performance comparable to state-of-the-art models on few-shot and zero-shot tasks, with our few-shot approach attaining an average F1 score of 80.1 on the CrossNER datasets. Models trained with our paraphrasing approach show consistent improvements in F1 scores of up to 17 points over baseline versions, offering a promising solution for groups with limited NER training data and compute power."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          MT-Video-Bench: A Holistic Video Understanding Benchmark for Evaluating Multimodal LLMs in Multi-Turn Dialogues", "authors": "Yaning Pan, Zekun Wang, Qianqian Xie, Yongqian Wen, Yuanxing Zhang, Guohui Zhang, Haoxuan Hu, Zhiyu Pan, Yibing Huang, Zhidong Gan, Yonghong Lin, An Ping, Tianhao Peng, Jiaheng Liu", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "abstract": "The recent development of Multimodal Large Language Models (MLLMs) has significantly advanced AI's ability to understand visual modalities. However, existing evaluation benchmarks remain limited to single-turn question answering, overlooking the complexity of multi-turn dialogues in real-world scenarios. To bridge this gap, we introduce MT-Video-Bench, a holistic video understanding benchmark for evaluating MLLMs in multi-turn dialogues. Specifically, our MT-Video-Bench mainly assesses six core competencies that focus on perceptivity and interactivity, encompassing 987 meticulously curated multi-turn dialogues from diverse domains. These capabilities are rigorously aligned with real-world applications, such as interactive sports analysis and multi-turn video-based intelligent tutoring. With MT-Video-Bench, we extensively evaluate various state-of-the-art open-source and closed-source MLLMs, revealing their significant performance discrepancies and limitations in handling multi-turn video dialogues. The benchmark will be publicly available to foster future research."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Signature Forgery Detection: Improving Cross-Dataset Generalization", "authors": "Matheus Ramos Parracho", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "abstract": "Automated signature verification is a critical biometric technique used in banking, identity authentication, and legal documentation. Despite the notable progress achieved by deep learning methods, most approaches in offline signature verification still struggle to generalize across datasets, as variations in handwriting styles and acquisition protocols often degrade performance. This study investigates feature learning strategies for signature forgery detection, focusing on improving cross-dataset generalization -- that is, model robustness when trained on one dataset and tested on another. Using three public benchmarks -- CEDAR, ICDAR, and GPDS Synthetic -- two experimental pipelines were developed: one based on raw signature images and another employing a preprocessing method referred to as shell preprocessing. Several behavioral patterns were identified and analyzed; however, no definitive superiority between the two approaches was established. The results show that the raw-image model achieved higher performance across benchmarks, while the shell-based model demonstrated promising potential for future refinement toward robust, cross-domain signature verification."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          AcademicEval: Live Long-Context LLM Benchmark", "authors": "Haozhen Zhang, Tao Feng, Pengrui Han, Jiaxuan You", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "abstract": "Large Language Models (LLMs) have recently achieved remarkable performance in long-context understanding. However, current long-context LLM benchmarks are limited by rigid context length, labor-intensive annotation, and the pressing challenge of label leakage issues during LLM training. Therefore, we propose \\textsc{AcademicEval}, a live benchmark for evaluating LLMs over long-context generation tasks. \\textsc{AcademicEval} adopts papers on arXiv to introduce several academic writing tasks with long-context inputs, \\textit{i.e.}, \\textsc{Title}, \\textsc{Abstract}, \\textsc{Introduction}, and \\textsc{Related Work}, which cover a wide range of abstraction levels and require no manual labeling. Moreover, \\textsc{AcademicEval} integrates high-quality and expert-curated few-shot demonstrations from a collected co-author graph to enable flexible context length. Especially, \\textsc{AcademicEval} features an efficient live evaluation, ensuring no label leakage. We conduct a holistic evaluation on \\textsc{AcademicEval}, and the results illustrate that LLMs perform poorly on tasks with hierarchical abstraction levels and tend to struggle with long few-shot demonstrations, highlighting the challenge of our benchmark. Through experimental analysis, we also reveal some insights for enhancing LLMs' long-context modeling capabilities. Code is available at this https URL"}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Rethinking Search: A Study of University Students' Perspectives on Using LLMs and Traditional Search Engines in Academic Problem Solving", "authors": "Md. Faiyaz Abdullah Sayeedi, Md. Sadman Haque, Zobaer Ibn Razzaque, Robiul Awoul Robin, Sabila Nawshin", "subjects": "Human-Computer Interaction (cs.HC)", "abstract": "With the increasing integration of Artificial Intelligence (AI) in academic problem solving, university students frequently alternate between traditional search engines like Google and large language models (LLMs) for information retrieval. This study explores students' perceptions of both tools, emphasizing usability, efficiency, and their integration into academic workflows. Employing a mixed-methods approach, we surveyed 109 students from diverse disciplines and conducted in-depth interviews with 12 participants. Quantitative analyses, including ANOVA and chi-square tests, were used to assess differences in efficiency, satisfaction, and tool preference. Qualitative insights revealed that students commonly switch between GPT and Google: using Google for credible, multi-source information and GPT for summarization, explanation, and drafting. While neither tool proved sufficient on its own, there was a strong demand for a hybrid solution. In response, we developed a prototype, a chatbot embedded within the search interface, that combines GPT's conversational capabilities with Google's reliability to enhance academic research and reduce cognitive load."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Enabling Fine-Grained Operating Points for Black-Box LLMs", "authors": "Ege Beyazit, KL Navaneet, Prashant Mathur, Roi Blanco, Vidit Bansal, Karim Bouyarmane", "subjects": "Machine Learning (cs.LG)", "abstract": "Black-box Large Language Models (LLMs) provide practical and accessible alternatives to other machine learning methods, as they require minimal labeled data and machine learning expertise to develop solutions for various decision making problems. However, for applications that need operating with constraints on specific metrics (e.g., precision $\\geq$ 95%), decision making with black-box LLMs remains unfavorable, due to their low numerical output cardinalities. This results in limited control over their operating points, preventing fine-grained adjustment of their decision making behavior. In this paper, we study using black-box LLMs as classifiers, focusing on efficiently improving their operational granularity without performance loss. Specifically, we first investigate the reasons behind their low-cardinality numerical outputs and show that they are biased towards generating rounded but informative verbalized probabilities. Then, we experiment with standard prompt engineering, uncertainty estimation and confidence elicitation techniques, and observe that they do not effectively improve operational granularity without sacrificing performance or increasing inference cost. Finally, we propose efficient approaches to significantly increase the number and diversity of available operating points. Our proposed approaches provide finer-grained operating points and achieve comparable to or better performance than the benchmark methods across 11 datasets and 3 LLMs."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Can Image-To-Video Models Simulate Pedestrian Dynamics?", "authors": "Aaron Appelle, Jerome P. Lynch", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Recent high-performing image-to-video (I2V) models based on variants of the diffusion transformer (DiT) have displayed remarkable inherent world-modeling capabilities by virtue of training on large scale video datasets. We investigate whether these models can generate realistic pedestrian movement patterns in crowded public scenes. Our framework conditions I2V models on keyframes extracted from pedestrian trajectory benchmarks, then evaluates their trajectory prediction performance using quantitative measures of pedestrian dynamics."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Train for Truth, Keep the Skills: Binary Retrieval-Augmented Reward Mitigates Hallucinations", "authors": "Tong Chen, Akari Asai, Luke Zettlemoyer, Hannaneh Hajishirzi, Faeze Brahman", "subjects": "Computation and Language (cs.CL); Machine Learning (cs.LG)", "abstract": "Language models often generate factually incorrect information unsupported by their training data, a phenomenon known as extrinsic hallucination. Existing mitigation approaches often degrade performance on open-ended generation and downstream tasks, limiting their practical utility. We propose an online reinforcement learning method using a novel binary retrieval-augmented reward (RAR) to address this tradeoff. Unlike continuous reward schemes, our approach assigns a reward of one only when the model's output is entirely factually correct, and zero otherwise. We evaluate our method on Qwen3 reasoning models across diverse tasks. For open-ended generation, binary RAR achieves a 39.3% reduction in hallucination rates, substantially outperforming both supervised training and continuous-reward RL baselines. In short-form question answering, the model learns calibrated abstention, strategically outputting \"I don't know\" when faced with insufficient parametric knowledge. This yields 44.4% and 21.7% fewer incorrect answers on PopQA and GPQA, respectively. Crucially, these factuality gains come without performance degradation on instruction following, math, or code, whereas continuous-reward RL, despite improving factuality, induces quality regressions."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Efficient Tensor Completion Algorithms for Highly Oscillatory Operators", "authors": "Navjot Singh, Edgar Solomonik, Xiaoye Sherry Li, Yang Liu", "subjects": "Numerical Analysis (math.NA); Machine Learning (cs.LG)", "abstract": "This paper presents low-complexity tensor completion algorithms and their efficient implementation to reconstruct highly oscillatory operators discretized as $n\\times n$ matrices. The underlying tensor decomposition is based on the reshaping of the input matrix and its butterfly decomposition into an order $\\mathcal{O} (\\log n)$ tensor. The reshaping of the input matrix into a tensor allows for representation of the butterfly decomposition as a tensor decomposition with dense tensors. This leads to efficient utilization of the existing software infrastructure for dense and sparse tensor computations. We propose two tensor completion algorithms in the butterfly format, using alternating least squares and gradient-based optimization, as well as a novel strategy that uses low-rank matrix completion to efficiently generate an initial guess for the proposed algorithms. To demonstrate the efficiency and applicability of our proposed algorithms, we perform three numerical experiments using simulated oscillatory operators in seismic applications. In these experiments, we use $\\mathcal {O} (n \\log n)$ observed entries in the input matrix and demonstrate an $\\mathcal{O}(n\\log^3 n)$ computational cost of the proposed algorithms, leading to a speedup of orders of magnitudes per iteration for large matrices compared to the low-rank matrix and quantized tensor-train completion. Moreover, the proposed butterfly completion algorithms, equipped with the novel initial guess generation strategy, achieve reconstruction errors that are smaller by an order of magnitude, enabling accurate recovery of the underlying structure compared to the state-of-the-art completion algorithms."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Flow-Aware Ellipsoidal Filtration for Persistent Homology of Recurrent Signals", "authors": "Omer Bahadir Eryilmaz, Cihan Katar, Max A. Little", "subjects": "Computational Geometry (cs.CG)", "abstract": "One common use of persistent homology is to explore the shape of point clouds, where points are assumed to be sampled from a geometric object. We propose a novel filtration, called ellipsoidal filtration, which assumes that point clouds are sampled from a dynamic smooth flow. Instead of creating topologies from point clouds at increasing scales using isotropic balls (for example, Vietoris-Rips filtration), ellipsoidal filtration creates ellipsoids around points based on local flow variances, approximating the flow's manifold as the scale increases. We show that constructing ellipsoidal neighbourhoods improves the denoising of recurrent signals and the estimation of recurrence times, especially when the data contain bottlenecks. Choosing ellipsoids according to the maximum persistence of the H1 class provides a data-driven threshold for both denoising and recurrence-time estimation."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Who Needs Crossings?: Noncrossing Linkages are Universal, and Deciding (Global) Rigidity is Hard", "authors": "Zachary Abel, Erik D. Demaine, Martin L. Demaine, Sarah Eisenstat, Jayson Lynch, Tao B. Schardl", "subjects": "Computational Geometry (cs.CG); Metric Geometry (math.MG)", "abstract": "We exactly settle the complexity of graph realization, graph rigidity, and graph global rigidity as applied to three types of graphs: \"globally noncrossing\" graphs, which avoid crossings in all of their configurations; matchstick graphs, with unit-length edges and where only noncrossing configurations are considered; and unrestricted graphs (crossings allowed) with unit edge lengths (or in the global rigidity case, edge lengths in $\\{1,2\\}$). We show that all nine of these questions are complete for the class $\\exists\\mathbb{R}$, defined by the Existential Theory of the Reals, or its complement $\\forall\\mathbb{R}$; in particular, each problem is (co)NP-hard. One of these nine results--that realization of unit-distance graphs is $\\exists\\mathbb{R}$-complete--was shown previously by Schaefer (2013), but the other eight are new. We strengthen several prior results. Matchstick graph realization was known to be NP-hard (Eades \\& Wormald 1990, or Cabello et al.\\ 2007), but its membership in NP remained open; we show it is complete for the (possibly) larger class $\\exists\\mathbb{R}$. Global rigidity of graphs with edge lengths in $\\{1,2\\}$ was known to be coNP-hard (Saxe 1979); we show it is $\\forall\\mathbb{R}$-complete. The majority of the paper is devoted to proving an analog of Kempe's Universality Theorem--informally, \"there is a linkage to sign your name\"--for globally noncrossing linkages. In particular, we show that any polynomial curve $\\phi(x,y)=0$ can be traced by a noncrossing linkage, settling an open problem from 2004. More generally, we show that the regions in the plane that may be traced by a noncrossing linkage are precisely the compact semialgebraic regions (plus the trivial case of the entire plane). Thus, no drawing power is lost by restricting to noncrossing linkages. We prove analogous results for matchstick linkages and unit-distance linkages as well."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Joint Multi-Condition Representation Modelling via Matrix Factorisation for Visual Place Recognition", "authors": "Timur Ismagilov, Shakaiba Majeed, Michael Milford, Tan Viet Tuyen Nguyen, Sarvapali D. Ramchurn, Shoaib Ehsan", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "We address multi-reference visual place recognition (VPR), where reference sets captured under varying conditions are used to improve localisation performance. While deep learning with large-scale training improves robustness, increasing data diversity and model complexity incur extensive computational cost during training and deployment. Descriptor-level fusion via voting or aggregation avoids training, but often targets multi-sensor setups or relies on heuristics with limited gains under appearance and viewpoint change. We propose a training-free, descriptor-agnostic approach that jointly models places using multiple reference descriptors via matrix decomposition into basis representations, enabling projection-based residual matching. We also introduce SotonMV, a structured benchmark for multi-viewpoint VPR. On multi-appearance data, our method improves Recall@1 by up to ~18% over single-reference and outperforms multi-reference baselines across appearance and viewpoint changes, with gains of ~5% on unstructured data, demonstrating strong generalisation while remaining lightweight."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Generalized Flow in Nearly-linear Time on Moderately Dense Graphs", "authors": "Shunhua Jiang, Michael Kapralov, Lawrence Li, Aaron Sidford", "subjects": "Data Structures and Algorithms (cs.DS)", "abstract": "In this paper we consider generalized flow problems where there is an $m$-edge $n$-node directed graph $G = (V,E)$ and each edge $e \\in E$ has a loss factor $\\gamma_e >0$ governing whether the flow is increased or decreased as it crosses edge $e$. We provide a randomized $\\tilde{O}( (m + n^{1.5}) \\cdot \\mathrm{polylog}(\\frac{W}{\\delta}))$ time algorithm for solving the generalized maximum flow and generalized minimum cost flow problems in this setting where $\\delta$ is the target accuracy and $W$ is the maximum of all costs, capacities, and loss factors and their inverses. This improves upon the previous state-of-the-art $\\tilde{O}(m \\sqrt{n} \\cdot \\log^2(\\frac{W}{\\delta}) )$ time algorithm, obtained by combining the algorithm of [Daitch-Spielman, 2008] with techniques from [Lee-Sidford, 2014]. To obtain this result we provide new dynamic data structures and spectral results regarding the matrices associated to generalized flows and apply them through the interior point method framework of [Brand-Lee-Liu-Saranurak-Sidford-Song-Wang, 2021]."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          A Multi-Threading Kernel for Enabling Neuromorphic Edge Applications", "authors": "Lars Niedermeier (1 and 3), Vyom Shah (2), Jeffrey L. Krichmar (2 and 3) ((1) Niedermeier Consulting, Zurich, ZH, Switzerland, (2) Department of Computer Science, University of California, Irvine, CA, USA, (3) Department of Cognitive Sciences, University of California, Irvine, CA, USA)", "subjects": "Neural and Evolutionary Computing (cs.NE); Artificial Intelligence (cs.AI)", "abstract": "Spiking Neural Networks (SNNs) have sparse, event driven processing that can leverage neuromorphic applications. In this work, we introduce a multi-threading kernel that enables neuromorphic applications running at the edge, meaning they process sensory input directly and without any up-link to or dependency on a cloud service. The kernel shows speed-up gains over single thread processing by a factor of four on moderately sized SNNs and 1.7X on a Synfire network. Furthermore, it load-balances all cores available on multi-core processors, such as ARM, which run today's mobile devices and is up to 70% more energy efficient compared to statical core assignment. The present work can enable the development of edge applications that have low Size, Weight, and Power (SWaP), and can prototype the integration of neuromorphic chips."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          This is Going to Sound Crazy, But What If We Used Large Language Models to Boost Automatic Database Tuning Algorithms By Leveraging Prior History? We Will Find Better Configurations More Quickly Than Retraining From Scratch!", "authors": "William Zhang, Wan Shen Lim, Andrew Pavlo", "subjects": "Databases (cs.DB)", "abstract": "Tuning database management systems (DBMSs) is challenging due to trillions of possible configurations and evolving workloads. Recent advances in tuning have led to breakthroughs in optimizing over the possible configurations. However, due to their design and inability to leverage query-level historical insights, existing automated tuners struggle to adapt and re-optimize the DBMS when the environment changes (e.g., workload drift, schema transfer). This paper presents the Booster framework that assists existing tuners in adapting to environment changes (e.g., drift, cross-schema transfer). Booster structures historical artifacts into query-configuration contexts, prompts large language models (LLMs) to suggest configurations for each query based on relevant contexts, and then composes the query-level suggestions into a holistic configuration with beam search. With multiple OLAP workloads, we evaluate Booster's ability to assist different state-of-the-art tuners (e.g., cost-/machine learning-/LLM-based) in adapting to environment changes. By composing recommendations derived from query-level insights, Booster assists tuners in discovering configurations that are up to 74% better and in up to 4.7x less time than the alternative approach of continuing to tune from historical configurations."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Pattern Matching under Weighted Edit Distance", "authors": "Panagiotis Charalampopoulos, Tomasz Kociumaka, Philip Wellnitz", "subjects": "Data Structures and Algorithms (cs.DS)", "abstract": "In Pattern Matching with Weighted Edits (PMWED), we are given a pattern $P$ of length $m$, a text $T$ of length $n$, a positive threshold $k$, and oracle access to a weight function that specifies the costs of edits (depending on the involved characters, and normalized so that the cost of each edit is at least $1$). The goal is to compute the starting positions of all fragments of $T$ that can be obtained from $P$ with edits of total cost at most $k$. PMWED captures typical real-world applications more accurately than its unweighted variant (PMED), where all edits have unit costs. We obtain three main results: (a) a conceptually simple $\\tilde{O}(nk)$-time algorithm for PMWED, very different from that of Landau and Vishkin for PMED; (b) a significantly more complicated $\\tilde{O}(n+k^{3.5} \\cdot W^4\\cdot n/m)$-time algorithm for PMWED under the assumption that the weight function is a metric with integer values between $0$ and $W$; and (c) an $\\tilde{O}(n+k^4 \\cdot n/m)$-time algorithm for PMWED for the case of arbitrary weights. In the setting of metrics with small integer values, we nearly match the state of the art for PMED where $W=1$."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Human-AI Interactions: Cognitive, Behavioral, and Emotional Impacts", "authors": "Celeste Riley, Omar Al-Refai, Yadira Colunga Reyes, Eman Hammad", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI); Computers and Society (cs.CY)", "abstract": "As stories of human-AI interactions continue to be highlighted in the news and research platforms, the challenges are becoming more pronounced, including potential risks of overreliance, cognitive offloading, social and emotional manipulation, and the nuanced degradation of human agency and judgment. This paper surveys recent research on these issues through the lens of the psychological triad: cognition, behavior, and emotion. Observations seem to suggest that while AI can substantially enhance memory, creativity, and engagement, it also introduces risks such as diminished critical thinking, skill erosion, and increased anxiety. Emotional outcomes are similarly mixed, with AI systems showing promise for support and stress reduction, but raising concerns about dependency, inappropriate attachments, and ethical oversight. This paper aims to underscore the need for responsible and context-aware AI design, highlighting gaps for longitudinal research and grounded evaluation frameworks to balance benefits with emerging human-centric risks."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Prediction of Sea Ice Velocity and Concentration in the Arctic Ocean using Physics-informed Neural Network", "authors": "Younghyun Koo, Maryam Rahnemoonfar", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "abstract": "As an increasing amount of remote sensing data becomes available in the Arctic Ocean, data-driven machine learning (ML) techniques are becoming widely used to predict sea ice velocity (SIV) and sea ice concentration (SIC). However, fully data-driven ML models have limitations in generalizability and physical consistency due to their excessive reliance on the quantity and quality of training data. In particular, as Arctic sea ice entered a new phase with thinner ice and accelerated melting, there is a possibility that an ML model trained with historical sea ice data cannot fully represent the dynamically changing sea ice conditions in the future. In this study, we develop physics-informed neural network (PINN) strategies to integrate physical knowledge of sea ice into the ML model. Based on the Hierarchical Information-sharing U-net (HIS-Unet) architecture, we incorporate the physics loss function and the activation function to produce physically plausible SIV and SIC outputs. Our PINN model outperforms the fully data-driven model in the daily predictions of SIV and SIC, even when trained with a small number of samples. The PINN approach particularly improves SIC predictions in melting and early freezing seasons and near fast-moving ice regions."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          VERA-V: Variational Inference Framework for Jailbreaking Vision-Language Models", "authors": "Qilin Liao, Anamika Lochab, Ruqi Zhang", "subjects": "Cryptography and Security (cs.CR); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)", "abstract": "Vision-Language Models (VLMs) extend large language models with visual reasoning, but their multimodal design also introduces new, underexplored vulnerabilities. Existing multimodal red-teaming methods largely rely on brittle templates, focus on single-attack settings, and expose only a narrow subset of vulnerabilities. To address these limitations, we introduce VERA-V, a variational inference framework that recasts multimodal jailbreak discovery as learning a joint posterior distribution over paired text-image prompts. This probabilistic view enables the generation of stealthy, coupled adversarial inputs that bypass model guardrails. We train a lightweight attacker to approximate the posterior, allowing efficient sampling of diverse jailbreaks and providing distributional insights into vulnerabilities. VERA-V further integrates three complementary strategies: (i) typography-based text prompts that embed harmful cues, (ii) diffusion-based image synthesis that introduces adversarial signals, and (iii) structured distractors to fragment VLM attention. Experiments on HarmBench and HADES benchmarks show that VERA-V consistently outperforms state-of-the-art baselines on both open-source and frontier VLMs, achieving up to 53.75% higher attack success rate (ASR) over the best baseline on GPT-4o."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Trajectory Optimization for Minimum Threat Exposure using Physics-Informed Neural Networks", "authors": "Alexandra E. Ballentine, Raghvendra V. Cowlagi", "subjects": "Systems and Control (eess.SY)", "abstract": "We apply a physics-informed neural network (PINN) to solve the two-point boundary value problem (BVP) arising from the necessary conditions postulated by Pontryagin's Minimum Principle for optimal control. Such BVPs are known to be numerically difficult to solve by traditional shooting methods due to extremely high sensitivity to initial guesses. In the light of recent successes in applying PINNs for solving high-dimensional differential equations, we develop a PINN to solve the problem of finding trajectories with minimum exposure to a spatiotemporal threat for a vehicle kinematic model. First, we implement PINNs that are trained to solve the BVP for a given pair of initial and final states for a given threat field. Next, we implement a PINN conditioned on the initial state for a given threat field, which eliminates the need for retraining for each initial state. We demonstrate that the PINN outputs satisfy the necessary conditions with low numerical error."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Evaluating Medical LLMs by Levels of Autonomy: A Survey Moving from Benchmarks to Applications", "authors": "Xiao Ye, Jacob Dineen, Zhaonan Li, Zhikun Xu, Weiyu Chen, Shijie Lu, Yuxi Huang, Ming Shen, Phu Tran, Ji-Eun Irene Yum, Muhammad Ali Khan, Muhammad Umar Afzal, Irbaz Bin Riaz, Ben Zhou", "subjects": "Computation and Language (cs.CL)", "abstract": "Medical Large language models achieve strong scores on standard benchmarks; however, the transfer of those results to safe and reliable performance in clinical workflows remains a challenge. This survey reframes evaluation through a levels-of-autonomy lens (L0-L3), spanning informational tools, information transformation and aggregation, decision support, and supervised agents. We align existing benchmarks and metrics with the actions permitted at each level and their associated risks, making the evaluation targets explicit. This motivates a level-conditioned blueprint for selecting metrics, assembling evidence, and reporting claims, alongside directions that link evaluation to oversight. By centering autonomy, the survey moves the field beyond score-based claims toward credible, risk-aware evidence for real clinical use."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Data-driven Communication and Control Design for Distributed Frequency Regulation with Black-box Inverters", "authors": "Michael Nestor, Jiaxin Wang, Ning Zhang, Fei Teng", "subjects": "Systems and Control (eess.SY)", "abstract": "The increasing penetration of inverter-based resources into the power grid, with often only black-box models available, challenges long-standing frequency control methods. Most recent works take a decentralized approach without online device coordination via communication. This paper considers both dynamic behavior and communication within secondary frequency control on an intermediate timescale. We develop a distributed data-driven approach that utilizes peer-to-peer communication between inverters to avoid the need for a central control center. To enable a trade off between communication network requirements and control performance, we present a framework to guide communication topology design for secondary frequency regulation. Following design of the inter-agent information exchange scheme, we design a controller that is structured according to the communication topology with a closed-loop stability guarantee. Case studies on the IEEE 39-bus system validate the framework and illustrate the trade-off between communication requirements and control performance that is enabled by our approach."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Seeing but Not Believing: Probing the Disconnect Between Visual Attention and Answer Correctness in VLMs", "authors": "Zhining Liu, Ziyi Chen, Hui Liu, Chen Luo, Xianfeng Tang, Suhang Wang, Joy Zeng, Zhenwei Dai, Zhan Shi, Tianxin Wei, Benoit Dumoulin, Hanghang Tong", "subjects": "Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Vision-Language Models (VLMs) achieve strong results on multimodal tasks such as visual question answering, yet they can still fail even when the correct visual evidence is present. In this work, we systematically investigate whether these failures arise from not perceiving the evidence or from not leveraging it effectively. By examining layer-wise attention dynamics, we find that shallow layers focus primarily on text, while deeper layers sparsely but reliably attend to localized evidence regions. Surprisingly, VLMs often perceive the visual evidence when outputting incorrect answers, a phenomenon we term ``seeing but not believing'' that widely exists in major VLM families. Building on this, we introduce an inference-time intervention that highlights deep-layer evidence regions through selective attention-based masking. It requires no training and consistently improves accuracy across multiple families, including LLaVA, Qwen, Gemma, and InternVL. These results show that VLMs encode reliable evidence internally but under-utilize it, making such signals explicit can bridge the gap between perception and reasoning, advancing the diagnostic understanding and reliability of VLMs."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Atlas-based Manifold Representations for Interpretable Riemannian Machine Learning", "authors": "Ryan A. Robinett, Sophia A. Madejski, Kyle Ruark, Samantha J. Riesenfeld, Lorenzo Orecchia", "subjects": "Machine Learning (cs.LG); Applications (stat.AP)", "abstract": "Despite the popularity of the manifold hypothesis, current manifold-learning methods do not support machine learning directly on the latent $d$-dimensional data manifold, as they primarily aim to perform dimensionality reduction into $\\mathbb{R}^D$, losing key manifold features when the embedding dimension $D$ approaches $d$. On the other hand, methods that directly learn the latent manifold as a differentiable atlas have been relatively underexplored. In this paper, we aim to give a proof of concept of the effectiveness and potential of atlas-based methods. To this end, we implement a generic data structure to maintain a differentiable atlas that enables Riemannian optimization over the manifold. We complement this with an unsupervised heuristic that learns a differentiable atlas from point cloud data. We experimentally demonstrate that this approach has advantages in terms of efficiency and accuracy in selected settings. Moreover, in a supervised classification task over the Klein bottle and in RNA velocity analysis of hematopoietic data, we showcase the improved interpretability and robustness of our approach."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Towards Explainable Skin Cancer Classification: A Dual-Network Attention Model with Lesion Segmentation and Clinical Metadata Fusion", "authors": "Md. Enamul Atiq, Shaikh Anowarul Fattah", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "abstract": "Skin cancer is a life-threatening disease where early detection significantly improves patient outcomes. Automated diagnosis from dermoscopic images is challenging due to high intra-class variability and subtle inter-class differences. Many deep learning models operate as \"black boxes,\" limiting clinical trust. In this work, we propose a dual-encoder attention-based framework that leverages both segmented lesions and clinical metadata to enhance skin lesion classification in terms of both accuracy and interpretability. A novel Deep-UNet architecture with Dual Attention Gates (DAG) and Atrous Spatial Pyramid Pooling (ASPP) is first employed to segment lesions. The classification stage uses two DenseNet201 encoders-one on the original image and another on the segmented lesion whose features are fused via multi-head cross-attention. This dual-input design guides the model to focus on salient pathological regions. In addition, a transformer-based module incorporates patient metadata (age, sex, lesion site) into the prediction. We evaluate our approach on the HAM10000 dataset and the ISIC 2018 and 2019 challenges. The proposed method achieves state-of-the-art segmentation performance and significantly improves classification accuracy and average AUC compared to baseline models. To validate our model's reliability, we use Gradient-weighted Class Activation Mapping (Grad-CAM) to generate heatmaps. These visualizations confirm that our model's predictions are based on the lesion area, unlike models that rely on spurious background features. These results demonstrate that integrating precise lesion segmentation and clinical data with attention-based fusion leads to a more accurate and interpretable skin cancer classification model."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Mapping Post-Training Forgetting in Language Models at Scale", "authors": "Jackson Harmon, Andreas Hochlehnert, Matthias Bethge, Ameya Prabhu", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "abstract": "Scaled post-training now drives many of the largest capability gains in language models (LMs), yet its effect on pretrained knowledge remains poorly understood. Not all forgetting is equal: Forgetting one fact (e.g., a U.S. president or an API call) does not \"average out\" by recalling another. Hence, we propose a sample-wise paradigm to measure what is forgotten and when backward transfer occurs. Our metric counts 1->0 transitions (correct before post-training, incorrect after) to quantify forgetting and 0->1 transitions to quantify backward transfer. Traditional task averages conflate these effects and obscure large changes. For multiple-choice benchmarks, we add chance-adjusted variants that subtract the expected contribution of random guessing from pre- and post-training accuracies. We apply this framework across post-training stages, model sizes, and data scales. Our large-scale analysis shows that: (1) Domain-continual pretraining induces moderate forgetting with low-to-moderate backward transfer; (2) RL/SFT post-training applied to base models and Instruction tuning yields moderate-to-large backward transfer on math and logic with overall low-to-moderate forgetting; (3) Applying RL/SFT to instruction-tuned models is sensitive on data scale: at small scales, both forgetting and backward transfer are small; at larger scales, effects are mixed and warrant further study with better controls; (4) Model merging does not reliably mitigate forgetting. Overall, our framework offers a practical yardstick for mapping how post-training alters pretrained knowledge at scale -- enabling progress towards generally capable AI systems."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          SparseVILA: Decoupling Visual Sparsity for Efficient VLM Inference", "authors": "Samir Khaki, Junxian Guo, Jiaming Tang, Shang Yang, Yukang Chen, Konstantinos N. Plataniotis, Yao Lu, Song Han, Zhijian Liu", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Vision Language Models (VLMs) have rapidly advanced in integrating visual and textual reasoning, powering applications across high-resolution image understanding, long-video analysis, and multi-turn conversation. However, their scalability remains limited by the growing number of visual tokens that dominate inference latency. We present SparseVILA, a new paradigm for efficient VLM inference that decouples visual sparsity across the prefilling and decoding stages. SparseVILA distributes sparsity across stages by pruning redundant visual tokens during prefill and retrieving only query-relevant tokens during decoding. This decoupled design matches leading prefill pruning methods while preserving multi-turn fidelity by retaining most of the visual cache so that query-aware tokens can be retrieved at each conversation round. Built on an AWQ-optimized inference pipeline, SparseVILA achieves up to 4.0 times faster prefilling, 2.5 times faster decoding, and an overall 2.6 times end-to-end speedup on long-context video tasks -- while improving accuracy on document-understanding and reasoning tasks. By decoupling query-agnostic pruning and query-aware retrieval, SparseVILA establishes a new direction for efficient multimodal inference, offering a training-free, architecture-agnostic framework for accelerating large VLMs without sacrificing capability."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          On the Capacity of Erasure-prone Quantum Storage with Erasure-prone Entanglement Assistance", "authors": "Hua Sun, Syed A. Jafar", "subjects": "Information Theory (cs.IT); Quantum Physics (quant-ph)", "abstract": "A quantum message is encoded into $N$ storage nodes (quantum systems $Q_1\\dots Q_N$) with assistance from $N_B$ maximally entangled bi-partite quantum systems $A_1B_1, \\dots, A_{N_B}B_{N_B}$, that are prepared in advance such that $B_1\\dots B_{N_B}$ are stored separately as entanglement assistance (EA) nodes, while $A_1\\dots A_{N_B}$ are made available to the encoder. Both the storage nodes and EA nodes are erasure-prone. The quantum message must be recoverable given any $K$ of the $N$ storage nodes along with any $K_B$ of the $N_B$ EA nodes. The capacity for this setting is the maximum size of the quantum message, given that the size of each EA node is $\\lambda_B$. All node sizes are relative to the size of a storage node, which is normalized to unity. The exact capacity is characterized as a function of $N,K,N_B,K_B, \\lambda_B$ in all cases, with one exception. The capacity remains open for an intermediate range of $\\lambda_B$ values when a strict majority of the $N$ storage nodes, and a strict non-zero minority of the $N_B$ EA nodes, are erased. As a key stepping stone, an analogous classical storage (with shared-randomness assistance) problem is introduced. A set of constraints is identified for the classical problem, such that classical linear code constructions translate to quantum storage codes, and the converse bounds for the two settings utilize similar insights. In particular, the capacity characterizations for the classical and quantum settings are shown to be identical in all cases where the capacity is settled."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Botany-Bot: Digital Twin Monitoring of Occluded and Underleaf Plant Structures with Gaussian Splats", "authors": "Simeon Adebola, Chung Min Kim, Justin Kerr, Shuangyu Xie, Prithvi Akella, Jose Luis Susa Rincon, Eugen Solowjow, Ken Goldberg", "subjects": "Robotics (cs.RO); Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Commercial plant phenotyping systems using fixed cameras cannot perceive many plant details due to leaf occlusion. In this paper, we present Botany-Bot, a system for building detailed \"annotated digital twins\" of living plants using two stereo cameras, a digital turntable inside a lightbox, an industrial robot arm, and 3D segmentated Gaussian Splat models. We also present robot algorithms for manipulating leaves to take high-resolution indexable images of occluded details such as stem buds and the underside/topside of leaves. Results from experiments suggest that Botany-Bot can segment leaves with 90.8% accuracy, detect leaves with 86.2% accuracy, lift/push leaves with 77.9% accuracy, and take detailed overside/underside images with 77.3% accuracy. Code, videos, and datasets are available at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Local Solvers for High-Order Patch Smoothers via p-Multigrid", "authors": "Micha\u0142 Wichrowski", "subjects": "Numerical Analysis (math.NA)", "abstract": "I propose a vertex patch smoother where local problems are solved inexactly by a nested, matrix-free p-multigrid, creating a multigrid-within-multigrid framework. A single iteration of the local solver can be evaluated with $\\mathcal{O}(p^{d+1})$ operations, and the approach is applicable to non-separable problems on unstructured meshes. Numerical experiments demonstrate limited sensitivity to geometric distortion and high-contrast coefficients. When used in a global geometric multigrid solver, the method achieves robustness with respect to both polynomial degree $p$ and mesh refinement, even on heavily distorted meshes."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Inference-Time Compute Scaling For Flow Matching", "authors": "Adam Stecklov, Noah El Rimawi-Fine, Mathieu Blanchette", "subjects": "Machine Learning (cs.LG)", "abstract": "Allocating extra computation at inference time has recently improved sample quality in large language models and diffusion-based image generation. In parallel, Flow Matching (FM) has gained traction in language, vision, and scientific domains, but inference-time scaling methods for it remain under-explored. Concurrently, Kim et al., 2025 approach this problem but replace the linear interpolant with a non-linear variance-preserving (VP) interpolant at inference, sacrificing FM's efficient and straight sampling. Additionally, inference-time compute scaling for flow matching has only been applied to visual tasks, like image generation. We introduce novel inference-time scaling procedures for FM that preserve the linear interpolant during sampling. Evaluations of our method on image generation, and for the first time (to the best of our knowledge), unconditional protein generation, show that I) sample quality consistently improves as inference compute increases, and II) flow matching inference-time scaling can be applied to scientific domains."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          UltraCUA: A Foundation Model for Computer Use Agents with Hybrid Action", "authors": "Yuhao Yang, Zhen Yang, Zi-Yi Dou, Anh Nguyen, Keen You, Omar Attia, Andrew Szot, Michael Feng, Ram Ramrakhya, Alexander Toshev, Chao Huang, Yinfei Yang, Zhe Gan", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Computation and Language (cs.CL)", "abstract": "Multimodal agents for computer use rely exclusively on primitive actions (click, type, scroll) that require accurate visual grounding and lengthy execution chains, leading to cascading failures and performance bottlenecks. While other agents leverage rich programmatic interfaces (APIs, MCP servers, tools), computer-use agents (CUAs) remain isolated from these capabilities. We present UltraCUA, a foundation model that bridges this gap through hybrid action -- seamlessly integrating GUI primitives with high-level programmatic tool calls. To achieve this, our approach comprises four key components: (1) an automated pipeline that scales programmatic tools from software documentation, open-source repositories, and code generation; (2) a synthetic data engine producing over 17,000 verifiable tasks spanning real-world computer-use scenarios; (3) a large-scale high-quality hybrid action trajectory collection with both low-level GUI actions and high-level programmatic tool calls; and (4) a two-stage training pipeline combining supervised fine-tuning with online reinforcement learning, enabling strategic alternation between low-level and high-level actions. Experiments with our 7B and 32B models demonstrate substantial improvements over state-of-the-art agents. On OSWorld, UltraCUA models achieve an average 22% relative improvement over base models, while being 11% faster in terms of steps. Out-of-domain evaluation on WindowsAgentArena shows our model reaches 21.7% success rate, outperforming baselines trained on Windows data. The hybrid action mechanism proves critical, reducing error propagation while maintaining execution efficiency."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          SoftMimic: Learning Compliant Whole-body Control from Examples", "authors": "Gabriel B. Margolis, Michelle Wang, Nolan Fey, Pulkit Agrawal", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "abstract": "We introduce SoftMimic, a framework for learning compliant whole-body control policies for humanoid robots from example motions. Imitating human motions with reinforcement learning allows humanoids to quickly learn new skills, but existing methods incentivize stiff control that aggressively corrects deviations from a reference motion, leading to brittle and unsafe behavior when the robot encounters unexpected contacts. In contrast, SoftMimic enables robots to respond compliantly to external forces while maintaining balance and posture. Our approach leverages an inverse kinematics solver to generate an augmented dataset of feasible compliant motions, which we use to train a reinforcement learning policy. By rewarding the policy for matching compliant responses rather than rigidly tracking the reference motion, SoftMimic learns to absorb disturbances and generalize to varied tasks from a single motion clip. We validate our method through simulations and real-world experiments, demonstrating safe and effective interaction with the environment."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Foundational Automatic Evaluators: Scaling Multi-Task Generative Evaluator Training for Reasoning-Centric Domains", "authors": "Austin Xu, Xuan-Phi Nguyen, Yilun Zhou, Chien-Sheng Wu, Caiming Xiong, Shafiq Joty", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "abstract": "Finetuning specialized generative evaluators has emerged as a popular paradigm to meet the increasing demand for scalable evaluation during both training and test-time. However, recent work has largely focused on applying new methodology, such as reinforcement learning (RL), to training evaluators, shying away from large-scale, data-driven development. In this work, we focus on data scaling, curating a set of 2.5M samples spanning five unique evaluation tasks (pairwise, step-level, reference-free and reference-based verification, and single rating) and multiple domains focused on reasoning evaluation. With our data, we train Foundational Automatic Reasoning Evaluators (FARE), a family of 8B and 20B (with 3.6B active) parameter evaluators, with a simple iterative rejection-sampling supervised finetuning (SFT) approach. FARE-8B challenges larger specialized RL-trained evaluators and FARE-20B sets the new standard for open-source evaluators, surpassing specialized 70B+ evaluators. Beyond static benchmarks, we evaluate FARE in real-world tasks: As inference-time rerankers, FARE-20B achieves near-oracle performance on MATH. As verifiers in RL training, FARE improves the downstream RL-trained model performance by up to 14.1% vs. string-matching verifiers. When initialized from FARE, a continually-finetuned FARE-Code outperforms gpt-oss-20B by 65% on evaluating test-case quality."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Functional Distribution Networks (FDN)", "authors": "Omer Haq", "subjects": "Machine Learning (cs.LG); Machine Learning (stat.ML)", "abstract": "Modern probabilistic regressors often remain overconfident under distribution shift. We present Functional Distribution Networks (FDN), an input-conditioned distribution over network weights that induces predictive mixtures whose dispersion adapts to the input. FDN is trained with a beta-ELBO and Monte Carlo sampling. We further propose an evaluation protocol that cleanly separates interpolation from extrapolation and stresses OOD sanity checks (e.g., that predictive likelihood degrades under shift while in-distribution accuracy and calibration are maintained). On standard regression tasks, we benchmark against strong Bayesian, ensemble, dropout, and hypernetwork baselines under matched parameter and update budgets, and assess accuracy, calibration, and shift-awareness with standard diagnostics. Together, the framework and protocol aim to make OOD-aware, well-calibrated neural regression practical and modular."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Executable Knowledge Graphs for Replicating AI Research", "authors": "Yujie Luo, Zhuoyun Yu, Xuehai Wang, Yuqi Zhu, Ningyu Zhang, Lanning Wei, Lun Du, Da Zheng, Huajun Chen", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multiagent Systems (cs.MA); Software Engineering (cs.SE)", "abstract": "Replicating AI research is a crucial yet challenging task for large language model (LLM) agents. Existing approaches often struggle to generate executable code, primarily due to insufficient background knowledge and the limitations of retrieval-augmented generation (RAG) methods, which fail to capture latent technical details hidden in referenced papers. Furthermore, previous approaches tend to overlook valuable implementation-level code signals and lack structured knowledge representations that support multi-granular retrieval and reuse. To overcome these challenges, we propose Executable Knowledge Graphs (xKG), a modular and pluggable knowledge base that automatically integrates technical insights, code snippets, and domain-specific knowledge extracted from scientific literature. When integrated into three agent frameworks with two different LLMs, xKG shows substantial performance gains (10.9% with o3-mini) on PaperBench, demonstrating its effectiveness as a general and extensible solution for automated AI research replication. Code will released at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Enterprise Deep Research: Steerable Multi-Agent Deep Research for Enterprise Analytics", "authors": "Akshara Prabhakar, Roshan Ram, Zixiang Chen, Silvio Savarese, Frank Wang, Caiming Xiong, Huan Wang, Weiran Yao", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "abstract": "As information grows exponentially, enterprises face increasing pressure to transform unstructured data into coherent, actionable insights. While autonomous agents show promise, they often struggle with domain-specific nuances, intent alignment, and enterprise integration. We present Enterprise Deep Research (EDR), a multi-agent system that integrates (1) a Master Planning Agent for adaptive query decomposition, (2) four specialized search agents (General, Academic, GitHub, LinkedIn), (3) an extensible MCP-based tool ecosystem supporting NL2SQL, file analysis, and enterprise workflows, (4) a Visualization Agent for data-driven insights, and (5) a reflection mechanism that detects knowledge gaps and updates research direction with optional human-in-the-loop steering guidance. These components enable automated report generation, real-time streaming, and seamless enterprise deployment, as validated on internal datasets. On open-ended benchmarks including DeepResearch Bench and DeepConsult, EDR outperforms state-of-the-art agentic systems without any human steering. We release the EDR framework and benchmark trajectories to advance research on multi-agent reasoning applications. Code at this https URL and Dataset at this https URL"}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Admittance Matrix Concentration Inequalities for Understanding Uncertain Power Networks", "authors": "Samuel Talkington, Cameron Khanpour, Rahul K. Gupta, Sergio A. Dorado-Rojas, Daniel Turizo, Hyeongon Park, Dmitrii M. Ostrovskii, Daniel K. Molzahn", "subjects": "Systems and Control (eess.SY); Applications (stat.AP)", "abstract": "This paper presents probabilistic bounds for the spectrum of the admittance matrix and classical linear power flow models under uncertain network parameters; for example, probabilistic line contingencies. Our proposed approach imports tools from probability theory, such as concentration inequalities for random matrices with independent entries. It yields error bounds for common approximations of the AC power flow equations under parameter uncertainty, including the DC and LinDistFlow approximations."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Dynamic Dyck and Tree Edit Distance: Decompositions and Reductions to String Edit Distance", "authors": "Debarati Das, Jacob Gilbert, MohammadTaghi Hajiaghayi, Tomasz Kociumaka, Barna Saha", "subjects": "Data Structures and Algorithms (cs.DS)", "abstract": "We present the first dynamic algorithms for Dyck and tree edit distances with subpolynomial update times. Dyck edit distance measures how far a parenthesis string is from a well-parenthesized expression, while tree edit distance quantifies the minimum number of node insertions, deletions, and substitutions required to transform one rooted, ordered, labeled tree into another. Despite extensive study, no prior work has addressed efficient dynamic algorithms for these problems, which naturally arise in evolving structured data such as LaTeX documents, JSON or XML files, and RNA secondary structures. Our main contribution is a set of reductions and decompositions that transform Dyck and tree edit distance instances into efficiently maintainable string edit distance instances, which can be approximated within a $n^{o(1)}$ factor in $n^{o(1)}$ update time. For Dyck edit distance, our reduction incurs only polylogarithmic overheads in approximation and update time, yielding an $n^{o(1)}$-approximation with $n^{o(1)}$ updates. For tree edit distance, we introduce a new static reduction that improves the best-known approximation ratio from $n^{3/4}$ to $\\tilde{O}(\\sqrt{n})$ and removes the restriction to constant-degree trees. Extending this reduction dynamically achieves $n^{1/2+o(1)}$ approximation with $n^{o(1)}$ update time. A key component is a dynamic maintenance algorithm for history-independent heavy-light decompositions, of independent interest. We also provide a novel static and dynamic decomposition achieving an $O(k \\log n)$-approximation when the tree edit distance is at most $k$. Combined with the trivial bound $k \\le n$, this yields a dynamic deterministic $O(\\sqrt{n \\log n})$-approximation. In the static setting, our algorithm runs in near-linear time; dynamically, it requires only polylogarithmic updates, improving on prior linear-time static $O(\\sqrt{n})$-approximation."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Glyph: Scaling Context Windows via Visual-Text Compression", "authors": "Jiale Cheng, Yusen Liu, Xinyu Zhang, Yulin Fei, Wenyi Hong, Ruiliang Lyu, Weihan Wang, Zhe Su, Xiaotao Gu, Xiao Liu, Yushi Bai, Jie Tang, Hongning Wang, Minlie Huang", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Computation and Language (cs.CL); Machine Learning (cs.LG)", "abstract": "Large language models (LLMs) increasingly rely on long-context modeling for tasks such as document understanding, code analysis, and multi-step reasoning. However, scaling context windows to the million-token level brings prohibitive computational and memory costs, limiting the practicality of long-context LLMs. In this work, we take a different perspective-visual context scaling-to tackle this challenge. Instead of extending token-based sequences, we propose Glyph, a framework that renders long texts into images and processes them with vision-language models (VLMs). This approach substantially compresses textual input while preserving semantic information, and we further design an LLM-driven genetic search to identify optimal visual rendering configurations for balancing accuracy and compression. Through extensive experiments, we demonstrate that our method achieves 3-4x token compression while maintaining accuracy comparable to leading LLMs such as Qwen3-8B on various long-context benchmarks. This compression also leads to around 4x faster prefilling and decoding, and approximately 2x faster SFT training. Furthermore, under extreme compression, a 128K-context VLM could scale to handle 1M-token-level text tasks. In addition, the rendered text data benefits real-world multimodal tasks, such as document understanding. Our code and model are released at this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Robobench: A Comprehensive Evaluation Benchmark for Multimodal Large Language Models as Embodied Brain", "authors": "Yulin Luo, Chun-Kai Fan, Menghang Dong, Jiayu Shi, Mengdi Zhao, Bo-Wen Zhang, Cheng Chi, Jiaming Liu, Gaole Dai, Rongyu Zhang, Ruichuan An, Kun Wu, Zhengping Che, Shaoxuan Xie, Guocai Yao, Zhongxia Zhao, Pengwei Wang, Guang Liu, Zhongyuan Wang, Tiejun Huang, Shanghang Zhang", "subjects": "Robotics (cs.RO)", "abstract": "Building robots that can perceive, reason, and act in dynamic, unstructured environments remains a core challenge. Recent embodied systems often adopt a dual-system paradigm, where System 2 handles high-level reasoning while System 1 executes low-level control. In this work, we refer to System 2 as the embodied brain, emphasizing its role as the cognitive core for reasoning and decision-making in manipulation tasks. Given this role, systematic evaluation of the embodied brain is essential. Yet existing benchmarks emphasize execution success, or when targeting high-level reasoning, suffer from incomplete dimensions and limited task realism, offering only a partial picture of cognitive capability. To bridge this gap, we introduce RoboBench, a benchmark that systematically evaluates multimodal large language models (MLLMs) as embodied brains. Motivated by the critical roles across the full manipulation pipeline, RoboBench defines five dimensions-instruction comprehension, perception reasoning, generalized planning, affordance prediction, and failure analysis-spanning 14 capabilities, 25 tasks, and 6092 QA pairs. To ensure realism, we curate datasets across diverse embodiments, attribute-rich objects, and multi-view scenes, drawing from large-scale real robotic data. For planning, RoboBench introduces an evaluation framework, MLLM-as-world-simulator. It evaluate embodied feasibility by simulating whether predicted plans can achieve critical object-state changes. Experiments on 14 MLLMs reveal fundamental limitations: difficulties with implicit instruction comprehension, spatiotemporal reasoning, cross-scenario planning, fine-grained affordance understanding, and execution failure diagnosis. RoboBench provides a comprehensive scaffold to quantify high-level cognition, and guide the development of next-generation embodied MLLMs. The project page is in this https URL."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          Unbiased Gradient Low-Rank Projection", "authors": "Rui Pan, Yang Luo, Yuxing Liu, Yang You, Tong Zhang", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Optimization and Control (math.OC)", "abstract": "Memory-efficient optimization is critical for training increasingly large language models (LLMs). A popular strategy involves gradient low-rank projection, storing only the projected optimizer states, with GaLore being a representative example. However, a significant drawback of many such methods is their lack of convergence guarantees, as various low-rank projection approaches introduce inherent biases relative to the original optimization algorithms, which contribute to performance gaps compared to full-parameter training. Aiming to tackle this problem, this paper investigates the layerwise sampling technique for debiasing low-rank projection mechanisms. In particular, an instantiation of the paradigm gives rise to a novel and unbiased low-rank optimization method built upon GaLore's mechanism and the Muon algorithm, named GaLore Unbiased with Muon (GUM). We theoretically prove our method matches the convergence guarantees of the base Muon algorithm while preserving the memory efficiency of low-rank techniques. Empirical experiments on LLM fine-tuning and pretraining also demonstrate non-trivial improvements over GaLore and even better performance than full-parameter training. Further investigation shows that the improvement of this technique comes from a more uniform distribution of knowledge inside layers, leading to more efficient utilization of the model parameter space and better memorization."}
{"main_page": "https://arxiv.org/abs/", "pdf": "https://arxiv.org/pdf/", "title": "Title:\n          ConsistEdit: Highly Consistent and Precise Training-free Visual Editing", "authors": "Zixin Yin, Ling-Hao Chen, Lionel Ni, Xili Dai", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "abstract": "Recent advances in training-free attention control methods have enabled flexible and efficient text-guided editing capabilities for existing generation models. However, current approaches struggle to simultaneously deliver strong editing strength while preserving consistency with the source. This limitation becomes particularly critical in multi-round and video editing, where visual errors can accumulate over time. Moreover, most existing methods enforce global consistency, which limits their ability to modify individual attributes such as texture while preserving others, thereby hindering fine-grained editing. Recently, the architectural shift from U-Net to MM-DiT has brought significant improvements in generative performance and introduced a novel mechanism for integrating text and vision modalities. These advancements pave the way for overcoming challenges that previous methods failed to resolve. Through an in-depth analysis of MM-DiT, we identify three key insights into its attention mechanisms. Building on these, we propose ConsistEdit, a novel attention control method specifically tailored for MM-DiT. ConsistEdit incorporates vision-only attention control, mask-guided pre-attention fusion, and differentiated manipulation of the query, key, and value tokens to produce consistent, prompt-aligned edits. Extensive experiments demonstrate that ConsistEdit achieves state-of-the-art performance across a wide range of image and video editing tasks, including both structure-consistent and structure-inconsistent scenarios. Unlike prior methods, it is the first approach to perform editing across all inference steps and attention layers without handcraft, significantly enhancing reliability and consistency, which enables robust multi-round and multi-region editing. Furthermore, it supports progressive adjustment of structural consistency, enabling finer control."}
