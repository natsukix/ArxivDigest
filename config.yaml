# # For physics topics, use the specific subtopics, e.g. "Astrophysics"
# topic: "Computer Science"
# # An empty list here will include all categories in a topic
# # Use the natural language names of the topics, found here: https://arxiv.org
# # Including more categories will result in more calls to the large language model
# categories: ["Artificial Intelligence", "Computation and Language"]

# # Relevance score threshold. abstracts that receive a score less than this from the large language model
# # will have their papers filtered out.
# #
# # Must be within 1-10
# threshold: 7

# # A natural language statement that the large language model will use to judge which papers are relevant 
# #
# # For example:
# #     "I am interested in complexity theory papers that establish upper bounds"
# #     "gas chromatography, mass spectrometry"
# #     "making lots of money"
# #
# # This can be empty, which just return a full list of papers with no judgement or filtering,
# # in whatever order arXiv responds with.
# interest: |
#   1. Large language model pretraining and finetunings
#   2. Multimodal machine learning
#   3. Do not care about specific application, for example, information extraction, summarization, etc.
#   4. Not interested in paper focus on specific languages, e.g., Arabic, Chinese, etc.

run:
  categories: ["cs.AI", "cs.CL", "cs.LG"]   # 取得するarXivカテゴリ
  max_items_from_rss: 60                    # RSSから一旦取る件数（多めに取って後で絞る）
  pick_top_n: 5                             # 最終的に選ぶ件数（毎日5件）
  language: "ja"                            # 要約の言語
  interests: |                              # あなたの興味（フィルタのヒント）
    RAG/検索拡張、ツール利用、エージェント、効率化（蒸留・量子化・軽量化）、
    評価（benchmarks）、安全性、実運用に効く手法。

openai:
  model: "gpt-5"                            # 使いたいモデル名
  max_summary_chars: 700                    # 3分で読める目安（日本語で約400〜600字）

output:
  email:
    enabled: false                          # まずはメールを使わない場合
  markdown:
    enabled: true
    path: "out/daily.md"                    # 生成ファイル（ActionsのArtifactsで確認可）
